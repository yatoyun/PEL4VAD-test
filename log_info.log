[2023-10-01 15:50:50,264][main.py][line:215][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 15:50:53,317][main.py][line:256][INFO] total params:8.2169M
[2023-10-01 15:50:53,317][main.py][line:259][INFO] Training Mode
[2023-10-01 15:50:53,319][main.py][line:106][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 15:51:10,592][main.py][line:170][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54044
[2023-10-01 15:58:34,218][main.py][line:215][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 15:58:37,312][main.py][line:256][INFO] total params:8.2169M
[2023-10-01 15:58:37,312][main.py][line:259][INFO] Training Mode
[2023-10-01 15:58:37,314][main.py][line:106][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 15:58:54,780][main.py][line:170][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54044
[2023-10-01 16:00:25,865][main.py][line:215][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:00:28,921][main.py][line:256][INFO] total params:8.2169M
[2023-10-01 16:00:28,921][main.py][line:259][INFO] Training Mode
[2023-10-01 16:00:28,923][main.py][line:106][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:00:46,417][main.py][line:170][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54045
[2023-10-01 16:04:07,600][main.py][line:201][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:04:10,690][main.py][line:242][INFO] total params:8.2169M
[2023-10-01 16:04:10,690][main.py][line:245][INFO] Training Mode
[2023-10-01 16:04:10,692][main.py][line:106][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:04:28,773][main.py][line:156][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54045
[2023-10-01 16:06:55,598][main.py][line:200][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:06:58,674][main.py][line:241][INFO] total params:8.2169M
[2023-10-01 16:06:58,674][main.py][line:244][INFO] Training Mode
[2023-10-01 16:06:58,677][main.py][line:105][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:07:16,359][main.py][line:155][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54045
[2023-10-01 16:11:51,745][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:11:54,836][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:11:54,836][main.py][line:250][INFO] Training Mode
[2023-10-01 16:11:54,839][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:12:12,570][main.py][line:161][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54045
[2023-10-01 16:13:34,274][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:13:37,332][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:13:37,332][main.py][line:250][INFO] Training Mode
[2023-10-01 16:13:37,334][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:13:57,666][main.py][line:161][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54046
[2023-10-01 16:16:06,147][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:16:09,201][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:16:09,201][main.py][line:250][INFO] Training Mode
[2023-10-01 16:16:09,203][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:16:27,439][main.py][line:161][INFO] Random initialize AUCAUC:0.5755 Anomaly AUC:0.53950
[2023-10-01 16:19:49,413][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:19:52,430][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:19:52,430][main.py][line:250][INFO] Training Mode
[2023-10-01 16:19:52,433][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:20:10,608][main.py][line:161][INFO] Random initialize AUCAUC:0.5755 Anomaly AUC:0.53950
[2023-10-01 16:22:12,438][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:22:15,483][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:22:15,483][main.py][line:250][INFO] Training Mode
[2023-10-01 16:22:15,486][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:22:33,980][main.py][line:161][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 16:26:26,701][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:26:29,808][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:26:29,808][main.py][line:250][INFO] Training Mode
[2023-10-01 16:26:29,810][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:27:14,494][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:27:17,553][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:27:17,553][main.py][line:250][INFO] Training Mode
[2023-10-01 16:27:17,556][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:28:17,186][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:28:20,248][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:28:20,248][main.py][line:250][INFO] Training Mode
[2023-10-01 16:28:20,250][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:28:46,905][main.py][line:206][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:28:49,975][main.py][line:247][INFO] total params:8.2169M
[2023-10-01 16:28:49,975][main.py][line:250][INFO] Training Mode
[2023-10-01 16:28:49,978][main.py][line:109][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:29:08,919][main.py][line:161][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 16:43:27,729][main.py][line:209][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:43:30,868][main.py][line:250][INFO] total params:8.2169M
[2023-10-01 16:43:30,868][main.py][line:253][INFO] Training Mode
[2023-10-01 16:43:30,870][main.py][line:110][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:43:49,857][main.py][line:162][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 16:54:45,069][main.py][line:209][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 16:54:48,193][main.py][line:250][INFO] total params:8.2169M
[2023-10-01 16:54:48,193][main.py][line:253][INFO] Training Mode
[2023-10-01 16:54:48,195][main.py][line:110][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 16:55:07,015][main.py][line:162][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 17:30:42,517][main.py][line:209][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 17:30:45,638][main.py][line:250][INFO] total params:8.2169M
[2023-10-01 17:30:45,639][main.py][line:253][INFO] Training Mode
[2023-10-01 17:30:45,641][main.py][line:110][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 17:31:04,199][main.py][line:162][INFO] Random initialize AUCAUC:0.5756 Anomaly AUC:0.53951
[2023-10-01 17:31:37,912][main.py][line:209][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 16, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 17:31:40,973][main.py][line:250][INFO] total params:8.2169M
[2023-10-01 17:31:40,973][main.py][line:253][INFO] Training Mode
[2023-10-01 17:31:40,975][main.py][line:110][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 17:31:59,950][main.py][line:162][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 18:06:28,687][main.py][line:215][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 18:06:31,748][main.py][line:256][INFO] total params:8.2169M
[2023-10-01 18:06:31,748][main.py][line:259][INFO] Training Mode
[2023-10-01 18:06:31,750][main.py][line:114][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 18:06:50,546][main.py][line:166][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 18:08:30,249][main.py][line:216][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 18:08:33,416][main.py][line:257][INFO] total params:8.2169M
[2023-10-01 18:08:33,416][main.py][line:260][INFO] Training Mode
[2023-10-01 18:08:33,419][main.py][line:114][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 18:08:52,340][main.py][line:167][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 18:11:30,654][main.py][line:215][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 18:11:33,774][main.py][line:256][INFO] total params:8.2169M
[2023-10-01 18:11:33,774][main.py][line:259][INFO] Training Mode
[2023-10-01 18:11:33,777][main.py][line:114][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 18:11:52,631][main.py][line:165][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 18:19:42,095][main.py][line:215][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 18:19:45,144][main.py][line:256][INFO] total params:8.2169M
[2023-10-01 18:19:45,144][main.py][line:259][INFO] Training Mode
[2023-10-01 18:19:45,146][main.py][line:114][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 18:20:04,407][main.py][line:165][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 18:20:31,923][main.py][line:194][INFO] [IDX:2/10, Epoch:1/20]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-01 18:21:00,836][main.py][line:194][INFO] [IDX:2/10, Epoch:2/20]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-01 18:21:32,379][main.py][line:194][INFO] [IDX:2/10, Epoch:3/20]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-01 18:22:01,533][main.py][line:194][INFO] [IDX:2/10, Epoch:4/20]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-01 18:22:28,866][main.py][line:194][INFO] [IDX:2/10, Epoch:5/20]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-01 18:23:00,521][main.py][line:194][INFO] [IDX:2/10, Epoch:6/20]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-01 18:23:31,763][main.py][line:194][INFO] [IDX:2/10, Epoch:7/20]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-01 18:24:04,335][main.py][line:194][INFO] [IDX:2/10, Epoch:8/20]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-01 18:24:34,607][main.py][line:194][INFO] [IDX:2/10, Epoch:9/20]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-01 18:25:05,864][main.py][line:194][INFO] [IDX:2/10, Epoch:10/20]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-01 18:25:36,569][main.py][line:194][INFO] [IDX:2/10, Epoch:11/20]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-01 18:26:08,023][main.py][line:194][INFO] [IDX:2/10, Epoch:12/20]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-01 18:26:38,347][main.py][line:194][INFO] [IDX:2/10, Epoch:13/20]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-01 18:27:05,609][main.py][line:194][INFO] [IDX:2/10, Epoch:14/20]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-01 18:27:36,210][main.py][line:194][INFO] [IDX:2/10, Epoch:15/20]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-01 18:28:05,516][main.py][line:194][INFO] [IDX:2/10, Epoch:16/20]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-01 18:28:32,715][main.py][line:194][INFO] [IDX:2/10, Epoch:17/20]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-01 18:29:04,067][main.py][line:194][INFO] [IDX:2/10, Epoch:18/20]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-01 18:29:35,141][main.py][line:194][INFO] [IDX:2/10, Epoch:19/20]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-01 18:30:06,449][main.py][line:194][INFO] [IDX:2/10, Epoch:20/20]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-01 18:30:06,472][main.py][line:204][INFO] [IDX:2/10] Training completes in 10m 2s | best AUCAUC:0.8714 Anomaly AUC:0.7014

[2023-10-01 19:31:11,614][main.py][line:220][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:31:14,719][main.py][line:261][INFO] total params:8.2169M
[2023-10-01 19:31:14,719][main.py][line:264][INFO] Training Mode
[2023-10-01 19:31:14,722][main.py][line:119][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:36:22,320][main.py][line:220][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:36:25,771][main.py][line:261][INFO] total params:8.2169M
[2023-10-01 19:36:25,772][main.py][line:264][INFO] Training Mode
[2023-10-01 19:36:25,774][main.py][line:119][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:37:39,251][main.py][line:220][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:37:42,304][main.py][line:261][INFO] total params:8.2169M
[2023-10-01 19:37:42,304][main.py][line:264][INFO] Training Mode
[2023-10-01 19:37:42,307][main.py][line:119][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:40:09,788][main.py][line:220][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:40:12,855][main.py][line:261][INFO] total params:8.2169M
[2023-10-01 19:40:12,856][main.py][line:264][INFO] Training Mode
[2023-10-01 19:40:12,858][main.py][line:119][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:42:28,353][main.py][line:221][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:42:31,395][main.py][line:262][INFO] total params:8.2169M
[2023-10-01 19:42:31,395][main.py][line:265][INFO] Training Mode
[2023-10-01 19:42:31,397][main.py][line:120][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:42:42,424][main.py][line:221][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:42:45,515][main.py][line:262][INFO] total params:8.2169M
[2023-10-01 19:42:45,515][main.py][line:265][INFO] Training Mode
[2023-10-01 19:42:45,517][main.py][line:120][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:42:57,425][main.py][line:221][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:43:00,503][main.py][line:262][INFO] total params:8.2169M
[2023-10-01 19:43:00,503][main.py][line:265][INFO] Training Mode
[2023-10-01 19:43:00,506][main.py][line:120][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:44:46,537][main.py][line:222][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:44:49,598][main.py][line:263][INFO] total params:8.2169M
[2023-10-01 19:44:49,598][main.py][line:266][INFO] Training Mode
[2023-10-01 19:44:49,601][main.py][line:121][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:45:32,796][main.py][line:221][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:45:35,841][main.py][line:262][INFO] total params:8.2169M
[2023-10-01 19:45:35,841][main.py][line:265][INFO] Training Mode
[2023-10-01 19:45:35,843][main.py][line:120][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:45:55,778][main.py][line:171][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 19:52:12,379][main.py][line:225][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:52:15,394][main.py][line:266][INFO] total params:8.2169M
[2023-10-01 19:52:15,394][main.py][line:269][INFO] Training Mode
[2023-10-01 19:52:15,397][main.py][line:124][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:52:37,321][main.py][line:175][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 19:54:04,218][main.py][line:226][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:54:07,262][main.py][line:267][INFO] total params:8.2169M
[2023-10-01 19:54:07,262][main.py][line:270][INFO] Training Mode
[2023-10-01 19:54:07,265][main.py][line:125][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:54:27,125][main.py][line:176][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 19:54:48,739][main.py][line:226][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 19:54:51,802][main.py][line:267][INFO] total params:8.2169M
[2023-10-01 19:54:51,803][main.py][line:270][INFO] Training Mode
[2023-10-01 19:54:51,805][main.py][line:125][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 19:55:11,379][main.py][line:176][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 19:55:38,974][main.py][line:205][INFO] [IDX:2/10, Epoch:1/6]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-01 19:56:11,475][main.py][line:205][INFO] [IDX:2/10, Epoch:2/6]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-01 19:56:42,276][main.py][line:205][INFO] [IDX:2/10, Epoch:3/6]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-01 19:57:09,793][main.py][line:205][INFO] [IDX:2/10, Epoch:4/6]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-01 19:57:42,417][main.py][line:205][INFO] [IDX:2/10, Epoch:5/6]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-01 19:58:10,158][main.py][line:205][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-01 19:58:40,643][main.py][line:205][INFO] [IDX:2/10, Epoch:7/6]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-01 19:59:08,227][main.py][line:205][INFO] [IDX:2/10, Epoch:8/6]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-01 19:59:42,715][main.py][line:205][INFO] [IDX:2/10, Epoch:9/6]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-01 20:00:16,141][main.py][line:205][INFO] [IDX:2/10, Epoch:10/6]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-01 20:00:50,284][main.py][line:205][INFO] [IDX:2/10, Epoch:11/6]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-01 20:01:17,850][main.py][line:205][INFO] [IDX:2/10, Epoch:12/6]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-01 20:01:52,222][main.py][line:205][INFO] [IDX:2/10, Epoch:13/6]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-01 20:02:26,290][main.py][line:205][INFO] [IDX:2/10, Epoch:14/6]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-01 20:03:00,508][main.py][line:205][INFO] [IDX:2/10, Epoch:15/6]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-01 20:03:33,247][main.py][line:205][INFO] [IDX:2/10, Epoch:16/6]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-01 20:04:00,793][main.py][line:205][INFO] [IDX:2/10, Epoch:17/6]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-01 20:04:35,016][main.py][line:205][INFO] [IDX:2/10, Epoch:18/6]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-01 20:05:02,480][main.py][line:205][INFO] [IDX:2/10, Epoch:19/6]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-01 20:05:35,988][main.py][line:205][INFO] [IDX:2/10, Epoch:20/6]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-01 20:06:03,603][main.py][line:205][INFO] [IDX:2/10, Epoch:21/6]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-01 20:06:38,683][main.py][line:205][INFO] [IDX:2/10, Epoch:22/6]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-01 20:07:09,621][main.py][line:205][INFO] [IDX:2/10, Epoch:23/6]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-01 20:07:37,344][main.py][line:205][INFO] [IDX:2/10, Epoch:24/6]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-01 20:08:11,977][main.py][line:205][INFO] [IDX:2/10, Epoch:25/6]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-01 20:08:43,971][main.py][line:205][INFO] [IDX:2/10, Epoch:26/6]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-01 20:09:12,010][main.py][line:205][INFO] [IDX:2/10, Epoch:27/6]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-01 20:09:46,645][main.py][line:205][INFO] [IDX:2/10, Epoch:28/6]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-01 20:10:21,895][main.py][line:205][INFO] [IDX:2/10, Epoch:29/6]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-01 20:10:53,492][main.py][line:205][INFO] [IDX:2/10, Epoch:30/6]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-01 20:10:53,514][main.py][line:215][INFO] [IDX:2/10] Training completes in 15m 42s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-01 21:25:13,296][main.py][line:228][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 21:25:16,378][main.py][line:269][INFO] total params:8.2169M
[2023-10-01 21:25:16,378][main.py][line:272][INFO] Training Mode
[2023-10-01 21:25:16,380][main.py][line:127][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 21:25:36,191][main.py][line:178][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 21:26:07,983][main.py][line:207][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-01 21:26:40,518][main.py][line:207][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-01 21:27:14,939][main.py][line:207][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-01 21:27:49,065][main.py][line:207][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-01 21:28:22,757][main.py][line:207][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-01 21:28:50,413][main.py][line:207][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-01 21:29:23,746][main.py][line:207][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-01 21:29:51,338][main.py][line:207][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-01 21:30:18,834][main.py][line:207][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-01 21:30:49,087][main.py][line:207][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-01 21:31:16,827][main.py][line:207][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-01 21:31:44,711][main.py][line:207][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-01 21:32:14,528][main.py][line:207][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-01 21:32:43,784][main.py][line:207][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-01 21:33:11,545][main.py][line:207][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-01 21:33:39,346][main.py][line:207][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-01 21:34:09,742][main.py][line:207][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-01 21:34:37,325][main.py][line:207][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-01 21:35:05,042][main.py][line:207][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-01 21:35:32,656][main.py][line:207][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-01 21:36:00,137][main.py][line:207][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-01 21:36:27,737][main.py][line:207][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-01 21:36:55,408][main.py][line:207][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-01 21:37:23,355][main.py][line:207][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-01 21:37:51,218][main.py][line:207][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-01 21:38:18,747][main.py][line:207][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-01 21:38:46,409][main.py][line:207][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-01 21:39:13,914][main.py][line:207][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-01 21:39:41,661][main.py][line:207][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-01 21:40:09,436][main.py][line:207][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-01 21:40:09,472][main.py][line:217][INFO] [IDX:2/10] Training completes in 14m 33s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-01 22:24:10,756][main.py][line:229][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 22:24:13,836][main.py][line:270][INFO] total params:8.2169M
[2023-10-01 22:24:13,836][main.py][line:273][INFO] Training Mode
[2023-10-01 22:24:13,839][main.py][line:128][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 22:24:33,543][main.py][line:179][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 22:25:01,676][main.py][line:208][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-01 22:25:33,894][main.py][line:208][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-01 22:26:05,913][main.py][line:208][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-01 22:26:37,317][main.py][line:208][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-01 22:27:09,537][main.py][line:208][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-01 22:27:41,855][main.py][line:208][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-01 22:28:13,604][main.py][line:208][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-01 22:28:43,958][main.py][line:208][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-01 22:29:12,251][main.py][line:208][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-01 22:29:42,213][main.py][line:208][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-01 22:30:10,112][main.py][line:208][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-01 22:30:44,151][main.py][line:208][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-01 22:31:15,701][main.py][line:208][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-01 22:31:47,299][main.py][line:208][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-01 22:32:15,319][main.py][line:208][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-01 22:32:47,474][main.py][line:208][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-01 22:33:20,801][main.py][line:208][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-01 22:33:48,633][main.py][line:208][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-01 22:34:19,961][main.py][line:208][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-01 22:34:48,035][main.py][line:208][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-01 22:35:21,264][main.py][line:208][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-01 22:35:53,570][main.py][line:208][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-01 22:36:25,269][main.py][line:208][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-01 22:36:59,724][main.py][line:208][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-01 22:37:32,865][main.py][line:208][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-01 22:38:05,660][main.py][line:208][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-01 22:38:37,684][main.py][line:208][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-01 22:39:10,427][main.py][line:208][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-01 22:39:44,883][main.py][line:208][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-01 22:40:17,441][main.py][line:208][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-01 22:40:17,477][main.py][line:218][INFO] [IDX:2/10] Training completes in 15m 44s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-01 22:55:03,703][main.py][line:229][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-01 22:55:06,753][main.py][line:270][INFO] total params:8.2169M
[2023-10-01 22:55:06,753][main.py][line:273][INFO] Training Mode
[2023-10-01 22:55:06,755][main.py][line:128][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-01 22:55:26,628][main.py][line:179][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-01 22:55:57,321][main.py][line:208][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-01 22:56:29,061][main.py][line:208][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-01 22:56:59,421][main.py][line:208][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-01 22:57:26,842][main.py][line:208][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-01 22:57:56,897][main.py][line:208][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-01 22:58:25,291][main.py][line:208][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-01 22:59:00,446][main.py][line:208][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-01 22:59:29,664][main.py][line:208][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-01 22:59:57,018][main.py][line:208][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-01 23:00:27,412][main.py][line:208][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-01 23:00:54,819][main.py][line:208][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-01 23:01:24,869][main.py][line:208][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-01 23:01:52,659][main.py][line:208][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-01 23:02:25,194][main.py][line:208][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-01 23:02:55,284][main.py][line:208][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-01 23:03:22,705][main.py][line:208][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-01 23:03:57,876][main.py][line:208][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-01 23:04:29,707][main.py][line:208][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-01 23:05:00,389][main.py][line:208][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-01 23:05:30,124][main.py][line:208][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-01 23:05:57,453][main.py][line:208][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-01 23:06:29,449][main.py][line:208][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-01 23:06:56,880][main.py][line:208][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-01 23:07:28,219][main.py][line:208][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-01 23:07:55,700][main.py][line:208][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-01 23:08:27,931][main.py][line:208][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-01 23:08:55,410][main.py][line:208][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-01 23:09:31,424][main.py][line:208][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-01 23:10:01,149][main.py][line:208][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-01 23:10:28,564][main.py][line:208][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-01 23:10:28,601][main.py][line:218][INFO] [IDX:2/10] Training completes in 15m 2s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 00:55:55,563][main.py][line:230][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 00:55:58,689][main.py][line:271][INFO] total params:8.2169M
[2023-10-02 00:55:58,689][main.py][line:274][INFO] Training Mode
[2023-10-02 00:55:58,692][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 00:56:20,982][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 00:56:48,881][main.py][line:209][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 00:57:23,019][main.py][line:209][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 00:57:56,372][main.py][line:209][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 00:58:24,129][main.py][line:209][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 00:59:00,226][main.py][line:209][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 00:59:36,076][main.py][line:209][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 01:00:11,301][main.py][line:209][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 01:00:46,932][main.py][line:209][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 01:01:22,547][main.py][line:209][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 01:01:54,295][main.py][line:209][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 01:02:22,851][main.py][line:209][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 01:02:59,156][main.py][line:209][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 01:03:35,368][main.py][line:209][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 01:04:03,243][main.py][line:209][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 01:04:34,024][main.py][line:209][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 01:05:05,522][main.py][line:209][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 01:05:40,329][main.py][line:209][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 01:06:15,940][main.py][line:209][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 01:06:46,900][main.py][line:209][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 01:07:16,422][main.py][line:209][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 01:07:48,042][main.py][line:209][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 01:08:17,311][main.py][line:209][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 01:08:48,993][main.py][line:209][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 01:09:17,997][main.py][line:209][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 01:09:52,976][main.py][line:209][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 01:10:28,992][main.py][line:209][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 01:10:56,668][main.py][line:209][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 01:11:31,714][main.py][line:209][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 01:12:04,417][main.py][line:209][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 01:12:40,322][main.py][line:209][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 01:12:40,365][main.py][line:219][INFO] [IDX:2/10] Training completes in 16m 19s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 01:13:32,893][main.py][line:180][INFO] Random initialize AUCAUC:0.5236 Anomaly AUC:0.44544
[2023-10-02 01:14:23,419][main.py][line:209][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.7385 loss2:1.3391 loss3:0.4072 | AUC:0.8192 Anomaly AUC:0.5867
[2023-10-02 01:15:18,324][main.py][line:209][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2602 loss2:1.1859 loss3:0.4176 | AUC:0.8435 Anomaly AUC:0.6595
[2023-10-02 01:16:10,253][main.py][line:209][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1529 loss2:0.9295 loss3:0.3878 | AUC:0.8353 Anomaly AUC:0.6967
[2023-10-02 01:16:59,730][main.py][line:209][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0861 loss2:0.7861 loss3:0.3610 | AUC:0.8333 Anomaly AUC:0.6728
[2023-10-02 01:17:49,826][main.py][line:209][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0480 loss2:0.7108 loss3:0.3397 | AUC:0.8421 Anomaly AUC:0.6919
[2023-10-02 01:18:39,882][main.py][line:209][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0194 loss2:0.6487 loss3:0.3199 | AUC:0.8297 Anomaly AUC:0.6818
[2023-10-02 01:19:30,714][main.py][line:209][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0269 loss2:0.6011 loss3:0.3108 | AUC:0.8456 Anomaly AUC:0.7039
[2023-10-02 01:20:20,223][main.py][line:209][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5281 loss3:0.2970 | AUC:0.8507 Anomaly AUC:0.7058
[2023-10-02 01:21:10,118][main.py][line:209][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.4754 loss3:0.2884 | AUC:0.8462 Anomaly AUC:0.7012
[2023-10-02 01:21:57,625][main.py][line:209][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0389 loss2:0.4589 loss3:0.2928 | AUC:0.8513 Anomaly AUC:0.7053
[2023-10-02 01:22:48,772][main.py][line:209][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0310 loss2:0.4304 loss3:0.2958 | AUC:0.8357 Anomaly AUC:0.7015
[2023-10-02 01:23:37,481][main.py][line:209][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0128 loss2:0.3695 loss3:0.2907 | AUC:0.8507 Anomaly AUC:0.7013
[2023-10-02 01:24:24,875][main.py][line:209][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0080 loss2:0.3303 loss3:0.2853 | AUC:0.8458 Anomaly AUC:0.6967
[2023-10-02 01:25:15,052][main.py][line:209][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0416 loss2:0.3474 loss3:0.2915 | AUC:0.8428 Anomaly AUC:0.6934
[2023-10-02 01:26:05,222][main.py][line:209][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0271 loss2:0.3204 loss3:0.2995 | AUC:0.8499 Anomaly AUC:0.6994
[2023-10-02 01:26:56,330][main.py][line:209][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.2840 loss3:0.2987 | AUC:0.8582 Anomaly AUC:0.7163
[2023-10-02 01:27:46,141][main.py][line:209][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0162 loss2:0.2571 loss3:0.2995 | AUC:0.8438 Anomaly AUC:0.6888
[2023-10-02 01:28:36,005][main.py][line:209][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0156 loss2:0.2403 loss3:0.3010 | AUC:0.8319 Anomaly AUC:0.6454
[2023-10-02 01:29:24,190][main.py][line:209][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0261 loss2:0.2442 loss3:0.3037 | AUC:0.8441 Anomaly AUC:0.6770
[2023-10-02 01:30:13,923][main.py][line:209][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0121 loss2:0.2076 loss3:0.3025 | AUC:0.8321 Anomaly AUC:0.6755
[2023-10-02 01:31:03,352][main.py][line:209][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0059 loss2:0.1850 loss3:0.3004 | AUC:0.8412 Anomaly AUC:0.6766
[2023-10-02 01:31:52,168][main.py][line:209][INFO] [IDX:5/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0051 loss2:0.1704 loss3:0.2984 | AUC:0.8423 Anomaly AUC:0.6726
[2023-10-02 01:32:40,640][main.py][line:209][INFO] [IDX:5/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.1629 loss3:0.2984 | AUC:0.8440 Anomaly AUC:0.6845
[2023-10-02 01:33:28,761][main.py][line:209][INFO] [IDX:5/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.1571 loss3:0.2996 | AUC:0.8239 Anomaly AUC:0.6537
[2023-10-02 01:34:19,043][main.py][line:209][INFO] [IDX:5/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0519 loss2:0.2117 loss3:0.3118 | AUC:0.8404 Anomaly AUC:0.6293
[2023-10-02 01:35:09,318][main.py][line:209][INFO] [IDX:5/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0278 loss2:0.2046 loss3:0.3168 | AUC:0.8165 Anomaly AUC:0.6021
[2023-10-02 01:35:59,439][main.py][line:209][INFO] [IDX:5/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0187 loss2:0.1686 loss3:0.3141 | AUC:0.8139 Anomaly AUC:0.5886
[2023-10-02 01:36:47,589][main.py][line:209][INFO] [IDX:5/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0096 loss2:0.1421 loss3:0.3118 | AUC:0.8142 Anomaly AUC:0.5822
[2023-10-02 01:37:36,695][main.py][line:209][INFO] [IDX:5/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0053 loss2:0.1301 loss3:0.3102 | AUC:0.8105 Anomaly AUC:0.5880
[2023-10-02 01:38:27,028][main.py][line:209][INFO] [IDX:5/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0102 loss2:0.1249 loss3:0.3088 | AUC:0.8099 Anomaly AUC:0.5671
[2023-10-02 01:38:27,051][main.py][line:219][INFO] [IDX:5/10] Training completes in 24m 54s | best AUCAUC:0.8582 Anomaly AUC:0.7163

[2023-10-02 01:39:34,332][main.py][line:180][INFO] Random initialize AUCAUC:0.3818 Anomaly AUC:0.45991
[2023-10-02 01:40:48,900][main.py][line:209][INFO] [IDX:10/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.5195 loss2:1.2656 loss3:0.4119 | AUC:0.8224 Anomaly AUC:0.6677
[2023-10-02 01:42:03,792][main.py][line:209][INFO] [IDX:10/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.1440 loss2:0.8749 loss3:0.3774 | AUC:0.8211 Anomaly AUC:0.7045
[2023-10-02 01:43:25,111][main.py][line:209][INFO] [IDX:10/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.0484 loss2:0.6985 loss3:0.3350 | AUC:0.8464 Anomaly AUC:0.7089
[2023-10-02 01:44:41,817][main.py][line:209][INFO] [IDX:10/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0264 loss2:0.5998 loss3:0.3096 | AUC:0.8363 Anomaly AUC:0.6882
[2023-10-02 01:45:57,098][main.py][line:209][INFO] [IDX:10/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0244 loss2:0.5065 loss3:0.2976 | AUC:0.8400 Anomaly AUC:0.6834
[2023-10-02 01:47:11,426][main.py][line:209][INFO] [IDX:10/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0212 loss2:0.4261 loss3:0.2950 | AUC:0.8500 Anomaly AUC:0.7042
[2023-10-02 01:48:24,834][main.py][line:209][INFO] [IDX:10/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0245 loss2:0.3645 loss3:0.2978 | AUC:0.8396 Anomaly AUC:0.7047
[2023-10-02 01:49:37,423][main.py][line:209][INFO] [IDX:10/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0159 loss2:0.2991 loss3:0.2989 | AUC:0.8584 Anomaly AUC:0.6984
[2023-10-02 01:50:49,540][main.py][line:209][INFO] [IDX:10/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0166 loss2:0.2601 loss3:0.3002 | AUC:0.8519 Anomaly AUC:0.6851
[2023-10-02 01:52:00,362][main.py][line:209][INFO] [IDX:10/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0164 loss2:0.2277 loss3:0.3049 | AUC:0.8408 Anomaly AUC:0.6897
[2023-10-02 01:53:20,083][main.py][line:209][INFO] [IDX:10/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0195 loss2:0.1959 loss3:0.3034 | AUC:0.8203 Anomaly AUC:0.6540
[2023-10-02 01:54:32,224][main.py][line:209][INFO] [IDX:10/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0183 loss2:0.1939 loss3:0.3114 | AUC:0.8581 Anomaly AUC:0.6895
[2023-10-02 01:55:45,012][main.py][line:209][INFO] [IDX:10/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0244 loss2:0.1727 loss3:0.3091 | AUC:0.8233 Anomaly AUC:0.6884
[2023-10-02 01:56:57,756][main.py][line:209][INFO] [IDX:10/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0193 loss2:0.1622 loss3:0.3153 | AUC:0.8348 Anomaly AUC:0.6462
[2023-10-02 01:58:09,905][main.py][line:209][INFO] [IDX:10/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0059 loss2:0.1227 loss3:0.3103 | AUC:0.8571 Anomaly AUC:0.6996
[2023-10-02 01:59:22,413][main.py][line:209][INFO] [IDX:10/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0167 loss2:0.1383 loss3:0.3167 | AUC:0.8436 Anomaly AUC:0.6691
[2023-10-02 02:00:35,056][main.py][line:209][INFO] [IDX:10/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0147 loss2:0.1284 loss3:0.3186 | AUC:0.8272 Anomaly AUC:0.6111
[2023-10-02 02:01:46,428][main.py][line:209][INFO] [IDX:10/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0051 loss2:0.1009 loss3:0.3170 | AUC:0.8461 Anomaly AUC:0.6537
[2023-10-02 02:03:01,495][main.py][line:209][INFO] [IDX:10/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.0914 loss3:0.3155 | AUC:0.8405 Anomaly AUC:0.6577
[2023-10-02 02:04:14,151][main.py][line:209][INFO] [IDX:10/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0188 loss2:0.1124 loss3:0.3233 | AUC:0.8140 Anomaly AUC:0.6156
[2023-10-02 02:05:26,323][main.py][line:209][INFO] [IDX:10/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0048 loss2:0.0805 loss3:0.3206 | AUC:0.8190 Anomaly AUC:0.6191
[2023-10-02 02:06:39,368][main.py][line:209][INFO] [IDX:10/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0048 loss2:0.0739 loss3:0.3184 | AUC:0.8120 Anomaly AUC:0.6116
[2023-10-02 02:07:51,754][main.py][line:209][INFO] [IDX:10/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0206 loss2:0.0986 loss3:0.3261 | AUC:0.8236 Anomaly AUC:0.6245
[2023-10-02 02:09:07,226][main.py][line:209][INFO] [IDX:10/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0058 loss2:0.0656 loss3:0.3213 | AUC:0.8053 Anomaly AUC:0.5792
[2023-10-02 02:10:19,312][main.py][line:209][INFO] [IDX:10/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0050 loss2:0.0617 loss3:0.3218 | AUC:0.8228 Anomaly AUC:0.6208
[2023-10-02 02:11:32,743][main.py][line:209][INFO] [IDX:10/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0044 loss2:0.0561 loss3:0.3197 | AUC:0.8149 Anomaly AUC:0.6148
[2023-10-02 02:12:46,035][main.py][line:209][INFO] [IDX:10/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0044 loss2:0.0534 loss3:0.3192 | AUC:0.8206 Anomaly AUC:0.6244
[2023-10-02 02:13:57,313][main.py][line:209][INFO] [IDX:10/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0232 loss2:0.0803 loss3:0.3237 | AUC:0.7747 Anomaly AUC:0.5793
[2023-10-02 02:15:11,757][main.py][line:209][INFO] [IDX:10/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0151 loss2:0.0848 loss3:0.3333 | AUC:0.8221 Anomaly AUC:0.5989
[2023-10-02 02:16:24,586][main.py][line:209][INFO] [IDX:10/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0071 loss2:0.0457 loss3:0.3282 | AUC:0.8232 Anomaly AUC:0.6166
[2023-10-02 02:16:24,633][main.py][line:219][INFO] [IDX:10/10] Training completes in 36m 50s | best AUCAUC:0.8584 Anomaly AUC:0.6984

[2023-10-02 10:50:51,572][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 10:50:54,782][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 10:50:54,783][main.py][line:280][INFO] Training Mode
[2023-10-02 10:50:54,785][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 10:51:14,040][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 10:54:21,014][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 10:54:24,115][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 10:54:24,115][main.py][line:280][INFO] Training Mode
[2023-10-02 10:54:24,118][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 10:54:43,388][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 10:56:59,825][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 10:57:03,216][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 10:57:03,216][main.py][line:280][INFO] Training Mode
[2023-10-02 10:57:03,218][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 10:57:22,993][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 10:58:44,169][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 10:58:47,263][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 10:58:47,263][main.py][line:280][INFO] Training Mode
[2023-10-02 10:58:47,265][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 10:59:06,679][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 11:07:43,824][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 11:07:46,928][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 11:07:46,929][main.py][line:280][INFO] Training Mode
[2023-10-02 11:07:46,931][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 11:08:06,275][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 11:09:18,944][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 11:09:22,043][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 11:09:22,043][main.py][line:280][INFO] Training Mode
[2023-10-02 11:09:22,045][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 11:09:41,828][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 11:11:36,878][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 11:11:39,932][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 11:11:39,932][main.py][line:280][INFO] Training Mode
[2023-10-02 11:11:39,935][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 11:11:59,187][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 11:12:32,463][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 11:12:35,536][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 11:12:35,537][main.py][line:280][INFO] Training Mode
[2023-10-02 11:12:35,539][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 11:12:54,917][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 11:13:22,914][main.py][line:215][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 11:13:51,012][main.py][line:215][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 11:14:19,253][main.py][line:215][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 11:14:46,908][main.py][line:215][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 11:15:15,506][main.py][line:215][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 11:15:46,529][main.py][line:215][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 11:16:14,387][main.py][line:215][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 11:16:42,590][main.py][line:215][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 11:17:10,460][main.py][line:215][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 11:17:39,020][main.py][line:215][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 11:18:08,236][main.py][line:215][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 11:18:36,470][main.py][line:215][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 11:19:05,940][main.py][line:215][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 11:19:35,684][main.py][line:215][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 11:20:04,837][main.py][line:215][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 11:20:32,627][main.py][line:215][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 11:21:00,365][main.py][line:215][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 11:21:28,044][main.py][line:215][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 11:21:55,750][main.py][line:215][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 11:22:23,542][main.py][line:215][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 11:22:51,384][main.py][line:215][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 11:23:19,167][main.py][line:215][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 11:23:46,966][main.py][line:215][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 11:24:14,580][main.py][line:215][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 11:24:42,275][main.py][line:215][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 11:25:10,128][main.py][line:215][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 11:25:37,811][main.py][line:215][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 11:26:05,625][main.py][line:215][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 11:26:33,572][main.py][line:215][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 11:27:01,341][main.py][line:215][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 11:27:01,375][main.py][line:225][INFO] [IDX:2/10] Training completes in 14m 6s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 11:27:49,134][main.py][line:180][INFO] Random initialize AUCAUC:0.5236 Anomaly AUC:0.44544
[2023-10-02 11:28:33,784][main.py][line:215][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6602 loss2:1.3393 loss3:0.4107 | AUC:0.8165 Anomaly AUC:0.5773
[2023-10-02 11:29:20,643][main.py][line:215][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2050 loss2:1.2372 loss3:0.4389 | AUC:0.7918 Anomaly AUC:0.6095
[2023-10-02 11:30:09,756][main.py][line:215][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1205 loss2:1.1539 loss3:0.4356 | AUC:0.7727 Anomaly AUC:0.5965
[2023-10-02 11:30:57,296][main.py][line:215][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0617 loss2:0.9964 loss3:0.4323 | AUC:0.7705 Anomaly AUC:0.6079
[2023-10-02 11:31:43,699][main.py][line:215][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0486 loss2:0.8375 loss3:0.4221 | AUC:0.7723 Anomaly AUC:0.6183
[2023-10-02 11:32:30,445][main.py][line:215][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0163 loss2:0.7678 loss3:0.4151 | AUC:0.7958 Anomaly AUC:0.6189
[2023-10-02 11:33:16,941][main.py][line:215][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0108 loss2:0.7174 loss3:0.4071 | AUC:0.8112 Anomaly AUC:0.6456
[2023-10-02 11:34:03,130][main.py][line:215][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0046 loss2:0.6642 loss3:0.3984 | AUC:0.8050 Anomaly AUC:0.6269
[2023-10-02 11:34:48,624][main.py][line:215][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0035 loss2:0.6165 loss3:0.3925 | AUC:0.8004 Anomaly AUC:0.6116
[2023-10-02 11:35:36,169][main.py][line:215][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0032 loss2:0.5586 loss3:0.3901 | AUC:0.7627 Anomaly AUC:0.5850
[2023-10-02 11:36:21,574][main.py][line:215][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0030 loss2:0.5124 loss3:0.3891 | AUC:0.7117 Anomaly AUC:0.5484
[2023-10-02 11:37:09,382][main.py][line:215][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0509 loss2:0.5977 loss3:0.4177 | AUC:0.7405 Anomaly AUC:0.5951
[2023-10-02 11:37:54,908][main.py][line:215][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0209 loss2:0.5161 loss3:0.4131 | AUC:0.7902 Anomaly AUC:0.6107
[2023-10-02 11:38:41,961][main.py][line:215][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0170 loss2:0.4740 loss3:0.4022 | AUC:0.7677 Anomaly AUC:0.5885
[2023-10-02 11:39:27,515][main.py][line:215][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4215 loss3:0.3961 | AUC:0.7627 Anomaly AUC:0.5640
[2023-10-02 11:40:12,700][main.py][line:215][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0031 loss2:0.3689 loss3:0.3914 | AUC:0.7169 Anomaly AUC:0.5293
[2023-10-02 11:41:00,295][main.py][line:215][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0033 loss2:0.3354 loss3:0.3899 | AUC:0.6956 Anomaly AUC:0.5272
[2023-10-02 11:41:48,646][main.py][line:215][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0187 loss2:0.3402 loss3:0.3946 | AUC:0.7125 Anomaly AUC:0.5675
[2023-10-02 11:42:36,117][main.py][line:215][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0168 loss2:0.3519 loss3:0.4018 | AUC:0.7849 Anomaly AUC:0.5767
[2023-10-02 11:43:20,610][main.py][line:215][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0162 loss2:0.3191 loss3:0.3969 | AUC:0.7773 Anomaly AUC:0.5713
[2023-10-02 11:44:07,648][main.py][line:215][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0038 loss2:0.2679 loss3:0.3948 | AUC:0.7865 Anomaly AUC:0.5457
[2023-10-02 11:44:52,844][main.py][line:215][INFO] [IDX:5/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0038 loss2:0.2456 loss3:0.3914 | AUC:0.7759 Anomaly AUC:0.5462
[2023-10-02 11:45:38,041][main.py][line:215][INFO] [IDX:5/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0030 loss2:0.2227 loss3:0.3892 | AUC:0.7761 Anomaly AUC:0.5443
[2023-10-02 11:46:23,151][main.py][line:215][INFO] [IDX:5/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0029 loss2:0.2072 loss3:0.3879 | AUC:0.7800 Anomaly AUC:0.5446
[2023-10-02 11:47:08,131][main.py][line:215][INFO] [IDX:5/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0029 loss2:0.1927 loss3:0.3864 | AUC:0.7904 Anomaly AUC:0.5607
[2023-10-02 11:47:54,467][main.py][line:215][INFO] [IDX:5/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0228 loss2:0.2648 loss3:0.3905 | AUC:0.7360 Anomaly AUC:0.5433
[2023-10-02 11:48:41,375][main.py][line:215][INFO] [IDX:5/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.2156 loss3:0.3926 | AUC:0.7541 Anomaly AUC:0.5323
[2023-10-02 11:49:27,396][main.py][line:215][INFO] [IDX:5/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0037 loss2:0.1781 loss3:0.3896 | AUC:0.7723 Anomaly AUC:0.5387
[2023-10-02 11:50:14,329][main.py][line:215][INFO] [IDX:5/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0031 loss2:0.1643 loss3:0.3859 | AUC:0.7751 Anomaly AUC:0.5453
[2023-10-02 11:50:59,524][main.py][line:215][INFO] [IDX:5/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.1754 loss3:0.3855 | AUC:0.7621 Anomaly AUC:0.5512
[2023-10-02 11:50:59,546][main.py][line:225][INFO] [IDX:5/10] Training completes in 23m 10s | best AUCAUC:0.8112 Anomaly AUC:0.6456

[2023-10-02 11:52:02,623][main.py][line:180][INFO] Random initialize AUCAUC:0.3818 Anomaly AUC:0.45991
[2023-10-02 11:53:12,711][main.py][line:215][INFO] [IDX:10/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.4607 loss2:1.3671 loss3:0.4350 | AUC:0.8400 Anomaly AUC:0.6142
[2023-10-02 11:54:23,793][main.py][line:215][INFO] [IDX:10/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.1049 loss2:1.3663 loss3:0.4968 | AUC:0.8171 Anomaly AUC:0.6129
[2023-10-02 11:55:39,787][main.py][line:215][INFO] [IDX:10/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.0499 loss2:1.3629 loss3:0.5291 | AUC:0.7998 Anomaly AUC:0.5917
[2023-10-02 11:56:57,483][main.py][line:215][INFO] [IDX:10/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0316 loss2:1.3595 loss3:0.5467 | AUC:0.8091 Anomaly AUC:0.5643
[2023-10-02 11:58:12,775][main.py][line:215][INFO] [IDX:10/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0162 loss2:1.3567 loss3:0.5573 | AUC:0.8176 Anomaly AUC:0.5694
[2023-10-02 11:59:26,254][main.py][line:215][INFO] [IDX:10/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0187 loss2:1.3593 loss3:0.5567 | AUC:0.8204 Anomaly AUC:0.5799
[2023-10-02 12:00:39,888][main.py][line:215][INFO] [IDX:10/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0195 loss2:1.3618 loss3:0.5517 | AUC:0.7814 Anomaly AUC:0.5480
[2023-10-02 12:01:54,272][main.py][line:215][INFO] [IDX:10/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0101 loss2:1.3643 loss3:0.5558 | AUC:0.7775 Anomaly AUC:0.5401
[2023-10-02 12:03:08,851][main.py][line:215][INFO] [IDX:10/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0059 loss2:1.3651 loss3:0.5556 | AUC:0.8000 Anomaly AUC:0.5335
[2023-10-02 12:04:22,261][main.py][line:215][INFO] [IDX:10/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0117 loss2:1.3609 loss3:0.5337 | AUC:0.7975 Anomaly AUC:0.5395
[2023-10-02 12:05:36,067][main.py][line:215][INFO] [IDX:10/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0070 loss2:1.3583 loss3:0.5252 | AUC:0.8013 Anomaly AUC:0.5351
[2023-10-02 12:06:49,366][main.py][line:215][INFO] [IDX:10/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0037 loss2:1.3625 loss3:0.5389 | AUC:0.7832 Anomaly AUC:0.5326
[2023-10-02 12:08:01,775][main.py][line:215][INFO] [IDX:10/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0068 loss2:1.3612 loss3:0.5302 | AUC:0.7451 Anomaly AUC:0.4490
[2023-10-02 12:09:14,400][main.py][line:215][INFO] [IDX:10/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0105 loss2:1.3622 loss3:0.5065 | AUC:0.7157 Anomaly AUC:0.4592
[2023-10-02 12:10:27,249][main.py][line:215][INFO] [IDX:10/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0077 loss2:1.3611 loss3:0.4775 | AUC:0.7681 Anomaly AUC:0.5007
[2023-10-02 12:11:38,106][main.py][line:215][INFO] [IDX:10/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0067 loss2:1.3581 loss3:0.4826 | AUC:0.7938 Anomaly AUC:0.5089
[2023-10-02 12:12:48,937][main.py][line:215][INFO] [IDX:10/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:1.3631 loss3:0.4991 | AUC:0.5927 Anomaly AUC:0.4166
[2023-10-02 12:14:01,670][main.py][line:215][INFO] [IDX:10/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0070 loss2:1.3622 loss3:0.4481 | AUC:0.7854 Anomaly AUC:0.5329
[2023-10-02 12:15:14,487][main.py][line:215][INFO] [IDX:10/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0051 loss2:1.3567 loss3:0.4654 | AUC:0.7845 Anomaly AUC:0.4983
[2023-10-02 12:16:27,497][main.py][line:215][INFO] [IDX:10/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0050 loss2:1.3604 loss3:0.4665 | AUC:0.7651 Anomaly AUC:0.5085
[2023-10-02 12:17:40,319][main.py][line:215][INFO] [IDX:10/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0046 loss2:1.3619 loss3:0.4601 | AUC:0.7667 Anomaly AUC:0.4950
[2023-10-02 12:18:53,292][main.py][line:215][INFO] [IDX:10/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0046 loss2:1.3599 loss3:0.4884 | AUC:0.7252 Anomaly AUC:0.4652
[2023-10-02 12:20:05,997][main.py][line:215][INFO] [IDX:10/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0039 loss2:1.3609 loss3:0.4663 | AUC:0.7843 Anomaly AUC:0.5070
[2023-10-02 12:21:19,153][main.py][line:215][INFO] [IDX:10/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0063 loss2:1.3598 loss3:0.4571 | AUC:0.7782 Anomaly AUC:0.4910
[2023-10-02 12:22:29,847][main.py][line:215][INFO] [IDX:10/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0041 loss2:1.3594 loss3:0.4583 | AUC:0.7558 Anomaly AUC:0.4903
[2023-10-02 12:23:43,953][main.py][line:215][INFO] [IDX:10/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0052 loss2:1.3607 loss3:0.4476 | AUC:0.7467 Anomaly AUC:0.5131
[2023-10-02 12:24:54,800][main.py][line:215][INFO] [IDX:10/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0058 loss2:1.3602 loss3:0.4401 | AUC:0.5780 Anomaly AUC:0.4386
[2023-10-02 12:26:07,224][main.py][line:215][INFO] [IDX:10/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0055 loss2:1.3604 loss3:0.3905 | AUC:0.6084 Anomaly AUC:0.4508
[2023-10-02 12:27:19,753][main.py][line:215][INFO] [IDX:10/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0053 loss2:1.3591 loss3:0.3906 | AUC:0.6173 Anomaly AUC:0.4526
[2023-10-02 12:28:32,523][main.py][line:215][INFO] [IDX:10/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0051 loss2:1.3579 loss3:0.3906 | AUC:0.6151 Anomaly AUC:0.4472
[2023-10-02 12:28:32,568][main.py][line:225][INFO] [IDX:10/10] Training completes in 36m 30s | best AUCAUC:0.8400 Anomaly AUC:0.6142

[2023-10-02 12:56:23,408][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 12:56:26,516][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 12:56:26,516][main.py][line:280][INFO] Training Mode
[2023-10-02 12:56:26,518][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 12:56:45,978][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 12:57:14,013][main.py][line:215][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 12:57:42,082][main.py][line:215][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 12:58:10,888][main.py][line:215][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 12:58:38,868][main.py][line:215][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 12:59:06,837][main.py][line:215][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 12:59:34,545][main.py][line:215][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 13:00:03,014][main.py][line:215][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 13:00:31,970][main.py][line:215][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 13:01:03,066][main.py][line:215][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 13:01:33,934][main.py][line:215][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 13:02:04,805][main.py][line:215][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 13:02:35,744][main.py][line:215][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 13:03:04,804][main.py][line:215][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 13:03:36,844][main.py][line:215][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 13:04:06,947][main.py][line:215][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 13:04:37,642][main.py][line:215][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 13:05:06,924][main.py][line:215][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 13:05:34,643][main.py][line:215][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 13:06:05,596][main.py][line:215][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 13:06:36,439][main.py][line:215][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 13:07:10,647][main.py][line:215][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 13:07:38,431][main.py][line:215][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 13:08:09,742][main.py][line:215][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 13:08:40,741][main.py][line:215][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 13:09:12,185][main.py][line:215][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 13:09:43,524][main.py][line:215][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 13:10:12,736][main.py][line:215][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 13:10:40,646][main.py][line:215][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 13:11:11,855][main.py][line:215][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 13:11:41,470][main.py][line:215][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 13:11:41,504][main.py][line:225][INFO] [IDX:2/10] Training completes in 14m 55s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 13:12:29,967][main.py][line:180][INFO] Random initialize AUCAUC:0.5236 Anomaly AUC:0.44544
[2023-10-02 13:13:13,018][main.py][line:215][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6502 loss2:1.3258 loss3:0.4109 | AUC:0.8132 Anomaly AUC:0.5911
[2023-10-02 13:14:00,541][main.py][line:215][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2064 loss2:1.2079 loss3:0.4266 | AUC:0.7735 Anomaly AUC:0.5999
[2023-10-02 13:14:51,153][main.py][line:215][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1073 loss2:1.0254 loss3:0.4153 | AUC:0.7650 Anomaly AUC:0.6192
[2023-10-02 13:15:37,650][main.py][line:215][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0821 loss2:0.8497 loss3:0.4049 | AUC:0.7620 Anomaly AUC:0.5965
[2023-10-02 13:16:26,896][main.py][line:215][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0272 loss2:0.7588 loss3:0.3912 | AUC:0.7835 Anomaly AUC:0.6212
[2023-10-02 13:17:13,519][main.py][line:215][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0108 loss2:0.7046 loss3:0.3776 | AUC:0.7849 Anomaly AUC:0.6177
[2023-10-02 13:17:59,983][main.py][line:215][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0302 loss2:0.6694 loss3:0.3706 | AUC:0.7873 Anomaly AUC:0.6240
[2023-10-02 13:18:47,102][main.py][line:215][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0185 loss2:0.6172 loss3:0.3668 | AUC:0.7834 Anomaly AUC:0.5945
[2023-10-02 13:19:32,952][main.py][line:215][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.5577 loss3:0.3577 | AUC:0.7591 Anomaly AUC:0.5823
[2023-10-02 13:20:21,267][main.py][line:215][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0041 loss2:0.4978 loss3:0.3533 | AUC:0.7444 Anomaly AUC:0.5670
[2023-10-02 13:21:08,623][main.py][line:215][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0038 loss2:0.4470 loss3:0.3526 | AUC:0.7332 Anomaly AUC:0.5411
[2023-10-02 13:21:54,163][main.py][line:215][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0038 loss2:0.4001 loss3:0.3531 | AUC:0.7369 Anomaly AUC:0.5608
[2023-10-02 13:22:41,006][main.py][line:215][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0036 loss2:0.3569 loss3:0.3540 | AUC:0.7154 Anomaly AUC:0.5392
[2023-10-02 13:23:26,612][main.py][line:215][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0369 loss2:0.3714 loss3:0.3579 | AUC:0.8104 Anomaly AUC:0.6437
[2023-10-02 13:24:12,199][main.py][line:215][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0397 loss2:0.4114 loss3:0.3728 | AUC:0.7615 Anomaly AUC:0.5914
[2023-10-02 13:24:57,750][main.py][line:215][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0179 loss2:0.3306 loss3:0.3675 | AUC:0.7967 Anomaly AUC:0.6016
[2023-10-02 13:25:43,198][main.py][line:215][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0142 loss2:0.3025 loss3:0.3693 | AUC:0.7759 Anomaly AUC:0.5221
[2023-10-02 13:26:29,002][main.py][line:215][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0041 loss2:0.2584 loss3:0.3640 | AUC:0.7654 Anomaly AUC:0.5331
[2023-10-02 13:27:14,946][main.py][line:215][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0037 loss2:0.2418 loss3:0.3621 | AUC:0.7714 Anomaly AUC:0.5427
[2023-10-02 13:28:00,222][main.py][line:215][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0045 loss2:0.2275 loss3:0.3608 | AUC:0.7746 Anomaly AUC:0.5950
[2023-10-02 13:28:47,317][main.py][line:215][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0294 loss2:0.2745 loss3:0.3728 | AUC:0.7868 Anomaly AUC:0.5562
[2023-10-02 14:05:15,416][main.py][line:235][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 14:05:18,498][main.py][line:276][INFO] total params:8.2169M
[2023-10-02 14:05:18,498][main.py][line:279][INFO] Training Mode
[2023-10-02 14:05:18,501][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 14:07:02,028][main.py][line:234][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 14:07:05,090][main.py][line:275][INFO] total params:8.2169M
[2023-10-02 14:07:05,090][main.py][line:278][INFO] Training Mode
[2023-10-02 14:07:05,093][main.py][line:128][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 14:07:25,012][main.py][line:178][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 14:07:52,845][main.py][line:213][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 14:08:20,385][main.py][line:213][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 14:08:47,965][main.py][line:213][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 14:09:15,501][main.py][line:213][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 14:09:43,031][main.py][line:213][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 14:10:10,712][main.py][line:213][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 14:10:38,144][main.py][line:213][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 14:11:05,585][main.py][line:213][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 14:11:32,992][main.py][line:213][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 14:12:00,457][main.py][line:213][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 14:12:28,003][main.py][line:213][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 14:12:55,667][main.py][line:213][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 14:13:23,255][main.py][line:213][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 14:13:50,761][main.py][line:213][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 14:14:18,216][main.py][line:213][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 14:14:45,702][main.py][line:213][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 14:15:13,173][main.py][line:213][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 14:15:40,647][main.py][line:213][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 14:16:08,044][main.py][line:213][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 14:16:35,387][main.py][line:213][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 14:17:02,880][main.py][line:213][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 14:17:30,445][main.py][line:213][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 14:17:58,173][main.py][line:213][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 14:18:25,734][main.py][line:213][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 14:18:52,997][main.py][line:213][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 14:19:20,431][main.py][line:213][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 14:19:49,945][main.py][line:213][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 14:20:17,553][main.py][line:213][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 14:20:44,983][main.py][line:213][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 14:21:12,365][main.py][line:213][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 14:21:12,399][main.py][line:223][INFO] [IDX:2/10] Training completes in 13m 47s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 14:21:55,765][main.py][line:178][INFO] Random initialize AUCAUC:0.5236 Anomaly AUC:0.44544
[2023-10-02 14:22:41,286][main.py][line:213][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.7304 loss2:1.3408 loss3:0.4076 | AUC:0.8268 Anomaly AUC:0.5986
[2023-10-02 14:23:26,136][main.py][line:213][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2715 loss2:1.1921 loss3:0.4221 | AUC:0.8570 Anomaly AUC:0.6672
[2023-10-02 14:24:14,430][main.py][line:213][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1706 loss2:0.9710 loss3:0.3962 | AUC:0.8741 Anomaly AUC:0.7108
[2023-10-02 14:25:04,608][main.py][line:213][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0905 loss2:0.8093 loss3:0.3738 | AUC:0.8719 Anomaly AUC:0.7170
[2023-10-02 14:25:52,884][main.py][line:213][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0377 loss2:0.7240 loss3:0.3512 | AUC:0.8729 Anomaly AUC:0.7085
[2023-10-02 14:26:41,585][main.py][line:213][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0215 loss2:0.6664 loss3:0.3340 | AUC:0.8542 Anomaly AUC:0.6809
[2023-10-02 14:27:30,013][main.py][line:213][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0189 loss2:0.6102 loss3:0.3228 | AUC:0.8646 Anomaly AUC:0.7043
[2023-10-02 14:28:18,797][main.py][line:213][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0130 loss2:0.5489 loss3:0.3147 | AUC:0.8564 Anomaly AUC:0.6867
[2023-10-02 14:29:07,279][main.py][line:213][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.5061 loss3:0.3109 | AUC:0.8560 Anomaly AUC:0.6836
[2023-10-02 14:29:54,264][main.py][line:213][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0461 loss2:0.4816 loss3:0.3148 | AUC:0.8686 Anomaly AUC:0.7099
[2023-10-02 14:30:43,196][main.py][line:213][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0165 loss2:0.4300 loss3:0.3129 | AUC:0.8768 Anomaly AUC:0.7212
[2023-10-02 14:31:31,679][main.py][line:213][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0078 loss2:0.3722 loss3:0.3055 | AUC:0.8760 Anomaly AUC:0.7154
[2023-10-02 14:32:16,694][main.py][line:213][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0080 loss2:0.3365 loss3:0.3028 | AUC:0.8772 Anomaly AUC:0.7154
[2023-10-02 14:33:03,397][main.py][line:213][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0483 loss2:0.3751 loss3:0.3132 | AUC:0.8678 Anomaly AUC:0.7053
[2023-10-02 14:33:50,255][main.py][line:213][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.3349 loss3:0.3216 | AUC:0.8578 Anomaly AUC:0.6784
[2023-10-02 14:34:34,648][main.py][line:213][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.2761 loss3:0.3144 | AUC:0.8557 Anomaly AUC:0.6864
[2023-10-02 14:35:22,546][main.py][line:213][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0062 loss2:0.2432 loss3:0.3082 | AUC:0.8441 Anomaly AUC:0.6625
[2023-10-02 14:36:09,311][main.py][line:213][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0209 loss2:0.2461 loss3:0.3123 | AUC:0.8387 Anomaly AUC:0.6548
[2023-10-02 14:36:56,046][main.py][line:213][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0361 loss2:0.2816 loss3:0.3236 | AUC:0.8646 Anomaly AUC:0.6985
[2023-10-02 14:37:43,933][main.py][line:213][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0138 loss2:0.2226 loss3:0.3225 | AUC:0.8551 Anomaly AUC:0.6854
[2023-10-02 14:38:30,707][main.py][line:213][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0100 loss2:0.1949 loss3:0.3180 | AUC:0.8471 Anomaly AUC:0.6699
[2023-10-02 14:39:17,603][main.py][line:213][INFO] [IDX:5/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0214 loss2:0.2087 loss3:0.3214 | AUC:0.8448 Anomaly AUC:0.6587
[2023-10-02 14:40:04,524][main.py][line:213][INFO] [IDX:5/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0066 loss2:0.1750 loss3:0.3191 | AUC:0.8453 Anomaly AUC:0.6684
[2023-10-02 14:40:48,982][main.py][line:213][INFO] [IDX:5/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0054 loss2:0.1593 loss3:0.3159 | AUC:0.8420 Anomaly AUC:0.6537
[2023-10-02 14:41:35,304][main.py][line:213][INFO] [IDX:5/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0052 loss2:0.1479 loss3:0.3151 | AUC:0.8360 Anomaly AUC:0.6480
[2023-10-02 14:42:22,045][main.py][line:213][INFO] [IDX:5/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0050 loss2:0.1409 loss3:0.3150 | AUC:0.8165 Anomaly AUC:0.6099
[2023-10-02 14:43:08,881][main.py][line:213][INFO] [IDX:5/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0133 loss2:0.1474 loss3:0.3172 | AUC:0.8263 Anomaly AUC:0.5997
[2023-10-02 14:43:55,158][main.py][line:213][INFO] [IDX:5/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0682 loss2:0.2931 loss3:0.3494 | AUC:0.8271 Anomaly AUC:0.6229
[2023-10-02 14:44:41,912][main.py][line:213][INFO] [IDX:5/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0111 loss2:0.1606 loss3:0.3354 | AUC:0.8069 Anomaly AUC:0.6191
[2023-10-02 14:45:26,544][main.py][line:213][INFO] [IDX:5/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0081 loss2:0.1324 loss3:0.3297 | AUC:0.8380 Anomaly AUC:0.6658
[2023-10-02 14:45:26,566][main.py][line:223][INFO] [IDX:5/10] Training completes in 23m 31s | best AUCAUC:0.8768 Anomaly AUC:0.7212

[2023-10-02 14:46:29,555][main.py][line:178][INFO] Random initialize AUCAUC:0.3818 Anomaly AUC:0.45991
[2023-10-02 14:47:38,728][main.py][line:213][INFO] [IDX:10/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.5330 loss2:1.2831 loss3:0.4151 | AUC:0.8560 Anomaly AUC:0.6550
[2023-10-02 14:48:48,376][main.py][line:213][INFO] [IDX:10/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.1449 loss2:0.9319 loss3:0.4012 | AUC:0.8732 Anomaly AUC:0.7049
[2023-10-02 14:50:09,603][main.py][line:213][INFO] [IDX:10/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.0518 loss2:0.7294 loss3:0.3709 | AUC:0.8677 Anomaly AUC:0.7015
[2023-10-02 14:51:24,067][main.py][line:213][INFO] [IDX:10/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0133 loss2:0.6205 loss3:0.3431 | AUC:0.8726 Anomaly AUC:0.7069
[2023-10-02 14:52:38,891][main.py][line:213][INFO] [IDX:10/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0297 loss2:0.5387 loss3:0.3354 | AUC:0.8624 Anomaly AUC:0.6938
[2023-10-02 14:53:51,212][main.py][line:213][INFO] [IDX:10/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0189 loss2:0.4463 loss3:0.3351 | AUC:0.8616 Anomaly AUC:0.7075
[2023-10-02 14:55:03,284][main.py][line:213][INFO] [IDX:10/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0202 loss2:0.3826 loss3:0.3357 | AUC:0.8597 Anomaly AUC:0.6872
[2023-10-02 14:56:16,788][main.py][line:213][INFO] [IDX:10/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0245 loss2:0.3295 loss3:0.3355 | AUC:0.8490 Anomaly AUC:0.6577
[2023-10-02 14:57:29,856][main.py][line:213][INFO] [IDX:10/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0182 loss2:0.2757 loss3:0.3363 | AUC:0.8494 Anomaly AUC:0.6663
[2023-10-02 14:58:42,990][main.py][line:213][INFO] [IDX:10/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0159 loss2:0.2456 loss3:0.3396 | AUC:0.8498 Anomaly AUC:0.6550
[2023-10-02 14:59:53,134][main.py][line:213][INFO] [IDX:10/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.2053 loss3:0.3399 | AUC:0.8363 Anomaly AUC:0.6463
[2023-10-02 15:01:05,177][main.py][line:213][INFO] [IDX:10/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0060 loss2:0.1654 loss3:0.3363 | AUC:0.8236 Anomaly AUC:0.6288
[2023-10-02 15:02:16,929][main.py][line:213][INFO] [IDX:10/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0141 loss2:0.1587 loss3:0.3392 | AUC:0.7722 Anomaly AUC:0.6218
[2023-10-02 15:03:28,975][main.py][line:213][INFO] [IDX:10/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0243 loss2:0.2011 loss3:0.3532 | AUC:0.8163 Anomaly AUC:0.6249
[2023-10-02 15:04:39,480][main.py][line:213][INFO] [IDX:10/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.1278 loss3:0.3471 | AUC:0.7805 Anomaly AUC:0.5615
[2023-10-02 15:05:51,663][main.py][line:213][INFO] [IDX:10/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0192 loss2:0.1451 loss3:0.3527 | AUC:0.8281 Anomaly AUC:0.6286
[2023-10-02 15:07:03,970][main.py][line:213][INFO] [IDX:10/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0110 loss2:0.1199 loss3:0.3543 | AUC:0.7905 Anomaly AUC:0.5749
[2023-10-02 15:08:16,476][main.py][line:213][INFO] [IDX:10/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0081 loss2:0.1024 loss3:0.3510 | AUC:0.8369 Anomaly AUC:0.5972
[2023-10-02 15:09:28,896][main.py][line:213][INFO] [IDX:10/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0136 loss2:0.1107 loss3:0.3565 | AUC:0.8372 Anomaly AUC:0.6281
[2023-10-02 15:10:40,999][main.py][line:213][INFO] [IDX:10/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0065 loss2:0.0875 loss3:0.3550 | AUC:0.8537 Anomaly AUC:0.6427
[2023-10-02 15:11:53,206][main.py][line:213][INFO] [IDX:10/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.0852 loss3:0.3535 | AUC:0.8278 Anomaly AUC:0.6446
[2023-10-02 15:13:05,078][main.py][line:213][INFO] [IDX:10/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.0816 loss3:0.3566 | AUC:0.8394 Anomaly AUC:0.6154
[2023-10-02 15:14:16,476][main.py][line:213][INFO] [IDX:10/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0048 loss2:0.0696 loss3:0.3533 | AUC:0.8208 Anomaly AUC:0.5607
[2023-10-02 15:15:28,346][main.py][line:213][INFO] [IDX:10/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0167 loss2:0.1120 loss3:0.3652 | AUC:0.8322 Anomaly AUC:0.6031
[2023-10-02 15:16:38,493][main.py][line:213][INFO] [IDX:10/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0080 loss2:0.0694 loss3:0.3587 | AUC:0.8428 Anomaly AUC:0.6202
[2023-10-02 15:17:48,645][main.py][line:213][INFO] [IDX:10/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0100 loss2:0.0669 loss3:0.3626 | AUC:0.8078 Anomaly AUC:0.5612
[2023-10-02 15:19:00,611][main.py][line:213][INFO] [IDX:10/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0070 loss2:0.0550 loss3:0.3601 | AUC:0.8248 Anomaly AUC:0.5814
[2023-10-02 15:20:13,003][main.py][line:213][INFO] [IDX:10/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0064 loss2:0.0508 loss3:0.3589 | AUC:0.8397 Anomaly AUC:0.6066
[2023-10-02 15:23:04,073][main.py][line:234][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 15:23:07,166][main.py][line:275][INFO] total params:8.2169M
[2023-10-02 15:23:07,166][main.py][line:278][INFO] Training Mode
[2023-10-02 15:23:07,168][main.py][line:128][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 15:23:30,355][main.py][line:178][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 15:24:03,339][main.py][line:213][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 15:24:54,109][main.py][line:213][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 15:25:33,187][main.py][line:213][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 15:26:06,749][main.py][line:213][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 15:26:44,622][main.py][line:213][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 15:27:12,307][main.py][line:213][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 15:27:41,248][main.py][line:213][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 15:28:08,741][main.py][line:213][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 15:28:36,322][main.py][line:213][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 15:29:05,777][main.py][line:213][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 15:29:35,562][main.py][line:213][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 15:30:03,171][main.py][line:213][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 15:30:30,572][main.py][line:213][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 15:30:58,156][main.py][line:213][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 15:31:28,693][main.py][line:213][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 15:31:56,395][main.py][line:213][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 15:32:23,885][main.py][line:213][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 15:32:51,398][main.py][line:213][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 15:33:18,912][main.py][line:213][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 15:33:46,336][main.py][line:213][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 15:34:13,899][main.py][line:213][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 15:34:41,400][main.py][line:213][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 15:35:08,851][main.py][line:213][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 15:35:36,268][main.py][line:213][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 15:36:03,739][main.py][line:213][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 15:36:31,218][main.py][line:213][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 15:36:58,546][main.py][line:213][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 15:37:25,907][main.py][line:213][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 15:37:53,412][main.py][line:213][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 15:38:21,011][main.py][line:213][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 15:38:21,046][main.py][line:223][INFO] [IDX:2/10] Training completes in 14m 51s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 15:39:03,661][main.py][line:178][INFO] Random initialize AUCAUC:0.5236 Anomaly AUC:0.44544
[2023-10-02 15:39:46,183][main.py][line:213][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.7276 loss2:1.3422 loss3:0.4081 | AUC:0.8323 Anomaly AUC:0.6047
[2023-10-02 15:40:28,779][main.py][line:213][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2630 loss2:1.2083 loss3:0.4243 | AUC:0.8566 Anomaly AUC:0.6590
[2023-10-02 15:41:11,513][main.py][line:213][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1643 loss2:1.0081 loss3:0.4000 | AUC:0.8734 Anomaly AUC:0.7129
[2023-10-02 15:41:54,364][main.py][line:213][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0916 loss2:0.8292 loss3:0.3764 | AUC:0.8680 Anomaly AUC:0.7104
[2023-10-02 15:42:37,044][main.py][line:213][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0381 loss2:0.7434 loss3:0.3538 | AUC:0.8603 Anomaly AUC:0.6977
[2023-10-02 15:43:27,467][main.py][line:234][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 15:43:30,505][main.py][line:275][INFO] total params:8.2169M
[2023-10-02 15:43:30,505][main.py][line:278][INFO] Training Mode
[2023-10-02 15:43:30,508][main.py][line:128][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 15:43:50,317][main.py][line:178][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 15:44:18,316][main.py][line:213][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 15:44:47,189][main.py][line:213][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 15:45:16,336][main.py][line:213][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 15:45:44,202][main.py][line:213][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 15:46:13,371][main.py][line:213][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 15:46:45,005][main.py][line:213][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 15:47:16,579][main.py][line:213][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 15:47:47,427][main.py][line:213][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 15:48:15,290][main.py][line:213][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 15:48:46,891][main.py][line:213][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 15:49:17,086][main.py][line:213][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 15:49:44,840][main.py][line:213][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 15:50:16,525][main.py][line:213][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 15:50:47,902][main.py][line:213][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 15:51:18,138][main.py][line:213][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 15:51:48,233][main.py][line:213][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 15:52:18,372][main.py][line:213][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 15:52:49,515][main.py][line:213][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 15:53:21,838][main.py][line:213][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 15:53:52,170][main.py][line:213][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 15:54:22,270][main.py][line:213][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 15:54:52,279][main.py][line:213][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 15:55:22,403][main.py][line:213][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 15:55:53,543][main.py][line:213][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 15:56:23,904][main.py][line:213][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 15:56:52,856][main.py][line:213][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 15:57:23,796][main.py][line:213][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 15:57:55,244][main.py][line:213][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 15:58:27,015][main.py][line:213][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 15:58:58,596][main.py][line:213][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 15:58:58,632][main.py][line:223][INFO] [IDX:2/10] Training completes in 15m 8s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 16:00:02,831][main.py][line:178][INFO] Random initialize AUCAUC:0.4504 Anomaly AUC:0.52771
[2023-10-02 16:00:49,193][main.py][line:213][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6395 loss2:1.3213 loss3:0.4159 | AUC:0.8465 Anomaly AUC:0.6262
[2023-10-02 16:01:37,112][main.py][line:213][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2524 loss2:1.1863 loss3:0.4216 | AUC:0.8643 Anomaly AUC:0.6694
[2023-10-02 16:02:22,777][main.py][line:213][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1466 loss2:0.9786 loss3:0.4029 | AUC:0.8731 Anomaly AUC:0.7075
[2023-10-02 16:03:09,941][main.py][line:213][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0992 loss2:0.8188 loss3:0.3815 | AUC:0.8752 Anomaly AUC:0.7141
[2023-10-02 16:03:57,147][main.py][line:213][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0375 loss2:0.7256 loss3:0.3622 | AUC:0.8733 Anomaly AUC:0.7019
[2023-10-02 16:04:44,230][main.py][line:213][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0197 loss2:0.6681 loss3:0.3411 | AUC:0.8740 Anomaly AUC:0.7004
[2023-10-02 16:05:32,163][main.py][line:213][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0117 loss2:0.6135 loss3:0.3263 | AUC:0.8806 Anomaly AUC:0.7055
[2023-10-02 16:06:17,379][main.py][line:213][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0098 loss2:0.5664 loss3:0.3178 | AUC:0.8731 Anomaly AUC:0.7016
[2023-10-02 16:07:02,515][main.py][line:213][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0094 loss2:0.5066 loss3:0.3106 | AUC:0.8665 Anomaly AUC:0.6856
[2023-10-02 16:07:48,743][main.py][line:213][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0383 loss2:0.4954 loss3:0.3126 | AUC:0.8647 Anomaly AUC:0.6876
[2023-10-02 16:08:37,234][main.py][line:213][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0310 loss2:0.4668 loss3:0.3159 | AUC:0.8672 Anomaly AUC:0.6889
[2023-10-02 16:09:23,782][main.py][line:213][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0119 loss2:0.4021 loss3:0.3104 | AUC:0.8628 Anomaly AUC:0.7002
[2023-10-02 16:10:11,397][main.py][line:213][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0195 loss2:0.3725 loss3:0.3089 | AUC:0.8833 Anomaly AUC:0.7104
[2023-10-02 16:10:58,629][main.py][line:213][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0275 loss2:0.3618 loss3:0.3164 | AUC:0.8783 Anomaly AUC:0.7127
[2023-10-02 16:11:45,860][main.py][line:213][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0057 loss2:0.2960 loss3:0.3070 | AUC:0.8758 Anomaly AUC:0.7065
[2023-10-02 16:12:33,404][main.py][line:213][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0058 loss2:0.2713 loss3:0.3056 | AUC:0.8699 Anomaly AUC:0.6888
[2023-10-02 16:13:20,571][main.py][line:213][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0050 loss2:0.2426 loss3:0.3039 | AUC:0.8672 Anomaly AUC:0.6828
[2023-10-02 16:14:08,126][main.py][line:213][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0231 loss2:0.2423 loss3:0.3055 | AUC:0.8547 Anomaly AUC:0.6571
[2023-10-02 16:14:53,409][main.py][line:213][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0624 loss2:0.3567 loss3:0.3362 | AUC:0.8623 Anomaly AUC:0.6916
[2023-10-02 16:15:40,706][main.py][line:213][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0089 loss2:0.2188 loss3:0.3179 | AUC:0.8662 Anomaly AUC:0.6784
[2023-10-02 16:16:26,116][main.py][line:213][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0252 loss2:0.2275 loss3:0.3213 | AUC:0.8641 Anomaly AUC:0.6651
[2023-10-02 16:17:13,763][main.py][line:213][INFO] [IDX:5/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0139 loss2:0.2062 loss3:0.3227 | AUC:0.8556 Anomaly AUC:0.6585
[2023-10-02 16:17:58,966][main.py][line:213][INFO] [IDX:5/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0261 loss2:0.2159 loss3:0.3299 | AUC:0.8437 Anomaly AUC:0.6278
[2023-10-02 16:18:46,578][main.py][line:213][INFO] [IDX:5/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0163 loss2:0.1850 loss3:0.3288 | AUC:0.8569 Anomaly AUC:0.6579
[2023-10-02 16:19:34,388][main.py][line:213][INFO] [IDX:5/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0061 loss2:0.1569 loss3:0.3252 | AUC:0.8616 Anomaly AUC:0.6745
[2023-10-02 16:20:21,865][main.py][line:213][INFO] [IDX:5/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.1410 loss3:0.3208 | AUC:0.8532 Anomaly AUC:0.6521
[2023-10-02 16:21:07,413][main.py][line:213][INFO] [IDX:5/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0048 loss2:0.1341 loss3:0.3193 | AUC:0.8469 Anomaly AUC:0.6379
[2023-10-02 16:21:54,780][main.py][line:213][INFO] [IDX:5/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0045 loss2:0.1262 loss3:0.3191 | AUC:0.8389 Anomaly AUC:0.6271
[2023-10-02 16:22:42,462][main.py][line:213][INFO] [IDX:5/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0336 loss2:0.1782 loss3:0.3294 | AUC:0.8542 Anomaly AUC:0.6629
[2023-10-02 16:23:29,711][main.py][line:213][INFO] [IDX:5/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0144 loss2:0.1451 loss3:0.3330 | AUC:0.8558 Anomaly AUC:0.6582
[2023-10-02 16:23:29,754][main.py][line:223][INFO] [IDX:5/10] Training completes in 23m 27s | best AUCAUC:0.8752 Anomaly AUC:0.7141

[2023-10-02 16:25:18,569][main.py][line:178][INFO] Random initialize AUCAUC:0.4809 Anomaly AUC:0.49006
[2023-10-02 16:26:33,209][main.py][line:213][INFO] [IDX:10/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.5128 loss2:1.2901 loss3:0.4146 | AUC:0.8437 Anomaly AUC:0.6335
[2023-10-02 16:27:46,339][main.py][line:213][INFO] [IDX:10/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.1494 loss2:1.0261 loss3:0.4029 | AUC:0.8658 Anomaly AUC:0.6826
[2023-10-02 16:29:09,098][main.py][line:213][INFO] [IDX:10/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.0501 loss2:0.7688 loss3:0.3749 | AUC:0.8640 Anomaly AUC:0.6892
[2023-10-02 16:30:24,866][main.py][line:213][INFO] [IDX:10/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0168 loss2:0.6692 loss3:0.3504 | AUC:0.8614 Anomaly AUC:0.6932
[2023-10-02 16:31:38,723][main.py][line:213][INFO] [IDX:10/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0148 loss2:0.5853 loss3:0.3368 | AUC:0.8747 Anomaly AUC:0.7056
[2023-10-02 16:32:55,383][main.py][line:213][INFO] [IDX:10/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0152 loss2:0.4985 loss3:0.3331 | AUC:0.8722 Anomaly AUC:0.7082
[2023-10-02 16:34:11,836][main.py][line:213][INFO] [IDX:10/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0228 loss2:0.4378 loss3:0.3356 | AUC:0.8662 Anomaly AUC:0.6827
[2023-10-02 16:35:26,583][main.py][line:213][INFO] [IDX:10/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0160 loss2:0.3675 loss3:0.3341 | AUC:0.8544 Anomaly AUC:0.6777
[2023-10-02 16:36:41,148][main.py][line:213][INFO] [IDX:10/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0179 loss2:0.3149 loss3:0.3360 | AUC:0.8598 Anomaly AUC:0.6890
[2023-10-02 16:37:55,080][main.py][line:213][INFO] [IDX:10/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0105 loss2:0.2605 loss3:0.3368 | AUC:0.8525 Anomaly AUC:0.6656
[2023-10-02 16:39:09,167][main.py][line:213][INFO] [IDX:10/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0160 loss2:0.2485 loss3:0.3413 | AUC:0.8563 Anomaly AUC:0.6574
[2023-10-02 16:40:20,524][main.py][line:213][INFO] [IDX:10/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0109 loss2:0.1901 loss3:0.3372 | AUC:0.8347 Anomaly AUC:0.5964
[2023-10-02 16:41:33,193][main.py][line:213][INFO] [IDX:10/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0229 loss2:0.2020 loss3:0.3488 | AUC:0.8357 Anomaly AUC:0.6061
[2023-10-02 16:42:43,765][main.py][line:213][INFO] [IDX:10/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0117 loss2:0.1609 loss3:0.3448 | AUC:0.8017 Anomaly AUC:0.5853
[2023-10-02 16:43:56,386][main.py][line:213][INFO] [IDX:10/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0123 loss2:0.1481 loss3:0.3498 | AUC:0.8035 Anomaly AUC:0.5965
[2023-10-02 16:45:08,956][main.py][line:213][INFO] [IDX:10/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0105 loss2:0.1326 loss3:0.3533 | AUC:0.8312 Anomaly AUC:0.6226
[2023-10-02 16:46:20,559][main.py][line:213][INFO] [IDX:10/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0063 loss2:0.1123 loss3:0.3543 | AUC:0.8445 Anomaly AUC:0.6299
[2023-10-02 16:47:32,163][main.py][line:213][INFO] [IDX:10/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0041 loss2:0.0973 loss3:0.3522 | AUC:0.8434 Anomaly AUC:0.6294
[2023-10-02 16:48:44,772][main.py][line:213][INFO] [IDX:10/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0118 loss2:0.1112 loss3:0.3544 | AUC:0.8253 Anomaly AUC:0.6119
[2023-10-02 16:49:56,344][main.py][line:213][INFO] [IDX:10/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0167 loss2:0.1388 loss3:0.3724 | AUC:0.8272 Anomaly AUC:0.5896
[2023-10-02 16:51:07,174][main.py][line:213][INFO] [IDX:10/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0084 loss2:0.0931 loss3:0.3691 | AUC:0.8359 Anomaly AUC:0.6131
[2023-10-02 16:52:18,083][main.py][line:213][INFO] [IDX:10/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0061 loss2:0.0796 loss3:0.3654 | AUC:0.8299 Anomaly AUC:0.5946
[2023-10-02 16:53:29,092][main.py][line:213][INFO] [IDX:10/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0091 loss2:0.0752 loss3:0.3656 | AUC:0.8323 Anomaly AUC:0.6172
[2023-10-02 16:54:40,474][main.py][line:213][INFO] [IDX:10/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0064 loss2:0.0742 loss3:0.3689 | AUC:0.8354 Anomaly AUC:0.6294
[2023-10-02 16:55:51,486][main.py][line:213][INFO] [IDX:10/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0065 loss2:0.0659 loss3:0.3678 | AUC:0.8257 Anomaly AUC:0.5902
[2023-10-02 16:57:04,566][main.py][line:213][INFO] [IDX:10/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0053 loss2:0.0561 loss3:0.3652 | AUC:0.8378 Anomaly AUC:0.6256
[2023-10-02 16:58:19,065][main.py][line:213][INFO] [IDX:10/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0107 loss2:0.0760 loss3:0.3690 | AUC:0.8192 Anomaly AUC:0.6144
[2023-10-02 16:59:35,083][main.py][line:213][INFO] [IDX:10/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0052 loss2:0.0590 loss3:0.3724 | AUC:0.8096 Anomaly AUC:0.5951
[2023-10-02 17:00:46,048][main.py][line:213][INFO] [IDX:10/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0094 loss2:0.0648 loss3:0.3743 | AUC:0.8032 Anomaly AUC:0.5696
[2023-10-02 17:01:55,711][main.py][line:213][INFO] [IDX:10/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0046 loss2:0.0441 loss3:0.3704 | AUC:0.8274 Anomaly AUC:0.6272
[2023-10-02 17:01:55,756][main.py][line:223][INFO] [IDX:10/10] Training completes in 36m 37s | best AUCAUC:0.8747 Anomaly AUC:0.7056

[2023-10-02 18:58:38,439][main.py][line:235][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 18:58:41,576][main.py][line:276][INFO] total params:8.2169M
[2023-10-02 18:58:41,576][main.py][line:279][INFO] Training Mode
[2023-10-02 18:58:41,578][main.py][line:129][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 18:59:01,581][main.py][line:179][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 18:59:29,628][main.py][line:214][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 19:00:00,160][main.py][line:214][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 19:00:34,112][main.py][line:214][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 19:01:08,533][main.py][line:214][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 19:01:42,843][main.py][line:214][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 19:02:14,338][main.py][line:214][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 19:02:42,345][main.py][line:214][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 19:03:10,137][main.py][line:214][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 19:03:38,064][main.py][line:214][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 19:04:05,679][main.py][line:214][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 19:04:33,665][main.py][line:214][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 19:05:01,531][main.py][line:214][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 19:05:29,438][main.py][line:214][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 19:05:57,298][main.py][line:214][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 19:06:25,144][main.py][line:214][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 19:06:53,045][main.py][line:214][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 19:07:22,138][main.py][line:214][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 19:07:53,349][main.py][line:214][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 19:08:21,342][main.py][line:214][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 19:08:49,258][main.py][line:214][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 19:09:17,191][main.py][line:214][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 19:09:45,038][main.py][line:214][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 19:10:12,803][main.py][line:214][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 19:10:40,744][main.py][line:214][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 19:11:08,624][main.py][line:214][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 19:11:39,367][main.py][line:214][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 19:12:07,134][main.py][line:214][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 19:12:35,013][main.py][line:214][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 19:13:02,928][main.py][line:214][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 19:13:30,764][main.py][line:214][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 19:13:30,809][main.py][line:224][INFO] [IDX:2/10] Training completes in 14m 29s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 19:14:33,495][main.py][line:179][INFO] Random initialize AUCAUC:0.4504 Anomaly AUC:0.52771
[2023-10-02 19:15:19,075][main.py][line:214][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6487 loss2:1.3227 loss3:0.4157 | AUC:0.8429 Anomaly AUC:0.6185
[2023-10-02 19:16:05,752][main.py][line:214][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2439 loss2:1.1938 loss3:0.4262 | AUC:0.8643 Anomaly AUC:0.6747
[2023-10-02 19:16:51,600][main.py][line:214][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1460 loss2:0.9842 loss3:0.4024 | AUC:0.8666 Anomaly AUC:0.7018
[2023-10-02 19:17:37,383][main.py][line:214][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.1023 loss2:0.8190 loss3:0.3818 | AUC:0.8777 Anomaly AUC:0.7158
[2023-10-02 19:18:24,725][main.py][line:214][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0526 loss2:0.7274 loss3:0.3627 | AUC:0.8752 Anomaly AUC:0.7175
[2023-10-02 19:19:10,584][main.py][line:214][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0209 loss2:0.6646 loss3:0.3431 | AUC:0.8731 Anomaly AUC:0.7078
[2023-10-02 19:19:56,430][main.py][line:214][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0094 loss2:0.6050 loss3:0.3272 | AUC:0.8777 Anomaly AUC:0.7090
[2023-10-02 19:20:43,322][main.py][line:214][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5591 loss3:0.3184 | AUC:0.8750 Anomaly AUC:0.7066
[2023-10-02 19:21:29,209][main.py][line:214][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0063 loss2:0.4974 loss3:0.3088 | AUC:0.8732 Anomaly AUC:0.7044
[2023-10-02 19:22:15,916][main.py][line:214][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0060 loss2:0.4484 loss3:0.3043 | AUC:0.8746 Anomaly AUC:0.7119
[2023-10-02 19:23:03,667][main.py][line:214][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0578 loss2:0.4599 loss3:0.3142 | AUC:0.8768 Anomaly AUC:0.7021
[2023-10-02 19:23:51,259][main.py][line:214][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0301 loss2:0.4167 loss3:0.3180 | AUC:0.8657 Anomaly AUC:0.7024
[2023-10-02 19:24:38,831][main.py][line:214][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0243 loss2:0.3695 loss3:0.3166 | AUC:0.8695 Anomaly AUC:0.6953
[2023-10-02 19:25:25,528][main.py][line:214][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0240 loss2:0.3452 loss3:0.3198 | AUC:0.8766 Anomaly AUC:0.7090
[2023-10-02 19:26:13,119][main.py][line:214][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0217 loss2:0.3185 loss3:0.3192 | AUC:0.8618 Anomaly AUC:0.7003
[2023-10-02 19:26:25,519][main.py][line:236][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 19:26:28,587][main.py][line:277][INFO] total params:8.2169M
[2023-10-02 19:26:28,588][main.py][line:280][INFO] Training Mode
[2023-10-02 19:26:28,590][main.py][line:130][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 19:26:50,529][main.py][line:180][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 19:27:18,737][main.py][line:215][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 19:27:46,373][main.py][line:215][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 19:28:13,907][main.py][line:215][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 19:28:42,024][main.py][line:215][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 19:29:09,520][main.py][line:215][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 19:29:37,361][main.py][line:215][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 19:30:08,578][main.py][line:215][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 19:30:36,299][main.py][line:215][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 19:31:07,059][main.py][line:215][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 19:31:36,826][main.py][line:215][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 19:32:04,483][main.py][line:215][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 19:32:34,007][main.py][line:215][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 19:33:04,862][main.py][line:215][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 19:33:32,571][main.py][line:215][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 19:34:02,572][main.py][line:215][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 19:34:30,219][main.py][line:215][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 19:35:01,292][main.py][line:215][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 19:35:31,980][main.py][line:215][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 19:36:01,996][main.py][line:215][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 19:36:32,972][main.py][line:215][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 19:37:04,021][main.py][line:215][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 19:37:33,672][main.py][line:215][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 19:38:03,152][main.py][line:215][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 19:38:32,319][main.py][line:215][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 19:39:00,064][main.py][line:215][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 19:39:31,062][main.py][line:215][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 19:40:01,648][main.py][line:215][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 19:40:31,387][main.py][line:215][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 19:41:02,345][main.py][line:215][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 19:41:33,806][main.py][line:215][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 19:41:33,842][main.py][line:225][INFO] [IDX:2/10] Training completes in 14m 43s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 19:42:36,982][main.py][line:180][INFO] Random initialize AUCAUC:0.4504 Anomaly AUC:0.52771
[2023-10-02 19:43:23,191][main.py][line:215][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6609 loss2:1.3231 loss3:0.4137 | AUC:0.8456 Anomaly AUC:0.6243
[2023-10-02 19:44:09,250][main.py][line:215][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2672 loss2:1.1983 loss3:0.4214 | AUC:0.8686 Anomaly AUC:0.6754
[2023-10-02 19:44:56,592][main.py][line:215][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1496 loss2:0.9775 loss3:0.3956 | AUC:0.8801 Anomaly AUC:0.7210
[2023-10-02 19:45:41,604][main.py][line:215][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.1021 loss2:0.8222 loss3:0.3773 | AUC:0.8862 Anomaly AUC:0.7252
[2023-10-02 19:46:28,171][main.py][line:215][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0486 loss2:0.7277 loss3:0.3570 | AUC:0.8846 Anomaly AUC:0.7216
[2023-10-02 19:47:12,990][main.py][line:215][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0196 loss2:0.6688 loss3:0.3399 | AUC:0.8853 Anomaly AUC:0.7168
[2023-10-02 19:47:59,615][main.py][line:215][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0173 loss2:0.6142 loss3:0.3257 | AUC:0.8780 Anomaly AUC:0.7023
[2023-10-02 19:48:44,213][main.py][line:215][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0213 loss2:0.5815 loss3:0.3195 | AUC:0.8793 Anomaly AUC:0.7024
[2023-10-02 19:49:30,684][main.py][line:215][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0199 loss2:0.5310 loss3:0.3142 | AUC:0.8825 Anomaly AUC:0.7103
[2023-10-02 19:50:19,460][main.py][line:215][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0164 loss2:0.4907 loss3:0.3110 | AUC:0.8852 Anomaly AUC:0.7220
[2023-10-02 19:51:05,868][main.py][line:215][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0205 loss2:0.4499 loss3:0.3077 | AUC:0.8829 Anomaly AUC:0.7138
[2023-10-02 19:51:52,193][main.py][line:215][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0285 loss2:0.4194 loss3:0.3110 | AUC:0.8657 Anomaly AUC:0.6827
[2023-10-02 19:52:38,650][main.py][line:215][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0248 loss2:0.3875 loss3:0.3153 | AUC:0.8864 Anomaly AUC:0.7236
[2023-10-02 19:53:25,265][main.py][line:215][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0192 loss2:0.3468 loss3:0.3122 | AUC:0.8807 Anomaly AUC:0.7124
[2023-10-02 19:54:12,065][main.py][line:215][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0073 loss2:0.3047 loss3:0.3111 | AUC:0.8855 Anomaly AUC:0.7195
[2023-10-02 19:54:58,758][main.py][line:215][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0364 loss2:0.3208 loss3:0.3155 | AUC:0.8835 Anomaly AUC:0.7180
[2023-10-02 19:55:45,142][main.py][line:215][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0098 loss2:0.2646 loss3:0.3141 | AUC:0.8572 Anomaly AUC:0.6532
[2023-10-02 19:56:31,695][main.py][line:215][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0207 loss2:0.2592 loss3:0.3162 | AUC:0.8681 Anomaly AUC:0.6677
[2023-10-02 19:57:18,720][main.py][line:215][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0102 loss2:0.2320 loss3:0.3150 | AUC:0.8571 Anomaly AUC:0.6471
[2023-10-02 19:58:05,166][main.py][line:215][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0050 loss2:0.1995 loss3:0.3121 | AUC:0.8559 Anomaly AUC:0.6432
[2023-10-02 19:58:51,827][main.py][line:215][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0048 loss2:0.1813 loss3:0.3117 | AUC:0.8506 Anomaly AUC:0.6291
[2023-10-02 19:59:38,879][main.py][line:215][INFO] [IDX:5/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0048 loss2:0.1693 loss3:0.3116 | AUC:0.8541 Anomaly AUC:0.6384
[2023-10-02 20:00:25,753][main.py][line:215][INFO] [IDX:5/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0050 loss2:0.1566 loss3:0.3123 | AUC:0.8468 Anomaly AUC:0.6217
[2023-10-02 20:01:10,474][main.py][line:215][INFO] [IDX:5/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0684 loss2:0.2417 loss3:0.3260 | AUC:0.8539 Anomaly AUC:0.6594
[2023-10-02 20:01:56,979][main.py][line:215][INFO] [IDX:5/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0346 loss2:0.2513 loss3:0.3500 | AUC:0.8516 Anomaly AUC:0.6478
[2023-10-02 20:02:41,668][main.py][line:215][INFO] [IDX:5/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0257 loss2:0.1962 loss3:0.3330 | AUC:0.8676 Anomaly AUC:0.6787
[2023-10-02 20:03:28,746][main.py][line:215][INFO] [IDX:5/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.1559 loss3:0.3281 | AUC:0.8516 Anomaly AUC:0.6352
[2023-10-02 20:04:15,599][main.py][line:215][INFO] [IDX:5/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0273 loss2:0.1525 loss3:0.3261 | AUC:0.8760 Anomaly AUC:0.6891
[2023-10-02 20:05:00,323][main.py][line:215][INFO] [IDX:5/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0122 loss2:0.1566 loss3:0.3292 | AUC:0.8276 Anomaly AUC:0.5880
[2023-10-02 20:05:45,183][main.py][line:215][INFO] [IDX:5/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0086 loss2:0.1281 loss3:0.3264 | AUC:0.8505 Anomaly AUC:0.6327
[2023-10-02 20:05:45,206][main.py][line:225][INFO] [IDX:5/10] Training completes in 23m 8s | best AUCAUC:0.8862 Anomaly AUC:0.7252

[2023-10-02 20:07:32,907][main.py][line:180][INFO] Random initialize AUCAUC:0.4809 Anomaly AUC:0.49006
[2023-10-02 20:08:46,841][main.py][line:215][INFO] [IDX:10/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.5232 loss2:1.2917 loss3:0.4148 | AUC:0.8551 Anomaly AUC:0.6461
[2023-10-02 20:10:00,431][main.py][line:215][INFO] [IDX:10/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.1542 loss2:1.0001 loss3:0.3969 | AUC:0.8757 Anomaly AUC:0.7044
[2023-10-02 20:11:13,202][main.py][line:215][INFO] [IDX:10/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.0506 loss2:0.7646 loss3:0.3677 | AUC:0.8776 Anomaly AUC:0.7149
[2023-10-02 20:12:27,130][main.py][line:215][INFO] [IDX:10/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0191 loss2:0.6689 loss3:0.3446 | AUC:0.8764 Anomaly AUC:0.7151
[2023-10-02 20:13:41,795][main.py][line:215][INFO] [IDX:10/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0174 loss2:0.5863 loss3:0.3337 | AUC:0.8733 Anomaly AUC:0.6995
[2023-10-02 20:14:55,262][main.py][line:215][INFO] [IDX:10/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0064 loss2:0.4783 loss3:0.3263 | AUC:0.8739 Anomaly AUC:0.7143
[2023-10-02 20:16:19,378][main.py][line:242][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 20:16:22,556][main.py][line:283][INFO] total params:8.2169M
[2023-10-02 20:16:22,556][main.py][line:286][INFO] Training Mode
[2023-10-02 20:16:22,558][main.py][line:136][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 20:16:47,420][main.py][line:186][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 20:17:47,546][main.py][line:243][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-02 20:17:50,640][main.py][line:284][INFO] total params:8.2169M
[2023-10-02 20:17:50,640][main.py][line:287][INFO] Training Mode
[2023-10-02 20:17:50,643][main.py][line:137][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-02 20:18:13,305][main.py][line:187][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-02 20:18:41,574][main.py][line:222][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-02 20:19:14,987][main.py][line:222][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-02 20:19:44,333][main.py][line:222][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-02 20:20:19,303][main.py][line:222][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-02 20:20:50,747][main.py][line:222][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-02 20:21:23,786][main.py][line:222][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-02 20:21:52,467][main.py][line:222][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-02 20:22:24,180][main.py][line:222][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-02 20:22:56,256][main.py][line:222][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-02 20:23:26,267][main.py][line:222][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-02 20:24:02,366][main.py][line:222][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-02 20:24:34,021][main.py][line:222][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-02 20:25:06,017][main.py][line:222][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-02 20:25:37,815][main.py][line:222][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-02 20:26:08,087][main.py][line:222][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-02 20:26:35,952][main.py][line:222][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-02 20:27:06,070][main.py][line:222][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-02 20:27:35,494][main.py][line:222][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-02 20:28:07,940][main.py][line:222][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-02 20:28:39,472][main.py][line:222][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-02 20:29:11,870][main.py][line:222][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-02 20:29:41,742][main.py][line:222][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-02 20:30:09,462][main.py][line:222][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-02 20:30:41,323][main.py][line:222][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-02 20:31:13,028][main.py][line:222][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-02 20:31:44,948][main.py][line:222][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-02 20:32:16,634][main.py][line:222][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-02 20:32:48,617][main.py][line:222][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-02 20:33:20,017][main.py][line:222][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-02 20:33:52,244][main.py][line:222][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-02 20:33:52,302][main.py][line:232][INFO] [IDX:2/10] Training completes in 15m 39s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-02 20:34:55,828][main.py][line:187][INFO] Random initialize AUCAUC:0.4504 Anomaly AUC:0.52771
[2023-10-02 20:35:40,538][main.py][line:222][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6484 loss2:1.3250 loss3:0.4161 | AUC:0.8434 Anomaly AUC:0.6171
[2023-10-02 20:36:28,310][main.py][line:222][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2669 loss2:1.2018 loss3:0.4262 | AUC:0.8640 Anomaly AUC:0.6651
[2023-10-02 20:37:17,812][main.py][line:222][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1459 loss2:1.0000 loss3:0.4009 | AUC:0.8689 Anomaly AUC:0.7114
[2023-10-02 20:38:05,457][main.py][line:222][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0947 loss2:0.8234 loss3:0.3795 | AUC:0.8774 Anomaly AUC:0.7193
[2023-10-02 20:38:52,699][main.py][line:222][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0395 loss2:0.7267 loss3:0.3596 | AUC:0.8713 Anomaly AUC:0.7119
[2023-10-02 20:39:43,669][main.py][line:222][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0176 loss2:0.6682 loss3:0.3403 | AUC:0.8764 Anomaly AUC:0.7160
[2023-10-02 20:40:31,916][main.py][line:222][INFO] [IDX:5/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0197 loss2:0.6183 loss3:0.3276 | AUC:0.8649 Anomaly AUC:0.6874
[2023-10-02 20:41:19,128][main.py][line:222][INFO] [IDX:5/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0100 loss2:0.5725 loss3:0.3183 | AUC:0.8693 Anomaly AUC:0.6998
[2023-10-02 20:42:07,921][main.py][line:222][INFO] [IDX:5/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0228 loss2:0.5249 loss3:0.3137 | AUC:0.8727 Anomaly AUC:0.7021
[2023-10-02 20:42:55,800][main.py][line:222][INFO] [IDX:5/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0231 loss2:0.4933 loss3:0.3113 | AUC:0.8648 Anomaly AUC:0.7028
[2023-10-02 20:43:45,364][main.py][line:222][INFO] [IDX:5/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0173 loss2:0.4454 loss3:0.3096 | AUC:0.8678 Anomaly AUC:0.6899
[2023-10-02 20:44:32,837][main.py][line:222][INFO] [IDX:5/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4401 loss3:0.3143 | AUC:0.8594 Anomaly AUC:0.6803
[2023-10-02 20:45:23,156][main.py][line:222][INFO] [IDX:5/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0134 loss2:0.3685 loss3:0.3105 | AUC:0.8615 Anomaly AUC:0.6979
[2023-10-02 20:46:10,736][main.py][line:222][INFO] [IDX:5/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0064 loss2:0.3238 loss3:0.3068 | AUC:0.8647 Anomaly AUC:0.7010
[2023-10-02 20:46:58,175][main.py][line:222][INFO] [IDX:5/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0051 loss2:0.2856 loss3:0.3026 | AUC:0.8630 Anomaly AUC:0.6900
[2023-10-02 20:47:47,973][main.py][line:222][INFO] [IDX:5/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0052 loss2:0.2610 loss3:0.3028 | AUC:0.8569 Anomaly AUC:0.6687
[2023-10-02 20:48:35,467][main.py][line:222][INFO] [IDX:5/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.2322 loss3:0.3023 | AUC:0.8547 Anomaly AUC:0.6775
[2023-10-02 20:49:20,587][main.py][line:222][INFO] [IDX:5/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0604 loss2:0.3255 loss3:0.3247 | AUC:0.8592 Anomaly AUC:0.6902
[2023-10-02 20:50:07,468][main.py][line:222][INFO] [IDX:5/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0287 loss2:0.2667 loss3:0.3279 | AUC:0.8329 Anomaly AUC:0.6290
[2023-10-02 20:50:56,778][main.py][line:222][INFO] [IDX:5/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0175 loss2:0.2367 loss3:0.3270 | AUC:0.8593 Anomaly AUC:0.6848
[2023-10-02 20:51:44,304][main.py][line:222][INFO] [IDX:5/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0108 loss2:0.2008 loss3:0.3201 | AUC:0.7988 Anomaly AUC:0.5857
[2023-10-02 20:52:31,688][main.py][line:222][INFO] [IDX:5/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0215 loss2:0.2167 loss3:0.3273 | AUC:0.8490 Anomaly AUC:0.6630
[2023-10-02 20:53:17,402][main.py][line:222][INFO] [IDX:5/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.1763 loss3:0.3217 | AUC:0.8348 Anomaly AUC:0.6357
[2023-10-02 20:54:06,200][main.py][line:222][INFO] [IDX:5/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0072 loss2:0.1592 loss3:0.3202 | AUC:0.8279 Anomaly AUC:0.6274
[2023-10-02 20:54:54,645][main.py][line:222][INFO] [IDX:5/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0086 loss2:0.1537 loss3:0.3201 | AUC:0.7767 Anomaly AUC:0.5579
[2023-10-02 20:55:41,957][main.py][line:222][INFO] [IDX:5/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0194 loss2:0.1707 loss3:0.3245 | AUC:0.7793 Anomaly AUC:0.5819
[2023-10-02 20:56:31,038][main.py][line:222][INFO] [IDX:5/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0354 loss2:0.1804 loss3:0.3299 | AUC:0.8501 Anomaly AUC:0.6503
[2023-10-02 20:57:19,323][main.py][line:222][INFO] [IDX:5/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0156 loss2:0.1569 loss3:0.3339 | AUC:0.8508 Anomaly AUC:0.6524
[2023-10-02 20:58:07,252][main.py][line:222][INFO] [IDX:5/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0047 loss2:0.1243 loss3:0.3257 | AUC:0.8329 Anomaly AUC:0.6275
[2023-10-02 20:58:55,004][main.py][line:222][INFO] [IDX:5/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0046 loss2:0.1152 loss3:0.3244 | AUC:0.8153 Anomaly AUC:0.6131
[2023-10-02 20:58:55,046][main.py][line:232][INFO] [IDX:5/10] Training completes in 23m 59s | best AUCAUC:0.8774 Anomaly AUC:0.7193

[2023-10-02 21:00:57,141][main.py][line:187][INFO] Random initialize AUCAUC:0.4809 Anomaly AUC:0.49006
[2023-10-02 21:02:09,093][main.py][line:222][INFO] [IDX:10/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.5187 loss2:1.2915 loss3:0.4157 | AUC:0.8485 Anomaly AUC:0.6470
[2023-10-02 21:03:28,552][main.py][line:222][INFO] [IDX:10/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.1496 loss2:1.0260 loss3:0.4016 | AUC:0.8754 Anomaly AUC:0.6975
[2023-10-02 21:04:42,678][main.py][line:222][INFO] [IDX:10/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.0500 loss2:0.7729 loss3:0.3735 | AUC:0.8759 Anomaly AUC:0.7016
[2023-10-02 21:05:57,728][main.py][line:222][INFO] [IDX:10/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.0236 loss2:0.6812 loss3:0.3494 | AUC:0.8751 Anomaly AUC:0.7082
[2023-10-02 21:07:12,952][main.py][line:222][INFO] [IDX:10/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.5777 loss3:0.3322 | AUC:0.8692 Anomaly AUC:0.6941
[2023-10-02 21:08:27,863][main.py][line:222][INFO] [IDX:10/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0052 loss2:0.4685 loss3:0.3255 | AUC:0.8675 Anomaly AUC:0.6976
[2023-10-02 21:09:41,095][main.py][line:222][INFO] [IDX:10/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.0383 loss2:0.4443 loss3:0.3394 | AUC:0.8644 Anomaly AUC:0.6885
[2023-10-02 21:10:57,245][main.py][line:222][INFO] [IDX:10/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.0128 loss2:0.3522 loss3:0.3375 | AUC:0.8699 Anomaly AUC:0.7048
[2023-10-02 21:12:14,419][main.py][line:222][INFO] [IDX:10/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0046 loss2:0.2756 loss3:0.3276 | AUC:0.8665 Anomaly AUC:0.6873
[2023-10-02 21:13:31,726][main.py][line:222][INFO] [IDX:10/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0361 loss2:0.2974 loss3:0.3414 | AUC:0.8594 Anomaly AUC:0.6662
[2023-10-02 21:14:47,074][main.py][line:222][INFO] [IDX:10/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0139 loss2:0.2303 loss3:0.3427 | AUC:0.8375 Anomaly AUC:0.6530
[2023-10-02 21:16:02,198][main.py][line:222][INFO] [IDX:10/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0154 loss2:0.2019 loss3:0.3407 | AUC:0.8364 Anomaly AUC:0.6461
[2023-10-02 21:17:18,862][main.py][line:222][INFO] [IDX:10/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0045 loss2:0.1578 loss3:0.3373 | AUC:0.8190 Anomaly AUC:0.6044
[2023-10-02 21:18:33,535][main.py][line:222][INFO] [IDX:10/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0215 loss2:0.1818 loss3:0.3465 | AUC:0.8479 Anomaly AUC:0.6334
[2023-10-02 21:19:48,850][main.py][line:222][INFO] [IDX:10/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0081 loss2:0.1408 loss3:0.3486 | AUC:0.8626 Anomaly AUC:0.6664
[2023-10-02 21:21:01,768][main.py][line:222][INFO] [IDX:10/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0064 loss2:0.1226 loss3:0.3497 | AUC:0.8429 Anomaly AUC:0.6205
[2023-10-02 21:22:17,518][main.py][line:222][INFO] [IDX:10/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0164 loss2:0.1344 loss3:0.3609 | AUC:0.8435 Anomaly AUC:0.6210
[2023-10-02 21:23:32,758][main.py][line:222][INFO] [IDX:10/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.1031 loss3:0.3582 | AUC:0.8269 Anomaly AUC:0.6240
[2023-10-02 21:24:48,585][main.py][line:222][INFO] [IDX:10/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0088 loss2:0.1052 loss3:0.3617 | AUC:0.8342 Anomaly AUC:0.5963
[2023-10-02 21:26:06,170][main.py][line:222][INFO] [IDX:10/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.0964 loss3:0.3601 | AUC:0.8407 Anomaly AUC:0.6317
[2023-10-02 21:27:21,284][main.py][line:222][INFO] [IDX:10/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.0846 loss3:0.3604 | AUC:0.8435 Anomaly AUC:0.6261
[2023-10-02 21:28:37,948][main.py][line:222][INFO] [IDX:10/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0096 loss2:0.0888 loss3:0.3623 | AUC:0.8263 Anomaly AUC:0.5952
[2023-10-02 21:29:54,754][main.py][line:222][INFO] [IDX:10/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0049 loss2:0.0690 loss3:0.3572 | AUC:0.8157 Anomaly AUC:0.5743
[2023-10-02 21:31:10,014][main.py][line:222][INFO] [IDX:10/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.0701 loss3:0.3533 | AUC:0.8504 Anomaly AUC:0.6342
[2023-10-02 21:32:25,901][main.py][line:222][INFO] [IDX:10/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.0831 loss3:0.3620 | AUC:0.8458 Anomaly AUC:0.6327
[2023-10-02 21:33:41,369][main.py][line:222][INFO] [IDX:10/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0053 loss2:0.0580 loss3:0.3560 | AUC:0.8374 Anomaly AUC:0.6200
[2023-10-02 21:34:57,804][main.py][line:222][INFO] [IDX:10/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0067 loss2:0.0599 loss3:0.3578 | AUC:0.8501 Anomaly AUC:0.6490
[2023-10-02 21:36:13,530][main.py][line:222][INFO] [IDX:10/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0083 loss2:0.0633 loss3:0.3597 | AUC:0.8432 Anomaly AUC:0.6073
[2023-10-02 21:37:30,156][main.py][line:222][INFO] [IDX:10/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0059 loss2:0.0516 loss3:0.3593 | AUC:0.8525 Anomaly AUC:0.6525
[2023-10-02 21:38:47,230][main.py][line:222][INFO] [IDX:10/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0064 loss2:0.0465 loss3:0.3569 | AUC:0.8538 Anomaly AUC:0.6535
[2023-10-02 21:38:47,254][main.py][line:232][INFO] [IDX:10/10] Training completes in 37m 50s | best AUCAUC:0.8759 Anomaly AUC:0.7016

[2023-10-03 00:04:34,976][main.py][line:243][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 5, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-10-03 00:04:38,322][main.py][line:284][INFO] total params:8.2169M
[2023-10-03 00:04:38,323][main.py][line:287][INFO] Training Mode
[2023-10-03 00:04:38,325][main.py][line:137][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-10-03 00:04:58,653][main.py][line:187][INFO] Random initialize AUCAUC:0.5770 Anomaly AUC:0.54043
[2023-10-03 00:05:26,303][main.py][line:222][INFO] [IDX:2/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.9663 loss2:1.3575 loss3:0.3991 | AUC:0.7584 Anomaly AUC:0.5394
[2023-10-03 00:05:53,694][main.py][line:222][INFO] [IDX:2/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.6936 loss2:1.3325 loss3:0.3997 | AUC:0.8125 Anomaly AUC:0.5854
[2023-10-03 00:06:21,060][main.py][line:222][INFO] [IDX:2/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.3793 loss2:1.2488 loss3:0.4232 | AUC:0.8341 Anomaly AUC:0.6097
[2023-10-03 00:06:48,476][main.py][line:222][INFO] [IDX:2/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.2734 loss2:1.1874 loss3:0.4206 | AUC:0.8503 Anomaly AUC:0.6387
[2023-10-03 00:07:15,871][main.py][line:222][INFO] [IDX:2/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.1812 loss2:1.0733 loss3:0.4159 | AUC:0.8656 Anomaly AUC:0.6881
[2023-10-03 00:07:43,320][main.py][line:222][INFO] [IDX:2/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.1723 loss2:0.9382 loss3:0.4005 | AUC:0.8725 Anomaly AUC:0.6914
[2023-10-03 00:08:10,809][main.py][line:222][INFO] [IDX:2/10, Epoch:7/30]: lr:1.000e-04 | loss1:0.1014 loss2:0.8294 loss3:0.3896 | AUC:0.8607 Anomaly AUC:0.6883
[2023-10-03 00:08:38,395][main.py][line:222][INFO] [IDX:2/10, Epoch:8/30]: lr:1.000e-04 | loss1:0.1151 loss2:0.7931 loss3:0.3783 | AUC:0.8714 Anomaly AUC:0.7014
[2023-10-03 00:09:05,911][main.py][line:222][INFO] [IDX:2/10, Epoch:9/30]: lr:1.000e-04 | loss1:0.0615 loss2:0.7301 loss3:0.3659 | AUC:0.8659 Anomaly AUC:0.6933
[2023-10-03 00:09:33,514][main.py][line:222][INFO] [IDX:2/10, Epoch:10/30]: lr:1.000e-04 | loss1:0.0317 loss2:0.6970 loss3:0.3512 | AUC:0.8695 Anomaly AUC:0.6980
[2023-10-03 00:10:01,090][main.py][line:222][INFO] [IDX:2/10, Epoch:11/30]: lr:1.000e-04 | loss1:0.0186 loss2:0.6622 loss3:0.3378 | AUC:0.8690 Anomaly AUC:0.6997
[2023-10-03 00:10:28,576][main.py][line:222][INFO] [IDX:2/10, Epoch:12/30]: lr:1.000e-04 | loss1:0.0143 loss2:0.6307 loss3:0.3272 | AUC:0.8693 Anomaly AUC:0.6999
[2023-10-03 00:10:55,981][main.py][line:222][INFO] [IDX:2/10, Epoch:13/30]: lr:1.000e-04 | loss1:0.0106 loss2:0.6045 loss3:0.3187 | AUC:0.8693 Anomaly AUC:0.7010
[2023-10-03 00:11:23,500][main.py][line:222][INFO] [IDX:2/10, Epoch:14/30]: lr:1.000e-04 | loss1:0.0090 loss2:0.5712 loss3:0.3114 | AUC:0.8673 Anomaly AUC:0.6958
[2023-10-03 00:11:50,953][main.py][line:222][INFO] [IDX:2/10, Epoch:15/30]: lr:1.000e-04 | loss1:0.0087 loss2:0.5461 loss3:0.3065 | AUC:0.8666 Anomaly AUC:0.6924
[2023-10-03 00:12:18,352][main.py][line:222][INFO] [IDX:2/10, Epoch:16/30]: lr:1.000e-04 | loss1:0.0085 loss2:0.5103 loss3:0.3023 | AUC:0.8698 Anomaly AUC:0.6981
[2023-10-03 00:12:45,967][main.py][line:222][INFO] [IDX:2/10, Epoch:17/30]: lr:1.000e-04 | loss1:0.0079 loss2:0.4894 loss3:0.2971 | AUC:0.8674 Anomaly AUC:0.6921
[2023-10-03 00:13:13,353][main.py][line:222][INFO] [IDX:2/10, Epoch:18/30]: lr:1.000e-04 | loss1:0.0076 loss2:0.4553 loss3:0.2929 | AUC:0.8679 Anomaly AUC:0.6990
[2023-10-03 00:13:40,856][main.py][line:222][INFO] [IDX:2/10, Epoch:19/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4338 loss3:0.2893 | AUC:0.8701 Anomaly AUC:0.6986
[2023-10-03 00:14:08,223][main.py][line:222][INFO] [IDX:2/10, Epoch:20/30]: lr:1.000e-04 | loss1:0.0074 loss2:0.4057 loss3:0.2868 | AUC:0.8701 Anomaly AUC:0.7002
[2023-10-03 00:14:35,758][main.py][line:222][INFO] [IDX:2/10, Epoch:21/30]: lr:1.000e-04 | loss1:0.0082 loss2:0.3950 loss3:0.2856 | AUC:0.8681 Anomaly AUC:0.6987
[2023-10-03 00:15:03,222][main.py][line:222][INFO] [IDX:2/10, Epoch:22/30]: lr:1.000e-04 | loss1:0.0198 loss2:0.3934 loss3:0.2888 | AUC:0.8673 Anomaly AUC:0.6968
[2023-10-03 00:15:30,715][main.py][line:222][INFO] [IDX:2/10, Epoch:23/30]: lr:1.000e-04 | loss1:0.0842 loss2:0.4413 loss3:0.2976 | AUC:0.8590 Anomaly AUC:0.6808
[2023-10-03 00:15:58,373][main.py][line:222][INFO] [IDX:2/10, Epoch:24/30]: lr:1.000e-04 | loss1:0.0432 loss2:0.4194 loss3:0.2984 | AUC:0.8754 Anomaly AUC:0.7013
[2023-10-03 00:16:25,986][main.py][line:222][INFO] [IDX:2/10, Epoch:25/30]: lr:1.000e-04 | loss1:0.0171 loss2:0.3630 loss3:0.2943 | AUC:0.8766 Anomaly AUC:0.7028
[2023-10-03 00:16:53,626][main.py][line:222][INFO] [IDX:2/10, Epoch:26/30]: lr:1.000e-04 | loss1:0.0129 loss2:0.3367 loss3:0.2875 | AUC:0.8754 Anomaly AUC:0.6960
[2023-10-03 00:17:21,176][main.py][line:222][INFO] [IDX:2/10, Epoch:27/30]: lr:1.000e-04 | loss1:0.0126 loss2:0.3278 loss3:0.2869 | AUC:0.8717 Anomaly AUC:0.7088
[2023-10-03 00:17:48,484][main.py][line:222][INFO] [IDX:2/10, Epoch:28/30]: lr:1.000e-04 | loss1:0.0097 loss2:0.3129 loss3:0.2829 | AUC:0.8755 Anomaly AUC:0.7044
[2023-10-03 00:18:16,003][main.py][line:222][INFO] [IDX:2/10, Epoch:29/30]: lr:1.000e-04 | loss1:0.0075 loss2:0.2952 loss3:0.2799 | AUC:0.8764 Anomaly AUC:0.7142
[2023-10-03 00:18:43,745][main.py][line:222][INFO] [IDX:2/10, Epoch:30/30]: lr:1.000e-04 | loss1:0.0068 loss2:0.2849 loss3:0.2765 | AUC:0.8769 Anomaly AUC:0.7056
[2023-10-03 00:18:43,782][main.py][line:232][INFO] [IDX:2/10] Training completes in 13m 45s | best AUCAUC:0.8764 Anomaly AUC:0.7142

[2023-10-03 00:19:42,719][main.py][line:187][INFO] Random initialize AUCAUC:0.4504 Anomaly AUC:0.52771
[2023-10-03 00:20:25,251][main.py][line:222][INFO] [IDX:5/10, Epoch:1/30]: lr:1.000e-04 | loss1:0.6435 loss2:1.3298 loss3:0.4168 | AUC:0.8461 Anomaly AUC:0.6262
[2023-10-03 00:21:11,244][main.py][line:222][INFO] [IDX:5/10, Epoch:2/30]: lr:1.000e-04 | loss1:0.2605 loss2:1.2189 loss3:0.4303 | AUC:0.8589 Anomaly AUC:0.6518
[2023-10-03 00:21:56,144][main.py][line:222][INFO] [IDX:5/10, Epoch:3/30]: lr:1.000e-04 | loss1:0.1404 loss2:1.0753 loss3:0.4143 | AUC:0.8680 Anomaly AUC:0.7005
[2023-10-03 00:22:41,926][main.py][line:222][INFO] [IDX:5/10, Epoch:4/30]: lr:1.000e-04 | loss1:0.1052 loss2:0.8880 loss3:0.3907 | AUC:0.8771 Anomaly AUC:0.7187
[2023-10-03 00:23:28,109][main.py][line:222][INFO] [IDX:5/10, Epoch:5/30]: lr:1.000e-04 | loss1:0.0444 loss2:0.7718 loss3:0.3715 | AUC:0.8753 Anomaly AUC:0.7124
[2023-10-03 00:24:14,201][main.py][line:222][INFO] [IDX:5/10, Epoch:6/30]: lr:1.000e-04 | loss1:0.0281 loss2:0.7149 loss3:0.3537 | AUC:0.8743 Anomaly AUC:0.7141
