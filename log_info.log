[2023-06-26 10:22:39,411][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': '/data/pyj/feat/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-06-26 10:22:41,974][main.py][line:113][INFO] total params:1.2091M
[2023-06-26 10:22:41,975][main.py][line:116][INFO] Training Mode
[2023-06-26 10:22:41,976][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-06-26 10:22:41,976][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0005
    lr: 0.0005
    weight_decay: 0
)

[2023-06-26 10:23:04,467][main.py][line:57][INFO] Random initialize AUC:0.5444 FAR:0.67905
[2023-06-26 10:28:20,970][main.py][line:74][INFO] [Epoch:1/50]: loss1:0.3674 loss2:1.0960 | AUC:0.8476 FAR:0.00341
[2023-06-26 10:30:40,865][main.py][line:74][INFO] [Epoch:2/50]: loss1:0.1536 loss2:0.8745 | AUC:0.8541 FAR:0.00519
[2023-06-26 10:33:03,047][main.py][line:74][INFO] [Epoch:3/50]: loss1:0.0670 loss2:0.7795 | AUC:0.8590 FAR:0.00314
[2023-06-26 10:35:17,897][main.py][line:74][INFO] [Epoch:4/50]: loss1:0.0374 loss2:0.7048 | AUC:0.8545 FAR:0.00242
[2023-06-26 10:37:32,002][main.py][line:74][INFO] [Epoch:5/50]: loss1:0.0248 loss2:0.6399 | AUC:0.8560 FAR:0.00232
[2023-06-26 10:39:47,095][main.py][line:74][INFO] [Epoch:6/50]: loss1:0.0166 loss2:0.5759 | AUC:0.8636 FAR:0.00580
[2023-06-26 10:42:02,062][main.py][line:74][INFO] [Epoch:7/50]: loss1:0.0365 loss2:0.5461 | AUC:0.8545 FAR:0.00328
[2023-06-26 10:44:15,828][main.py][line:74][INFO] [Epoch:8/50]: loss1:0.0120 loss2:0.4721 | AUC:0.8556 FAR:0.00264
[2023-06-26 10:46:30,014][main.py][line:74][INFO] [Epoch:9/50]: loss1:0.0087 loss2:0.4146 | AUC:0.8574 FAR:0.00259
[2023-06-26 10:48:41,037][main.py][line:74][INFO] [Epoch:10/50]: loss1:0.0081 loss2:0.3630 | AUC:0.8525 FAR:0.00370
[2023-06-26 10:50:55,236][main.py][line:74][INFO] [Epoch:11/50]: loss1:0.0073 loss2:0.3101 | AUC:0.8548 FAR:0.00408
[2023-06-26 10:53:07,085][main.py][line:74][INFO] [Epoch:12/50]: loss1:0.0064 loss2:0.2642 | AUC:0.8562 FAR:0.00235
[2023-06-26 10:55:18,935][main.py][line:74][INFO] [Epoch:13/50]: loss1:0.0161 loss2:0.2371 | AUC:0.8499 FAR:0.00790
[2023-06-26 10:57:37,384][main.py][line:74][INFO] [Epoch:14/50]: loss1:0.0484 loss2:0.2859 | AUC:0.8452 FAR:0.00368
[2023-06-26 11:00:35,001][main.py][line:74][INFO] [Epoch:15/50]: loss1:0.0098 loss2:0.2012 | AUC:0.8551 FAR:0.00304
[2023-06-26 11:03:11,084][main.py][line:74][INFO] [Epoch:16/50]: loss1:0.0094 loss2:0.1679 | AUC:0.8519 FAR:0.00306
[2023-06-26 11:05:38,862][main.py][line:74][INFO] [Epoch:17/50]: loss1:0.0147 loss2:0.1615 | AUC:0.8490 FAR:0.00277
[2023-06-26 11:08:03,205][main.py][line:74][INFO] [Epoch:18/50]: loss1:0.0047 loss2:0.1213 | AUC:0.8487 FAR:0.00227
[2023-06-26 11:10:24,212][main.py][line:74][INFO] [Epoch:19/50]: loss1:0.0036 loss2:0.0989 | AUC:0.8450 FAR:0.00245
[2023-06-26 11:13:19,243][main.py][line:74][INFO] [Epoch:20/50]: loss1:0.0041 loss2:0.0860 | AUC:0.8418 FAR:0.00232
[2023-06-26 11:15:38,669][main.py][line:74][INFO] [Epoch:21/50]: loss1:0.0029 loss2:0.0712 | AUC:0.8417 FAR:0.00200
[2023-06-26 11:18:00,753][main.py][line:74][INFO] [Epoch:22/50]: loss1:0.0024 loss2:0.0606 | AUC:0.8462 FAR:0.00235
[2023-06-26 11:20:18,162][main.py][line:74][INFO] [Epoch:23/50]: loss1:0.0020 loss2:0.0525 | AUC:0.8444 FAR:0.00311
[2023-06-26 11:22:40,464][main.py][line:74][INFO] [Epoch:24/50]: loss1:0.0017 loss2:0.0447 | AUC:0.8455 FAR:0.00232
[2023-06-26 11:24:56,506][main.py][line:74][INFO] [Epoch:25/50]: loss1:0.0018 loss2:0.0381 | AUC:0.8451 FAR:0.00319
[2023-06-26 11:27:15,959][main.py][line:74][INFO] [Epoch:26/50]: loss1:0.0017 loss2:0.0350 | AUC:0.8471 FAR:0.00257
[2023-06-26 11:29:41,893][main.py][line:74][INFO] [Epoch:27/50]: loss1:0.0015 loss2:0.0301 | AUC:0.8467 FAR:0.00232
[2023-06-26 11:32:09,740][main.py][line:74][INFO] [Epoch:28/50]: loss1:0.0014 loss2:0.0269 | AUC:0.8492 FAR:0.00262
[2023-06-26 11:34:33,227][main.py][line:74][INFO] [Epoch:29/50]: loss1:0.0010 loss2:0.0233 | AUC:0.8457 FAR:0.00299
[2023-06-26 11:37:08,390][main.py][line:74][INFO] [Epoch:30/50]: loss1:0.0258 loss2:0.0429 | AUC:0.8526 FAR:0.00294
[2023-06-26 11:39:32,361][main.py][line:74][INFO] [Epoch:31/50]: loss1:0.0112 loss2:0.0495 | AUC:0.8467 FAR:0.00294
[2023-06-26 11:41:57,373][main.py][line:74][INFO] [Epoch:32/50]: loss1:0.0028 loss2:0.0290 | AUC:0.8500 FAR:0.00289
[2023-06-26 11:44:23,142][main.py][line:74][INFO] [Epoch:33/50]: loss1:0.0014 loss2:0.0220 | AUC:0.8508 FAR:0.00319
[2023-06-26 11:46:44,860][main.py][line:74][INFO] [Epoch:34/50]: loss1:0.0010 loss2:0.0189 | AUC:0.8506 FAR:0.00343
[2023-06-26 11:49:10,181][main.py][line:74][INFO] [Epoch:35/50]: loss1:0.0010 loss2:0.0170 | AUC:0.8502 FAR:0.00408
[2023-06-26 11:51:38,606][main.py][line:74][INFO] [Epoch:36/50]: loss1:0.0011 loss2:0.0158 | AUC:0.8518 FAR:0.00314
[2023-06-26 11:53:58,995][main.py][line:74][INFO] [Epoch:37/50]: loss1:0.0029 loss2:0.0195 | AUC:0.8469 FAR:0.00380
[2023-06-26 11:56:12,383][main.py][line:74][INFO] [Epoch:38/50]: loss1:0.0009 loss2:0.0137 | AUC:0.8522 FAR:0.00368
[2023-06-26 11:58:23,435][main.py][line:74][INFO] [Epoch:39/50]: loss1:0.0008 loss2:0.0128 | AUC:0.8518 FAR:0.00366
[2023-06-26 12:00:33,337][main.py][line:74][INFO] [Epoch:40/50]: loss1:0.0006 loss2:0.0113 | AUC:0.8514 FAR:0.00380
[2023-06-26 12:02:45,002][main.py][line:74][INFO] [Epoch:41/50]: loss1:0.0006 loss2:0.0108 | AUC:0.8512 FAR:0.00405
[2023-06-26 12:05:00,560][main.py][line:74][INFO] [Epoch:42/50]: loss1:0.0005 loss2:0.0098 | AUC:0.8499 FAR:0.00316
[2023-06-26 12:07:11,449][main.py][line:74][INFO] [Epoch:43/50]: loss1:0.0005 loss2:0.0097 | AUC:0.8504 FAR:0.00368
[2023-06-26 12:09:23,488][main.py][line:74][INFO] [Epoch:44/50]: loss1:0.0005 loss2:0.0094 | AUC:0.8504 FAR:0.00353
[2023-06-26 12:11:36,193][main.py][line:74][INFO] [Epoch:45/50]: loss1:0.0005 loss2:0.0087 | AUC:0.8506 FAR:0.00385
[2023-06-26 12:13:48,758][main.py][line:74][INFO] [Epoch:46/50]: loss1:0.0004 loss2:0.0086 | AUC:0.8507 FAR:0.00348
[2023-06-26 12:15:58,737][main.py][line:74][INFO] [Epoch:47/50]: loss1:0.0005 loss2:0.0078 | AUC:0.8506 FAR:0.00346
[2023-06-26 12:18:23,042][main.py][line:74][INFO] [Epoch:48/50]: loss1:0.0004 loss2:0.0080 | AUC:0.8501 FAR:0.00326
[2023-06-26 12:20:36,653][main.py][line:74][INFO] [Epoch:49/50]: loss1:0.0004 loss2:0.0074 | AUC:0.8503 FAR:0.00373
[2023-06-26 12:23:07,479][main.py][line:74][INFO] [Epoch:50/50]: loss1:0.0004 loss2:0.0078 | AUC:0.8499 FAR:0.00341
[2023-06-26 12:23:07,491][main.py][line:80][INFO] Training completes in 120m 3s | best AUC:0.8636 FAR:0.00580

[2023-06-26 12:58:17,606][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': '/data/pyj/feat/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-06-26 12:58:19,910][main.py][line:113][INFO] total params:1.2091M
[2023-06-26 12:58:19,910][main.py][line:120][INFO] Test Mode
[2023-06-26 12:58:19,910][main.py][line:26][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-06-26 12:58:32,117][infer.py][line:47][INFO] offline AUC:0.8676 AP:0.3399 FAR:0.0047 | Complete in 0m 12s

[2023-06-26 12:59:02,787][main.py][line:87][INFO] Config:{'dataset': 'xd-violence', 'model_name': 'xd_', 'metrics': 'AP', 'feat_prefix': '/data/pyj/feat/xd-i3d', 'train_list': './list/xd/train.list', 'test_list': './list/xd/test.list', 'token_feat': './list/xd/xd-prompt.npy', 'gt': './list/xd/xd-gt.npy', 'win_size': 9, 'gamma': 0.06, 'bias': 0.02, 'norm': False, 't_step': 3, 'temp': 0.05, 'lamda': 1, 'seed': 4, 'test_bs': 5, 'smooth': 'fixed', 'kappa': 8, 'ckpt_path': './ckpt/xd__8526.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-06-26 12:59:05,198][main.py][line:113][INFO] total params:1.2073M
[2023-06-26 12:59:05,198][main.py][line:116][INFO] Training Mode
[2023-06-26 12:59:05,199][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(3,), stride=(1,))
)

[2023-06-26 12:59:05,200][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0005
    lr: 0.0005
    weight_decay: 0
)

[2023-06-26 12:59:18,902][main.py][line:57][INFO] Random initialize AP:0.2742 FAR:0.44700
[2023-06-26 13:01:57,379][main.py][line:74][INFO] [Epoch:1/50]: loss1:0.3384 loss2:0.5558 | AUC:0.7968 FAR:0.00456
[2023-06-26 13:04:52,989][main.py][line:74][INFO] [Epoch:2/50]: loss1:0.1947 loss2:0.3543 | AUC:0.8526 FAR:0.00625
[2023-06-26 13:07:34,256][main.py][line:74][INFO] [Epoch:3/50]: loss1:0.1335 loss2:0.2872 | AUC:0.8308 FAR:0.00221
[2023-06-26 13:10:18,471][main.py][line:74][INFO] [Epoch:4/50]: loss1:0.0996 loss2:0.2413 | AUC:0.8173 FAR:0.00126
[2023-06-26 13:12:57,282][main.py][line:74][INFO] [Epoch:5/50]: loss1:0.0694 loss2:0.2068 | AUC:0.8211 FAR:0.00284
[2023-06-26 13:15:36,887][main.py][line:74][INFO] [Epoch:6/50]: loss1:0.0557 loss2:0.1810 | AUC:0.7612 FAR:0.00112
[2023-06-26 13:18:18,239][main.py][line:74][INFO] [Epoch:7/50]: loss1:0.0558 loss2:0.1695 | AUC:0.8357 FAR:0.00404
[2023-06-26 13:20:57,396][main.py][line:74][INFO] [Epoch:8/50]: loss1:0.0400 loss2:0.1440 | AUC:0.8156 FAR:0.00363
[2023-06-26 13:23:37,743][main.py][line:74][INFO] [Epoch:9/50]: loss1:0.0278 loss2:0.1172 | AUC:0.7929 FAR:0.00229
[2023-06-26 13:26:19,042][main.py][line:74][INFO] [Epoch:10/50]: loss1:0.0448 loss2:0.1164 | AUC:0.8142 FAR:0.00328
[2023-06-26 13:28:58,999][main.py][line:74][INFO] [Epoch:11/50]: loss1:0.0307 loss2:0.1071 | AUC:0.8013 FAR:0.00066
[2023-06-26 13:31:42,415][main.py][line:74][INFO] [Epoch:12/50]: loss1:0.0209 loss2:0.0798 | AUC:0.8348 FAR:0.00309
[2023-06-26 13:34:19,254][main.py][line:74][INFO] [Epoch:13/50]: loss1:0.0175 loss2:0.0514 | AUC:0.8350 FAR:0.00263
[2023-06-26 13:36:51,850][main.py][line:74][INFO] [Epoch:14/50]: loss1:0.0101 loss2:0.0470 | AUC:0.7933 FAR:0.00080
[2023-06-26 13:39:23,674][main.py][line:74][INFO] [Epoch:15/50]: loss1:0.0108 loss2:0.0437 | AUC:0.8283 FAR:0.00231
[2023-06-26 13:42:20,757][main.py][line:74][INFO] [Epoch:16/50]: loss1:0.0082 loss2:0.0198 | AUC:0.7936 FAR:0.00064
[2023-06-26 13:44:59,435][main.py][line:74][INFO] [Epoch:17/50]: loss1:0.0154 loss2:0.0166 | AUC:0.8021 FAR:0.00121
[2023-06-26 13:47:50,154][main.py][line:74][INFO] [Epoch:18/50]: loss1:0.0185 loss2:0.0014 | AUC:0.8113 FAR:0.00184
[2023-06-26 13:50:30,184][main.py][line:74][INFO] [Epoch:19/50]: loss1:0.0046 loss2:0.0000 | AUC:0.8097 FAR:0.00215
[2023-06-26 13:53:36,445][main.py][line:74][INFO] [Epoch:20/50]: loss1:0.0036 loss2:0.0000 | AUC:0.8255 FAR:0.00179
[2023-06-26 13:56:21,920][main.py][line:74][INFO] [Epoch:21/50]: loss1:0.0255 loss2:0.0442 | AUC:0.7577 FAR:0.00151
[2023-06-26 13:58:58,932][main.py][line:74][INFO] [Epoch:22/50]: loss1:0.0109 loss2:0.0460 | AUC:0.7752 FAR:0.00054
[2023-06-26 14:01:49,618][main.py][line:74][INFO] [Epoch:23/50]: loss1:0.0079 loss2:0.0030 | AUC:0.8155 FAR:0.00156
[2023-06-26 14:04:31,046][main.py][line:74][INFO] [Epoch:24/50]: loss1:0.0082 loss2:0.0057 | AUC:0.8271 FAR:0.00207
[2023-06-26 14:07:17,468][main.py][line:74][INFO] [Epoch:25/50]: loss1:0.0022 loss2:0.0000 | AUC:0.8208 FAR:0.00239
[2023-06-26 14:10:09,596][main.py][line:74][INFO] [Epoch:26/50]: loss1:0.0061 loss2:0.0000 | AUC:0.8141 FAR:0.00144
[2023-06-26 14:13:11,678][main.py][line:74][INFO] [Epoch:27/50]: loss1:0.0033 loss2:0.0000 | AUC:0.8114 FAR:0.00133
[2023-06-26 14:15:41,063][main.py][line:74][INFO] [Epoch:28/50]: loss1:0.0025 loss2:0.0000 | AUC:0.8147 FAR:0.00180
[2023-06-26 14:18:21,049][main.py][line:74][INFO] [Epoch:29/50]: loss1:0.0018 loss2:0.0000 | AUC:0.8146 FAR:0.00144
[2023-06-26 14:21:01,533][main.py][line:74][INFO] [Epoch:30/50]: loss1:0.0010 loss2:0.0000 | AUC:0.8137 FAR:0.00170
[2023-06-26 14:23:50,767][main.py][line:74][INFO] [Epoch:31/50]: loss1:0.0116 loss2:0.0000 | AUC:0.8052 FAR:0.00183
[2023-06-26 14:26:37,664][main.py][line:74][INFO] [Epoch:32/50]: loss1:0.0133 loss2:0.0085 | AUC:0.8202 FAR:0.00126
[2023-06-26 14:29:21,201][main.py][line:74][INFO] [Epoch:33/50]: loss1:0.0022 loss2:0.0000 | AUC:0.8125 FAR:0.00354
[2023-06-26 14:32:20,565][main.py][line:74][INFO] [Epoch:34/50]: loss1:0.0011 loss2:0.0000 | AUC:0.8175 FAR:0.00199
[2023-06-26 14:35:02,375][main.py][line:74][INFO] [Epoch:35/50]: loss1:0.0018 loss2:0.0000 | AUC:0.8223 FAR:0.00252
[2023-06-26 14:37:52,408][main.py][line:74][INFO] [Epoch:36/50]: loss1:0.0009 loss2:0.0000 | AUC:0.8187 FAR:0.00286
[2023-06-26 14:40:35,544][main.py][line:74][INFO] [Epoch:37/50]: loss1:0.0007 loss2:0.0000 | AUC:0.8142 FAR:0.00266
[2023-06-26 14:43:26,219][main.py][line:74][INFO] [Epoch:38/50]: loss1:0.0006 loss2:0.0000 | AUC:0.8145 FAR:0.00217
[2023-06-26 14:46:16,282][main.py][line:74][INFO] [Epoch:39/50]: loss1:0.0006 loss2:0.0000 | AUC:0.8158 FAR:0.00236
[2023-06-26 14:49:05,279][main.py][line:74][INFO] [Epoch:40/50]: loss1:0.0006 loss2:0.0000 | AUC:0.8171 FAR:0.00236
[2023-06-26 14:51:52,563][main.py][line:74][INFO] [Epoch:41/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8156 FAR:0.00224
[2023-06-26 14:54:41,250][main.py][line:74][INFO] [Epoch:42/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8161 FAR:0.00212
[2023-06-26 14:57:32,924][main.py][line:74][INFO] [Epoch:43/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8148 FAR:0.00222
[2023-06-26 15:00:19,503][main.py][line:74][INFO] [Epoch:44/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8143 FAR:0.00239
[2023-06-26 15:03:07,044][main.py][line:74][INFO] [Epoch:45/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8150 FAR:0.00221
[2023-06-26 15:05:51,733][main.py][line:74][INFO] [Epoch:46/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8160 FAR:0.00236
[2023-06-26 15:08:43,028][main.py][line:74][INFO] [Epoch:47/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8150 FAR:0.00204
[2023-06-26 15:11:28,315][main.py][line:74][INFO] [Epoch:48/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8138 FAR:0.00220
[2023-06-26 15:14:14,464][main.py][line:74][INFO] [Epoch:49/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8136 FAR:0.00221
[2023-06-26 15:16:59,857][main.py][line:74][INFO] [Epoch:50/50]: loss1:0.0005 loss2:0.0000 | AUC:0.8146 FAR:0.00222
[2023-06-26 15:16:59,870][main.py][line:80][INFO] Training completes in 137m 41s | best AP:0.8526 FAR:0.00625

[2023-06-26 15:41:47,285][main.py][line:87][INFO] Config:{'dataset': 'xd-violence', 'model_name': 'xd_', 'metrics': 'AP', 'feat_prefix': '/data/pyj/feat/xd-i3d', 'train_list': './list/xd/train.list', 'test_list': './list/xd/test.list', 'token_feat': './list/xd/xd-prompt.npy', 'gt': './list/xd/xd-gt.npy', 'win_size': 9, 'gamma': 0.06, 'bias': 0.02, 'norm': False, 't_step': 3, 'temp': 0.05, 'lamda': 1, 'seed': 4, 'test_bs': 5, 'smooth': 'fixed', 'kappa': 8, 'ckpt_path': './ckpt/xd__8526.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-06-26 15:41:49,642][main.py][line:113][INFO] total params:1.2073M
[2023-06-26 15:41:49,643][main.py][line:120][INFO] Test Mode
[2023-06-26 15:41:49,643][main.py][line:26][INFO] loading pretrained checkpoint from ./ckpt/xd__8526.pkl.
[2023-06-26 15:42:03,950][infer.py][line:47][INFO] offline AUC:0.9494 AP:0.8559 FAR:0.0057 | Complete in 0m 14s

[2023-06-26 15:57:20,503][main.py][line:87][INFO] Config:{'dataset': 'shanghaiTech', 'model_name': 'SH_', 'metrics': 'AUC', 'feat_prefix': '/data/pyj/feat/SHTech-i3d', 'train_list': './list/sh/train.list', 'test_list': './list/sh/test.list', 'token_feat': './list/sh/sh-prompt.npy', 'abn_label': './list/sh/relabel.list', 'gt': './list/sh/sh-gt.npy', 'win_size': 5, 'gamma': 0.08, 'bias': 0.1, 'norm': True, 't_step': 3, 'temp': 0.2, 'lamda': 9, 'seed': 0, 'test_bs': 10, 'smooth': 'slide', 'kappa': 3, 'ckpt_path': './ckpt/SH__98.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-06-26 15:57:22,852][main.py][line:113][INFO] total params:1.2073M
[2023-06-26 15:57:22,852][main.py][line:116][INFO] Training Mode
[2023-06-26 15:57:22,853][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(3,), stride=(1,))
)

[2023-06-26 15:57:22,853][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0005
    lr: 0.0005
    weight_decay: 0
)

[2023-06-26 15:57:28,770][main.py][line:57][INFO] Random initialize AUC:0.5546 FAR:0.00402
[2023-06-26 15:57:47,743][main.py][line:74][INFO] [Epoch:1/50]: loss1:0.4849 loss2:0.7652 | AUC:0.9503 FAR:0.00013
[2023-06-26 15:58:02,767][main.py][line:74][INFO] [Epoch:2/50]: loss1:0.2230 loss2:0.6820 | AUC:0.9743 FAR:0.00013
[2023-06-26 15:58:17,780][main.py][line:74][INFO] [Epoch:3/50]: loss1:0.1478 loss2:0.6645 | AUC:0.9720 FAR:0.00052
[2023-06-26 15:58:33,830][main.py][line:74][INFO] [Epoch:4/50]: loss1:0.1041 loss2:0.6497 | AUC:0.9708 FAR:0.00675
[2023-06-26 15:58:48,718][main.py][line:74][INFO] [Epoch:5/50]: loss1:0.0817 loss2:0.6001 | AUC:0.9727 FAR:0.00117
[2023-06-26 15:59:03,862][main.py][line:74][INFO] [Epoch:6/50]: loss1:0.0786 loss2:0.5964 | AUC:0.9701 FAR:0.00221
[2023-06-26 15:59:25,136][main.py][line:74][INFO] [Epoch:7/50]: loss1:0.0591 loss2:0.5651 | AUC:0.9710 FAR:0.00065
[2023-06-26 15:59:44,337][main.py][line:74][INFO] [Epoch:8/50]: loss1:0.0509 loss2:0.5515 | AUC:0.9725 FAR:0.00039
[2023-06-26 15:59:59,596][main.py][line:74][INFO] [Epoch:9/50]: loss1:0.0404 loss2:0.5450 | AUC:0.9747 FAR:0.00039
[2023-06-26 16:00:16,175][main.py][line:74][INFO] [Epoch:10/50]: loss1:0.0459 loss2:0.5249 | AUC:0.9747 FAR:0.00286
[2023-06-26 16:00:31,393][main.py][line:74][INFO] [Epoch:11/50]: loss1:0.0296 loss2:0.4967 | AUC:0.9746 FAR:0.00026
[2023-06-26 16:00:46,321][main.py][line:74][INFO] [Epoch:12/50]: loss1:0.0291 loss2:0.4867 | AUC:0.9745 FAR:0.00208
[2023-06-26 16:01:01,580][main.py][line:74][INFO] [Epoch:13/50]: loss1:0.0219 loss2:0.4663 | AUC:0.9758 FAR:0.00234
[2023-06-26 16:01:16,639][main.py][line:74][INFO] [Epoch:14/50]: loss1:0.0229 loss2:0.4645 | AUC:0.9757 FAR:0.00013
[2023-06-26 16:01:31,589][main.py][line:74][INFO] [Epoch:15/50]: loss1:0.0174 loss2:0.4635 | AUC:0.9765 FAR:0.00026
[2023-06-26 16:01:46,888][main.py][line:74][INFO] [Epoch:16/50]: loss1:0.0178 loss2:0.4456 | AUC:0.9756 FAR:0.00104
[2023-06-26 16:02:03,523][main.py][line:74][INFO] [Epoch:17/50]: loss1:0.0147 loss2:0.4356 | AUC:0.9780 FAR:0.00039
[2023-06-26 16:02:18,675][main.py][line:74][INFO] [Epoch:18/50]: loss1:0.0140 loss2:0.4257 | AUC:0.9786 FAR:0.00000
[2023-06-26 16:02:33,844][main.py][line:74][INFO] [Epoch:19/50]: loss1:0.0131 loss2:0.4216 | AUC:0.9764 FAR:0.00026
[2023-06-26 16:02:49,216][main.py][line:74][INFO] [Epoch:20/50]: loss1:0.0161 loss2:0.4072 | AUC:0.9791 FAR:0.00013
[2023-06-26 16:03:04,618][main.py][line:74][INFO] [Epoch:21/50]: loss1:0.0127 loss2:0.3953 | AUC:0.9773 FAR:0.00026
[2023-06-26 16:03:20,056][main.py][line:74][INFO] [Epoch:22/50]: loss1:0.0160 loss2:0.4061 | AUC:0.9800 FAR:0.00000
[2023-06-26 16:03:35,280][main.py][line:74][INFO] [Epoch:23/50]: loss1:0.0083 loss2:0.3886 | AUC:0.9787 FAR:0.00052
[2023-06-26 16:03:50,522][main.py][line:74][INFO] [Epoch:24/50]: loss1:0.0090 loss2:0.3822 | AUC:0.9796 FAR:0.00091
[2023-06-26 16:04:05,581][main.py][line:74][INFO] [Epoch:25/50]: loss1:0.0085 loss2:0.3805 | AUC:0.9793 FAR:0.00052
[2023-06-26 16:04:20,777][main.py][line:74][INFO] [Epoch:26/50]: loss1:0.0087 loss2:0.3793 | AUC:0.9785 FAR:0.00026
[2023-06-26 16:04:36,022][main.py][line:74][INFO] [Epoch:27/50]: loss1:0.0082 loss2:0.3715 | AUC:0.9787 FAR:0.00117
[2023-06-26 16:04:51,156][main.py][line:74][INFO] [Epoch:28/50]: loss1:0.0069 loss2:0.3495 | AUC:0.9791 FAR:0.00026
[2023-06-26 16:05:06,556][main.py][line:74][INFO] [Epoch:29/50]: loss1:0.0068 loss2:0.3575 | AUC:0.9794 FAR:0.00026
[2023-06-26 16:05:21,932][main.py][line:74][INFO] [Epoch:30/50]: loss1:0.0066 loss2:0.3542 | AUC:0.9788 FAR:0.00052
[2023-06-26 16:05:37,223][main.py][line:74][INFO] [Epoch:31/50]: loss1:0.0071 loss2:0.3470 | AUC:0.9789 FAR:0.00039
[2023-06-26 16:05:52,259][main.py][line:74][INFO] [Epoch:32/50]: loss1:0.0077 loss2:0.3470 | AUC:0.9764 FAR:0.00026
[2023-06-26 16:06:07,467][main.py][line:74][INFO] [Epoch:33/50]: loss1:0.0122 loss2:0.3454 | AUC:0.9787 FAR:0.00052
[2023-06-26 16:06:26,627][main.py][line:74][INFO] [Epoch:34/50]: loss1:0.0067 loss2:0.3325 | AUC:0.9787 FAR:0.00026
[2023-06-26 16:06:41,889][main.py][line:74][INFO] [Epoch:35/50]: loss1:0.0075 loss2:0.3349 | AUC:0.9791 FAR:0.00078
[2023-06-26 16:06:57,134][main.py][line:74][INFO] [Epoch:36/50]: loss1:0.0073 loss2:0.3387 | AUC:0.9782 FAR:0.00026
[2023-06-26 16:07:12,229][main.py][line:74][INFO] [Epoch:37/50]: loss1:0.0064 loss2:0.3327 | AUC:0.9781 FAR:0.00039
[2023-06-26 16:07:27,618][main.py][line:74][INFO] [Epoch:38/50]: loss1:0.0057 loss2:0.3290 | AUC:0.9792 FAR:0.00026
[2023-06-26 16:07:42,658][main.py][line:74][INFO] [Epoch:39/50]: loss1:0.0060 loss2:0.3263 | AUC:0.9782 FAR:0.00026
[2023-06-26 16:07:57,784][main.py][line:74][INFO] [Epoch:40/50]: loss1:0.0056 loss2:0.3296 | AUC:0.9785 FAR:0.00026
[2023-06-26 16:08:12,894][main.py][line:74][INFO] [Epoch:41/50]: loss1:0.0053 loss2:0.3223 | AUC:0.9791 FAR:0.00026
[2023-06-26 16:08:28,308][main.py][line:74][INFO] [Epoch:42/50]: loss1:0.0051 loss2:0.3198 | AUC:0.9784 FAR:0.00026
[2023-06-26 16:08:43,714][main.py][line:74][INFO] [Epoch:43/50]: loss1:0.0047 loss2:0.3193 | AUC:0.9782 FAR:0.00026
[2023-06-26 16:08:59,230][main.py][line:74][INFO] [Epoch:44/50]: loss1:0.0052 loss2:0.3182 | AUC:0.9784 FAR:0.00013
[2023-06-26 16:09:14,430][main.py][line:74][INFO] [Epoch:45/50]: loss1:0.0055 loss2:0.3144 | AUC:0.9780 FAR:0.00039
[2023-06-26 16:09:29,465][main.py][line:74][INFO] [Epoch:46/50]: loss1:0.0051 loss2:0.3161 | AUC:0.9782 FAR:0.00052
[2023-06-26 16:09:44,569][main.py][line:74][INFO] [Epoch:47/50]: loss1:0.0054 loss2:0.3129 | AUC:0.9780 FAR:0.00026
[2023-06-26 16:09:59,630][main.py][line:74][INFO] [Epoch:48/50]: loss1:0.0052 loss2:0.3086 | AUC:0.9780 FAR:0.00026
[2023-06-26 16:10:14,719][main.py][line:74][INFO] [Epoch:49/50]: loss1:0.0053 loss2:0.3102 | AUC:0.9776 FAR:0.00026
[2023-06-26 16:10:30,256][main.py][line:74][INFO] [Epoch:50/50]: loss1:0.0054 loss2:0.3068 | AUC:0.9778 FAR:0.00026
[2023-06-26 16:10:30,266][main.py][line:80][INFO] Training completes in 13m 1s | best AUC:0.9800 FAR:0.00000

[2023-06-26 16:11:33,636][main.py][line:87][INFO] Config:{'dataset': 'shanghaiTech', 'model_name': 'SH_', 'metrics': 'AUC', 'feat_prefix': '/data/pyj/feat/SHTech-i3d', 'train_list': './list/sh/train.list', 'test_list': './list/sh/test.list', 'token_feat': './list/sh/sh-prompt.npy', 'abn_label': './list/sh/relabel.list', 'gt': './list/sh/sh-gt.npy', 'win_size': 5, 'gamma': 0.08, 'bias': 0.1, 'norm': True, 't_step': 3, 'temp': 0.2, 'lamda': 9, 'seed': 0, 'test_bs': 10, 'smooth': 'slide', 'kappa': 3, 'ckpt_path': './ckpt/SH__98.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-06-26 16:11:36,131][main.py][line:113][INFO] total params:1.2073M
[2023-06-26 16:11:36,132][main.py][line:120][INFO] Test Mode
[2023-06-26 16:11:36,132][main.py][line:26][INFO] loading pretrained checkpoint from ./ckpt/SH__98.pkl.
[2023-06-26 16:11:39,240][infer.py][line:47][INFO] offline AUC:0.9814 AP:0.7256 FAR:0.0000 | Complete in 0m 3s

[2023-07-18 18:54:03,714][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 18:59:39,683][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 18:59:39,770][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 18:59:39,770][main.py][line:116][INFO] Training Mode
[2023-07-18 18:59:39,770][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 18:59:39,770][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 19:00:55,941][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 19:00:56,021][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 19:00:56,021][main.py][line:116][INFO] Training Mode
[2023-07-18 19:00:56,021][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 19:00:56,021][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 19:01:19,432][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 19:01:19,510][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 19:01:19,510][main.py][line:116][INFO] Training Mode
[2023-07-18 19:01:19,510][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 19:01:19,510][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 21:09:03,798][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 21:09:03,867][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 21:09:03,867][main.py][line:116][INFO] Training Mode
[2023-07-18 21:09:03,868][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 21:09:03,868][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 21:10:13,301][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 21:10:13,386][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 21:10:13,386][main.py][line:116][INFO] Training Mode
[2023-07-18 21:10:13,386][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 21:10:13,386][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 21:11:15,753][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': 'data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 21:11:15,839][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 21:11:15,839][main.py][line:116][INFO] Training Mode
[2023-07-18 21:11:15,839][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 21:11:15,839][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 21:13:07,296][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 21:13:07,372][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 21:13:07,372][main.py][line:116][INFO] Training Mode
[2023-07-18 21:13:07,372][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 21:13:07,372][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-18 21:19:16,657][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-18 21:19:16,735][main.py][line:113][INFO] total params:1.2091M
[2023-07-18 21:19:16,735][main.py][line:116][INFO] Training Mode
[2023-07-18 21:19:16,736][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-18 21:19:16,736][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 11:27:03,988][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 11:27:04,068][main.py][line:113][INFO] total params:1.2091M
[2023-07-19 11:27:04,068][main.py][line:116][INFO] Training Mode
[2023-07-19 11:27:04,068][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-19 11:27:04,068][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 11:27:09,343][main.py][line:57][INFO] Random initialize AUC:0.5444 FAR:0.67905
[2023-07-19 12:21:54,239][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 12:21:54,309][main.py][line:113][INFO] total params:1.2091M
[2023-07-19 12:21:54,309][main.py][line:116][INFO] Training Mode
[2023-07-19 12:21:54,309][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-19 12:21:54,309][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 12:22:00,012][main.py][line:57][INFO] Random initialize AUC:0.5444 FAR:0.67905
[2023-07-19 12:23:08,184][main.py][line:74][INFO] [Epoch:1/50]: loss1:0.3876 loss2:1.1033 | AUC:0.8392 FAR:0.01675
[2023-07-19 12:24:18,179][main.py][line:74][INFO] [Epoch:2/50]: loss1:0.1549 loss2:0.8760 | AUC:0.8480 FAR:0.00432
[2023-07-19 12:25:21,828][main.py][line:74][INFO] [Epoch:3/50]: loss1:0.0676 loss2:0.7808 | AUC:0.8484 FAR:0.00615
[2023-07-19 12:26:25,442][main.py][line:74][INFO] [Epoch:4/50]: loss1:0.0359 loss2:0.7089 | AUC:0.8434 FAR:0.01408
[2023-07-19 12:27:20,958][main.py][line:74][INFO] [Epoch:5/50]: loss1:0.0322 loss2:0.6461 | AUC:0.8439 FAR:0.00445
[2023-07-19 12:28:19,012][main.py][line:74][INFO] [Epoch:6/50]: loss1:0.0299 loss2:0.5980 | AUC:0.8548 FAR:0.00457
[2023-07-19 12:29:19,856][main.py][line:74][INFO] [Epoch:7/50]: loss1:0.0124 loss2:0.5263 | AUC:0.8540 FAR:0.00385
[2023-07-19 12:30:19,107][main.py][line:74][INFO] [Epoch:8/50]: loss1:0.0097 loss2:0.4665 | AUC:0.8489 FAR:0.00336
[2023-07-19 12:31:18,359][main.py][line:74][INFO] [Epoch:9/50]: loss1:0.0145 loss2:0.4156 | AUC:0.8466 FAR:0.02181
[2023-07-19 12:32:18,710][main.py][line:74][INFO] [Epoch:10/50]: loss1:0.0372 loss2:0.4206 | AUC:0.8433 FAR:0.00766
[2023-07-19 12:33:18,271][main.py][line:74][INFO] [Epoch:11/50]: loss1:0.0131 loss2:0.3500 | AUC:0.8461 FAR:0.00257
[2023-07-19 12:34:14,807][main.py][line:74][INFO] [Epoch:12/50]: loss1:0.0120 loss2:0.2901 | AUC:0.8480 FAR:0.00450
[2023-07-19 12:35:12,484][main.py][line:74][INFO] [Epoch:13/50]: loss1:0.0063 loss2:0.2259 | AUC:0.8495 FAR:0.00336
[2023-07-19 12:36:15,644][main.py][line:74][INFO] [Epoch:14/50]: loss1:0.0100 loss2:0.1968 | AUC:0.8492 FAR:0.00454
[2023-07-19 12:37:14,230][main.py][line:74][INFO] [Epoch:15/50]: loss1:0.0049 loss2:0.1675 | AUC:0.8493 FAR:0.00412
[2023-07-19 12:38:15,076][main.py][line:74][INFO] [Epoch:16/50]: loss1:0.0040 loss2:0.1473 | AUC:0.8468 FAR:0.00247
[2023-07-19 12:39:14,637][main.py][line:74][INFO] [Epoch:17/50]: loss1:0.0035 loss2:0.1242 | AUC:0.8470 FAR:0.00346
[2023-07-19 12:40:12,584][main.py][line:74][INFO] [Epoch:18/50]: loss1:0.0032 loss2:0.1100 | AUC:0.8485 FAR:0.00309
[2023-07-19 12:41:10,767][main.py][line:74][INFO] [Epoch:19/50]: loss1:0.0030 loss2:0.0976 | AUC:0.8466 FAR:0.00306
[2023-07-19 12:42:10,567][main.py][line:74][INFO] [Epoch:20/50]: loss1:0.0158 loss2:0.1086 | AUC:0.8364 FAR:0.00232
[2023-07-19 12:43:11,065][main.py][line:74][INFO] [Epoch:21/50]: loss1:0.0228 loss2:0.1320 | AUC:0.8434 FAR:0.00427
[2023-07-19 12:44:10,795][main.py][line:74][INFO] [Epoch:22/50]: loss1:0.0101 loss2:0.1010 | AUC:0.8441 FAR:0.00521
[2023-07-19 12:45:10,883][main.py][line:74][INFO] [Epoch:23/50]: loss1:0.0045 loss2:0.0745 | AUC:0.8465 FAR:0.00370
[2023-07-19 12:46:08,643][main.py][line:74][INFO] [Epoch:24/50]: loss1:0.0030 loss2:0.0618 | AUC:0.8506 FAR:0.00442
[2023-07-19 12:47:08,362][main.py][line:74][INFO] [Epoch:25/50]: loss1:0.0022 loss2:0.0517 | AUC:0.8491 FAR:0.00469
[2023-07-19 12:48:07,082][main.py][line:74][INFO] [Epoch:26/50]: loss1:0.0017 loss2:0.0433 | AUC:0.8502 FAR:0.00383
[2023-07-19 12:49:05,367][main.py][line:74][INFO] [Epoch:27/50]: loss1:0.0015 loss2:0.0376 | AUC:0.8500 FAR:0.00400
[2023-07-19 12:50:05,385][main.py][line:74][INFO] [Epoch:28/50]: loss1:0.0017 loss2:0.0341 | AUC:0.8437 FAR:0.00351
[2023-07-19 12:51:03,628][main.py][line:74][INFO] [Epoch:29/50]: loss1:0.0015 loss2:0.0298 | AUC:0.8479 FAR:0.00390
[2023-07-19 12:52:00,475][main.py][line:74][INFO] [Epoch:30/50]: loss1:0.0013 loss2:0.0263 | AUC:0.8473 FAR:0.00408
[2023-07-19 12:52:58,913][main.py][line:74][INFO] [Epoch:31/50]: loss1:0.0019 loss2:0.0247 | AUC:0.8495 FAR:0.00383
[2023-07-19 12:54:03,204][main.py][line:74][INFO] [Epoch:32/50]: loss1:0.0014 loss2:0.0247 | AUC:0.8509 FAR:0.00333
[2023-07-19 12:55:04,813][main.py][line:74][INFO] [Epoch:33/50]: loss1:0.0011 loss2:0.0219 | AUC:0.8533 FAR:0.00380
[2023-07-19 12:56:03,081][main.py][line:74][INFO] [Epoch:34/50]: loss1:0.0010 loss2:0.0196 | AUC:0.8535 FAR:0.00398
[2023-07-19 12:57:01,575][main.py][line:74][INFO] [Epoch:35/50]: loss1:0.0009 loss2:0.0185 | AUC:0.8520 FAR:0.00351
[2023-07-19 12:57:59,037][main.py][line:74][INFO] [Epoch:36/50]: loss1:0.0008 loss2:0.0169 | AUC:0.8509 FAR:0.00363
[2023-07-19 12:58:56,710][main.py][line:74][INFO] [Epoch:37/50]: loss1:0.0007 loss2:0.0148 | AUC:0.8505 FAR:0.00388
[2023-07-19 12:59:53,102][main.py][line:74][INFO] [Epoch:38/50]: loss1:0.0007 loss2:0.0150 | AUC:0.8505 FAR:0.00341
[2023-07-19 13:00:50,637][main.py][line:74][INFO] [Epoch:39/50]: loss1:0.0007 loss2:0.0135 | AUC:0.8520 FAR:0.00385
[2023-07-19 13:01:46,874][main.py][line:74][INFO] [Epoch:40/50]: loss1:0.0006 loss2:0.0131 | AUC:0.8513 FAR:0.00388
[2023-07-19 13:02:44,088][main.py][line:74][INFO] [Epoch:41/50]: loss1:0.0006 loss2:0.0121 | AUC:0.8509 FAR:0.00338
[2023-07-19 13:03:40,512][main.py][line:74][INFO] [Epoch:42/50]: loss1:0.0007 loss2:0.0123 | AUC:0.8483 FAR:0.00405
[2023-07-19 13:04:39,407][main.py][line:74][INFO] [Epoch:43/50]: loss1:0.0006 loss2:0.0115 | AUC:0.8496 FAR:0.00403
[2023-07-19 13:05:38,419][main.py][line:74][INFO] [Epoch:44/50]: loss1:0.0005 loss2:0.0106 | AUC:0.8506 FAR:0.00383
[2023-07-19 13:06:39,686][main.py][line:74][INFO] [Epoch:45/50]: loss1:0.0005 loss2:0.0100 | AUC:0.8501 FAR:0.00378
[2023-07-19 13:07:36,798][main.py][line:74][INFO] [Epoch:46/50]: loss1:0.0005 loss2:0.0094 | AUC:0.8489 FAR:0.00375
[2023-07-19 13:08:36,666][main.py][line:74][INFO] [Epoch:47/50]: loss1:0.0004 loss2:0.0093 | AUC:0.8492 FAR:0.00378
[2023-07-19 13:09:35,876][main.py][line:74][INFO] [Epoch:48/50]: loss1:0.0005 loss2:0.0092 | AUC:0.8489 FAR:0.00348
[2023-07-19 13:10:34,812][main.py][line:74][INFO] [Epoch:49/50]: loss1:0.0004 loss2:0.0091 | AUC:0.8498 FAR:0.00370
[2023-07-19 13:11:34,259][main.py][line:74][INFO] [Epoch:50/50]: loss1:0.0004 loss2:0.0083 | AUC:0.8498 FAR:0.00366
[2023-07-19 13:11:34,271][main.py][line:80][INFO] Training completes in 49m 34s | best AUC:0.8548 FAR:0.00457

[2023-07-19 13:34:44,147][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 13:34:44,242][main.py][line:113][INFO] total params:1.2091M
[2023-07-19 13:34:44,242][main.py][line:120][INFO] Test Mode
[2023-07-19 13:34:44,242][main.py][line:26][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-19 13:34:49,601][infer.py][line:47][INFO] offline AUC:0.8676 AP:0.3399 FAR:0.0047 | Complete in 0m 5s

[2023-07-19 13:36:37,769][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 13:36:37,837][main.py][line:113][INFO] total params:1.2091M
[2023-07-19 13:36:37,837][main.py][line:120][INFO] Test Mode
[2023-07-19 13:36:37,837][main.py][line:26][INFO] loading pretrained checkpoint from ./ckpt/ucf__8548.pkl.
[2023-07-19 13:36:43,176][infer.py][line:47][INFO] offline AUC:0.8601 AP:0.3172 FAR:0.0036 | Complete in 0m 5s

[2023-07-19 13:44:17,248][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 13:44:17,327][main.py][line:113][INFO] total params:1.2091M
[2023-07-19 13:44:17,327][main.py][line:116][INFO] Training Mode
[2023-07-19 13:44:17,328][main.py][line:53][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-19 13:44:17,328][main.py][line:54][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 13:44:22,210][main.py][line:57][INFO] Random initialize AUC:0.5444 FAR:0.67905
[2023-07-19 13:45:12,135][main.py][line:74][INFO] [Epoch:1/50]: loss1:0.3876 loss2:1.1033 | AUC:0.8392 FAR:0.01675
[2023-07-19 13:46:04,114][main.py][line:74][INFO] [Epoch:2/50]: loss1:0.1549 loss2:0.8760 | AUC:0.8480 FAR:0.00432
[2023-07-19 13:46:55,996][main.py][line:74][INFO] [Epoch:3/50]: loss1:0.0676 loss2:0.7808 | AUC:0.8484 FAR:0.00615
[2023-07-19 13:47:46,716][main.py][line:74][INFO] [Epoch:4/50]: loss1:0.0359 loss2:0.7089 | AUC:0.8434 FAR:0.01408
[2023-07-19 13:48:38,106][main.py][line:74][INFO] [Epoch:5/50]: loss1:0.0322 loss2:0.6461 | AUC:0.8439 FAR:0.00445
[2023-07-19 13:49:30,838][main.py][line:74][INFO] [Epoch:6/50]: loss1:0.0299 loss2:0.5980 | AUC:0.8548 FAR:0.00457
[2023-07-19 13:50:22,555][main.py][line:74][INFO] [Epoch:7/50]: loss1:0.0124 loss2:0.5263 | AUC:0.8540 FAR:0.00385
[2023-07-19 13:51:14,730][main.py][line:74][INFO] [Epoch:8/50]: loss1:0.0097 loss2:0.4665 | AUC:0.8489 FAR:0.00336
[2023-07-19 13:52:06,086][main.py][line:74][INFO] [Epoch:9/50]: loss1:0.0145 loss2:0.4156 | AUC:0.8466 FAR:0.02181
[2023-07-19 13:52:58,214][main.py][line:74][INFO] [Epoch:10/50]: loss1:0.0372 loss2:0.4206 | AUC:0.8433 FAR:0.00766
[2023-07-19 13:53:49,869][main.py][line:74][INFO] [Epoch:11/50]: loss1:0.0131 loss2:0.3500 | AUC:0.8461 FAR:0.00257
[2023-07-19 13:54:43,000][main.py][line:74][INFO] [Epoch:12/50]: loss1:0.0120 loss2:0.2901 | AUC:0.8480 FAR:0.00450
[2023-07-19 13:55:34,854][main.py][line:74][INFO] [Epoch:13/50]: loss1:0.0063 loss2:0.2259 | AUC:0.8495 FAR:0.00336
[2023-07-19 13:56:27,173][main.py][line:74][INFO] [Epoch:14/50]: loss1:0.0100 loss2:0.1968 | AUC:0.8492 FAR:0.00454
[2023-07-19 13:57:19,376][main.py][line:74][INFO] [Epoch:15/50]: loss1:0.0049 loss2:0.1675 | AUC:0.8493 FAR:0.00412
[2023-07-19 13:58:11,296][main.py][line:74][INFO] [Epoch:16/50]: loss1:0.0040 loss2:0.1473 | AUC:0.8468 FAR:0.00247
[2023-07-19 13:59:02,315][main.py][line:74][INFO] [Epoch:17/50]: loss1:0.0035 loss2:0.1242 | AUC:0.8470 FAR:0.00346
[2023-07-19 13:59:52,658][main.py][line:74][INFO] [Epoch:18/50]: loss1:0.0032 loss2:0.1100 | AUC:0.8485 FAR:0.00309
[2023-07-19 14:00:43,211][main.py][line:74][INFO] [Epoch:19/50]: loss1:0.0030 loss2:0.0976 | AUC:0.8466 FAR:0.00306
[2023-07-19 14:01:33,752][main.py][line:74][INFO] [Epoch:20/50]: loss1:0.0158 loss2:0.1086 | AUC:0.8364 FAR:0.00232
[2023-07-19 14:02:25,479][main.py][line:74][INFO] [Epoch:21/50]: loss1:0.0228 loss2:0.1320 | AUC:0.8434 FAR:0.00427
[2023-07-19 14:03:17,481][main.py][line:74][INFO] [Epoch:22/50]: loss1:0.0101 loss2:0.1010 | AUC:0.8441 FAR:0.00521
[2023-07-19 14:04:08,212][main.py][line:74][INFO] [Epoch:23/50]: loss1:0.0045 loss2:0.0745 | AUC:0.8465 FAR:0.00370
[2023-07-19 14:04:59,895][main.py][line:74][INFO] [Epoch:24/50]: loss1:0.0030 loss2:0.0618 | AUC:0.8506 FAR:0.00442
[2023-07-19 14:05:51,942][main.py][line:74][INFO] [Epoch:25/50]: loss1:0.0022 loss2:0.0517 | AUC:0.8491 FAR:0.00469
[2023-07-19 14:06:43,910][main.py][line:74][INFO] [Epoch:26/50]: loss1:0.0017 loss2:0.0433 | AUC:0.8502 FAR:0.00383
[2023-07-19 14:07:34,779][main.py][line:74][INFO] [Epoch:27/50]: loss1:0.0015 loss2:0.0376 | AUC:0.8500 FAR:0.00400
[2023-07-19 14:08:26,450][main.py][line:74][INFO] [Epoch:28/50]: loss1:0.0017 loss2:0.0341 | AUC:0.8437 FAR:0.00351
[2023-07-19 14:09:18,383][main.py][line:74][INFO] [Epoch:29/50]: loss1:0.0015 loss2:0.0298 | AUC:0.8479 FAR:0.00390
[2023-07-19 14:10:09,184][main.py][line:74][INFO] [Epoch:30/50]: loss1:0.0013 loss2:0.0263 | AUC:0.8473 FAR:0.00408
[2023-07-19 14:11:00,238][main.py][line:74][INFO] [Epoch:31/50]: loss1:0.0019 loss2:0.0247 | AUC:0.8495 FAR:0.00383
[2023-07-19 14:11:51,064][main.py][line:74][INFO] [Epoch:32/50]: loss1:0.0014 loss2:0.0247 | AUC:0.8509 FAR:0.00333
[2023-07-19 14:12:43,198][main.py][line:74][INFO] [Epoch:33/50]: loss1:0.0011 loss2:0.0219 | AUC:0.8533 FAR:0.00380
[2023-07-19 14:13:33,490][main.py][line:74][INFO] [Epoch:34/50]: loss1:0.0010 loss2:0.0196 | AUC:0.8535 FAR:0.00398
[2023-07-19 14:14:24,571][main.py][line:74][INFO] [Epoch:35/50]: loss1:0.0009 loss2:0.0185 | AUC:0.8520 FAR:0.00351
[2023-07-19 14:15:15,101][main.py][line:74][INFO] [Epoch:36/50]: loss1:0.0008 loss2:0.0169 | AUC:0.8509 FAR:0.00363
[2023-07-19 14:16:06,224][main.py][line:74][INFO] [Epoch:37/50]: loss1:0.0007 loss2:0.0148 | AUC:0.8505 FAR:0.00388
[2023-07-19 14:16:57,093][main.py][line:74][INFO] [Epoch:38/50]: loss1:0.0007 loss2:0.0150 | AUC:0.8505 FAR:0.00341
[2023-07-19 14:17:47,626][main.py][line:74][INFO] [Epoch:39/50]: loss1:0.0007 loss2:0.0135 | AUC:0.8520 FAR:0.00385
[2023-07-19 14:18:39,840][main.py][line:74][INFO] [Epoch:40/50]: loss1:0.0006 loss2:0.0131 | AUC:0.8513 FAR:0.00388
[2023-07-19 14:19:31,497][main.py][line:74][INFO] [Epoch:41/50]: loss1:0.0006 loss2:0.0121 | AUC:0.8509 FAR:0.00338
[2023-07-19 14:20:22,261][main.py][line:74][INFO] [Epoch:42/50]: loss1:0.0007 loss2:0.0123 | AUC:0.8483 FAR:0.00405
[2023-07-19 14:21:14,083][main.py][line:74][INFO] [Epoch:43/50]: loss1:0.0006 loss2:0.0115 | AUC:0.8496 FAR:0.00403
[2023-07-19 14:22:05,324][main.py][line:74][INFO] [Epoch:44/50]: loss1:0.0005 loss2:0.0106 | AUC:0.8506 FAR:0.00383
[2023-07-19 14:22:57,235][main.py][line:74][INFO] [Epoch:45/50]: loss1:0.0005 loss2:0.0100 | AUC:0.8501 FAR:0.00378
[2023-07-19 14:23:47,949][main.py][line:74][INFO] [Epoch:46/50]: loss1:0.0005 loss2:0.0094 | AUC:0.8489 FAR:0.00375
[2023-07-19 14:24:38,447][main.py][line:74][INFO] [Epoch:47/50]: loss1:0.0004 loss2:0.0093 | AUC:0.8492 FAR:0.00378
[2023-07-19 14:25:29,430][main.py][line:74][INFO] [Epoch:48/50]: loss1:0.0005 loss2:0.0092 | AUC:0.8489 FAR:0.00348
[2023-07-19 14:26:20,997][main.py][line:74][INFO] [Epoch:49/50]: loss1:0.0004 loss2:0.0091 | AUC:0.8498 FAR:0.00370
[2023-07-19 14:27:12,147][main.py][line:74][INFO] [Epoch:50/50]: loss1:0.0004 loss2:0.0083 | AUC:0.8498 FAR:0.00366
[2023-07-19 14:27:12,160][main.py][line:80][INFO] Training completes in 42m 50s | best AUC:0.8548 FAR:0.00457

[2023-07-19 14:31:40,316][main.py][line:87][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 14:31:40,425][main.py][line:113][INFO] total params:1.2091M
[2023-07-19 14:31:40,425][main.py][line:120][INFO] Test Mode
[2023-07-19 14:31:40,425][main.py][line:26][INFO] loading pretrained checkpoint from ./ckpt/ucf__8548.pkl.
[2023-07-19 14:31:46,121][infer.py][line:47][INFO] offline AUC:0.8601 AP:0.3172 FAR:0.0036 | Complete in 0m 6s

[2023-07-19 14:46:54,402][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 14:46:54,485][main.py][line:108][INFO] total params:1.2091M
[2023-07-19 14:46:54,485][main.py][line:111][INFO] Training Mode
[2023-07-19 14:46:54,486][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-19 14:46:54,486][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 14:48:43,190][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 14:48:43,272][main.py][line:108][INFO] total params:1.2091M
[2023-07-19 14:48:43,272][main.py][line:111][INFO] Training Mode
[2023-07-19 14:48:43,272][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-07-19 14:48:43,272][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 14:58:30,622][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 14:58:30,788][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 14:58:30,788][main.py][line:111][INFO] Training Mode
[2023-07-19 14:58:30,789][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
)

[2023-07-19 14:58:30,789][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:08:44,535][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:08:44,693][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:08:44,693][main.py][line:111][INFO] Training Mode
[2023-07-19 15:08:44,694][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
)

[2023-07-19 15:08:44,694][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:09:58,519][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:09:58,667][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:09:58,667][main.py][line:111][INFO] Training Mode
[2023-07-19 15:09:58,667][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
)

[2023-07-19 15:09:58,667][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:10:41,077][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8548.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:11:58,286][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:11:58,446][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:11:58,446][main.py][line:111][INFO] Training Mode
[2023-07-19 15:11:58,446][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
)

[2023-07-19 15:11:58,446][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:12:33,472][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:12:33,631][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:12:33,631][main.py][line:111][INFO] Training Mode
[2023-07-19 15:12:33,632][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:12:33,632][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:13:25,037][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:13:25,201][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:13:25,201][main.py][line:111][INFO] Training Mode
[2023-07-19 15:13:25,201][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:13:25,201][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:13:37,921][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:13:38,078][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:13:38,078][main.py][line:111][INFO] Training Mode
[2023-07-19 15:13:38,079][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:13:38,079][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:14:03,343][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:14:03,506][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:14:03,506][main.py][line:111][INFO] Training Mode
[2023-07-19 15:14:03,506][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:14:03,506][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:39:27,713][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:39:40,531][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:39:40,679][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:39:40,679][main.py][line:111][INFO] Training Mode
[2023-07-19 15:39:40,679][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:39:40,679][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:40:05,811][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:40:05,969][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:40:05,969][main.py][line:111][INFO] Training Mode
[2023-07-19 15:40:05,969][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:40:05,969][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:43:33,112][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:43:33,272][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:43:33,272][main.py][line:111][INFO] Training Mode
[2023-07-19 15:43:33,272][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:43:33,272][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:44:58,268][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:44:58,418][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:44:58,418][main.py][line:111][INFO] Training Mode
[2023-07-19 15:44:58,418][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:44:58,418][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:45:26,066][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:45:26,214][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:45:26,214][main.py][line:111][INFO] Training Mode
[2023-07-19 15:45:26,214][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:45:26,214][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:59:14,813][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:59:14,972][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:59:14,972][main.py][line:111][INFO] Training Mode
[2023-07-19 15:59:14,972][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:59:14,972][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 15:59:26,260][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 15:59:26,409][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 15:59:26,409][main.py][line:111][INFO] Training Mode
[2023-07-19 15:59:26,410][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 15:59:26,410][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:00:17,464][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:00:17,623][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:00:17,623][main.py][line:111][INFO] Training Mode
[2023-07-19 16:00:17,624][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:00:17,624][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:00:27,960][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:00:28,109][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:00:28,109][main.py][line:111][INFO] Training Mode
[2023-07-19 16:00:28,109][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:00:28,109][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:01:28,931][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:01:29,091][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:01:29,091][main.py][line:111][INFO] Training Mode
[2023-07-19 16:01:29,091][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:01:29,091][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:01:57,114][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:01:57,271][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:01:57,271][main.py][line:111][INFO] Training Mode
[2023-07-19 16:01:57,272][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:01:57,272][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:02:15,599][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:02:15,757][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:02:15,758][main.py][line:111][INFO] Training Mode
[2023-07-19 16:02:15,758][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:02:15,758][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:02:25,387][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:02:25,544][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:02:25,544][main.py][line:111][INFO] Training Mode
[2023-07-19 16:02:25,544][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:02:25,544][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:02:54,098][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:02:54,258][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:02:54,258][main.py][line:111][INFO] Training Mode
[2023-07-19 16:02:54,258][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:02:54,258][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:03:13,069][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:03:13,227][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:03:13,227][main.py][line:111][INFO] Training Mode
[2023-07-19 16:03:13,228][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:03:13,228][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:03:55,900][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:03:56,066][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:03:56,066][main.py][line:111][INFO] Training Mode
[2023-07-19 16:03:56,067][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:03:56,067][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:04:47,740][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:04:47,904][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:04:47,904][main.py][line:111][INFO] Training Mode
[2023-07-19 16:04:47,904][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:04:47,904][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:05:02,269][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:05:02,420][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:05:02,420][main.py][line:111][INFO] Training Mode
[2023-07-19 16:05:02,420][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:05:02,420][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:06:20,525][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:06:20,675][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:06:20,675][main.py][line:111][INFO] Training Mode
[2023-07-19 16:06:20,675][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:06:20,676][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:11:53,816][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:11:53,971][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:11:53,971][main.py][line:111][INFO] Training Mode
[2023-07-19 16:11:53,972][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:11:53,972][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:16:58,189][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:16:58,345][main.py][line:108][INFO] total params:27.0045M
[2023-07-19 16:16:58,345][main.py][line:111][INFO] Training Mode
[2023-07-19 16:16:58,345][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:16:58,345][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:23:34,186][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:23:34,342][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:23:34,342][main.py][line:111][INFO] Training Mode
[2023-07-19 16:23:34,343][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:23:34,343][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:24:25,160][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:24:25,326][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:24:25,326][main.py][line:111][INFO] Training Mode
[2023-07-19 16:24:25,327][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:24:25,327][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:27:12,296][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:27:12,455][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:27:12,455][main.py][line:111][INFO] Training Mode
[2023-07-19 16:27:12,455][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:27:12,455][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:27:24,611][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:27:24,778][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:27:24,778][main.py][line:111][INFO] Training Mode
[2023-07-19 16:27:24,778][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:27:24,778][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:28:41,579][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:28:41,732][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:28:41,732][main.py][line:111][INFO] Training Mode
[2023-07-19 16:28:41,732][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:28:41,732][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:30:16,308][main.py][line:82][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:30:16,477][main.py][line:108][INFO] total params:27.0270M
[2023-07-19 16:30:16,477][main.py][line:111][INFO] Training Mode
[2023-07-19 16:30:16,477][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:30:16,478][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:32:44,531][main.py][line:83][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:32:44,694][main.py][line:109][INFO] total params:27.0270M
[2023-07-19 16:32:44,694][main.py][line:112][INFO] Training Mode
[2023-07-19 16:32:44,695][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:32:44,695][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:34:07,788][main.py][line:83][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:34:07,951][main.py][line:109][INFO] total params:27.0270M
[2023-07-19 16:34:07,951][main.py][line:112][INFO] Training Mode
[2023-07-19 16:34:07,951][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:34:07,951][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:34:15,549][main.py][line:52][INFO] Random initialize AUC:initial AUC:0.5452 initial AUC2:0.5444 FAR:0.67905
[2023-07-19 16:36:01,443][main.py][line:83][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:36:01,606][main.py][line:109][INFO] total params:27.0270M
[2023-07-19 16:36:01,606][main.py][line:112][INFO] Training Mode
[2023-07-19 16:36:01,606][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:36:01,606][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:36:09,149][main.py][line:52][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-19 16:38:29,607][main.py][line:83][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 16:38:29,782][main.py][line:109][INFO] total params:27.0270M
[2023-07-19 16:38:29,782][main.py][line:112][INFO] Training Mode
[2023-07-19 16:38:29,782][main.py][line:48][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 16:38:29,782][main.py][line:49][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 16:38:37,322][main.py][line:52][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-19 16:39:43,780][main.py][line:70][INFO] [Epoch:1/50]: loss1:0.3749 loss2:1.1640 | AUC:0.8316 AUC2:0.8316 FAR:0.00830
[2023-07-19 16:40:49,846][main.py][line:70][INFO] [Epoch:2/50]: loss1:0.1347 loss2:0.9541 | AUC:0.8518 AUC2:0.8517 FAR:0.00990
[2023-07-19 16:41:56,816][main.py][line:70][INFO] [Epoch:3/50]: loss1:0.0532 loss2:0.8623 | AUC:0.8554 AUC2:0.8553 FAR:0.01148
[2023-07-19 16:43:03,490][main.py][line:70][INFO] [Epoch:4/50]: loss1:0.0257 loss2:0.7901 | AUC:0.8447 AUC2:0.8553 FAR:0.00314
[2023-07-19 16:44:10,005][main.py][line:70][INFO] [Epoch:5/50]: loss1:0.0181 loss2:0.7232 | AUC:0.8501 AUC2:0.8553 FAR:0.00687
[2023-07-19 16:45:16,784][main.py][line:70][INFO] [Epoch:6/50]: loss1:0.0233 loss2:0.6746 | AUC:0.8471 AUC2:0.8553 FAR:0.00531
[2023-07-19 16:46:23,514][main.py][line:70][INFO] [Epoch:7/50]: loss1:0.0070 loss2:0.6079 | AUC:0.8466 AUC2:0.8553 FAR:0.00198
[2023-07-19 16:47:30,262][main.py][line:70][INFO] [Epoch:8/50]: loss1:0.0055 loss2:0.5477 | AUC:0.8531 AUC2:0.8553 FAR:0.00240
[2023-07-19 16:48:36,972][main.py][line:70][INFO] [Epoch:9/50]: loss1:0.0049 loss2:0.4848 | AUC:0.8494 AUC2:0.8553 FAR:0.00230
[2023-07-19 16:49:43,650][main.py][line:70][INFO] [Epoch:10/50]: loss1:0.0044 loss2:0.4338 | AUC:0.8456 AUC2:0.8553 FAR:0.00254
[2023-07-19 16:50:50,242][main.py][line:70][INFO] [Epoch:11/50]: loss1:0.0047 loss2:0.3830 | AUC:0.8392 AUC2:0.8553 FAR:0.00672
[2023-07-19 16:51:56,625][main.py][line:70][INFO] [Epoch:12/50]: loss1:0.0379 loss2:0.4065 | AUC:0.8534 AUC2:0.8553 FAR:0.00926
[2023-07-19 16:53:03,544][main.py][line:70][INFO] [Epoch:13/50]: loss1:0.0222 loss2:0.3520 | AUC:0.8516 AUC2:0.8553 FAR:0.00948
[2023-07-19 16:54:10,193][main.py][line:70][INFO] [Epoch:14/50]: loss1:0.0054 loss2:0.2840 | AUC:0.8504 AUC2:0.8553 FAR:0.00501
[2023-07-19 16:55:17,334][main.py][line:70][INFO] [Epoch:15/50]: loss1:0.0030 loss2:0.2417 | AUC:0.8510 AUC2:0.8553 FAR:0.00511
[2023-07-19 16:56:24,108][main.py][line:70][INFO] [Epoch:16/50]: loss1:0.0024 loss2:0.2048 | AUC:0.8512 AUC2:0.8553 FAR:0.00445
[2023-07-19 16:57:31,159][main.py][line:70][INFO] [Epoch:17/50]: loss1:0.0023 loss2:0.1751 | AUC:0.8478 AUC2:0.8553 FAR:0.00467
[2023-07-19 16:58:37,880][main.py][line:70][INFO] [Epoch:18/50]: loss1:0.0019 loss2:0.1487 | AUC:0.8490 AUC2:0.8553 FAR:0.00462
[2023-07-19 16:59:44,768][main.py][line:70][INFO] [Epoch:19/50]: loss1:0.0018 loss2:0.1273 | AUC:0.8506 AUC2:0.8553 FAR:0.00450
[2023-07-19 17:00:51,397][main.py][line:70][INFO] [Epoch:20/50]: loss1:0.0016 loss2:0.1072 | AUC:0.8478 AUC2:0.8553 FAR:0.00457
[2023-07-19 17:06:51,490][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 400, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 17:06:51,700][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 17:06:51,700][main.py][line:119][INFO] Training Mode
[2023-07-19 17:06:51,700][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 17:06:51,700][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0
)

[2023-07-19 17:06:59,538][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-19 17:07:54,176][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.4485 loss2:1.2754 main_loss:2.1725 | AUC:0.8194 AUC2:0.8194 FAR:0.02433
[2023-07-19 17:08:50,124][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.2570 loss2:1.1698 main_loss:1.6838 | AUC:0.8389 AUC2:0.8389 FAR:0.01223
[2023-07-19 17:09:46,478][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.1547 loss2:1.0519 main_loss:1.3613 | AUC:0.8474 AUC2:0.8474 FAR:0.00958
[2023-07-19 17:11:39,916][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 17:11:40,109][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 17:11:40,110][main.py][line:119][INFO] Training Mode
[2023-07-19 17:11:40,110][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 17:11:40,110][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0
)

[2023-07-19 17:11:48,068][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-19 17:13:22,557][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3629 loss2:1.1955 main_loss:1.9213 | AUC:0.8264 AUC2:0.8264 FAR:0.03816
[2023-07-19 17:14:56,395][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1381 loss2:1.0275 main_loss:1.3038 | AUC:0.8410 AUC2:0.8410 FAR:0.02023
[2023-07-19 17:16:26,214][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0442 loss2:0.9445 main_loss:1.0328 | AUC:0.8454 AUC2:0.8454 FAR:0.01319
[2023-07-19 17:17:52,735][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0233 loss2:0.8820 main_loss:0.9287 | AUC:0.8375 AUC2:0.8454 FAR:0.01512
[2023-07-19 17:19:25,363][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0129 loss2:0.8164 main_loss:0.8422 | AUC:0.8473 AUC2:0.8473 FAR:0.01487
[2023-07-19 17:20:49,699][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0100 loss2:0.7686 main_loss:0.7886 | AUC:0.8449 AUC2:0.8473 FAR:0.01218
[2023-07-19 17:22:11,673][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0111 loss2:0.7032 main_loss:0.7253 | AUC:0.8430 AUC2:0.8473 FAR:0.01420
[2023-07-19 17:23:31,803][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0178 loss2:0.6556 main_loss:0.6913 | AUC:0.8475 AUC2:0.8474 FAR:0.02737
[2023-07-19 17:24:46,241][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0074 loss2:0.5936 main_loss:0.6085 | AUC:0.8531 AUC2:0.8531 FAR:0.00489
[2023-07-19 17:26:01,668][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0071 loss2:0.5268 main_loss:0.5410 | AUC:0.8504 AUC2:0.8531 FAR:0.02220
[2023-07-19 17:27:19,595][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.0111 loss2:0.4812 main_loss:0.5035 | AUC:0.8531 AUC2:0.8531 FAR:0.00943
[2023-07-19 17:28:38,521][main.py][line:76][INFO] [Epoch:12/100]: loss1:0.0082 loss2:0.4237 main_loss:0.4400 | AUC:0.8474 AUC2:0.8531 FAR:0.01146
[2023-07-19 17:30:06,568][main.py][line:76][INFO] [Epoch:13/100]: loss1:0.0052 loss2:0.3560 main_loss:0.3663 | AUC:0.8493 AUC2:0.8531 FAR:0.01531
[2023-07-19 17:31:13,212][main.py][line:76][INFO] [Epoch:14/100]: loss1:0.0042 loss2:0.3048 main_loss:0.3132 | AUC:0.8518 AUC2:0.8531 FAR:0.01470
[2023-07-19 17:32:20,754][main.py][line:76][INFO] [Epoch:15/100]: loss1:0.0034 loss2:0.2458 main_loss:0.2527 | AUC:0.8500 AUC2:0.8531 FAR:0.00919
[2023-07-19 17:33:33,166][main.py][line:76][INFO] [Epoch:16/100]: loss1:0.0036 loss2:0.2038 main_loss:0.2110 | AUC:0.8522 AUC2:0.8531 FAR:0.01558
[2023-07-19 17:34:49,879][main.py][line:76][INFO] [Epoch:17/100]: loss1:0.0041 loss2:0.1666 main_loss:0.1748 | AUC:0.8470 AUC2:0.8531 FAR:0.01778
[2023-07-19 17:36:01,448][main.py][line:76][INFO] [Epoch:18/100]: loss1:0.0154 loss2:0.1745 main_loss:0.2052 | AUC:0.8399 AUC2:0.8531 FAR:0.04611
[2023-07-19 17:37:08,646][main.py][line:76][INFO] [Epoch:19/100]: loss1:0.0083 loss2:0.1454 main_loss:0.1620 | AUC:0.8486 AUC2:0.8531 FAR:0.01460
[2023-07-19 17:38:17,270][main.py][line:76][INFO] [Epoch:20/100]: loss1:0.0096 loss2:0.1003 main_loss:0.1195 | AUC:0.8418 AUC2:0.8531 FAR:0.01907
[2023-07-19 17:39:21,493][main.py][line:76][INFO] [Epoch:21/100]: loss1:0.0117 loss2:0.0891 main_loss:0.1125 | AUC:0.8451 AUC2:0.8531 FAR:0.02206
[2023-07-19 17:40:23,342][main.py][line:76][INFO] [Epoch:22/100]: loss1:0.0017 loss2:0.0657 main_loss:0.0690 | AUC:0.8458 AUC2:0.8531 FAR:0.02396
[2023-07-19 17:41:29,408][main.py][line:76][INFO] [Epoch:23/100]: loss1:0.0024 loss2:0.0572 main_loss:0.0620 | AUC:0.8437 AUC2:0.8531 FAR:0.01761
[2023-07-19 17:42:37,390][main.py][line:76][INFO] [Epoch:24/100]: loss1:0.0012 loss2:0.0448 main_loss:0.0472 | AUC:0.8473 AUC2:0.8531 FAR:0.01344
[2023-07-19 17:43:50,878][main.py][line:76][INFO] [Epoch:25/100]: loss1:0.0008 loss2:0.0362 main_loss:0.0378 | AUC:0.8481 AUC2:0.8531 FAR:0.01894
[2023-07-19 17:45:04,074][main.py][line:76][INFO] [Epoch:26/100]: loss1:0.0006 loss2:0.0280 main_loss:0.0293 | AUC:0.8501 AUC2:0.8531 FAR:0.01576
[2023-07-19 17:46:14,035][main.py][line:76][INFO] [Epoch:27/100]: loss1:0.0006 loss2:0.0238 main_loss:0.0250 | AUC:0.8495 AUC2:0.8531 FAR:0.01447
[2023-07-19 17:47:25,870][main.py][line:76][INFO] [Epoch:28/100]: loss1:0.0005 loss2:0.0190 main_loss:0.0199 | AUC:0.8501 AUC2:0.8531 FAR:0.01255
[2023-07-19 17:48:43,655][main.py][line:76][INFO] [Epoch:29/100]: loss1:0.0004 loss2:0.0173 main_loss:0.0181 | AUC:0.8499 AUC2:0.8531 FAR:0.01423
[2023-07-19 17:50:06,776][main.py][line:76][INFO] [Epoch:30/100]: loss1:0.0004 loss2:0.0146 main_loss:0.0154 | AUC:0.8498 AUC2:0.8531 FAR:0.01665
[2023-07-19 17:51:28,772][main.py][line:76][INFO] [Epoch:31/100]: loss1:0.0014 loss2:0.0145 main_loss:0.0173 | AUC:0.8488 AUC2:0.8531 FAR:0.01334
[2023-07-19 17:52:33,413][main.py][line:76][INFO] [Epoch:32/100]: loss1:0.0003 loss2:0.0117 main_loss:0.0124 | AUC:0.8493 AUC2:0.8531 FAR:0.01344
[2023-07-19 17:53:40,997][main.py][line:76][INFO] [Epoch:33/100]: loss1:0.0003 loss2:0.0100 main_loss:0.0106 | AUC:0.8492 AUC2:0.8531 FAR:0.01349
[2023-07-19 17:54:50,752][main.py][line:76][INFO] [Epoch:34/100]: loss1:0.0007 loss2:0.0106 main_loss:0.0121 | AUC:0.8480 AUC2:0.8531 FAR:0.01314
[2023-07-19 17:56:01,694][main.py][line:76][INFO] [Epoch:35/100]: loss1:0.0003 loss2:0.0089 main_loss:0.0094 | AUC:0.8500 AUC2:0.8531 FAR:0.01319
[2023-07-19 17:57:12,364][main.py][line:76][INFO] [Epoch:36/100]: loss1:0.0002 loss2:0.0072 main_loss:0.0077 | AUC:0.8500 AUC2:0.8531 FAR:0.01405
[2023-07-19 17:58:24,434][main.py][line:76][INFO] [Epoch:37/100]: loss1:0.0041 loss2:0.0122 main_loss:0.0204 | AUC:0.8411 AUC2:0.8531 FAR:0.01729
[2023-07-19 17:59:37,657][main.py][line:76][INFO] [Epoch:38/100]: loss1:0.0024 loss2:0.0146 main_loss:0.0195 | AUC:0.8486 AUC2:0.8531 FAR:0.01326
[2023-07-19 18:00:49,750][main.py][line:76][INFO] [Epoch:39/100]: loss1:0.0004 loss2:0.0078 main_loss:0.0086 | AUC:0.8508 AUC2:0.8531 FAR:0.01358
[2023-07-19 18:02:09,513][main.py][line:76][INFO] [Epoch:40/100]: loss1:0.0003 loss2:0.0067 main_loss:0.0074 | AUC:0.8480 AUC2:0.8531 FAR:0.01566
[2023-07-19 18:03:20,202][main.py][line:76][INFO] [Epoch:41/100]: loss1:0.0003 loss2:0.0062 main_loss:0.0068 | AUC:0.8506 AUC2:0.8531 FAR:0.01625
[2023-07-19 18:04:35,435][main.py][line:76][INFO] [Epoch:42/100]: loss1:0.0002 loss2:0.0057 main_loss:0.0062 | AUC:0.8507 AUC2:0.8531 FAR:0.01554
[2023-07-19 18:05:44,239][main.py][line:76][INFO] [Epoch:43/100]: loss1:0.0002 loss2:0.0052 main_loss:0.0056 | AUC:0.8499 AUC2:0.8531 FAR:0.01603
[2023-07-19 18:07:00,009][main.py][line:76][INFO] [Epoch:44/100]: loss1:0.0018 loss2:0.0093 main_loss:0.0128 | AUC:0.8444 AUC2:0.8531 FAR:0.02576
[2023-07-19 18:08:20,508][main.py][line:76][INFO] [Epoch:45/100]: loss1:0.0003 loss2:0.0056 main_loss:0.0061 | AUC:0.8463 AUC2:0.8531 FAR:0.01620
[2023-07-19 18:09:27,513][main.py][line:76][INFO] [Epoch:46/100]: loss1:0.0002 loss2:0.0049 main_loss:0.0053 | AUC:0.8469 AUC2:0.8531 FAR:0.01635
[2023-07-19 18:10:38,493][main.py][line:76][INFO] [Epoch:47/100]: loss1:0.0002 loss2:0.0043 main_loss:0.0046 | AUC:0.8472 AUC2:0.8531 FAR:0.01613
[2023-07-19 18:11:57,701][main.py][line:76][INFO] [Epoch:48/100]: loss1:0.0001 loss2:0.0041 main_loss:0.0044 | AUC:0.8475 AUC2:0.8531 FAR:0.01576
[2023-07-19 18:13:16,841][main.py][line:76][INFO] [Epoch:49/100]: loss1:0.0001 loss2:0.0039 main_loss:0.0042 | AUC:0.8478 AUC2:0.8531 FAR:0.01529
[2023-07-19 18:14:32,305][main.py][line:76][INFO] [Epoch:50/100]: loss1:0.0001 loss2:0.0037 main_loss:0.0040 | AUC:0.8480 AUC2:0.8531 FAR:0.01546
[2023-07-19 18:15:47,656][main.py][line:76][INFO] [Epoch:51/100]: loss1:0.0001 loss2:0.0036 main_loss:0.0038 | AUC:0.8482 AUC2:0.8531 FAR:0.01504
[2023-07-19 18:17:05,706][main.py][line:76][INFO] [Epoch:52/100]: loss1:0.0001 loss2:0.0034 main_loss:0.0036 | AUC:0.8483 AUC2:0.8531 FAR:0.01558
[2023-07-19 18:18:15,379][main.py][line:76][INFO] [Epoch:53/100]: loss1:0.0001 loss2:0.0035 main_loss:0.0037 | AUC:0.8484 AUC2:0.8531 FAR:0.01521
[2023-07-19 18:19:25,668][main.py][line:76][INFO] [Epoch:54/100]: loss1:0.0001 loss2:0.0033 main_loss:0.0036 | AUC:0.8485 AUC2:0.8531 FAR:0.01529
[2023-07-19 18:20:35,727][main.py][line:76][INFO] [Epoch:55/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0035 | AUC:0.8485 AUC2:0.8531 FAR:0.01534
[2023-07-19 18:21:48,012][main.py][line:76][INFO] [Epoch:56/100]: loss1:0.0001 loss2:0.0034 main_loss:0.0036 | AUC:0.8486 AUC2:0.8531 FAR:0.01531
[2023-07-19 18:22:52,817][main.py][line:76][INFO] [Epoch:57/100]: loss1:0.0001 loss2:0.0030 main_loss:0.0033 | AUC:0.8486 AUC2:0.8531 FAR:0.01534
[2023-07-19 18:24:01,597][main.py][line:76][INFO] [Epoch:58/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0034 | AUC:0.8487 AUC2:0.8531 FAR:0.01620
[2023-07-19 18:25:15,296][main.py][line:76][INFO] [Epoch:59/100]: loss1:0.0001 loss2:0.0033 main_loss:0.0035 | AUC:0.8487 AUC2:0.8531 FAR:0.01608
[2023-07-19 18:26:36,903][main.py][line:76][INFO] [Epoch:60/100]: loss1:0.0001 loss2:0.0033 main_loss:0.0035 | AUC:0.8487 AUC2:0.8531 FAR:0.01600
[2023-07-19 18:27:46,452][main.py][line:76][INFO] [Epoch:61/100]: loss1:0.0001 loss2:0.0031 main_loss:0.0033 | AUC:0.8487 AUC2:0.8531 FAR:0.01600
[2023-07-19 18:28:51,162][main.py][line:76][INFO] [Epoch:62/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0034 | AUC:0.8487 AUC2:0.8531 FAR:0.01600
[2023-07-19 18:30:07,543][main.py][line:76][INFO] [Epoch:63/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0035 | AUC:0.8487 AUC2:0.8531 FAR:0.01581
[2023-07-19 18:31:17,366][main.py][line:76][INFO] [Epoch:64/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0034 | AUC:0.8487 AUC2:0.8531 FAR:0.01571
[2023-07-19 18:32:28,097][main.py][line:76][INFO] [Epoch:65/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0034 | AUC:0.8488 AUC2:0.8531 FAR:0.01551
[2023-07-19 18:33:43,775][main.py][line:76][INFO] [Epoch:66/100]: loss1:0.0001 loss2:0.0031 main_loss:0.0033 | AUC:0.8488 AUC2:0.8531 FAR:0.01509
[2023-07-19 18:34:52,319][main.py][line:76][INFO] [Epoch:67/100]: loss1:0.0001 loss2:0.0032 main_loss:0.0034 | AUC:0.8488 AUC2:0.8531 FAR:0.01531
[2023-07-19 18:36:11,436][main.py][line:76][INFO] [Epoch:68/100]: loss1:0.0001 loss2:0.0031 main_loss:0.0033 | AUC:0.8489 AUC2:0.8531 FAR:0.01502
[2023-07-19 18:37:25,506][main.py][line:76][INFO] [Epoch:69/100]: loss1:0.0001 loss2:0.0028 main_loss:0.0030 | AUC:0.8489 AUC2:0.8531 FAR:0.01465
[2023-07-19 18:38:40,558][main.py][line:76][INFO] [Epoch:70/100]: loss1:0.0002 loss2:0.0033 main_loss:0.0036 | AUC:0.8476 AUC2:0.8531 FAR:0.01450
[2023-07-19 18:40:00,807][main.py][line:76][INFO] [Epoch:71/100]: loss1:0.0001 loss2:0.0029 main_loss:0.0031 | AUC:0.8476 AUC2:0.8531 FAR:0.01447
[2023-07-19 18:41:06,392][main.py][line:76][INFO] [Epoch:72/100]: loss1:0.0001 loss2:0.0025 main_loss:0.0027 | AUC:0.8471 AUC2:0.8531 FAR:0.01571
[2023-07-19 18:42:18,240][main.py][line:76][INFO] [Epoch:73/100]: loss1:0.0003 loss2:0.0034 main_loss:0.0040 | AUC:0.8446 AUC2:0.8531 FAR:0.01763
[2023-07-19 18:43:31,400][main.py][line:76][INFO] [Epoch:74/100]: loss1:0.0001 loss2:0.0029 main_loss:0.0031 | AUC:0.8458 AUC2:0.8531 FAR:0.01628
[2023-07-19 18:44:39,476][main.py][line:76][INFO] [Epoch:75/100]: loss1:0.0001 loss2:0.0026 main_loss:0.0028 | AUC:0.8454 AUC2:0.8531 FAR:0.01114
[2023-07-19 18:46:01,233][main.py][line:76][INFO] [Epoch:76/100]: loss1:0.0001 loss2:0.0027 main_loss:0.0029 | AUC:0.8460 AUC2:0.8531 FAR:0.01474
[2023-07-19 18:47:14,436][main.py][line:76][INFO] [Epoch:77/100]: loss1:0.0001 loss2:0.0023 main_loss:0.0025 | AUC:0.8476 AUC2:0.8531 FAR:0.01524
[2023-07-19 18:48:27,219][main.py][line:76][INFO] [Epoch:78/100]: loss1:0.0001 loss2:0.0021 main_loss:0.0022 | AUC:0.8457 AUC2:0.8531 FAR:0.01514
[2023-07-19 18:49:44,929][main.py][line:76][INFO] [Epoch:79/100]: loss1:0.0001 loss2:0.0027 main_loss:0.0030 | AUC:0.8437 AUC2:0.8531 FAR:0.01106
[2023-07-19 18:50:56,390][main.py][line:76][INFO] [Epoch:80/100]: loss1:0.0013 loss2:0.0046 main_loss:0.0071 | AUC:0.8406 AUC2:0.8531 FAR:0.01267
[2023-07-19 18:52:09,394][main.py][line:76][INFO] [Epoch:81/100]: loss1:0.0001 loss2:0.0023 main_loss:0.0025 | AUC:0.8410 AUC2:0.8531 FAR:0.01121
[2023-07-19 18:53:18,676][main.py][line:76][INFO] [Epoch:82/100]: loss1:0.0001 loss2:0.0019 main_loss:0.0021 | AUC:0.8419 AUC2:0.8531 FAR:0.01161
[2023-07-19 18:54:37,585][main.py][line:76][INFO] [Epoch:83/100]: loss1:0.0001 loss2:0.0017 main_loss:0.0018 | AUC:0.8420 AUC2:0.8531 FAR:0.01141
[2023-07-19 18:55:55,349][main.py][line:76][INFO] [Epoch:84/100]: loss1:0.0000 loss2:0.0016 main_loss:0.0017 | AUC:0.8420 AUC2:0.8531 FAR:0.01042
[2023-07-19 18:57:16,231][main.py][line:76][INFO] [Epoch:85/100]: loss1:0.0099 loss2:0.0126 main_loss:0.0324 | AUC:0.8359 AUC2:0.8531 FAR:0.02294
[2023-07-19 18:58:36,771][main.py][line:76][INFO] [Epoch:86/100]: loss1:0.0011 loss2:0.0064 main_loss:0.0086 | AUC:0.8405 AUC2:0.8531 FAR:0.01889
[2023-07-19 19:00:01,733][main.py][line:76][INFO] [Epoch:87/100]: loss1:0.0039 loss2:0.0089 main_loss:0.0166 | AUC:0.8401 AUC2:0.8531 FAR:0.01986
[2023-07-19 19:01:12,801][main.py][line:76][INFO] [Epoch:88/100]: loss1:0.0003 loss2:0.0038 main_loss:0.0044 | AUC:0.8386 AUC2:0.8531 FAR:0.01904
[2023-07-19 19:02:24,944][main.py][line:76][INFO] [Epoch:89/100]: loss1:0.0003 loss2:0.0027 main_loss:0.0034 | AUC:0.8376 AUC2:0.8531 FAR:0.02218
[2023-07-19 19:03:34,789][main.py][line:76][INFO] [Epoch:90/100]: loss1:0.0003 loss2:0.0027 main_loss:0.0032 | AUC:0.8396 AUC2:0.8531 FAR:0.02159
[2023-07-19 19:04:58,918][main.py][line:76][INFO] [Epoch:91/100]: loss1:0.0003 loss2:0.0022 main_loss:0.0027 | AUC:0.8391 AUC2:0.8531 FAR:0.01568
[2023-07-19 19:06:22,645][main.py][line:76][INFO] [Epoch:92/100]: loss1:0.0002 loss2:0.0019 main_loss:0.0023 | AUC:0.8403 AUC2:0.8531 FAR:0.01689
[2023-07-19 19:07:45,054][main.py][line:76][INFO] [Epoch:93/100]: loss1:0.0001 loss2:0.0016 main_loss:0.0019 | AUC:0.8405 AUC2:0.8531 FAR:0.01714
[2023-07-19 19:08:58,211][main.py][line:76][INFO] [Epoch:94/100]: loss1:0.0001 loss2:0.0015 main_loss:0.0016 | AUC:0.8411 AUC2:0.8531 FAR:0.01494
[2023-07-19 19:10:22,884][main.py][line:76][INFO] [Epoch:95/100]: loss1:0.0001 loss2:0.0012 main_loss:0.0013 | AUC:0.8416 AUC2:0.8531 FAR:0.01482
[2023-07-19 19:11:48,900][main.py][line:76][INFO] [Epoch:96/100]: loss1:0.0000 loss2:0.0013 main_loss:0.0014 | AUC:0.8419 AUC2:0.8531 FAR:0.01400
[2023-07-19 19:13:36,554][main.py][line:76][INFO] [Epoch:97/100]: loss1:0.0001 loss2:0.0010 main_loss:0.0011 | AUC:0.8409 AUC2:0.8531 FAR:0.01494
[2023-07-19 19:14:57,196][main.py][line:76][INFO] [Epoch:98/100]: loss1:0.0001 loss2:0.0014 main_loss:0.0015 | AUC:0.8412 AUC2:0.8531 FAR:0.00753
[2023-07-19 19:16:34,649][main.py][line:76][INFO] [Epoch:99/100]: loss1:0.0486 loss2:0.0482 main_loss:0.1455 | AUC:0.8388 AUC2:0.8531 FAR:0.00778
[2023-07-19 19:17:58,102][main.py][line:76][INFO] [Epoch:100/100]: loss1:0.0092 loss2:0.0164 main_loss:0.0348 | AUC:0.8301 AUC2:0.8531 FAR:0.01754
[2023-07-19 19:17:58,104][main.py][line:82][INFO] Training completes in 126m 10s | best AUC:0.8531 FAR:0.00489

[2023-07-19 20:28:54,913][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8548.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:28:55,094][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:28:55,095][main.py][line:123][INFO] Test Mode
[2023-07-19 20:31:00,761][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8531.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:31:00,921][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:31:00,921][main.py][line:123][INFO] Test Mode
[2023-07-19 20:32:43,985][main.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': ('./ckpt/ucf__8531.pkl',), 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:32:44,145][main.py][line:117][INFO] total params:27.0270M
[2023-07-19 20:32:44,146][main.py][line:124][INFO] Test Mode
[2023-07-19 20:33:15,846][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:33:15,995][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:33:15,996][main.py][line:123][INFO] Test Mode
[2023-07-19 20:33:15,996][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8531.pkl.
[2023-07-19 20:34:48,895][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:34:49,044][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:34:49,044][main.py][line:123][INFO] Test Mode
[2023-07-19 20:34:49,044][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8531.pkl.
[2023-07-19 20:35:46,979][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:35:47,126][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:35:47,127][main.py][line:123][INFO] Test Mode
[2023-07-19 20:35:47,127][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8531.pkl.
[2023-07-19 20:35:55,296][infer_bert.py][line:55][INFO] offline AUC:0.8531 AUC2:0.8568 AP:0.3223 FAR:0.0040 | Complete in 0m 8s

[2023-07-19 20:39:16,844][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:39:17,005][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:39:17,005][main.py][line:123][INFO] Test Mode
[2023-07-19 20:39:17,005][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8531.pkl.
[2023-07-19 20:39:23,634][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 500, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:39:23,781][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:39:23,781][main.py][line:119][INFO] Training Mode
[2023-07-19 20:39:23,782][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 20:39:23,782][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0
)

[2023-07-19 20:39:31,301][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-19 20:40:29,063][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3642 loss2:1.1187 main_loss:1.4829 | AUC:0.8266 AUC2:0.8266 FAR:0.04483
[2023-07-19 20:41:28,490][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1438 loss2:0.9801 main_loss:1.1239 | AUC:0.8429 AUC2:0.8429 FAR:0.01894
[2023-07-19 20:42:27,619][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0586 loss2:0.8905 main_loss:0.9491 | AUC:0.8530 AUC2:0.8530 FAR:0.00773
[2023-07-19 20:43:27,620][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0403 loss2:0.7955 main_loss:0.8359 | AUC:0.8409 AUC2:0.8530 FAR:0.00328
[2023-07-19 20:44:27,087][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0270 loss2:0.7031 main_loss:0.7301 | AUC:0.8427 AUC2:0.8530 FAR:0.01274
[2023-07-19 20:45:24,872][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0271 loss2:0.6249 main_loss:0.6520 | AUC:0.8363 AUC2:0.8530 FAR:0.00882
[2023-07-19 20:46:24,055][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0177 loss2:0.5493 main_loss:0.5670 | AUC:0.8475 AUC2:0.8530 FAR:0.00674
[2023-07-19 20:47:23,770][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0202 loss2:0.4792 main_loss:0.4994 | AUC:0.8384 AUC2:0.8530 FAR:0.00212
[2023-07-19 20:48:23,221][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0240 loss2:0.4227 main_loss:0.4467 | AUC:0.8515 AUC2:0.8530 FAR:0.01168
[2023-07-19 20:49:23,291][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0254 loss2:0.3722 main_loss:0.3975 | AUC:0.8383 AUC2:0.8530 FAR:0.01512
[2023-07-19 20:50:20,328][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 55, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 256, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 20:50:20,511][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 20:50:20,511][main.py][line:119][INFO] Training Mode
[2023-07-19 20:50:20,511][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 20:50:20,511][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 20:50:28,781][main.py][line:53][INFO] Random initialize AUC:0.5760 initial_AUC2:0.5763 FAR:0.05021
[2023-07-19 20:54:07,818][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.4335 loss2:1.1767 main_loss:1.6102 | AUC:0.8263 AUC2:0.8263 FAR:0.01336
[2023-07-19 20:57:25,356][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.2136 loss2:0.9531 main_loss:1.1667 | AUC:0.8301 AUC2:0.8301 FAR:0.00635
[2023-07-19 21:00:33,003][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0978 loss2:0.8595 main_loss:0.9573 | AUC:0.8421 AUC2:0.8422 FAR:0.00314
[2023-07-19 21:03:14,116][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0562 loss2:0.8048 main_loss:0.8610 | AUC:0.8359 AUC2:0.8422 FAR:0.00380
[2023-07-19 21:06:23,396][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0304 loss2:0.7535 main_loss:0.7838 | AUC:0.8375 AUC2:0.8422 FAR:0.00148
[2023-07-19 21:09:12,046][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0229 loss2:0.7113 main_loss:0.7341 | AUC:0.8394 AUC2:0.8422 FAR:0.00479
[2023-07-19 21:11:57,250][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0252 loss2:0.6820 main_loss:0.7073 | AUC:0.8199 AUC2:0.8422 FAR:0.00637
[2023-07-19 21:14:37,112][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0161 loss2:0.6451 main_loss:0.6612 | AUC:0.8368 AUC2:0.8422 FAR:0.00405
[2023-07-19 21:17:34,684][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0104 loss2:0.6044 main_loss:0.6149 | AUC:0.8390 AUC2:0.8422 FAR:0.00432
[2023-07-19 21:20:39,798][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0188 loss2:0.5791 main_loss:0.5979 | AUC:0.8356 AUC2:0.8422 FAR:0.00526
[2023-07-19 21:23:35,423][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.0205 loss2:0.5566 main_loss:0.5771 | AUC:0.8469 AUC2:0.8469 FAR:0.00479
[2023-07-19 21:26:19,109][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8531.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-19 21:26:19,301][main.py][line:116][INFO] total params:27.0270M
[2023-07-19 21:26:19,301][main.py][line:119][INFO] Training Mode
[2023-07-19 21:26:19,301][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-19 21:26:19,301][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-19 21:26:27,452][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-19 21:28:45,247][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3725 loss2:1.0986 main_loss:1.4711 | AUC:0.8345 AUC2:0.8345 FAR:0.00450
[2023-07-19 21:31:00,212][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1418 loss2:0.8771 main_loss:1.0189 | AUC:0.8550 AUC2:0.8549 FAR:0.01173
[2023-07-19 21:32:50,431][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0635 loss2:0.7803 main_loss:0.8438 | AUC:0.8592 AUC2:0.8592 FAR:0.00200
[2023-07-19 21:34:34,061][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0409 loss2:0.7101 main_loss:0.7510 | AUC:0.8563 AUC2:0.8592 FAR:0.00756
[2023-07-19 21:36:40,099][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0246 loss2:0.6418 main_loss:0.6665 | AUC:0.8490 AUC2:0.8592 FAR:0.02648
[2023-07-19 21:39:00,233][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0297 loss2:0.5912 main_loss:0.6209 | AUC:0.8484 AUC2:0.8592 FAR:0.00462
[2023-07-19 21:41:18,336][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0185 loss2:0.5318 main_loss:0.5502 | AUC:0.8498 AUC2:0.8592 FAR:0.00450
[2023-07-19 21:43:38,854][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0116 loss2:0.4712 main_loss:0.4828 | AUC:0.8494 AUC2:0.8592 FAR:0.00450
[2023-07-19 21:45:19,089][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0098 loss2:0.4143 main_loss:0.4242 | AUC:0.8478 AUC2:0.8592 FAR:0.00254
[2023-07-19 21:47:08,281][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0162 loss2:0.3738 main_loss:0.3900 | AUC:0.8499 AUC2:0.8592 FAR:0.01457
[2023-07-19 21:49:31,350][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0303 loss2:0.3672 main_loss:0.3975 | AUC:0.8432 AUC2:0.8592 FAR:0.00580
[2023-07-19 21:52:01,306][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0184 loss2:0.3154 main_loss:0.3338 | AUC:0.8480 AUC2:0.8592 FAR:0.00321
[2023-07-19 21:53:54,356][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0063 loss2:0.2549 main_loss:0.2612 | AUC:0.8534 AUC2:0.8592 FAR:0.00405
[2023-07-19 21:55:53,513][main.py][line:76][INFO] [Epoch:14/50]: loss1:0.0050 loss2:0.2093 main_loss:0.2143 | AUC:0.8515 AUC2:0.8592 FAR:0.00358
[2023-07-19 21:58:13,411][main.py][line:76][INFO] [Epoch:15/50]: loss1:0.0045 loss2:0.1803 main_loss:0.1848 | AUC:0.8537 AUC2:0.8592 FAR:0.00319
[2023-07-19 22:00:26,459][main.py][line:76][INFO] [Epoch:16/50]: loss1:0.0041 loss2:0.1505 main_loss:0.1546 | AUC:0.8530 AUC2:0.8592 FAR:0.00400
[2023-07-19 22:02:22,186][main.py][line:76][INFO] [Epoch:17/50]: loss1:0.0036 loss2:0.1242 main_loss:0.1278 | AUC:0.8533 AUC2:0.8592 FAR:0.00378
[2023-07-19 22:05:01,623][main.py][line:76][INFO] [Epoch:18/50]: loss1:0.0209 loss2:0.1376 main_loss:0.1585 | AUC:0.8508 AUC2:0.8592 FAR:0.00877
[2023-07-19 22:07:37,911][main.py][line:76][INFO] [Epoch:19/50]: loss1:0.0205 loss2:0.1492 main_loss:0.1697 | AUC:0.8433 AUC2:0.8592 FAR:0.00556
[2023-07-19 22:09:48,582][main.py][line:76][INFO] [Epoch:20/50]: loss1:0.0046 loss2:0.0993 main_loss:0.1039 | AUC:0.8472 AUC2:0.8592 FAR:0.00469
[2023-07-19 22:11:57,487][main.py][line:76][INFO] [Epoch:21/50]: loss1:0.0031 loss2:0.0783 main_loss:0.0814 | AUC:0.8478 AUC2:0.8592 FAR:0.00356
[2023-07-19 22:14:05,746][main.py][line:76][INFO] [Epoch:22/50]: loss1:0.0025 loss2:0.0653 main_loss:0.0678 | AUC:0.8484 AUC2:0.8592 FAR:0.00415
[2023-07-19 22:16:38,353][main.py][line:76][INFO] [Epoch:23/50]: loss1:0.0022 loss2:0.0556 main_loss:0.0578 | AUC:0.8506 AUC2:0.8592 FAR:0.00353
[2023-07-19 22:18:30,701][main.py][line:76][INFO] [Epoch:24/50]: loss1:0.0021 loss2:0.0488 main_loss:0.0509 | AUC:0.8483 AUC2:0.8592 FAR:0.00309
[2023-07-19 22:20:34,902][main.py][line:76][INFO] [Epoch:25/50]: loss1:0.0020 loss2:0.0426 main_loss:0.0446 | AUC:0.8494 AUC2:0.8592 FAR:0.00336
[2023-07-19 22:22:27,756][main.py][line:76][INFO] [Epoch:26/50]: loss1:0.0017 loss2:0.0370 main_loss:0.0387 | AUC:0.8479 AUC2:0.8592 FAR:0.00380
[2023-07-19 22:24:51,858][main.py][line:76][INFO] [Epoch:27/50]: loss1:0.0014 loss2:0.0322 main_loss:0.0336 | AUC:0.8502 AUC2:0.8592 FAR:0.00370
[2023-07-19 22:26:50,108][main.py][line:76][INFO] [Epoch:28/50]: loss1:0.0013 loss2:0.0284 main_loss:0.0296 | AUC:0.8507 AUC2:0.8592 FAR:0.00326
[2023-07-19 22:29:05,625][main.py][line:76][INFO] [Epoch:29/50]: loss1:0.0014 loss2:0.0258 main_loss:0.0272 | AUC:0.8509 AUC2:0.8592 FAR:0.00306
[2023-07-19 22:31:25,037][main.py][line:76][INFO] [Epoch:30/50]: loss1:0.0010 loss2:0.0226 main_loss:0.0236 | AUC:0.8505 AUC2:0.8592 FAR:0.00351
[2023-07-19 22:33:09,828][main.py][line:76][INFO] [Epoch:31/50]: loss1:0.0010 loss2:0.0206 main_loss:0.0217 | AUC:0.8481 AUC2:0.8592 FAR:0.00346
[2023-07-19 22:35:30,957][main.py][line:76][INFO] [Epoch:32/50]: loss1:0.0010 loss2:0.0194 main_loss:0.0204 | AUC:0.8427 AUC2:0.8592 FAR:0.00227
[2023-07-19 22:37:22,930][main.py][line:76][INFO] [Epoch:33/50]: loss1:0.0009 loss2:0.0172 main_loss:0.0180 | AUC:0.8483 AUC2:0.8592 FAR:0.00417
[2023-07-19 22:39:30,077][main.py][line:76][INFO] [Epoch:34/50]: loss1:0.0008 loss2:0.0156 main_loss:0.0164 | AUC:0.8485 AUC2:0.8592 FAR:0.00425
[2023-07-19 22:41:23,668][main.py][line:76][INFO] [Epoch:35/50]: loss1:0.0009 loss2:0.0145 main_loss:0.0154 | AUC:0.8450 AUC2:0.8592 FAR:0.00245
[2023-07-19 22:43:40,817][main.py][line:76][INFO] [Epoch:36/50]: loss1:0.0008 loss2:0.0144 main_loss:0.0153 | AUC:0.8463 AUC2:0.8592 FAR:0.00338
[2023-07-19 22:45:58,384][main.py][line:76][INFO] [Epoch:37/50]: loss1:0.0007 loss2:0.0134 main_loss:0.0141 | AUC:0.8468 AUC2:0.8592 FAR:0.00316
[2023-07-19 22:47:56,321][main.py][line:76][INFO] [Epoch:38/50]: loss1:0.0009 loss2:0.0120 main_loss:0.0129 | AUC:0.8495 AUC2:0.8592 FAR:0.00753
[2023-07-19 22:49:49,275][main.py][line:76][INFO] [Epoch:39/50]: loss1:0.0007 loss2:0.0122 main_loss:0.0129 | AUC:0.8503 AUC2:0.8592 FAR:0.00331
[2023-07-19 22:52:15,879][main.py][line:76][INFO] [Epoch:40/50]: loss1:0.0005 loss2:0.0108 main_loss:0.0113 | AUC:0.8501 AUC2:0.8592 FAR:0.00338
[2023-07-19 22:54:34,549][main.py][line:76][INFO] [Epoch:41/50]: loss1:0.0005 loss2:0.0098 main_loss:0.0102 | AUC:0.8500 AUC2:0.8592 FAR:0.00351
[2023-07-19 22:56:21,810][main.py][line:76][INFO] [Epoch:42/50]: loss1:0.0005 loss2:0.0090 main_loss:0.0094 | AUC:0.8463 AUC2:0.8592 FAR:0.00259
[2023-07-19 22:58:21,596][main.py][line:76][INFO] [Epoch:43/50]: loss1:0.0005 loss2:0.0092 main_loss:0.0097 | AUC:0.8493 AUC2:0.8592 FAR:0.00324
[2023-07-19 23:00:36,589][main.py][line:76][INFO] [Epoch:44/50]: loss1:0.0005 loss2:0.0087 main_loss:0.0091 | AUC:0.8493 AUC2:0.8592 FAR:0.00333
[2023-07-19 23:02:38,542][main.py][line:76][INFO] [Epoch:45/50]: loss1:0.0004 loss2:0.0087 main_loss:0.0091 | AUC:0.8501 AUC2:0.8592 FAR:0.00319
[2023-07-19 23:04:27,142][main.py][line:76][INFO] [Epoch:46/50]: loss1:0.0007 loss2:0.0085 main_loss:0.0092 | AUC:0.8492 AUC2:0.8592 FAR:0.00274
[2023-07-19 23:06:08,470][main.py][line:76][INFO] [Epoch:47/50]: loss1:0.0004 loss2:0.0076 main_loss:0.0080 | AUC:0.8500 AUC2:0.8592 FAR:0.00282
[2023-07-19 23:08:25,323][main.py][line:76][INFO] [Epoch:48/50]: loss1:0.0004 loss2:0.0079 main_loss:0.0083 | AUC:0.8496 AUC2:0.8592 FAR:0.00314
[2023-07-19 23:10:17,999][main.py][line:76][INFO] [Epoch:49/50]: loss1:0.0004 loss2:0.0072 main_loss:0.0076 | AUC:0.8492 AUC2:0.8592 FAR:0.00304
[2023-07-19 23:11:57,878][main.py][line:76][INFO] [Epoch:50/50]: loss1:0.0003 loss2:0.0070 main_loss:0.0074 | AUC:0.8496 AUC2:0.8592 FAR:0.00304
[2023-07-19 23:11:57,879][main.py][line:82][INFO] Training completes in 105m 30s | best AUC:0.8592 FAR:0.00200

[2023-07-20 00:38:12,146][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:38:12,332][main.py][line:116][INFO] total params:27.0270M
[2023-07-20 00:38:12,333][main.py][line:123][INFO] Test Mode
[2023-07-20 00:38:12,333][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8592.pkl.
[2023-07-20 00:38:20,607][infer_bert.py][line:55][INFO] offline AUC:0.8592 AUC2:0.8651 AP:0.3193 FAR:0.0016 | Complete in 0m 8s

[2023-07-20 00:41:10,896][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:41:11,059][main.py][line:116][INFO] total params:27.0270M
[2023-07-20 00:41:11,060][main.py][line:119][INFO] Training Mode
[2023-07-20 00:41:11,060][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 00:41:11,060][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 00:41:18,661][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 00:42:08,444][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:42:08,596][main.py][line:116][INFO] total params:27.0270M
[2023-07-20 00:42:08,596][main.py][line:119][INFO] Training Mode
[2023-07-20 00:42:08,596][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 00:42:08,596][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 00:42:16,228][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 00:43:34,123][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:43:34,286][main.py][line:116][INFO] total params:27.0270M
[2023-07-20 00:43:34,286][main.py][line:119][INFO] Training Mode
[2023-07-20 00:43:34,287][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 00:43:34,287][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 00:43:41,858][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 00:45:18,225][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:45:18,374][main.py][line:116][INFO] total params:27.0270M
[2023-07-20 00:45:18,375][main.py][line:119][INFO] Training Mode
[2023-07-20 00:45:18,375][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 00:45:18,375][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 00:45:25,937][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 00:48:05,720][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:48:05,881][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 00:48:05,881][main.py][line:119][INFO] Training Mode
[2023-07-20 00:48:05,881][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 00:48:05,881][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 00:48:25,167][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 00:51:18,656][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3729 loss2:1.0986 main_loss:1.4714 | AUC:0.8271 AUC2:0.8271 FAR:0.00583
[2023-07-20 00:52:46,800][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 00:52:46,970][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 00:52:46,970][main.py][line:119][INFO] Training Mode
[2023-07-20 00:52:46,970][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 00:52:46,970][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 00:53:06,469][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 00:54:34,804][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3729 loss2:1.0986 main_loss:1.4714 | AUC:0.8271 AUC2:0.8271 FAR:0.00583
[2023-07-20 00:56:04,999][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1468 loss2:0.8741 main_loss:1.0209 | AUC:0.8501 AUC2:0.8501 FAR:0.00603
[2023-07-20 00:57:33,786][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0684 loss2:0.7777 main_loss:0.8461 | AUC:0.8417 AUC2:0.8501 FAR:0.00832
[2023-07-20 00:59:00,669][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0314 loss2:0.7010 main_loss:0.7324 | AUC:0.8486 AUC2:0.8501 FAR:0.00326
[2023-07-20 01:00:28,883][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0191 loss2:0.6276 main_loss:0.6466 | AUC:0.8481 AUC2:0.8501 FAR:0.00168
[2023-07-20 01:01:56,438][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0402 loss2:0.5925 main_loss:0.6327 | AUC:0.8405 AUC2:0.8501 FAR:0.00440
[2023-07-20 01:04:54,755][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 01:04:54,954][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 01:04:54,954][main.py][line:119][INFO] Training Mode
[2023-07-20 01:04:54,955][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 01:04:54,955][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 01:05:14,596][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 01:06:53,830][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3825 loss2:1.0427 main_loss:1.4681 | AUC:0.8352 AUC2:0.8295 FAR:0.00706
[2023-07-20 01:08:41,923][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1690 loss2:0.8141 main_loss:1.0624 | AUC:0.8464 AUC2:0.8425 FAR:0.00499
[2023-07-20 01:10:22,808][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.1025 loss2:0.7199 main_loss:0.9184 | AUC:0.8554 AUC2:0.8522 FAR:0.00958
[2023-07-20 01:12:05,880][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0625 loss2:0.6487 main_loss:0.8023 | AUC:0.8522 AUC2:0.8522 FAR:0.00405
[2023-07-20 01:13:47,661][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0512 loss2:0.5879 main_loss:0.7336 | AUC:0.8535 AUC2:0.8522 FAR:0.00309
[2023-07-20 01:15:32,146][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0369 loss2:0.5276 main_loss:0.6522 | AUC:0.8450 AUC2:0.8522 FAR:0.00242
[2023-07-20 01:17:12,360][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0727 loss2:0.4973 main_loss:0.6333 | AUC:0.8564 AUC2:0.8466 FAR:0.00210
[2023-07-20 01:19:01,699][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0243 loss2:0.4257 main_loss:0.5225 | AUC:0.8527 AUC2:0.8466 FAR:0.00190
[2023-07-20 01:20:43,282][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0189 loss2:0.3701 main_loss:0.4747 | AUC:0.8585 AUC2:0.8477 FAR:0.00225
[2023-07-20 01:22:30,322][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0158 loss2:0.3204 main_loss:0.4300 | AUC:0.8565 AUC2:0.8477 FAR:0.00133
[2023-07-20 01:24:22,205][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0149 loss2:0.2746 main_loss:0.3767 | AUC:0.8600 AUC2:0.8490 FAR:0.00286
[2023-07-20 01:26:09,383][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0127 loss2:0.2297 main_loss:0.3385 | AUC:0.8550 AUC2:0.8490 FAR:0.00207
[2023-07-20 01:27:46,821][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0435 loss2:0.2312 main_loss:0.3430 | AUC:0.8442 AUC2:0.8490 FAR:0.02149
[2023-07-20 01:29:25,395][main.py][line:76][INFO] [Epoch:14/50]: loss1:0.0543 loss2:0.2415 main_loss:0.3462 | AUC:0.8447 AUC2:0.8490 FAR:0.00353
[2023-07-20 01:31:05,005][main.py][line:76][INFO] [Epoch:15/50]: loss1:0.0214 loss2:0.1784 main_loss:0.2673 | AUC:0.8519 AUC2:0.8490 FAR:0.00499
[2023-07-20 01:32:44,964][main.py][line:76][INFO] [Epoch:16/50]: loss1:0.0118 loss2:0.1409 main_loss:0.2258 | AUC:0.8520 AUC2:0.8490 FAR:0.00284
[2023-07-20 01:34:25,662][main.py][line:76][INFO] [Epoch:17/50]: loss1:0.0092 loss2:0.1146 main_loss:0.1900 | AUC:0.8505 AUC2:0.8490 FAR:0.00232
[2023-07-20 01:36:05,436][main.py][line:76][INFO] [Epoch:18/50]: loss1:0.0073 loss2:0.0936 main_loss:0.1657 | AUC:0.8464 AUC2:0.8490 FAR:0.00210
[2023-07-20 01:37:44,883][main.py][line:76][INFO] [Epoch:19/50]: loss1:0.0071 loss2:0.0786 main_loss:0.1509 | AUC:0.8456 AUC2:0.8490 FAR:0.00153
[2023-07-20 01:39:26,853][main.py][line:76][INFO] [Epoch:20/50]: loss1:0.0058 loss2:0.0673 main_loss:0.1510 | AUC:0.8466 AUC2:0.8490 FAR:0.00170
[2023-07-20 01:41:07,356][main.py][line:76][INFO] [Epoch:21/50]: loss1:0.0049 loss2:0.0566 main_loss:0.1347 | AUC:0.8486 AUC2:0.8490 FAR:0.00205
[2023-07-20 01:42:53,645][main.py][line:76][INFO] [Epoch:22/50]: loss1:0.0046 loss2:0.0485 main_loss:0.1339 | AUC:0.8500 AUC2:0.8490 FAR:0.00198
[2023-07-20 01:44:30,429][main.py][line:76][INFO] [Epoch:23/50]: loss1:0.0042 loss2:0.0425 main_loss:0.1187 | AUC:0.8412 AUC2:0.8490 FAR:0.00205
[2023-07-20 01:46:05,156][main.py][line:76][INFO] [Epoch:24/50]: loss1:0.0037 loss2:0.0371 main_loss:0.1042 | AUC:0.8451 AUC2:0.8490 FAR:0.00220
[2023-07-20 01:47:47,872][main.py][line:76][INFO] [Epoch:25/50]: loss1:0.0034 loss2:0.0323 main_loss:0.0969 | AUC:0.8503 AUC2:0.8490 FAR:0.00237
[2023-07-20 01:49:26,185][main.py][line:76][INFO] [Epoch:26/50]: loss1:0.0032 loss2:0.0283 main_loss:0.0909 | AUC:0.8531 AUC2:0.8490 FAR:0.00203
[2023-07-20 01:51:04,904][main.py][line:76][INFO] [Epoch:27/50]: loss1:0.0026 loss2:0.0250 main_loss:0.0826 | AUC:0.8465 AUC2:0.8490 FAR:0.00188
[2023-07-20 01:52:46,316][main.py][line:76][INFO] [Epoch:28/50]: loss1:0.0028 loss2:0.0223 main_loss:0.0773 | AUC:0.8500 AUC2:0.8490 FAR:0.00212
[2023-07-20 01:54:22,609][main.py][line:76][INFO] [Epoch:29/50]: loss1:0.0023 loss2:0.0205 main_loss:0.0738 | AUC:0.8493 AUC2:0.8490 FAR:0.00222
[2023-07-20 01:55:57,981][main.py][line:76][INFO] [Epoch:30/50]: loss1:0.0022 loss2:0.0183 main_loss:0.0672 | AUC:0.8472 AUC2:0.8490 FAR:0.00301
[2023-07-20 01:57:39,023][main.py][line:76][INFO] [Epoch:31/50]: loss1:0.0128 loss2:0.0314 main_loss:0.0841 | AUC:0.8463 AUC2:0.8490 FAR:0.00059
[2023-07-20 01:59:17,308][main.py][line:76][INFO] [Epoch:32/50]: loss1:0.0338 loss2:0.0733 main_loss:0.1339 | AUC:0.8501 AUC2:0.8490 FAR:0.00543
[2023-07-20 02:00:53,223][main.py][line:76][INFO] [Epoch:33/50]: loss1:0.0056 loss2:0.0267 main_loss:0.0712 | AUC:0.8479 AUC2:0.8490 FAR:0.00395
[2023-07-20 02:02:28,782][main.py][line:76][INFO] [Epoch:34/50]: loss1:0.0032 loss2:0.0189 main_loss:0.0679 | AUC:0.8508 AUC2:0.8490 FAR:0.00333
[2023-07-20 02:04:08,125][main.py][line:76][INFO] [Epoch:35/50]: loss1:0.0025 loss2:0.0157 main_loss:0.0563 | AUC:0.8535 AUC2:0.8490 FAR:0.00311
[2023-07-20 02:05:46,639][main.py][line:76][INFO] [Epoch:36/50]: loss1:0.0031 loss2:0.0150 main_loss:0.0527 | AUC:0.8502 AUC2:0.8490 FAR:0.00412
[2023-07-20 02:07:24,294][main.py][line:76][INFO] [Epoch:37/50]: loss1:0.0025 loss2:0.0136 main_loss:0.0541 | AUC:0.8517 AUC2:0.8490 FAR:0.00286
[2023-07-20 02:09:01,487][main.py][line:76][INFO] [Epoch:38/50]: loss1:0.0018 loss2:0.0123 main_loss:0.0528 | AUC:0.8493 AUC2:0.8490 FAR:0.00279
[2023-07-20 02:10:41,784][main.py][line:76][INFO] [Epoch:39/50]: loss1:0.0017 loss2:0.0113 main_loss:0.0495 | AUC:0.8501 AUC2:0.8490 FAR:0.00262
[2023-07-20 02:12:20,983][main.py][line:76][INFO] [Epoch:40/50]: loss1:0.0017 loss2:0.0104 main_loss:0.0464 | AUC:0.8504 AUC2:0.8490 FAR:0.00286
[2023-07-20 02:13:58,100][main.py][line:76][INFO] [Epoch:41/50]: loss1:0.0016 loss2:0.0100 main_loss:0.0430 | AUC:0.8506 AUC2:0.8490 FAR:0.00264
[2023-07-20 02:15:33,988][main.py][line:76][INFO] [Epoch:42/50]: loss1:0.0016 loss2:0.0096 main_loss:0.0434 | AUC:0.8515 AUC2:0.8490 FAR:0.00274
[2023-07-20 02:17:10,608][main.py][line:76][INFO] [Epoch:43/50]: loss1:0.0014 loss2:0.0091 main_loss:0.0389 | AUC:0.8523 AUC2:0.8490 FAR:0.00269
[2023-07-20 02:18:46,134][main.py][line:76][INFO] [Epoch:44/50]: loss1:0.0013 loss2:0.0087 main_loss:0.0349 | AUC:0.8518 AUC2:0.8490 FAR:0.00284
[2023-07-20 02:20:23,049][main.py][line:76][INFO] [Epoch:45/50]: loss1:0.0011 loss2:0.0082 main_loss:0.0355 | AUC:0.8518 AUC2:0.8490 FAR:0.00279
[2023-07-20 02:22:03,520][main.py][line:76][INFO] [Epoch:46/50]: loss1:0.0012 loss2:0.0079 main_loss:0.0338 | AUC:0.8519 AUC2:0.8490 FAR:0.00262
[2023-07-20 02:23:44,085][main.py][line:76][INFO] [Epoch:47/50]: loss1:0.0012 loss2:0.0077 main_loss:0.0329 | AUC:0.8535 AUC2:0.8490 FAR:0.00279
[2023-07-20 02:25:18,471][main.py][line:76][INFO] [Epoch:48/50]: loss1:0.0011 loss2:0.0075 main_loss:0.0306 | AUC:0.8509 AUC2:0.8490 FAR:0.00279
[2023-07-20 02:26:57,674][main.py][line:76][INFO] [Epoch:49/50]: loss1:0.0013 loss2:0.0072 main_loss:0.0310 | AUC:0.8493 AUC2:0.8490 FAR:0.00284
[2023-07-20 02:28:34,558][main.py][line:76][INFO] [Epoch:50/50]: loss1:0.0010 loss2:0.0071 main_loss:0.0309 | AUC:0.8522 AUC2:0.8490 FAR:0.00286
[2023-07-20 02:28:34,684][main.py][line:82][INFO] Training completes in 83m 20s | best AUC:0.8600 FAR:0.00286

[2023-07-20 03:39:08,526][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 03:39:11,740][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8592.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 03:39:11,894][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 03:39:11,894][main.py][line:123][INFO] Test Mode
[2023-07-20 03:39:11,894][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8592.pkl.
[2023-07-20 03:39:11,951][main.py][line:32][INFO] bert.embedding.learnedPosition.pe size mismatch: load torch.Size([1, 33, 1024]) given torch.Size([1, 201, 1024])
[2023-07-20 03:39:34,358][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 03:39:34,518][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 03:39:34,518][main.py][line:123][INFO] Test Mode
[2023-07-20 03:39:34,518][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__86.pkl.
[2023-07-20 03:39:54,300][infer_bert.py][line:55][INFO] offline AUC:0.8600 AUC2:0.8541 AP:0.3277 FAR:0.0022 | Complete in 0m 20s

[2023-07-20 03:42:11,529][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 500, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 03:42:11,696][main.py][line:116][INFO] total params:27.5062M
[2023-07-20 03:42:11,696][main.py][line:119][INFO] Training Mode
[2023-07-20 03:42:11,696][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 03:42:11,696][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 03:42:50,611][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 03:47:11,406][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 500, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 03:47:11,571][main.py][line:116][INFO] total params:27.5062M
[2023-07-20 03:47:11,571][main.py][line:119][INFO] Training Mode
[2023-07-20 03:47:11,572][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 03:47:11,572][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 03:47:49,418][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 03:49:08,328][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 03:49:08,491][main.py][line:116][INFO] total params:27.3014M
[2023-07-20 03:49:08,491][main.py][line:119][INFO] Training Mode
[2023-07-20 03:49:08,491][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 03:49:08,491][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 03:49:33,864][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 03:51:16,449][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.5132 loss2:1.0940 main_loss:1.5696 | AUC:0.8343 AUC2:0.8315 FAR:0.00953
[2023-07-20 03:52:58,978][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.2477 loss2:0.8751 main_loss:1.1400 | AUC:0.8451 AUC2:0.8470 FAR:0.00934
[2023-07-20 03:54:42,505][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.1487 loss2:0.7792 main_loss:0.9739 | AUC:0.8471 AUC2:0.8437 FAR:0.00855
[2023-07-20 03:56:25,494][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0812 loss2:0.7029 main_loss:0.8626 | AUC:0.8469 AUC2:0.8437 FAR:0.00408
[2023-07-20 03:58:08,164][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0551 loss2:0.6406 main_loss:0.7698 | AUC:0.8438 AUC2:0.8437 FAR:0.00304
[2023-07-20 03:59:51,207][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0410 loss2:0.5811 main_loss:0.6909 | AUC:0.8450 AUC2:0.8437 FAR:0.00709
[2023-07-20 04:01:34,188][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0315 loss2:0.5271 main_loss:0.6334 | AUC:0.8507 AUC2:0.8412 FAR:0.01040
[2023-07-20 04:03:17,526][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0273 loss2:0.4768 main_loss:0.5930 | AUC:0.8473 AUC2:0.8412 FAR:0.00664
[2023-07-20 04:05:00,746][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0178 loss2:0.4176 main_loss:0.5344 | AUC:0.8411 AUC2:0.8412 FAR:0.00333
[2023-07-20 04:06:44,380][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0254 loss2:0.3845 main_loss:0.5093 | AUC:0.8334 AUC2:0.8412 FAR:0.00291
[2023-07-20 04:08:27,466][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0151 loss2:0.3326 main_loss:0.4768 | AUC:0.8438 AUC2:0.8412 FAR:0.00435
[2023-07-20 04:10:10,309][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0183 loss2:0.2957 main_loss:0.4374 | AUC:0.8489 AUC2:0.8412 FAR:0.00447
[2023-07-20 04:11:53,502][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0445 loss2:0.2989 main_loss:0.4424 | AUC:0.8290 AUC2:0.8412 FAR:0.01595
[2023-07-20 04:13:36,890][main.py][line:76][INFO] [Epoch:14/50]: loss1:0.0259 loss2:0.2631 main_loss:0.4036 | AUC:0.8307 AUC2:0.8412 FAR:0.00625
[2023-07-20 04:15:20,193][main.py][line:76][INFO] [Epoch:15/50]: loss1:0.0110 loss2:0.2054 main_loss:0.3332 | AUC:0.8404 AUC2:0.8412 FAR:0.00506
[2023-07-20 04:17:03,390][main.py][line:76][INFO] [Epoch:16/50]: loss1:0.0089 loss2:0.1717 main_loss:0.2996 | AUC:0.8327 AUC2:0.8412 FAR:0.00427
[2023-07-20 04:18:46,365][main.py][line:76][INFO] [Epoch:17/50]: loss1:0.0092 loss2:0.1515 main_loss:0.2639 | AUC:0.8383 AUC2:0.8412 FAR:0.00479
[2023-07-20 04:20:29,209][main.py][line:76][INFO] [Epoch:18/50]: loss1:0.0064 loss2:0.1241 main_loss:0.2348 | AUC:0.8400 AUC2:0.8412 FAR:0.00380
[2023-07-20 04:22:12,208][main.py][line:76][INFO] [Epoch:19/50]: loss1:0.0061 loss2:0.1063 main_loss:0.2159 | AUC:0.8340 AUC2:0.8412 FAR:0.00711
[2023-07-20 04:23:55,233][main.py][line:76][INFO] [Epoch:20/50]: loss1:0.0074 loss2:0.0926 main_loss:0.1969 | AUC:0.8406 AUC2:0.8412 FAR:0.00491
[2023-07-20 04:25:38,155][main.py][line:76][INFO] [Epoch:21/50]: loss1:0.0089 loss2:0.0895 main_loss:0.2048 | AUC:0.8262 AUC2:0.8412 FAR:0.00388
[2023-07-20 04:27:21,873][main.py][line:76][INFO] [Epoch:22/50]: loss1:0.0216 loss2:0.1048 main_loss:0.2203 | AUC:0.8363 AUC2:0.8412 FAR:0.00654
[2023-07-20 04:29:05,532][main.py][line:76][INFO] [Epoch:23/50]: loss1:0.0064 loss2:0.0721 main_loss:0.1789 | AUC:0.8201 AUC2:0.8412 FAR:0.01265
[2023-07-20 04:30:48,513][main.py][line:76][INFO] [Epoch:24/50]: loss1:0.0059 loss2:0.0598 main_loss:0.1606 | AUC:0.8199 AUC2:0.8412 FAR:0.00309
[2023-07-20 04:32:31,800][main.py][line:76][INFO] [Epoch:25/50]: loss1:0.0046 loss2:0.0518 main_loss:0.1480 | AUC:0.8196 AUC2:0.8412 FAR:0.01042
[2023-07-20 04:34:14,888][main.py][line:76][INFO] [Epoch:26/50]: loss1:0.0047 loss2:0.0449 main_loss:0.1357 | AUC:0.8318 AUC2:0.8412 FAR:0.00664
[2023-07-20 04:35:58,003][main.py][line:76][INFO] [Epoch:27/50]: loss1:0.0029 loss2:0.0385 main_loss:0.1258 | AUC:0.8149 AUC2:0.8412 FAR:0.00282
[2023-07-20 04:37:40,947][main.py][line:76][INFO] [Epoch:28/50]: loss1:0.0028 loss2:0.0340 main_loss:0.1192 | AUC:0.8223 AUC2:0.8412 FAR:0.00813
[2023-07-20 04:39:24,203][main.py][line:76][INFO] [Epoch:29/50]: loss1:0.0027 loss2:0.0314 main_loss:0.1106 | AUC:0.8130 AUC2:0.8412 FAR:0.00721
[2023-07-20 04:41:06,809][main.py][line:76][INFO] [Epoch:30/50]: loss1:0.0028 loss2:0.0279 main_loss:0.1134 | AUC:0.8238 AUC2:0.8412 FAR:0.00605
[2023-07-20 04:42:50,615][main.py][line:76][INFO] [Epoch:31/50]: loss1:0.0026 loss2:0.0250 main_loss:0.1094 | AUC:0.8157 AUC2:0.8412 FAR:0.00887
[2023-07-20 04:46:13,498][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 04:46:13,687][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 04:46:13,687][main.py][line:119][INFO] Training Mode
[2023-07-20 04:46:13,688][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 04:46:13,688][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 04:48:27,498][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 04:48:27,653][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 04:48:27,653][main.py][line:119][INFO] Training Mode
[2023-07-20 04:48:27,653][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 04:48:27,653][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 04:51:15,542][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 04:51:15,705][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 04:51:15,705][main.py][line:119][INFO] Training Mode
[2023-07-20 04:51:15,706][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 04:51:15,706][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 04:51:49,040][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 04:51:49,196][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 04:51:49,196][main.py][line:119][INFO] Training Mode
[2023-07-20 04:51:49,196][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 04:51:49,196][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 04:52:10,739][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 04:52:10,885][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 04:52:10,885][main.py][line:119][INFO] Training Mode
[2023-07-20 04:52:10,886][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 04:52:10,886][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 04:54:42,532][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 04:54:42,677][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 04:54:42,677][main.py][line:119][INFO] Training Mode
[2023-07-20 04:54:42,677][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 04:54:42,677][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:00:48,367][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:00:48,523][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:00:48,523][main.py][line:119][INFO] Training Mode
[2023-07-20 05:00:48,523][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:00:48,524][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:01:02,545][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:01:02,701][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:01:02,701][main.py][line:119][INFO] Training Mode
[2023-07-20 05:01:02,701][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:01:02,701][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:01:58,555][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:01:58,698][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:01:58,698][main.py][line:119][INFO] Training Mode
[2023-07-20 05:01:58,699][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:01:58,699][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:02:12,582][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:02:12,738][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:02:12,738][main.py][line:119][INFO] Training Mode
[2023-07-20 05:02:12,738][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:02:12,738][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:03:22,983][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:03:23,136][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:03:23,136][main.py][line:119][INFO] Training Mode
[2023-07-20 05:03:23,136][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:03:23,136][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:03:58,043][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:03:58,205][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:03:58,206][main.py][line:119][INFO] Training Mode
[2023-07-20 05:03:58,206][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:03:58,206][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:04:17,673][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:04:17,833][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:04:17,833][main.py][line:119][INFO] Training Mode
[2023-07-20 05:04:17,834][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:04:17,834][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:04:48,733][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:04:48,889][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:04:48,889][main.py][line:119][INFO] Training Mode
[2023-07-20 05:04:48,889][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:04:48,890][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:05:11,063][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:05:11,220][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:05:11,220][main.py][line:119][INFO] Training Mode
[2023-07-20 05:05:11,220][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:05:11,220][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:07:38,827][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:07:38,973][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:07:38,973][main.py][line:119][INFO] Training Mode
[2023-07-20 05:07:38,973][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:07:38,974][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:08:58,932][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:08:59,090][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:08:59,090][main.py][line:119][INFO] Training Mode
[2023-07-20 05:08:59,090][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:08:59,090][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:09:31,927][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:09:32,075][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:09:32,075][main.py][line:119][INFO] Training Mode
[2023-07-20 05:09:32,075][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:09:32,075][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:10:45,224][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:10:45,388][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:10:45,388][main.py][line:119][INFO] Training Mode
[2023-07-20 05:10:45,389][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:10:45,389][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:11:49,602][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:11:49,758][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:11:49,758][main.py][line:119][INFO] Training Mode
[2023-07-20 05:11:49,758][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:11:49,758][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:12:25,527][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:12:25,686][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:12:25,686][main.py][line:119][INFO] Training Mode
[2023-07-20 05:12:25,687][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:12:25,687][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:13:01,198][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:13:01,357][main.py][line:116][INFO] total params:27.3014M
[2023-07-20 05:13:01,357][main.py][line:119][INFO] Training Mode
[2023-07-20 05:13:01,358][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:13:01,358][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:13:57,632][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:13:57,793][main.py][line:116][INFO] total params:27.3014M
[2023-07-20 05:13:57,793][main.py][line:119][INFO] Training Mode
[2023-07-20 05:13:57,793][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:13:57,793][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:14:23,602][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 05:20:15,852][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:20:16,012][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:20:16,012][main.py][line:119][INFO] Training Mode
[2023-07-20 05:20:16,013][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:20:16,013][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:20:37,617][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:20:37,783][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:20:37,783][main.py][line:119][INFO] Training Mode
[2023-07-20 05:20:37,783][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:20:37,783][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:21:09,244][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:21:09,405][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:21:09,405][main.py][line:119][INFO] Training Mode
[2023-07-20 05:21:09,406][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:21:09,406][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:21:37,426][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:21:37,573][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:21:37,573][main.py][line:119][INFO] Training Mode
[2023-07-20 05:21:37,573][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:21:37,573][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:22:15,734][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:22:15,879][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:22:15,879][main.py][line:119][INFO] Training Mode
[2023-07-20 05:22:15,879][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:22:15,879][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:23:35,496][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:23:35,653][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:23:35,653][main.py][line:119][INFO] Training Mode
[2023-07-20 05:23:35,653][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:23:35,653][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:24:32,805][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:24:32,951][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:24:32,951][main.py][line:119][INFO] Training Mode
[2023-07-20 05:24:32,952][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:24:32,952][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:24:41,264][main.py][line:53][INFO] Random initialize AUC:0.5446 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 05:26:59,883][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:27:00,048][main.py][line:116][INFO] total params:26.9953M
[2023-07-20 05:27:00,048][main.py][line:119][INFO] Training Mode
[2023-07-20 05:27:00,048][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:27:00,048][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:27:08,284][main.py][line:53][INFO] Random initialize AUC:0.5446 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 05:30:02,880][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.5295 loss2:1.1985 main_loss:1.8068 | AUC:0.8353 AUC2:0.8351 FAR:0.01608
[2023-07-20 05:32:58,821][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.2921 loss2:0.9614 main_loss:1.3893 | AUC:0.8337 AUC2:0.8351 FAR:0.01025
[2023-07-20 05:35:38,227][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.1680 loss2:0.8312 main_loss:1.1463 | AUC:0.8372 AUC2:0.8518 FAR:0.00662
[2023-07-20 05:38:25,122][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0906 loss2:0.7292 main_loss:0.9934 | AUC:0.8370 AUC2:0.8518 FAR:0.00605
[2023-07-20 05:41:10,598][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0656 loss2:0.6605 main_loss:0.9070 | AUC:0.8312 AUC2:0.8518 FAR:0.00247
[2023-07-20 05:44:59,155][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:45:37,305][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:45:43,679][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:47:46,735][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:47:59,772][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:48:07,232][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:48:07,392][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 05:48:07,392][main.py][line:119][INFO] Training Mode
[2023-07-20 05:48:07,393][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:48:07,393][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:48:21,136][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:48:21,356][main.py][line:116][INFO] total params:52.3915M
[2023-07-20 05:48:21,356][main.py][line:119][INFO] Training Mode
[2023-07-20 05:48:21,357][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:48:21,357][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:48:42,491][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 05:49:41,975][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 05:49:42,223][main.py][line:116][INFO] total params:52.3915M
[2023-07-20 05:49:42,223][main.py][line:119][INFO] Training Mode
[2023-07-20 05:49:42,224][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 05:49:42,224][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 05:50:02,516][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 05:51:49,821][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3750 loss2:1.0443 main_loss:1.5780 | AUC:0.8327 AUC2:0.8327 FAR:0.00976
[2023-07-20 05:53:37,394][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1707 loss2:0.8155 main_loss:1.2475 | AUC:0.8428 AUC2:0.8428 FAR:0.00304
[2023-07-20 05:55:26,258][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0984 loss2:0.7261 main_loss:1.1219 | AUC:0.8391 AUC2:0.8428 FAR:0.00123
[2023-07-20 05:57:14,800][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0533 loss2:0.6461 main_loss:1.0194 | AUC:0.8495 AUC2:0.8495 FAR:0.00487
[2023-07-20 05:59:03,598][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0396 loss2:0.5823 main_loss:0.9487 | AUC:0.8442 AUC2:0.8495 FAR:0.00437
[2023-07-20 06:00:52,407][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0341 loss2:0.5232 main_loss:0.8867 | AUC:0.8431 AUC2:0.8495 FAR:0.00183
[2023-07-20 06:02:41,042][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0357 loss2:0.4766 main_loss:0.8409 | AUC:0.8474 AUC2:0.8495 FAR:0.00477
[2023-07-20 06:04:30,888][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0293 loss2:0.4206 main_loss:0.7812 | AUC:0.8473 AUC2:0.8495 FAR:0.00249
[2023-07-20 06:06:20,349][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0218 loss2:0.3662 main_loss:0.6621 | AUC:0.8480 AUC2:0.8495 FAR:0.00284
[2023-07-20 06:08:08,906][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0177 loss2:0.3195 main_loss:0.5655 | AUC:0.8486 AUC2:0.8495 FAR:0.00319
[2023-07-20 06:09:58,122][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0133 loss2:0.2680 main_loss:0.4706 | AUC:0.8541 AUC2:0.8479 FAR:0.00338
[2023-07-20 06:11:47,227][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0122 loss2:0.2235 main_loss:0.3941 | AUC:0.8570 AUC2:0.8499 FAR:0.00123
[2023-07-20 06:13:35,800][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0123 loss2:0.1928 main_loss:0.3446 | AUC:0.8549 AUC2:0.8499 FAR:0.00163
[2023-07-20 06:15:24,296][main.py][line:76][INFO] [Epoch:14/50]: loss1:0.0328 loss2:0.2002 main_loss:0.3557 | AUC:0.8497 AUC2:0.8499 FAR:0.00269
[2023-07-20 06:17:13,293][main.py][line:76][INFO] [Epoch:15/50]: loss1:0.0415 loss2:0.2006 main_loss:0.3507 | AUC:0.8567 AUC2:0.8499 FAR:0.00906
[2023-07-20 06:19:02,245][main.py][line:76][INFO] [Epoch:16/50]: loss1:0.0312 loss2:0.1695 main_loss:0.3077 | AUC:0.8569 AUC2:0.8499 FAR:0.00257
[2023-07-20 06:20:51,591][main.py][line:76][INFO] [Epoch:17/50]: loss1:0.0098 loss2:0.1184 main_loss:0.2429 | AUC:0.8584 AUC2:0.8498 FAR:0.00175
[2023-07-20 06:22:40,369][main.py][line:76][INFO] [Epoch:18/50]: loss1:0.0071 loss2:0.0956 main_loss:0.2251 | AUC:0.8576 AUC2:0.8498 FAR:0.00254
[2023-07-20 06:24:29,489][main.py][line:76][INFO] [Epoch:19/50]: loss1:0.0063 loss2:0.0789 main_loss:0.2057 | AUC:0.8578 AUC2:0.8498 FAR:0.00165
[2023-07-20 06:26:18,684][main.py][line:76][INFO] [Epoch:20/50]: loss1:0.0091 loss2:0.0687 main_loss:0.1838 | AUC:0.8522 AUC2:0.8498 FAR:0.00101
[2023-07-20 06:28:08,017][main.py][line:76][INFO] [Epoch:21/50]: loss1:0.0063 loss2:0.0604 main_loss:0.1669 | AUC:0.8544 AUC2:0.8498 FAR:0.00109
[2023-07-20 06:29:57,892][main.py][line:76][INFO] [Epoch:22/50]: loss1:0.0048 loss2:0.0503 main_loss:0.1473 | AUC:0.8529 AUC2:0.8498 FAR:0.00168
[2023-07-20 06:31:46,327][main.py][line:76][INFO] [Epoch:23/50]: loss1:0.0054 loss2:0.0455 main_loss:0.1501 | AUC:0.8548 AUC2:0.8498 FAR:0.00126
[2023-07-20 06:33:35,381][main.py][line:76][INFO] [Epoch:24/50]: loss1:0.0038 loss2:0.0383 main_loss:0.1413 | AUC:0.8552 AUC2:0.8498 FAR:0.00089
[2023-07-20 06:35:23,850][main.py][line:76][INFO] [Epoch:25/50]: loss1:0.0034 loss2:0.0334 main_loss:0.1274 | AUC:0.8555 AUC2:0.8498 FAR:0.00106
[2023-07-20 06:37:12,667][main.py][line:76][INFO] [Epoch:26/50]: loss1:0.0041 loss2:0.0312 main_loss:0.1233 | AUC:0.8530 AUC2:0.8498 FAR:0.00165
[2023-07-20 06:39:01,821][main.py][line:76][INFO] [Epoch:27/50]: loss1:0.0331 loss2:0.0810 main_loss:0.1881 | AUC:0.8563 AUC2:0.8498 FAR:0.00410
[2023-07-20 06:40:51,201][main.py][line:76][INFO] [Epoch:28/50]: loss1:0.0086 loss2:0.0407 main_loss:0.1318 | AUC:0.8526 AUC2:0.8498 FAR:0.00425
[2023-07-20 06:42:39,572][main.py][line:76][INFO] [Epoch:29/50]: loss1:0.0039 loss2:0.0277 main_loss:0.1151 | AUC:0.8535 AUC2:0.8498 FAR:0.00388
[2023-07-20 06:44:28,948][main.py][line:76][INFO] [Epoch:30/50]: loss1:0.0036 loss2:0.0233 main_loss:0.1058 | AUC:0.8514 AUC2:0.8498 FAR:0.00326
[2023-07-20 06:46:17,956][main.py][line:76][INFO] [Epoch:31/50]: loss1:0.0028 loss2:0.0205 main_loss:0.0989 | AUC:0.8525 AUC2:0.8498 FAR:0.00282
[2023-07-20 06:48:06,915][main.py][line:76][INFO] [Epoch:32/50]: loss1:0.0026 loss2:0.0179 main_loss:0.1001 | AUC:0.8527 AUC2:0.8498 FAR:0.00203
[2023-07-20 06:49:55,910][main.py][line:76][INFO] [Epoch:33/50]: loss1:0.0024 loss2:0.0161 main_loss:0.0889 | AUC:0.8521 AUC2:0.8498 FAR:0.00257
[2023-07-20 06:51:44,997][main.py][line:76][INFO] [Epoch:34/50]: loss1:0.0019 loss2:0.0148 main_loss:0.0892 | AUC:0.8523 AUC2:0.8498 FAR:0.00195
[2023-07-20 06:53:33,801][main.py][line:76][INFO] [Epoch:35/50]: loss1:0.0018 loss2:0.0137 main_loss:0.0838 | AUC:0.8527 AUC2:0.8498 FAR:0.00203
[2023-07-20 06:55:22,113][main.py][line:76][INFO] [Epoch:36/50]: loss1:0.0020 loss2:0.0133 main_loss:0.0822 | AUC:0.8517 AUC2:0.8498 FAR:0.00188
[2023-07-20 06:57:10,459][main.py][line:76][INFO] [Epoch:37/50]: loss1:0.0017 loss2:0.0116 main_loss:0.0806 | AUC:0.8514 AUC2:0.8498 FAR:0.00188
[2023-07-20 06:58:59,181][main.py][line:76][INFO] [Epoch:38/50]: loss1:0.0015 loss2:0.0112 main_loss:0.0817 | AUC:0.8544 AUC2:0.8498 FAR:0.00195
[2023-07-20 07:00:48,207][main.py][line:76][INFO] [Epoch:39/50]: loss1:0.0014 loss2:0.0103 main_loss:0.0767 | AUC:0.8535 AUC2:0.8498 FAR:0.00188
[2023-07-20 07:02:36,676][main.py][line:76][INFO] [Epoch:40/50]: loss1:0.0012 loss2:0.0096 main_loss:0.0700 | AUC:0.8535 AUC2:0.8498 FAR:0.00190
[2023-07-20 07:04:26,339][main.py][line:76][INFO] [Epoch:41/50]: loss1:0.0012 loss2:0.0092 main_loss:0.0686 | AUC:0.8503 AUC2:0.8498 FAR:0.00175
[2023-07-20 07:06:14,749][main.py][line:76][INFO] [Epoch:42/50]: loss1:0.0013 loss2:0.0092 main_loss:0.0690 | AUC:0.8520 AUC2:0.8498 FAR:0.00212
[2023-07-20 07:08:03,525][main.py][line:76][INFO] [Epoch:43/50]: loss1:0.0012 loss2:0.0087 main_loss:0.0667 | AUC:0.8534 AUC2:0.8498 FAR:0.00230
[2023-07-20 07:09:53,430][main.py][line:76][INFO] [Epoch:44/50]: loss1:0.0012 loss2:0.0084 main_loss:0.0633 | AUC:0.8525 AUC2:0.8498 FAR:0.00190
[2023-07-20 07:11:42,484][main.py][line:76][INFO] [Epoch:45/50]: loss1:0.0016 loss2:0.0083 main_loss:0.0634 | AUC:0.8509 AUC2:0.8498 FAR:0.00240
[2023-07-20 07:13:30,823][main.py][line:76][INFO] [Epoch:46/50]: loss1:0.0011 loss2:0.0077 main_loss:0.0604 | AUC:0.8519 AUC2:0.8498 FAR:0.00178
[2023-07-20 07:15:19,445][main.py][line:76][INFO] [Epoch:47/50]: loss1:0.0010 loss2:0.0073 main_loss:0.0616 | AUC:0.8529 AUC2:0.8498 FAR:0.00195
[2023-07-20 07:17:08,844][main.py][line:76][INFO] [Epoch:48/50]: loss1:0.0012 loss2:0.0073 main_loss:0.0612 | AUC:0.8509 AUC2:0.8498 FAR:0.00180
[2023-07-20 07:18:57,687][main.py][line:76][INFO] [Epoch:49/50]: loss1:0.0010 loss2:0.0071 main_loss:0.0585 | AUC:0.8524 AUC2:0.8498 FAR:0.00173
[2023-07-20 07:20:47,024][main.py][line:76][INFO] [Epoch:50/50]: loss1:0.0011 loss2:0.0070 main_loss:0.0588 | AUC:0.8530 AUC2:0.8498 FAR:0.00168
[2023-07-20 07:20:47,201][main.py][line:82][INFO] Training completes in 90m 45s | best AUC:0.8584 FAR:0.00175

[2023-07-20 14:12:08,126][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__86.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 14:12:08,386][main.py][line:116][INFO] total params:52.4939M
[2023-07-20 14:12:08,386][main.py][line:123][INFO] Test Mode
[2023-07-20 14:12:08,386][main.py][line:37][INFO] Not found pretrained checkpoint file.
[2023-07-20 14:12:42,743][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8584.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 128, 'max_seqlen': 300, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 14:12:42,974][main.py][line:116][INFO] total params:52.4939M
[2023-07-20 14:12:42,974][main.py][line:123][INFO] Test Mode
[2023-07-20 14:12:42,974][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8584.pkl.
[2023-07-20 14:12:43,032][main.py][line:32][INFO] bert.embedding.learnedPosition.pe size mismatch: load torch.Size([1, 201, 1024]) given torch.Size([1, 301, 1024])
[2023-07-20 14:13:11,072][infer_bert.py][line:55][INFO] offline AUC:0.8592 AUC2:0.8557 AP:0.3162 FAR:0.0011 | Complete in 0m 28s

[2023-07-20 14:22:07,101][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.5, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8584.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 14:22:07,342][main.py][line:116][INFO] total params:52.2891M
[2023-07-20 14:22:07,342][main.py][line:119][INFO] Training Mode
[2023-07-20 14:22:07,342][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 14:22:07,343][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 14:22:20,401][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 14:23:35,016][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3651 loss2:1.2105 main_loss:1.2431 | AUC:0.8272 AUC2:0.8273 FAR:0.00585
[2023-07-20 14:24:49,839][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1384 loss2:1.0035 main_loss:0.8672 | AUC:0.8501 AUC2:0.8441 FAR:0.00336
[2023-07-20 14:26:05,238][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0547 loss2:0.9084 main_loss:0.6741 | AUC:0.8534 AUC2:0.8487 FAR:0.00422
[2023-07-20 14:27:20,442][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0247 loss2:0.8165 main_loss:0.5637 | AUC:0.8482 AUC2:0.8487 FAR:0.00341
[2023-07-20 14:28:35,593][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0198 loss2:0.7432 main_loss:0.5005 | AUC:0.8494 AUC2:0.8487 FAR:0.00180
[2023-07-20 14:29:51,124][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0172 loss2:0.6822 main_loss:0.4538 | AUC:0.8509 AUC2:0.8487 FAR:0.00731
[2023-07-20 14:31:06,409][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0127 loss2:0.6207 main_loss:0.4130 | AUC:0.8525 AUC2:0.8487 FAR:0.00415
[2023-07-20 14:32:21,688][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0103 loss2:0.5571 main_loss:0.3806 | AUC:0.8450 AUC2:0.8487 FAR:0.00131
[2023-07-20 14:33:37,610][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0077 loss2:0.4899 main_loss:0.3390 | AUC:0.8563 AUC2:0.8470 FAR:0.00245
[2023-07-20 14:34:52,869][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0064 loss2:0.4361 main_loss:0.2934 | AUC:0.8416 AUC2:0.8470 FAR:0.00235
[2023-07-20 14:36:08,298][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0052 loss2:0.3728 main_loss:0.2636 | AUC:0.8379 AUC2:0.8470 FAR:0.00264
[2023-07-20 14:37:24,063][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0042 loss2:0.3249 main_loss:0.2223 | AUC:0.8520 AUC2:0.8470 FAR:0.00242
[2023-07-20 14:38:39,222][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0041 loss2:0.2819 main_loss:0.1958 | AUC:0.8529 AUC2:0.8470 FAR:0.00215
[2023-07-20 14:39:54,619][main.py][line:76][INFO] [Epoch:14/50]: loss1:0.0544 loss2:0.3312 main_loss:0.2756 | AUC:0.8589 AUC2:0.8506 FAR:0.00405
[2023-07-20 14:41:09,817][main.py][line:76][INFO] [Epoch:15/50]: loss1:0.0061 loss2:0.2414 main_loss:0.1759 | AUC:0.8586 AUC2:0.8506 FAR:0.00205
[2023-07-20 14:42:25,183][main.py][line:76][INFO] [Epoch:16/50]: loss1:0.0032 loss2:0.1975 main_loss:0.1506 | AUC:0.8612 AUC2:0.8528 FAR:0.00203
[2023-07-20 14:43:40,520][main.py][line:76][INFO] [Epoch:17/50]: loss1:0.0023 loss2:0.1623 main_loss:0.1225 | AUC:0.8578 AUC2:0.8528 FAR:0.00215
[2023-07-20 14:44:55,846][main.py][line:76][INFO] [Epoch:18/50]: loss1:0.0021 loss2:0.1481 main_loss:0.1219 | AUC:0.8585 AUC2:0.8528 FAR:0.00193
[2023-07-20 14:46:11,179][main.py][line:76][INFO] [Epoch:19/50]: loss1:0.0018 loss2:0.1172 main_loss:0.0975 | AUC:0.8579 AUC2:0.8528 FAR:0.00198
[2023-07-20 14:47:26,279][main.py][line:76][INFO] [Epoch:20/50]: loss1:0.0017 loss2:0.1021 main_loss:0.0863 | AUC:0.8541 AUC2:0.8528 FAR:0.00210
[2023-07-20 14:48:41,890][main.py][line:76][INFO] [Epoch:21/50]: loss1:0.0015 loss2:0.0896 main_loss:0.0807 | AUC:0.8558 AUC2:0.8528 FAR:0.00200
[2023-07-20 14:49:57,390][main.py][line:76][INFO] [Epoch:22/50]: loss1:0.0015 loss2:0.0787 main_loss:0.0726 | AUC:0.8638 AUC2:0.8490 FAR:0.00212
[2023-07-20 14:51:12,829][main.py][line:76][INFO] [Epoch:23/50]: loss1:0.0015 loss2:0.0686 main_loss:0.0630 | AUC:0.8586 AUC2:0.8490 FAR:0.00249
[2023-07-20 14:52:28,436][main.py][line:76][INFO] [Epoch:24/50]: loss1:0.0013 loss2:0.0601 main_loss:0.1247 | AUC:0.8501 AUC2:0.8490 FAR:0.00207
[2023-07-20 14:53:43,801][main.py][line:76][INFO] [Epoch:25/50]: loss1:0.0014 loss2:0.0533 main_loss:0.2221 | AUC:0.8543 AUC2:0.8490 FAR:0.00227
[2023-07-20 14:54:59,158][main.py][line:76][INFO] [Epoch:26/50]: loss1:0.0011 loss2:0.0458 main_loss:0.1437 | AUC:0.8554 AUC2:0.8490 FAR:0.00215
[2023-07-20 14:56:14,700][main.py][line:76][INFO] [Epoch:27/50]: loss1:0.0009 loss2:0.0382 main_loss:0.1172 | AUC:0.8516 AUC2:0.8490 FAR:0.00289
[2023-07-20 14:57:30,061][main.py][line:76][INFO] [Epoch:28/50]: loss1:0.0017 loss2:0.0424 main_loss:0.1018 | AUC:0.8500 AUC2:0.8490 FAR:0.00190
[2023-07-20 14:58:45,034][main.py][line:76][INFO] [Epoch:29/50]: loss1:0.0010 loss2:0.0346 main_loss:0.0842 | AUC:0.8519 AUC2:0.8490 FAR:0.00138
[2023-07-20 15:00:00,422][main.py][line:76][INFO] [Epoch:30/50]: loss1:0.0008 loss2:0.0303 main_loss:0.0776 | AUC:0.8531 AUC2:0.8490 FAR:0.00163
[2023-07-20 15:01:16,209][main.py][line:76][INFO] [Epoch:31/50]: loss1:0.0007 loss2:0.0278 main_loss:0.0737 | AUC:0.8543 AUC2:0.8490 FAR:0.00178
[2023-07-20 15:02:31,500][main.py][line:76][INFO] [Epoch:32/50]: loss1:0.0006 loss2:0.0264 main_loss:0.0764 | AUC:0.8603 AUC2:0.8490 FAR:0.00190
[2023-07-20 15:03:46,580][main.py][line:76][INFO] [Epoch:33/50]: loss1:0.0005 loss2:0.0213 main_loss:0.0918 | AUC:0.8584 AUC2:0.8490 FAR:0.00148
[2023-07-20 15:05:02,030][main.py][line:76][INFO] [Epoch:34/50]: loss1:0.0006 loss2:0.0211 main_loss:0.1323 | AUC:0.8550 AUC2:0.8490 FAR:0.00161
[2023-07-20 15:06:17,522][main.py][line:76][INFO] [Epoch:35/50]: loss1:0.0004 loss2:0.0192 main_loss:0.1724 | AUC:0.8572 AUC2:0.8490 FAR:0.00143
[2023-07-20 15:07:32,847][main.py][line:76][INFO] [Epoch:36/50]: loss1:0.0029 loss2:0.0225 main_loss:0.1524 | AUC:0.8526 AUC2:0.8490 FAR:0.00726
[2023-07-20 15:08:47,917][main.py][line:76][INFO] [Epoch:37/50]: loss1:0.0117 loss2:0.0520 main_loss:0.1695 | AUC:0.8563 AUC2:0.8490 FAR:0.00195
[2023-07-20 15:10:03,300][main.py][line:76][INFO] [Epoch:38/50]: loss1:0.0016 loss2:0.0258 main_loss:0.1673 | AUC:0.8546 AUC2:0.8490 FAR:0.00254
[2023-07-20 15:11:18,556][main.py][line:76][INFO] [Epoch:39/50]: loss1:0.0007 loss2:0.0205 main_loss:0.1581 | AUC:0.8577 AUC2:0.8490 FAR:0.00222
[2023-07-20 15:12:33,990][main.py][line:76][INFO] [Epoch:40/50]: loss1:0.0006 loss2:0.0170 main_loss:0.1495 | AUC:0.8580 AUC2:0.8490 FAR:0.00193
[2023-07-20 15:13:49,291][main.py][line:76][INFO] [Epoch:41/50]: loss1:0.0004 loss2:0.0159 main_loss:0.1399 | AUC:0.8587 AUC2:0.8490 FAR:0.00200
[2023-07-20 15:15:04,329][main.py][line:76][INFO] [Epoch:42/50]: loss1:0.0004 loss2:0.0149 main_loss:0.1291 | AUC:0.8589 AUC2:0.8490 FAR:0.00190
[2023-07-20 15:16:19,518][main.py][line:76][INFO] [Epoch:43/50]: loss1:0.0004 loss2:0.0137 main_loss:0.1243 | AUC:0.8590 AUC2:0.8490 FAR:0.00203
[2023-07-20 15:17:35,133][main.py][line:76][INFO] [Epoch:44/50]: loss1:0.0003 loss2:0.0134 main_loss:0.1171 | AUC:0.8592 AUC2:0.8490 FAR:0.00198
[2023-07-20 15:18:50,397][main.py][line:76][INFO] [Epoch:45/50]: loss1:0.0003 loss2:0.0122 main_loss:0.1165 | AUC:0.8600 AUC2:0.8490 FAR:0.00190
[2023-07-20 15:20:05,802][main.py][line:76][INFO] [Epoch:46/50]: loss1:0.0003 loss2:0.0126 main_loss:0.1114 | AUC:0.8610 AUC2:0.8490 FAR:0.00207
[2023-07-20 15:21:21,038][main.py][line:76][INFO] [Epoch:47/50]: loss1:0.0003 loss2:0.0105 main_loss:0.1082 | AUC:0.8611 AUC2:0.8490 FAR:0.00205
[2023-07-20 15:22:36,431][main.py][line:76][INFO] [Epoch:48/50]: loss1:0.0003 loss2:0.0108 main_loss:0.1048 | AUC:0.8606 AUC2:0.8490 FAR:0.00203
[2023-07-20 15:23:51,905][main.py][line:76][INFO] [Epoch:49/50]: loss1:0.0003 loss2:0.0108 main_loss:0.1032 | AUC:0.8609 AUC2:0.8490 FAR:0.00188
[2023-07-20 15:25:06,990][main.py][line:76][INFO] [Epoch:50/50]: loss1:0.0003 loss2:0.0100 main_loss:0.0983 | AUC:0.8606 AUC2:0.8490 FAR:0.00188
[2023-07-20 15:25:07,118][main.py][line:82][INFO] Training completes in 62m 47s | best AUC:0.8638 FAR:0.00212

[2023-07-20 15:34:00,531][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.5, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 15:34:00,813][main.py][line:116][INFO] total params:52.2891M
[2023-07-20 15:34:00,813][main.py][line:123][INFO] Test Mode
[2023-07-20 15:34:00,813][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-20 15:34:14,614][infer_bert.py][line:55][INFO] offline AUC:0.8638 AUC2:0.8558 AP:0.3289 FAR:0.0014 | Complete in 0m 14s

[2023-07-20 15:35:32,774][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.5, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 15:35:33,011][main.py][line:116][INFO] total params:52.2891M
[2023-07-20 15:35:33,011][main.py][line:119][INFO] Training Mode
[2023-07-20 15:35:33,011][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 15:35:33,012][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 15:35:46,042][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 15:37:00,743][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3684 loss2:1.3709 main_loss:4.6427 | AUC:0.8216 AUC2:0.8233 FAR:0.02131
[2023-07-20 15:38:15,422][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1426 loss2:1.3015 main_loss:2.3037 | AUC:0.8487 AUC2:0.8460 FAR:0.01319
[2023-07-20 15:39:30,790][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0390 loss2:1.2560 main_loss:1.1836 | AUC:0.8428 AUC2:0.8460 FAR:0.00617
[2023-07-20 15:40:46,036][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0236 loss2:1.2090 main_loss:0.9709 | AUC:0.8461 AUC2:0.8460 FAR:0.01452
[2023-07-20 15:42:01,313][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0090 loss2:1.1655 main_loss:0.7813 | AUC:0.8429 AUC2:0.8460 FAR:0.01057
[2023-07-20 15:43:17,120][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0234 loss2:1.1307 main_loss:0.8951 | AUC:0.8425 AUC2:0.8460 FAR:0.00677
[2023-07-20 15:44:32,429][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0025 loss2:1.0662 main_loss:0.6476 | AUC:0.8388 AUC2:0.8460 FAR:0.00916
[2023-07-20 15:45:47,748][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0010 loss2:1.0185 main_loss:0.6106 | AUC:0.8417 AUC2:0.8460 FAR:0.00556
[2023-07-20 15:47:03,275][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0007 loss2:0.9457 main_loss:0.5662 | AUC:0.8468 AUC2:0.8460 FAR:0.00529
[2023-07-20 15:48:18,572][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0007 loss2:0.8906 main_loss:0.5211 | AUC:0.8432 AUC2:0.8460 FAR:0.00450
[2023-07-20 15:49:34,210][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0007 loss2:0.8371 main_loss:0.4973 | AUC:0.8385 AUC2:0.8460 FAR:0.00338
[2023-07-20 15:50:49,955][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0007 loss2:0.7563 main_loss:0.4408 | AUC:0.8473 AUC2:0.8460 FAR:0.00412
[2023-07-20 15:52:05,386][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0006 loss2:0.7114 main_loss:0.4129 | AUC:0.8478 AUC2:0.8460 FAR:0.00304
[2023-07-20 15:53:21,095][main.py][line:76][INFO] [Epoch:14/50]: loss1:0.0007 loss2:0.6177 main_loss:0.3713 | AUC:0.8493 AUC2:0.8467 FAR:0.00316
[2023-07-20 15:54:36,551][main.py][line:76][INFO] [Epoch:15/50]: loss1:0.0006 loss2:0.5304 main_loss:0.3199 | AUC:0.8493 AUC2:0.8484 FAR:0.00316
[2023-07-20 15:55:52,087][main.py][line:76][INFO] [Epoch:16/50]: loss1:0.0005 loss2:0.4756 main_loss:0.2918 | AUC:0.8533 AUC2:0.8496 FAR:0.00368
[2023-07-20 15:57:07,392][main.py][line:76][INFO] [Epoch:17/50]: loss1:0.0006 loss2:0.4529 main_loss:0.2717 | AUC:0.8529 AUC2:0.8496 FAR:0.00336
[2023-07-20 15:58:23,170][main.py][line:76][INFO] [Epoch:18/50]: loss1:0.0455 loss2:0.4921 main_loss:0.7469 | AUC:0.8446 AUC2:0.8496 FAR:0.00161
[2023-07-20 15:59:38,854][main.py][line:76][INFO] [Epoch:19/50]: loss1:0.0306 loss2:0.6235 main_loss:0.6549 | AUC:0.8433 AUC2:0.8496 FAR:0.01642
[2023-07-20 16:00:54,144][main.py][line:76][INFO] [Epoch:20/50]: loss1:0.0044 loss2:0.4530 main_loss:0.3035 | AUC:0.8389 AUC2:0.8496 FAR:0.00709
[2023-07-20 16:02:09,582][main.py][line:76][INFO] [Epoch:21/50]: loss1:0.0007 loss2:0.3035 main_loss:0.1931 | AUC:0.8424 AUC2:0.8496 FAR:0.00531
[2023-07-20 16:03:24,631][main.py][line:76][INFO] [Epoch:22/50]: loss1:0.0004 loss2:0.2555 main_loss:0.1636 | AUC:0.8490 AUC2:0.8496 FAR:0.00494
[2023-07-20 16:04:39,618][main.py][line:76][INFO] [Epoch:23/50]: loss1:0.0004 loss2:0.2559 main_loss:0.1596 | AUC:0.8461 AUC2:0.8496 FAR:0.00489
[2023-07-20 16:05:54,851][main.py][line:76][INFO] [Epoch:24/50]: loss1:0.0004 loss2:0.1888 main_loss:0.1916 | AUC:0.8392 AUC2:0.8496 FAR:0.00482
[2023-07-20 16:07:09,627][main.py][line:76][INFO] [Epoch:25/50]: loss1:0.0003 loss2:0.1495 main_loss:0.2715 | AUC:0.8396 AUC2:0.8496 FAR:0.00531
[2023-07-20 16:08:24,522][main.py][line:76][INFO] [Epoch:26/50]: loss1:0.0002 loss2:0.1257 main_loss:0.1849 | AUC:0.8435 AUC2:0.8496 FAR:0.00435
[2023-07-20 16:08:45,648][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.5, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 16:08:45,903][main.py][line:116][INFO] total params:52.2891M
[2023-07-20 16:08:45,903][main.py][line:119][INFO] Training Mode
[2023-07-20 16:08:45,903][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 16:08:45,903][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-07-20 16:08:59,016][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 16:10:13,864][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3554 loss2:1.1499 main_loss:1.2712 | AUC:0.8341 AUC2:0.8283 FAR:0.00277
[2023-07-20 16:11:28,744][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1050 loss2:0.9077 main_loss:0.8439 | AUC:0.8450 AUC2:0.8417 FAR:0.00351
[2023-07-20 16:12:44,232][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0406 loss2:0.7850 main_loss:0.7339 | AUC:0.8411 AUC2:0.8417 FAR:0.00321
[2023-07-20 16:13:59,660][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0311 loss2:0.6588 main_loss:0.6656 | AUC:0.8230 AUC2:0.8417 FAR:0.00222
[2023-07-20 16:15:15,186][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0268 loss2:0.5569 main_loss:0.5745 | AUC:0.8410 AUC2:0.8417 FAR:0.01203
[2023-07-20 16:16:30,541][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0178 loss2:0.4723 main_loss:0.5150 | AUC:0.8289 AUC2:0.8417 FAR:0.00264
[2023-07-20 16:16:51,311][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.001, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 16:16:51,565][main.py][line:116][INFO] total params:52.3915M
[2023-07-20 16:16:51,565][main.py][line:119][INFO] Training Mode
[2023-07-20 16:16:51,565][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 16:16:51,565][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-07-20 16:17:12,213][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 16:19:04,406][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3464 loss2:1.0336 main_loss:1.9267 | AUC:0.8347 AUC2:0.8310 FAR:0.00437
[2023-07-20 16:21:00,939][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1192 loss2:0.7991 main_loss:1.2829 | AUC:0.8351 AUC2:0.8309 FAR:0.00696
[2023-07-20 16:22:59,313][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0540 loss2:0.6838 main_loss:1.0823 | AUC:0.8465 AUC2:0.8386 FAR:0.00889
[2023-07-20 16:24:51,444][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0542 loss2:0.5902 main_loss:0.9522 | AUC:0.8438 AUC2:0.8386 FAR:0.00699
[2023-07-20 16:26:42,347][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0333 loss2:0.5055 main_loss:0.8395 | AUC:0.8395 AUC2:0.8386 FAR:0.00274
[2023-07-20 16:28:36,398][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0126 loss2:0.3935 main_loss:0.7542 | AUC:0.8490 AUC2:0.8458 FAR:0.00277
[2023-07-20 16:30:29,384][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0146 loss2:0.3005 main_loss:0.6515 | AUC:0.8522 AUC2:0.8376 FAR:0.00645
[2023-07-20 16:32:22,683][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0348 loss2:0.2895 main_loss:0.6443 | AUC:0.8463 AUC2:0.8376 FAR:0.00450
[2023-07-20 16:34:13,710][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0078 loss2:0.1830 main_loss:0.5324 | AUC:0.8455 AUC2:0.8376 FAR:0.00417
[2023-07-20 16:36:04,452][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0073 loss2:0.1310 main_loss:0.4769 | AUC:0.8391 AUC2:0.8376 FAR:0.00099
[2023-07-20 16:37:55,108][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0522 loss2:0.1893 main_loss:0.5910 | AUC:0.8475 AUC2:0.8376 FAR:0.00694
[2023-07-20 16:39:46,729][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0099 loss2:0.1059 main_loss:0.5641 | AUC:0.8408 AUC2:0.8376 FAR:0.00696
[2023-07-20 16:41:38,625][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0045 loss2:0.0603 main_loss:0.5816 | AUC:0.8419 AUC2:0.8376 FAR:0.00761
[2023-07-20 16:41:47,971][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.999, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 4, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 16:41:48,233][main.py][line:116][INFO] total params:52.3915M
[2023-07-20 16:41:48,233][main.py][line:119][INFO] Training Mode
[2023-07-20 16:41:48,234][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 16:41:48,234][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-07-20 16:42:08,591][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 16:43:56,618][main.py][line:76][INFO] [Epoch:1/50]: loss1:0.3464 loss2:1.0336 main_loss:1.3805 | AUC:0.8305 AUC2:0.8310 FAR:0.00437
[2023-07-20 16:45:45,023][main.py][line:76][INFO] [Epoch:2/50]: loss1:0.1192 loss2:0.7991 main_loss:0.9187 | AUC:0.8377 AUC2:0.8309 FAR:0.00696
[2023-07-20 16:47:34,590][main.py][line:76][INFO] [Epoch:3/50]: loss1:0.0540 loss2:0.6838 main_loss:0.7382 | AUC:0.8418 AUC2:0.8386 FAR:0.00889
[2023-07-20 16:49:23,658][main.py][line:76][INFO] [Epoch:4/50]: loss1:0.0542 loss2:0.5902 main_loss:0.6448 | AUC:0.8385 AUC2:0.8386 FAR:0.00699
[2023-07-20 16:51:12,507][main.py][line:76][INFO] [Epoch:5/50]: loss1:0.0333 loss2:0.5055 main_loss:0.5391 | AUC:0.8380 AUC2:0.8386 FAR:0.00274
[2023-07-20 16:53:01,676][main.py][line:76][INFO] [Epoch:6/50]: loss1:0.0126 loss2:0.3935 main_loss:0.4064 | AUC:0.8497 AUC2:0.8458 FAR:0.00277
[2023-07-20 16:54:50,746][main.py][line:76][INFO] [Epoch:7/50]: loss1:0.0146 loss2:0.3005 main_loss:0.3154 | AUC:0.8493 AUC2:0.8458 FAR:0.00645
[2023-07-20 16:56:40,000][main.py][line:76][INFO] [Epoch:8/50]: loss1:0.0348 loss2:0.2895 main_loss:0.3247 | AUC:0.8444 AUC2:0.8458 FAR:0.00450
[2023-07-20 16:58:29,246][main.py][line:76][INFO] [Epoch:9/50]: loss1:0.0078 loss2:0.1830 main_loss:0.1911 | AUC:0.8411 AUC2:0.8458 FAR:0.00417
[2023-07-20 17:00:18,290][main.py][line:76][INFO] [Epoch:10/50]: loss1:0.0073 loss2:0.1310 main_loss:0.1386 | AUC:0.8383 AUC2:0.8458 FAR:0.00099
[2023-07-20 17:02:07,200][main.py][line:76][INFO] [Epoch:11/50]: loss1:0.0522 loss2:0.1893 main_loss:0.2417 | AUC:0.8471 AUC2:0.8458 FAR:0.00694
[2023-07-20 17:03:56,512][main.py][line:76][INFO] [Epoch:12/50]: loss1:0.0099 loss2:0.1059 main_loss:0.1161 | AUC:0.8431 AUC2:0.8458 FAR:0.00696
[2023-07-20 17:05:48,810][main.py][line:76][INFO] [Epoch:13/50]: loss1:0.0045 loss2:0.0603 main_loss:0.0650 | AUC:0.8446 AUC2:0.8458 FAR:0.00761
[2023-07-20 17:06:18,298][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.99, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 17:06:18,554][main.py][line:116][INFO] total params:52.3915M
[2023-07-20 17:06:18,554][main.py][line:119][INFO] Training Mode
[2023-07-20 17:06:18,555][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 17:06:18,555][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 17:06:39,261][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 17:09:05,867][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3649 loss2:1.0963 main_loss:1.4672 | AUC:0.8341 AUC2:0.8342 FAR:0.00734
[2023-07-20 17:11:45,277][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1498 loss2:0.8753 main_loss:1.0284 | AUC:0.8554 AUC2:0.8502 FAR:0.00462
[2023-07-20 17:14:20,246][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0607 loss2:0.7820 main_loss:0.8452 | AUC:0.8569 AUC2:0.8538 FAR:0.00442
[2023-07-20 17:16:38,267][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0353 loss2:0.7062 main_loss:0.7438 | AUC:0.8552 AUC2:0.8538 FAR:0.00474
[2023-07-20 17:19:15,825][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0349 loss2:0.6479 main_loss:0.6852 | AUC:0.8543 AUC2:0.8538 FAR:0.00810
[2023-07-20 17:21:53,406][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0298 loss2:0.6011 main_loss:0.6346 | AUC:0.8607 AUC2:0.8550 FAR:0.00462
[2023-07-20 17:24:29,926][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0121 loss2:0.5310 main_loss:0.5455 | AUC:0.8617 AUC2:0.8551 FAR:0.00188
[2023-07-20 17:27:13,274][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0100 loss2:0.4704 main_loss:0.4827 | AUC:0.8584 AUC2:0.8551 FAR:0.00237
[2023-07-20 17:29:41,108][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0089 loss2:0.4148 main_loss:0.4257 | AUC:0.8611 AUC2:0.8551 FAR:0.00212
[2023-07-20 17:32:17,550][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0081 loss2:0.3618 main_loss:0.3717 | AUC:0.8593 AUC2:0.8551 FAR:0.00291
[2023-07-20 17:35:07,656][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.0081 loss2:0.3139 main_loss:0.3237 | AUC:0.8593 AUC2:0.8551 FAR:0.00291
[2023-07-20 17:37:50,610][main.py][line:76][INFO] [Epoch:12/100]: loss1:0.0367 loss2:0.3315 main_loss:0.3699 | AUC:0.8551 AUC2:0.8551 FAR:0.00188
[2023-07-20 17:40:34,733][main.py][line:76][INFO] [Epoch:13/100]: loss1:0.0232 loss2:0.2938 main_loss:0.3188 | AUC:0.8477 AUC2:0.8551 FAR:0.00284
[2023-07-20 17:43:05,823][main.py][line:76][INFO] [Epoch:14/100]: loss1:0.0198 loss2:0.2561 main_loss:0.2780 | AUC:0.8483 AUC2:0.8551 FAR:0.00289
[2023-07-20 17:45:49,426][main.py][line:76][INFO] [Epoch:15/100]: loss1:0.0057 loss2:0.1958 main_loss:0.2035 | AUC:0.8534 AUC2:0.8551 FAR:0.00366
[2023-07-20 17:48:33,661][main.py][line:76][INFO] [Epoch:16/100]: loss1:0.0043 loss2:0.1638 main_loss:0.1698 | AUC:0.8519 AUC2:0.8551 FAR:0.00356
[2023-07-20 17:51:11,166][main.py][line:76][INFO] [Epoch:17/100]: loss1:0.0037 loss2:0.1360 main_loss:0.1414 | AUC:0.8489 AUC2:0.8551 FAR:0.00380
[2023-07-20 17:54:02,204][main.py][line:76][INFO] [Epoch:18/100]: loss1:0.0031 loss2:0.1142 main_loss:0.1190 | AUC:0.8494 AUC2:0.8551 FAR:0.00279
[2023-07-20 17:56:42,336][main.py][line:76][INFO] [Epoch:19/100]: loss1:0.0031 loss2:0.0964 main_loss:0.1010 | AUC:0.8508 AUC2:0.8551 FAR:0.00338
[2023-07-20 17:59:30,503][main.py][line:76][INFO] [Epoch:20/100]: loss1:0.0028 loss2:0.0827 main_loss:0.0873 | AUC:0.8533 AUC2:0.8551 FAR:0.00346
[2023-07-20 18:02:07,393][main.py][line:76][INFO] [Epoch:21/100]: loss1:0.0024 loss2:0.0703 main_loss:0.0742 | AUC:0.8502 AUC2:0.8551 FAR:0.00274
[2023-07-20 18:04:44,109][main.py][line:76][INFO] [Epoch:22/100]: loss1:0.0021 loss2:0.0592 main_loss:0.0626 | AUC:0.8488 AUC2:0.8551 FAR:0.00200
[2023-07-20 18:07:24,281][main.py][line:76][INFO] [Epoch:23/100]: loss1:0.0020 loss2:0.0525 main_loss:0.0557 | AUC:0.8504 AUC2:0.8551 FAR:0.00188
[2023-07-20 18:10:02,110][main.py][line:76][INFO] [Epoch:24/100]: loss1:0.0021 loss2:0.0444 main_loss:0.0477 | AUC:0.8485 AUC2:0.8551 FAR:0.00254
[2023-07-20 18:12:56,340][main.py][line:76][INFO] [Epoch:25/100]: loss1:0.0022 loss2:0.0408 main_loss:0.0443 | AUC:0.8542 AUC2:0.8551 FAR:0.00274
[2023-07-20 18:15:35,227][main.py][line:76][INFO] [Epoch:26/100]: loss1:0.0349 loss2:0.0996 main_loss:0.1356 | AUC:0.8534 AUC2:0.8551 FAR:0.00642
[2023-07-20 18:18:19,348][main.py][line:76][INFO] [Epoch:27/100]: loss1:0.0099 loss2:0.0632 main_loss:0.0742 | AUC:0.8464 AUC2:0.8551 FAR:0.00452
[2023-07-20 18:21:16,773][main.py][line:76][INFO] [Epoch:28/100]: loss1:0.0027 loss2:0.0399 main_loss:0.0436 | AUC:0.8487 AUC2:0.8551 FAR:0.00245
[2023-07-20 18:24:55,811][main.py][line:76][INFO] [Epoch:29/100]: loss1:0.0019 loss2:0.0313 main_loss:0.0344 | AUC:0.8465 AUC2:0.8551 FAR:0.00272
[2023-07-20 18:27:55,106][main.py][line:76][INFO] [Epoch:30/100]: loss1:0.0013 loss2:0.0267 main_loss:0.0290 | AUC:0.8490 AUC2:0.8551 FAR:0.00338
[2023-07-20 18:31:54,549][main.py][line:76][INFO] [Epoch:31/100]: loss1:0.0012 loss2:0.0234 main_loss:0.0254 | AUC:0.8447 AUC2:0.8551 FAR:0.00259
[2023-07-20 18:36:50,389][main.py][line:76][INFO] [Epoch:32/100]: loss1:0.0011 loss2:0.0208 main_loss:0.0228 | AUC:0.8465 AUC2:0.8551 FAR:0.00356
[2023-07-20 18:41:14,375][main.py][line:76][INFO] [Epoch:33/100]: loss1:0.0010 loss2:0.0186 main_loss:0.0205 | AUC:0.8512 AUC2:0.8551 FAR:0.00316
[2023-07-20 18:44:55,821][main.py][line:76][INFO] [Epoch:34/100]: loss1:0.0009 loss2:0.0172 main_loss:0.0190 | AUC:0.8489 AUC2:0.8551 FAR:0.00311
[2023-07-20 18:48:40,872][main.py][line:76][INFO] [Epoch:35/100]: loss1:0.0012 loss2:0.0173 main_loss:0.0193 | AUC:0.8479 AUC2:0.8551 FAR:0.00306
[2023-07-20 18:52:22,886][main.py][line:76][INFO] [Epoch:36/100]: loss1:0.0008 loss2:0.0154 main_loss:0.0170 | AUC:0.8493 AUC2:0.8551 FAR:0.00286
[2023-07-20 18:55:23,009][main.py][line:76][INFO] [Epoch:37/100]: loss1:0.0007 loss2:0.0140 main_loss:0.0154 | AUC:0.8516 AUC2:0.8551 FAR:0.00301
[2023-07-20 18:58:39,517][main.py][line:76][INFO] [Epoch:38/100]: loss1:0.0007 loss2:0.0136 main_loss:0.0150 | AUC:0.8509 AUC2:0.8551 FAR:0.00309
[2023-07-20 19:01:26,155][main.py][line:76][INFO] [Epoch:39/100]: loss1:0.0006 loss2:0.0125 main_loss:0.0138 | AUC:0.8478 AUC2:0.8551 FAR:0.00309
[2023-07-20 19:04:49,289][main.py][line:76][INFO] [Epoch:40/100]: loss1:0.0006 loss2:0.0113 main_loss:0.0126 | AUC:0.8469 AUC2:0.8551 FAR:0.00316
[2023-07-20 19:07:22,159][main.py][line:76][INFO] [Epoch:41/100]: loss1:0.0005 loss2:0.0108 main_loss:0.0120 | AUC:0.8491 AUC2:0.8551 FAR:0.00326
[2023-07-20 19:10:03,555][main.py][line:76][INFO] [Epoch:42/100]: loss1:0.0006 loss2:0.0107 main_loss:0.0119 | AUC:0.8498 AUC2:0.8551 FAR:0.00309
[2023-07-20 19:12:55,334][main.py][line:76][INFO] [Epoch:43/100]: loss1:0.0006 loss2:0.0103 main_loss:0.0115 | AUC:0.8515 AUC2:0.8551 FAR:0.00316
[2023-07-20 19:15:51,626][main.py][line:76][INFO] [Epoch:44/100]: loss1:0.0006 loss2:0.0099 main_loss:0.0112 | AUC:0.8507 AUC2:0.8551 FAR:0.00319
[2023-07-20 19:18:37,868][main.py][line:76][INFO] [Epoch:45/100]: loss1:0.0005 loss2:0.0095 main_loss:0.0106 | AUC:0.8517 AUC2:0.8551 FAR:0.00336
[2023-07-20 19:21:50,191][main.py][line:76][INFO] [Epoch:46/100]: loss1:0.0005 loss2:0.0091 main_loss:0.0102 | AUC:0.8521 AUC2:0.8551 FAR:0.00301
[2023-07-20 19:24:37,311][main.py][line:76][INFO] [Epoch:47/100]: loss1:0.0005 loss2:0.0088 main_loss:0.0098 | AUC:0.8520 AUC2:0.8551 FAR:0.00331
[2023-07-20 19:27:15,838][main.py][line:76][INFO] [Epoch:48/100]: loss1:0.0004 loss2:0.0082 main_loss:0.0091 | AUC:0.8518 AUC2:0.8551 FAR:0.00336
[2023-07-20 19:29:56,164][main.py][line:76][INFO] [Epoch:49/100]: loss1:0.0004 loss2:0.0081 main_loss:0.0091 | AUC:0.8518 AUC2:0.8551 FAR:0.00309
[2023-07-20 19:32:23,511][main.py][line:76][INFO] [Epoch:50/100]: loss1:0.0004 loss2:0.0079 main_loss:0.0088 | AUC:0.8519 AUC2:0.8551 FAR:0.00333
[2023-07-20 19:35:26,695][main.py][line:76][INFO] [Epoch:51/100]: loss1:0.0004 loss2:0.0079 main_loss:0.0088 | AUC:0.8523 AUC2:0.8551 FAR:0.00328
[2023-07-20 19:38:21,227][main.py][line:76][INFO] [Epoch:52/100]: loss1:0.0004 loss2:0.0077 main_loss:0.0085 | AUC:0.8531 AUC2:0.8551 FAR:0.00333
[2023-07-20 19:41:12,854][main.py][line:76][INFO] [Epoch:53/100]: loss1:0.0004 loss2:0.0077 main_loss:0.0086 | AUC:0.8528 AUC2:0.8551 FAR:0.00405
[2023-07-20 19:43:57,688][main.py][line:76][INFO] [Epoch:54/100]: loss1:0.0005 loss2:0.0077 main_loss:0.0086 | AUC:0.8527 AUC2:0.8551 FAR:0.00351
[2023-07-20 19:46:36,972][main.py][line:76][INFO] [Epoch:55/100]: loss1:0.0004 loss2:0.0076 main_loss:0.0085 | AUC:0.8529 AUC2:0.8551 FAR:0.00346
[2023-07-20 19:49:19,973][main.py][line:76][INFO] [Epoch:56/100]: loss1:0.0004 loss2:0.0073 main_loss:0.0082 | AUC:0.8528 AUC2:0.8551 FAR:0.00341
[2023-07-20 19:52:10,271][main.py][line:76][INFO] [Epoch:57/100]: loss1:0.0004 loss2:0.0073 main_loss:0.0081 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 19:54:46,514][main.py][line:76][INFO] [Epoch:58/100]: loss1:0.0004 loss2:0.0073 main_loss:0.0082 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 19:57:47,752][main.py][line:76][INFO] [Epoch:59/100]: loss1:0.0004 loss2:0.0075 main_loss:0.0083 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:00:53,481][main.py][line:76][INFO] [Epoch:60/100]: loss1:0.0004 loss2:0.0071 main_loss:0.0079 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:03:33,926][main.py][line:76][INFO] [Epoch:61/100]: loss1:0.0004 loss2:0.0071 main_loss:0.0080 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:06:18,833][main.py][line:76][INFO] [Epoch:62/100]: loss1:0.0004 loss2:0.0072 main_loss:0.0081 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:09:32,790][main.py][line:76][INFO] [Epoch:63/100]: loss1:0.0004 loss2:0.0071 main_loss:0.0079 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:12:48,226][main.py][line:76][INFO] [Epoch:64/100]: loss1:0.0004 loss2:0.0074 main_loss:0.0082 | AUC:0.8526 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:15:37,814][main.py][line:76][INFO] [Epoch:65/100]: loss1:0.0004 loss2:0.0074 main_loss:0.0083 | AUC:0.8526 AUC2:0.8551 FAR:0.00343
[2023-07-20 20:18:40,647][main.py][line:76][INFO] [Epoch:66/100]: loss1:0.0004 loss2:0.0073 main_loss:0.0082 | AUC:0.8525 AUC2:0.8551 FAR:0.00341
[2023-07-20 20:21:31,348][main.py][line:76][INFO] [Epoch:67/100]: loss1:0.0004 loss2:0.0074 main_loss:0.0082 | AUC:0.8522 AUC2:0.8551 FAR:0.00343
[2023-07-20 20:24:21,129][main.py][line:76][INFO] [Epoch:68/100]: loss1:0.0004 loss2:0.0070 main_loss:0.0078 | AUC:0.8517 AUC2:0.8551 FAR:0.00326
[2023-07-20 20:27:10,900][main.py][line:76][INFO] [Epoch:69/100]: loss1:0.0004 loss2:0.0072 main_loss:0.0080 | AUC:0.8523 AUC2:0.8551 FAR:0.00289
[2023-07-20 20:29:48,028][main.py][line:76][INFO] [Epoch:70/100]: loss1:0.0003 loss2:0.0068 main_loss:0.0076 | AUC:0.8516 AUC2:0.8551 FAR:0.00304
[2023-07-20 20:32:43,160][main.py][line:76][INFO] [Epoch:71/100]: loss1:0.0003 loss2:0.0067 main_loss:0.0075 | AUC:0.8527 AUC2:0.8551 FAR:0.00304
[2023-07-20 20:35:17,050][main.py][line:76][INFO] [Epoch:72/100]: loss1:0.0004 loss2:0.0067 main_loss:0.0075 | AUC:0.8525 AUC2:0.8551 FAR:0.00311
[2023-07-20 20:37:50,544][main.py][line:76][INFO] [Epoch:73/100]: loss1:0.0003 loss2:0.0064 main_loss:0.0071 | AUC:0.8520 AUC2:0.8551 FAR:0.00299
[2023-07-20 20:41:04,186][main.py][line:76][INFO] [Epoch:74/100]: loss1:0.0005 loss2:0.0063 main_loss:0.0073 | AUC:0.8523 AUC2:0.8551 FAR:0.00314
[2023-07-20 20:43:56,091][main.py][line:76][INFO] [Epoch:75/100]: loss1:0.0008 loss2:0.0068 main_loss:0.0080 | AUC:0.8484 AUC2:0.8551 FAR:0.00267
[2023-07-20 20:46:31,093][main.py][line:76][INFO] [Epoch:76/100]: loss1:0.0004 loss2:0.0061 main_loss:0.0069 | AUC:0.8492 AUC2:0.8551 FAR:0.00324
[2023-07-20 20:48:44,358][main.py][line:76][INFO] [Epoch:77/100]: loss1:0.0004 loss2:0.0058 main_loss:0.0066 | AUC:0.8467 AUC2:0.8551 FAR:0.00331
[2023-07-20 20:50:52,796][main.py][line:76][INFO] [Epoch:78/100]: loss1:0.0004 loss2:0.0052 main_loss:0.0060 | AUC:0.8504 AUC2:0.8551 FAR:0.00301
[2023-07-20 20:52:53,617][main.py][line:76][INFO] [Epoch:79/100]: loss1:0.0003 loss2:0.0049 main_loss:0.0057 | AUC:0.8492 AUC2:0.8551 FAR:0.00336
[2023-07-20 20:54:56,371][main.py][line:76][INFO] [Epoch:80/100]: loss1:0.0090 loss2:0.0216 main_loss:0.0311 | AUC:0.8475 AUC2:0.8551 FAR:0.00721
[2023-07-20 20:56:58,570][main.py][line:76][INFO] [Epoch:81/100]: loss1:0.0029 loss2:0.0122 main_loss:0.0156 | AUC:0.8545 AUC2:0.8551 FAR:0.00425
[2023-07-20 20:58:54,898][main.py][line:76][INFO] [Epoch:82/100]: loss1:0.0008 loss2:0.0061 main_loss:0.0075 | AUC:0.8544 AUC2:0.8551 FAR:0.00358
[2023-07-20 21:00:53,567][main.py][line:76][INFO] [Epoch:83/100]: loss1:0.0006 loss2:0.0051 main_loss:0.0062 | AUC:0.8555 AUC2:0.8551 FAR:0.00440
[2023-07-20 21:02:48,499][main.py][line:76][INFO] [Epoch:84/100]: loss1:0.0005 loss2:0.0044 main_loss:0.0054 | AUC:0.8529 AUC2:0.8551 FAR:0.00454
[2023-07-20 21:04:42,293][main.py][line:76][INFO] [Epoch:85/100]: loss1:0.0003 loss2:0.0041 main_loss:0.0049 | AUC:0.8521 AUC2:0.8551 FAR:0.00430
[2023-07-20 21:06:39,617][main.py][line:76][INFO] [Epoch:86/100]: loss1:0.0003 loss2:0.0035 main_loss:0.0044 | AUC:0.8530 AUC2:0.8551 FAR:0.00417
[2023-07-20 21:08:38,586][main.py][line:76][INFO] [Epoch:87/100]: loss1:0.0003 loss2:0.0033 main_loss:0.0040 | AUC:0.8525 AUC2:0.8551 FAR:0.00442
[2023-07-20 21:10:35,088][main.py][line:76][INFO] [Epoch:88/100]: loss1:0.0004 loss2:0.0035 main_loss:0.0045 | AUC:0.8542 AUC2:0.8551 FAR:0.00427
[2023-07-20 21:12:33,349][main.py][line:76][INFO] [Epoch:89/100]: loss1:0.0203 loss2:0.0314 main_loss:0.0522 | AUC:0.8474 AUC2:0.8551 FAR:0.00412
[2023-07-20 21:14:31,431][main.py][line:76][INFO] [Epoch:90/100]: loss1:0.0191 loss2:0.0362 main_loss:0.0557 | AUC:0.8527 AUC2:0.8551 FAR:0.00701
[2023-07-20 21:16:32,742][main.py][line:76][INFO] [Epoch:91/100]: loss1:0.0024 loss2:0.0104 main_loss:0.0132 | AUC:0.8512 AUC2:0.8551 FAR:0.00398
[2023-07-20 21:18:28,483][main.py][line:76][INFO] [Epoch:92/100]: loss1:0.0012 loss2:0.0060 main_loss:0.0077 | AUC:0.8531 AUC2:0.8551 FAR:0.00437
[2023-07-20 21:20:26,376][main.py][line:76][INFO] [Epoch:93/100]: loss1:0.0009 loss2:0.0051 main_loss:0.0065 | AUC:0.8551 AUC2:0.8551 FAR:0.00506
[2023-07-20 21:22:24,233][main.py][line:76][INFO] [Epoch:94/100]: loss1:0.0005 loss2:0.0036 main_loss:0.0047 | AUC:0.8567 AUC2:0.8551 FAR:0.00467
[2023-07-20 21:24:20,683][main.py][line:76][INFO] [Epoch:95/100]: loss1:0.0046 loss2:0.0086 main_loss:0.0137 | AUC:0.8515 AUC2:0.8551 FAR:0.00632
[2023-07-20 21:26:19,133][main.py][line:76][INFO] [Epoch:96/100]: loss1:0.0013 loss2:0.0052 main_loss:0.0072 | AUC:0.8493 AUC2:0.8551 FAR:0.00314
[2023-07-20 21:28:18,574][main.py][line:76][INFO] [Epoch:97/100]: loss1:0.0007 loss2:0.0033 main_loss:0.0047 | AUC:0.8480 AUC2:0.8551 FAR:0.00328
[2023-07-20 21:30:14,438][main.py][line:76][INFO] [Epoch:98/100]: loss1:0.0005 loss2:0.0027 main_loss:0.0044 | AUC:0.8496 AUC2:0.8551 FAR:0.00348
[2023-07-20 21:32:12,494][main.py][line:76][INFO] [Epoch:99/100]: loss1:0.0003 loss2:0.0021 main_loss:0.0034 | AUC:0.8543 AUC2:0.8551 FAR:0.00336
[2023-07-20 21:34:04,753][main.py][line:76][INFO] [Epoch:100/100]: loss1:0.0004 loss2:0.0023 main_loss:0.0035 | AUC:0.8524 AUC2:0.8551 FAR:0.00301
[2023-07-20 21:34:04,889][main.py][line:82][INFO] Training completes in 267m 25s | best AUC:0.8617 FAR:0.00188

[2023-07-20 22:10:06,816][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.99, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-20 22:10:07,012][main.py][line:116][INFO] total params:27.1990M
[2023-07-20 22:10:07,012][main.py][line:119][INFO] Training Mode
[2023-07-20 22:10:07,013][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-20 22:10:07,013][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-20 22:10:26,209][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-20 22:11:50,594][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3729 loss2:1.0986 main_loss:1.4758 | AUC:0.8320 AUC2:0.8271 FAR:0.00583
[2023-07-20 22:13:15,472][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1468 loss2:0.8741 main_loss:1.0236 | AUC:0.8540 AUC2:0.8501 FAR:0.00603
[2023-07-20 22:14:42,280][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0684 loss2:0.7777 main_loss:0.8482 | AUC:0.8495 AUC2:0.8501 FAR:0.00832
[2023-07-20 22:16:07,524][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0314 loss2:0.7010 main_loss:0.7343 | AUC:0.8516 AUC2:0.8501 FAR:0.00326
[2023-07-20 22:17:32,113][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0191 loss2:0.6276 main_loss:0.6486 | AUC:0.8504 AUC2:0.8501 FAR:0.00168
[2023-07-20 22:18:57,708][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0402 loss2:0.5925 main_loss:0.6343 | AUC:0.8497 AUC2:0.8501 FAR:0.00440
[2023-07-20 22:20:22,477][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0187 loss2:0.5309 main_loss:0.5512 | AUC:0.8549 AUC2:0.8439 FAR:0.00232
[2023-07-20 22:21:48,210][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0105 loss2:0.4652 main_loss:0.4770 | AUC:0.8560 AUC2:0.8526 FAR:0.00368
[2023-07-20 22:23:13,149][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0180 loss2:0.4175 main_loss:0.4367 | AUC:0.8512 AUC2:0.8526 FAR:0.00701
[2023-07-20 22:24:37,597][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0336 loss2:0.4118 main_loss:0.4466 | AUC:0.8440 AUC2:0.8526 FAR:0.00645
[2023-07-20 22:26:03,201][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.0138 loss2:0.3477 main_loss:0.3626 | AUC:0.8507 AUC2:0.8526 FAR:0.00343
[2023-07-20 22:27:29,468][main.py][line:76][INFO] [Epoch:12/100]: loss1:0.0075 loss2:0.2939 main_loss:0.3025 | AUC:0.8514 AUC2:0.8526 FAR:0.00573
[2023-07-20 22:28:54,938][main.py][line:76][INFO] [Epoch:13/100]: loss1:0.0078 loss2:0.2532 main_loss:0.2621 | AUC:0.8538 AUC2:0.8526 FAR:0.00430
[2023-07-20 22:30:20,972][main.py][line:76][INFO] [Epoch:14/100]: loss1:0.0058 loss2:0.2097 main_loss:0.2174 | AUC:0.8455 AUC2:0.8526 FAR:0.01151
[2023-07-20 22:31:47,246][main.py][line:76][INFO] [Epoch:15/100]: loss1:0.0078 loss2:0.1895 main_loss:0.1994 | AUC:0.8484 AUC2:0.8526 FAR:0.00309
[2023-07-20 22:33:12,356][main.py][line:76][INFO] [Epoch:16/100]: loss1:0.0040 loss2:0.1521 main_loss:0.1578 | AUC:0.8548 AUC2:0.8526 FAR:0.00388
[2023-07-20 22:34:37,211][main.py][line:76][INFO] [Epoch:17/100]: loss1:0.0033 loss2:0.1268 main_loss:0.1319 | AUC:0.8517 AUC2:0.8526 FAR:0.00467
[2023-07-20 22:36:02,719][main.py][line:76][INFO] [Epoch:18/100]: loss1:0.0032 loss2:0.1065 main_loss:0.1119 | AUC:0.8516 AUC2:0.8526 FAR:0.00351
[2023-07-20 22:37:27,711][main.py][line:76][INFO] [Epoch:19/100]: loss1:0.0027 loss2:0.0887 main_loss:0.0931 | AUC:0.8491 AUC2:0.8526 FAR:0.00279
[2023-07-20 22:38:53,564][main.py][line:76][INFO] [Epoch:20/100]: loss1:0.0025 loss2:0.0751 main_loss:0.0792 | AUC:0.8510 AUC2:0.8526 FAR:0.00249
[2023-07-20 22:40:18,063][main.py][line:76][INFO] [Epoch:21/100]: loss1:0.0022 loss2:0.0629 main_loss:0.0664 | AUC:0.8493 AUC2:0.8526 FAR:0.00477
[2023-07-20 22:41:42,837][main.py][line:76][INFO] [Epoch:22/100]: loss1:0.0020 loss2:0.0540 main_loss:0.0572 | AUC:0.8466 AUC2:0.8526 FAR:0.00230
[2023-07-20 22:43:08,164][main.py][line:76][INFO] [Epoch:23/100]: loss1:0.0229 loss2:0.0840 main_loss:0.1081 | AUC:0.8453 AUC2:0.8526 FAR:0.00664
[2023-07-20 22:44:32,913][main.py][line:76][INFO] [Epoch:24/100]: loss1:0.0318 loss2:0.1159 main_loss:0.1490 | AUC:0.8461 AUC2:0.8526 FAR:0.00420
[2023-07-20 22:45:58,918][main.py][line:76][INFO] [Epoch:25/100]: loss1:0.0115 loss2:0.0764 main_loss:0.0891 | AUC:0.8450 AUC2:0.8526 FAR:0.00820
[2023-07-20 22:47:25,792][main.py][line:76][INFO] [Epoch:26/100]: loss1:0.0032 loss2:0.0489 main_loss:0.0531 | AUC:0.8506 AUC2:0.8526 FAR:0.00437
[2023-07-20 22:48:51,865][main.py][line:76][INFO] [Epoch:27/100]: loss1:0.0020 loss2:0.0387 main_loss:0.0417 | AUC:0.8470 AUC2:0.8526 FAR:0.00445
[2023-07-20 22:50:17,637][main.py][line:76][INFO] [Epoch:28/100]: loss1:0.0016 loss2:0.0321 main_loss:0.0348 | AUC:0.8488 AUC2:0.8526 FAR:0.00459
[2023-07-20 22:51:43,156][main.py][line:76][INFO] [Epoch:29/100]: loss1:0.0015 loss2:0.0288 main_loss:0.0314 | AUC:0.8514 AUC2:0.8526 FAR:0.00427
[2023-07-20 22:53:11,052][main.py][line:76][INFO] [Epoch:30/100]: loss1:0.0013 loss2:0.0248 main_loss:0.0270 | AUC:0.8510 AUC2:0.8526 FAR:0.00311
[2023-07-20 22:54:38,279][main.py][line:76][INFO] [Epoch:31/100]: loss1:0.0012 loss2:0.0227 main_loss:0.0249 | AUC:0.8517 AUC2:0.8526 FAR:0.00370
[2023-07-20 22:56:05,408][main.py][line:76][INFO] [Epoch:32/100]: loss1:0.0009 loss2:0.0198 main_loss:0.0216 | AUC:0.8531 AUC2:0.8526 FAR:0.00410
[2023-07-20 22:57:31,188][main.py][line:76][INFO] [Epoch:33/100]: loss1:0.0009 loss2:0.0185 main_loss:0.0203 | AUC:0.8527 AUC2:0.8526 FAR:0.00403
[2023-07-20 22:58:56,635][main.py][line:76][INFO] [Epoch:34/100]: loss1:0.0008 loss2:0.0169 main_loss:0.0186 | AUC:0.8564 AUC2:0.8459 FAR:0.00432
[2023-07-20 23:00:24,219][main.py][line:76][INFO] [Epoch:35/100]: loss1:0.0007 loss2:0.0146 main_loss:0.0162 | AUC:0.8497 AUC2:0.8459 FAR:0.00353
[2023-07-20 23:01:51,598][main.py][line:76][INFO] [Epoch:36/100]: loss1:0.0008 loss2:0.0140 main_loss:0.0157 | AUC:0.8517 AUC2:0.8459 FAR:0.00390
[2023-07-20 23:03:17,900][main.py][line:76][INFO] [Epoch:37/100]: loss1:0.0008 loss2:0.0131 main_loss:0.0148 | AUC:0.8540 AUC2:0.8459 FAR:0.00437
[2023-07-20 23:04:44,058][main.py][line:76][INFO] [Epoch:38/100]: loss1:0.0006 loss2:0.0119 main_loss:0.0133 | AUC:0.8527 AUC2:0.8459 FAR:0.00361
[2023-07-20 23:06:08,698][main.py][line:76][INFO] [Epoch:39/100]: loss1:0.0006 loss2:0.0117 main_loss:0.0130 | AUC:0.8512 AUC2:0.8459 FAR:0.00309
[2023-07-20 23:07:34,120][main.py][line:76][INFO] [Epoch:40/100]: loss1:0.0006 loss2:0.0108 main_loss:0.0122 | AUC:0.8566 AUC2:0.8468 FAR:0.00410
[2023-07-20 23:09:00,163][main.py][line:76][INFO] [Epoch:41/100]: loss1:0.0006 loss2:0.0104 main_loss:0.0117 | AUC:0.8555 AUC2:0.8468 FAR:0.00363
[2023-07-20 23:10:25,603][main.py][line:76][INFO] [Epoch:42/100]: loss1:0.0005 loss2:0.0096 main_loss:0.0108 | AUC:0.8551 AUC2:0.8468 FAR:0.00361
[2023-07-20 23:11:51,787][main.py][line:76][INFO] [Epoch:43/100]: loss1:0.0005 loss2:0.0092 main_loss:0.0104 | AUC:0.8557 AUC2:0.8468 FAR:0.00328
[2023-07-20 23:13:17,603][main.py][line:76][INFO] [Epoch:44/100]: loss1:0.0005 loss2:0.0091 main_loss:0.0103 | AUC:0.8555 AUC2:0.8468 FAR:0.00321
[2023-07-20 23:14:42,929][main.py][line:76][INFO] [Epoch:45/100]: loss1:0.0008 loss2:0.0092 main_loss:0.0106 | AUC:0.8559 AUC2:0.8468 FAR:0.00321
[2023-07-20 23:16:10,078][main.py][line:76][INFO] [Epoch:46/100]: loss1:0.0005 loss2:0.0083 main_loss:0.0093 | AUC:0.8564 AUC2:0.8468 FAR:0.00321
[2023-07-20 23:17:37,640][main.py][line:76][INFO] [Epoch:47/100]: loss1:0.0005 loss2:0.0080 main_loss:0.0090 | AUC:0.8555 AUC2:0.8468 FAR:0.00319
[2023-07-20 23:19:03,550][main.py][line:76][INFO] [Epoch:48/100]: loss1:0.0004 loss2:0.0079 main_loss:0.0089 | AUC:0.8560 AUC2:0.8468 FAR:0.00294
[2023-07-20 23:20:29,251][main.py][line:76][INFO] [Epoch:49/100]: loss1:0.0004 loss2:0.0073 main_loss:0.0082 | AUC:0.8530 AUC2:0.8468 FAR:0.00299
[2023-07-20 23:21:55,458][main.py][line:76][INFO] [Epoch:50/100]: loss1:0.0004 loss2:0.0075 main_loss:0.0085 | AUC:0.8541 AUC2:0.8468 FAR:0.00316
[2023-07-20 23:23:21,101][main.py][line:76][INFO] [Epoch:51/100]: loss1:0.0004 loss2:0.0070 main_loss:0.0078 | AUC:0.8542 AUC2:0.8468 FAR:0.00319
[2023-07-20 23:24:47,887][main.py][line:76][INFO] [Epoch:52/100]: loss1:0.0004 loss2:0.0072 main_loss:0.0081 | AUC:0.8544 AUC2:0.8468 FAR:0.00319
[2023-07-20 23:26:14,324][main.py][line:76][INFO] [Epoch:53/100]: loss1:0.0004 loss2:0.0072 main_loss:0.0080 | AUC:0.8538 AUC2:0.8468 FAR:0.00284
[2023-07-20 23:27:40,211][main.py][line:76][INFO] [Epoch:54/100]: loss1:0.0004 loss2:0.0065 main_loss:0.0073 | AUC:0.8546 AUC2:0.8468 FAR:0.00301
[2023-07-20 23:29:06,769][main.py][line:76][INFO] [Epoch:55/100]: loss1:0.0003 loss2:0.0065 main_loss:0.0074 | AUC:0.8547 AUC2:0.8468 FAR:0.00309
[2023-07-20 23:30:34,617][main.py][line:76][INFO] [Epoch:56/100]: loss1:0.0003 loss2:0.0063 main_loss:0.0072 | AUC:0.8548 AUC2:0.8468 FAR:0.00309
[2023-07-20 23:32:02,763][main.py][line:76][INFO] [Epoch:57/100]: loss1:0.0003 loss2:0.0065 main_loss:0.0073 | AUC:0.8545 AUC2:0.8468 FAR:0.00286
[2023-07-20 23:33:29,492][main.py][line:76][INFO] [Epoch:58/100]: loss1:0.0004 loss2:0.0065 main_loss:0.0073 | AUC:0.8545 AUC2:0.8468 FAR:0.00286
[2023-07-20 23:34:55,572][main.py][line:76][INFO] [Epoch:59/100]: loss1:0.0004 loss2:0.0069 main_loss:0.0078 | AUC:0.8544 AUC2:0.8468 FAR:0.00286
[2023-07-20 23:36:22,011][main.py][line:76][INFO] [Epoch:60/100]: loss1:0.0004 loss2:0.0064 main_loss:0.0073 | AUC:0.8544 AUC2:0.8468 FAR:0.00286
[2023-07-20 23:37:47,670][main.py][line:76][INFO] [Epoch:61/100]: loss1:0.0004 loss2:0.0067 main_loss:0.0075 | AUC:0.8544 AUC2:0.8468 FAR:0.00286
[2023-07-20 23:39:14,467][main.py][line:76][INFO] [Epoch:62/100]: loss1:0.0004 loss2:0.0066 main_loss:0.0074 | AUC:0.8544 AUC2:0.8468 FAR:0.00286
[2023-07-20 23:40:40,550][main.py][line:76][INFO] [Epoch:63/100]: loss1:0.0004 loss2:0.0064 main_loss:0.0073 | AUC:0.8544 AUC2:0.8468 FAR:0.00296
[2023-07-20 23:42:07,975][main.py][line:76][INFO] [Epoch:64/100]: loss1:0.0003 loss2:0.0065 main_loss:0.0073 | AUC:0.8543 AUC2:0.8468 FAR:0.00301
[2023-07-20 23:43:34,789][main.py][line:76][INFO] [Epoch:65/100]: loss1:0.0004 loss2:0.0066 main_loss:0.0074 | AUC:0.8543 AUC2:0.8468 FAR:0.00309
[2023-07-20 23:45:00,932][main.py][line:76][INFO] [Epoch:66/100]: loss1:0.0003 loss2:0.0063 main_loss:0.0071 | AUC:0.8542 AUC2:0.8468 FAR:0.00304
[2023-07-20 23:46:27,519][main.py][line:76][INFO] [Epoch:67/100]: loss1:0.0003 loss2:0.0064 main_loss:0.0072 | AUC:0.8538 AUC2:0.8468 FAR:0.00304
[2023-07-20 23:47:54,072][main.py][line:76][INFO] [Epoch:68/100]: loss1:0.0004 loss2:0.0066 main_loss:0.0074 | AUC:0.8540 AUC2:0.8468 FAR:0.00314
[2023-07-20 23:49:18,404][main.py][line:76][INFO] [Epoch:69/100]: loss1:0.0004 loss2:0.0068 main_loss:0.0076 | AUC:0.8545 AUC2:0.8468 FAR:0.00314
[2023-07-20 23:50:44,485][main.py][line:76][INFO] [Epoch:70/100]: loss1:0.0004 loss2:0.0064 main_loss:0.0073 | AUC:0.8555 AUC2:0.8468 FAR:0.00306
[2023-07-20 23:52:11,276][main.py][line:76][INFO] [Epoch:71/100]: loss1:0.0003 loss2:0.0060 main_loss:0.0067 | AUC:0.8567 AUC2:0.8475 FAR:0.00309
[2023-07-20 23:53:38,196][main.py][line:76][INFO] [Epoch:72/100]: loss1:0.0003 loss2:0.0058 main_loss:0.0066 | AUC:0.8564 AUC2:0.8475 FAR:0.00311
[2023-07-20 23:55:04,959][main.py][line:76][INFO] [Epoch:73/100]: loss1:0.0004 loss2:0.0064 main_loss:0.0072 | AUC:0.8524 AUC2:0.8475 FAR:0.00269
[2023-07-20 23:56:30,494][main.py][line:76][INFO] [Epoch:74/100]: loss1:0.0004 loss2:0.0061 main_loss:0.0070 | AUC:0.8538 AUC2:0.8475 FAR:0.00284
[2023-07-20 23:57:57,094][main.py][line:76][INFO] [Epoch:75/100]: loss1:0.0003 loss2:0.0056 main_loss:0.0064 | AUC:0.8548 AUC2:0.8475 FAR:0.00282
[2023-07-20 23:59:24,338][main.py][line:76][INFO] [Epoch:76/100]: loss1:0.0004 loss2:0.0058 main_loss:0.0066 | AUC:0.8520 AUC2:0.8475 FAR:0.00222
[2023-07-21 00:00:51,908][main.py][line:76][INFO] [Epoch:77/100]: loss1:0.0003 loss2:0.0050 main_loss:0.0058 | AUC:0.8558 AUC2:0.8475 FAR:0.00336
[2023-07-21 00:02:18,468][main.py][line:76][INFO] [Epoch:78/100]: loss1:0.0003 loss2:0.0046 main_loss:0.0053 | AUC:0.8578 AUC2:0.8462 FAR:0.00390
[2023-07-21 00:03:45,478][main.py][line:76][INFO] [Epoch:79/100]: loss1:0.0003 loss2:0.0046 main_loss:0.0055 | AUC:0.8536 AUC2:0.8462 FAR:0.00279
[2023-07-21 00:05:12,306][main.py][line:76][INFO] [Epoch:80/100]: loss1:0.0002 loss2:0.0037 main_loss:0.0044 | AUC:0.8566 AUC2:0.8462 FAR:0.00257
[2023-07-21 00:07:19,291][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.9, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.01, 'dropout': 0.7, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 00:07:19,480][main.py][line:116][INFO] total params:27.1990M
[2023-07-21 00:07:19,480][main.py][line:119][INFO] Training Mode
[2023-07-21 00:07:19,481][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.7, inplace=False)
    (dropout2): Dropout(p=0.7, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.7, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 00:07:19,481][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.01
    lr: 0.01
    maximize: False
    weight_decay: 0
)

[2023-07-21 00:07:39,057][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 00:09:11,409][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.8998 loss2:1.3436 main_loss:2.3135 | AUC:0.7824 AUC2:0.7820 FAR:0.07370
[2023-07-21 00:10:43,575][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.6268 loss2:1.2556 main_loss:1.9515 | AUC:0.7244 AUC2:0.7820 FAR:0.28909
[2023-07-21 00:12:20,057][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.6203 loss2:1.2129 main_loss:1.9028 | AUC:0.7705 AUC2:0.7820 FAR:0.10269
[2023-07-21 00:13:58,633][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.5557 loss2:1.1780 main_loss:1.8033 | AUC:0.7720 AUC2:0.7820 FAR:0.11514
[2023-07-21 00:15:37,382][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.4971 loss2:1.1395 main_loss:1.7061 | AUC:0.7931 AUC2:0.7931 FAR:0.08785
[2023-07-21 00:17:14,649][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.5410 loss2:1.1643 main_loss:1.7747 | AUC:0.8166 AUC2:0.8166 FAR:0.02159
[2023-07-21 00:18:49,209][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.5975 loss2:1.1909 main_loss:1.8578 | AUC:0.8235 AUC2:0.8235 FAR:0.00000
[2023-07-21 00:20:27,016][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.6054 loss2:1.2629 main_loss:1.9377 | AUC:0.8240 AUC2:0.8240 FAR:0.03354
[2023-07-21 00:21:59,779][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.4657 loss2:1.1555 main_loss:1.6905 | AUC:0.8190 AUC2:0.8240 FAR:0.00200
[2023-07-21 00:23:34,149][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.4374 loss2:1.0944 main_loss:1.6011 | AUC:0.8173 AUC2:0.8240 FAR:0.00089
[2023-07-21 00:25:16,146][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.4410 loss2:1.1013 main_loss:1.6116 | AUC:0.8277 AUC2:0.8277 FAR:0.00650
[2023-07-21 00:26:54,749][main.py][line:76][INFO] [Epoch:12/100]: loss1:0.4040 loss2:1.0806 main_loss:1.5539 | AUC:0.8150 AUC2:0.8277 FAR:0.00245
[2023-07-21 00:28:36,847][main.py][line:76][INFO] [Epoch:13/100]: loss1:0.4098 loss2:1.0789 main_loss:1.5581 | AUC:0.7989 AUC2:0.8277 FAR:0.00022
[2023-07-21 00:30:16,966][main.py][line:76][INFO] [Epoch:14/100]: loss1:0.4110 loss2:1.0726 main_loss:1.5529 | AUC:0.8220 AUC2:0.8277 FAR:0.00000
[2023-07-21 00:31:56,666][main.py][line:76][INFO] [Epoch:15/100]: loss1:0.3934 loss2:1.0688 main_loss:1.5316 | AUC:0.8239 AUC2:0.8277 FAR:0.00037
[2023-07-21 00:33:38,429][main.py][line:76][INFO] [Epoch:16/100]: loss1:0.3795 loss2:1.0626 main_loss:1.5115 | AUC:0.8248 AUC2:0.8277 FAR:0.00000
[2023-07-21 00:35:15,424][main.py][line:76][INFO] [Epoch:17/100]: loss1:0.3950 loss2:1.0641 main_loss:1.5286 | AUC:0.8057 AUC2:0.8277 FAR:0.00000
[2023-07-21 00:36:48,110][main.py][line:76][INFO] [Epoch:18/100]: loss1:0.3754 loss2:1.0583 main_loss:1.5032 | AUC:0.8227 AUC2:0.8277 FAR:0.00000
[2023-07-21 00:38:28,801][main.py][line:76][INFO] [Epoch:19/100]: loss1:0.3654 loss2:1.0476 main_loss:1.4825 | AUC:0.8328 AUC2:0.8327 FAR:0.00000
[2023-07-21 00:40:06,082][main.py][line:76][INFO] [Epoch:20/100]: loss1:0.3736 loss2:1.0447 main_loss:1.4878 | AUC:0.8003 AUC2:0.8327 FAR:0.00000
[2023-07-21 00:41:41,216][main.py][line:76][INFO] [Epoch:21/100]: loss1:0.3865 loss2:1.0238 main_loss:1.4797 | AUC:0.8405 AUC2:0.8405 FAR:0.00000
[2023-07-21 00:43:16,706][main.py][line:76][INFO] [Epoch:22/100]: loss1:0.3583 loss2:1.0492 main_loss:1.4768 | AUC:0.8398 AUC2:0.8405 FAR:0.00007
[2023-07-21 00:44:47,099][main.py][line:76][INFO] [Epoch:23/100]: loss1:0.3621 loss2:1.0528 main_loss:1.4843 | AUC:0.8344 AUC2:0.8405 FAR:0.00000
[2023-07-21 00:46:20,914][main.py][line:76][INFO] [Epoch:24/100]: loss1:0.3684 loss2:1.0548 main_loss:1.4926 | AUC:0.8359 AUC2:0.8405 FAR:0.00000
[2023-07-21 00:48:00,989][main.py][line:76][INFO] [Epoch:25/100]: loss1:0.3432 loss2:1.0431 main_loss:1.4557 | AUC:0.8092 AUC2:0.8405 FAR:0.00037
[2023-07-21 00:49:38,492][main.py][line:76][INFO] [Epoch:26/100]: loss1:0.3441 loss2:1.0427 main_loss:1.4561 | AUC:0.8411 AUC2:0.8411 FAR:0.00007
[2023-07-21 00:51:11,194][main.py][line:76][INFO] [Epoch:27/100]: loss1:0.3348 loss2:1.0350 main_loss:1.4391 | AUC:0.8196 AUC2:0.8411 FAR:0.00000
[2023-07-21 00:52:48,223][main.py][line:76][INFO] [Epoch:28/100]: loss1:0.3458 loss2:1.0408 main_loss:1.4559 | AUC:0.8167 AUC2:0.8411 FAR:0.00000
[2023-07-21 00:54:23,141][main.py][line:76][INFO] [Epoch:29/100]: loss1:0.3267 loss2:1.0351 main_loss:1.4312 | AUC:0.8148 AUC2:0.8411 FAR:0.00000
[2023-07-21 00:56:01,029][main.py][line:76][INFO] [Epoch:30/100]: loss1:0.9663 loss2:1.0637 main_loss:2.0993 | AUC:0.6786 AUC2:0.8411 FAR:0.00000
[2023-07-21 00:57:35,602][main.py][line:76][INFO] [Epoch:31/100]: loss1:0.6455 loss2:1.1963 main_loss:1.9112 | AUC:0.6740 AUC2:0.8411 FAR:0.00000
[2023-07-21 00:59:10,769][main.py][line:76][INFO] [Epoch:32/100]: loss1:0.4749 loss2:1.0931 main_loss:1.6374 | AUC:0.6979 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:00:49,232][main.py][line:76][INFO] [Epoch:33/100]: loss1:0.4291 loss2:1.0770 main_loss:1.5754 | AUC:0.7419 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:02:32,385][main.py][line:76][INFO] [Epoch:34/100]: loss1:0.3971 loss2:1.0707 main_loss:1.5371 | AUC:0.6181 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:04:10,644][main.py][line:76][INFO] [Epoch:35/100]: loss1:0.3828 loss2:1.0567 main_loss:1.5088 | AUC:0.6787 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:05:51,786][main.py][line:76][INFO] [Epoch:36/100]: loss1:0.3715 loss2:1.0447 main_loss:1.4855 | AUC:0.6937 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:07:30,177][main.py][line:76][INFO] [Epoch:37/100]: loss1:0.3503 loss2:1.0456 main_loss:1.4653 | AUC:0.6879 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:09:15,046][main.py][line:76][INFO] [Epoch:38/100]: loss1:0.3385 loss2:1.0313 main_loss:1.4392 | AUC:0.7207 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:10:49,962][main.py][line:76][INFO] [Epoch:39/100]: loss1:0.3318 loss2:1.0346 main_loss:1.4357 | AUC:0.6993 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:12:23,365][main.py][line:76][INFO] [Epoch:40/100]: loss1:0.3227 loss2:1.0294 main_loss:1.4215 | AUC:0.8309 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:14:01,624][main.py][line:76][INFO] [Epoch:41/100]: loss1:0.3160 loss2:1.0282 main_loss:1.4135 | AUC:0.8338 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:15:34,659][main.py][line:76][INFO] [Epoch:42/100]: loss1:0.3091 loss2:1.0218 main_loss:1.4003 | AUC:0.8365 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:17:06,960][main.py][line:76][INFO] [Epoch:43/100]: loss1:0.3038 loss2:1.0206 main_loss:1.3937 | AUC:0.8322 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:18:36,329][main.py][line:76][INFO] [Epoch:44/100]: loss1:0.2924 loss2:1.0079 main_loss:1.3697 | AUC:0.8320 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:20:14,187][main.py][line:76][INFO] [Epoch:45/100]: loss1:0.2822 loss2:1.0133 main_loss:1.3649 | AUC:0.8365 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:21:46,326][main.py][line:76][INFO] [Epoch:46/100]: loss1:0.2724 loss2:0.9959 main_loss:1.3376 | AUC:0.8363 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:23:20,305][main.py][line:76][INFO] [Epoch:47/100]: loss1:0.2743 loss2:1.0053 main_loss:1.3490 | AUC:0.8352 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:24:59,473][main.py][line:76][INFO] [Epoch:48/100]: loss1:0.2604 loss2:1.0047 main_loss:1.3344 | AUC:0.8345 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:26:33,126][main.py][line:76][INFO] [Epoch:49/100]: loss1:0.2477 loss2:0.9956 main_loss:1.3126 | AUC:0.8325 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:28:03,439][main.py][line:76][INFO] [Epoch:50/100]: loss1:0.2459 loss2:0.9955 main_loss:1.3108 | AUC:0.8294 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:29:35,863][main.py][line:76][INFO] [Epoch:51/100]: loss1:0.2380 loss2:0.9829 main_loss:1.2902 | AUC:0.8306 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:31:10,862][main.py][line:76][INFO] [Epoch:52/100]: loss1:0.2366 loss2:0.9917 main_loss:1.2975 | AUC:0.8322 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:32:49,965][main.py][line:76][INFO] [Epoch:53/100]: loss1:0.2296 loss2:0.9891 main_loss:1.2880 | AUC:0.8313 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:34:28,358][main.py][line:76][INFO] [Epoch:54/100]: loss1:0.2293 loss2:0.9864 main_loss:1.2850 | AUC:0.8290 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:36:05,348][main.py][line:76][INFO] [Epoch:55/100]: loss1:0.2250 loss2:0.9852 main_loss:1.2795 | AUC:0.8285 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:37:34,957][main.py][line:76][INFO] [Epoch:56/100]: loss1:0.2219 loss2:0.9833 main_loss:1.2745 | AUC:0.8282 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:39:14,660][main.py][line:76][INFO] [Epoch:57/100]: loss1:0.2227 loss2:0.9819 main_loss:1.2739 | AUC:0.8290 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:40:41,834][main.py][line:76][INFO] [Epoch:58/100]: loss1:0.2221 loss2:0.9832 main_loss:1.2746 | AUC:0.8274 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:42:10,424][main.py][line:76][INFO] [Epoch:59/100]: loss1:0.2175 loss2:0.9832 main_loss:1.2700 | AUC:0.8275 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:43:40,058][main.py][line:76][INFO] [Epoch:60/100]: loss1:0.2201 loss2:0.9816 main_loss:1.2710 | AUC:0.8275 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:45:04,907][main.py][line:76][INFO] [Epoch:61/100]: loss1:0.2230 loss2:0.9797 main_loss:1.2721 | AUC:0.8275 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:46:31,333][main.py][line:76][INFO] [Epoch:62/100]: loss1:0.2200 loss2:0.9808 main_loss:1.2701 | AUC:0.8274 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:47:58,089][main.py][line:76][INFO] [Epoch:63/100]: loss1:0.2224 loss2:0.9839 main_loss:1.2756 | AUC:0.8279 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:49:24,631][main.py][line:76][INFO] [Epoch:64/100]: loss1:0.2178 loss2:0.9813 main_loss:1.2684 | AUC:0.8275 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:50:56,200][main.py][line:76][INFO] [Epoch:65/100]: loss1:0.2193 loss2:0.9806 main_loss:1.2692 | AUC:0.8272 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:52:21,828][main.py][line:76][INFO] [Epoch:66/100]: loss1:0.2211 loss2:0.9800 main_loss:1.2704 | AUC:0.8294 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:53:48,620][main.py][line:76][INFO] [Epoch:67/100]: loss1:0.2189 loss2:0.9830 main_loss:1.2712 | AUC:0.8291 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:55:17,716][main.py][line:76][INFO] [Epoch:68/100]: loss1:0.2211 loss2:0.9822 main_loss:1.2726 | AUC:0.8259 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:56:47,463][main.py][line:76][INFO] [Epoch:69/100]: loss1:0.2203 loss2:0.9822 main_loss:1.2718 | AUC:0.8251 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:58:16,346][main.py][line:76][INFO] [Epoch:70/100]: loss1:0.2221 loss2:0.9760 main_loss:1.2674 | AUC:0.8248 AUC2:0.8411 FAR:0.00000
[2023-07-21 01:59:44,256][main.py][line:76][INFO] [Epoch:71/100]: loss1:0.2163 loss2:0.9797 main_loss:1.2654 | AUC:0.8223 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:01:09,814][main.py][line:76][INFO] [Epoch:72/100]: loss1:0.2246 loss2:0.9748 main_loss:1.2688 | AUC:0.8240 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:02:37,307][main.py][line:76][INFO] [Epoch:73/100]: loss1:0.2180 loss2:0.9800 main_loss:1.2673 | AUC:0.8205 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:04:04,033][main.py][line:76][INFO] [Epoch:74/100]: loss1:0.2254 loss2:0.9840 main_loss:1.2787 | AUC:0.8213 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:05:32,076][main.py][line:76][INFO] [Epoch:75/100]: loss1:0.2188 loss2:0.9776 main_loss:1.2657 | AUC:0.8222 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:07:00,426][main.py][line:76][INFO] [Epoch:76/100]: loss1:0.2122 loss2:0.9814 main_loss:1.2630 | AUC:0.8206 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:08:28,573][main.py][line:76][INFO] [Epoch:77/100]: loss1:0.2180 loss2:0.9809 main_loss:1.2682 | AUC:0.8118 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:09:55,028][main.py][line:76][INFO] [Epoch:78/100]: loss1:0.2355 loss2:0.9884 main_loss:1.2932 | AUC:0.8125 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:11:25,046][main.py][line:76][INFO] [Epoch:79/100]: loss1:0.2176 loss2:0.9730 main_loss:1.2599 | AUC:0.8180 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:12:51,041][main.py][line:76][INFO] [Epoch:80/100]: loss1:0.2210 loss2:0.9627 main_loss:1.2531 | AUC:0.8194 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:14:22,236][main.py][line:76][INFO] [Epoch:81/100]: loss1:0.2236 loss2:0.9841 main_loss:1.2770 | AUC:0.8296 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:15:47,916][main.py][line:76][INFO] [Epoch:82/100]: loss1:0.2098 loss2:0.9763 main_loss:1.2554 | AUC:0.8255 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:17:16,291][main.py][line:76][INFO] [Epoch:83/100]: loss1:0.2079 loss2:0.9704 main_loss:1.2477 | AUC:0.8241 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:18:43,800][main.py][line:76][INFO] [Epoch:84/100]: loss1:0.2160 loss2:0.9746 main_loss:1.2600 | AUC:0.8028 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:20:10,911][main.py][line:76][INFO] [Epoch:85/100]: loss1:0.1960 loss2:0.9618 main_loss:1.2272 | AUC:0.8068 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:21:39,597][main.py][line:76][INFO] [Epoch:86/100]: loss1:0.2060 loss2:0.9706 main_loss:1.2459 | AUC:0.7689 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:23:07,053][main.py][line:76][INFO] [Epoch:87/100]: loss1:0.2165 loss2:0.9744 main_loss:1.2602 | AUC:0.7710 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:24:33,235][main.py][line:76][INFO] [Epoch:88/100]: loss1:0.2271 loss2:0.9838 main_loss:1.2804 | AUC:0.7344 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:26:01,278][main.py][line:76][INFO] [Epoch:89/100]: loss1:0.2045 loss2:0.9696 main_loss:1.2435 | AUC:0.7663 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:27:28,398][main.py][line:76][INFO] [Epoch:90/100]: loss1:0.1962 loss2:0.9569 main_loss:1.2225 | AUC:0.6980 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:28:55,426][main.py][line:76][INFO] [Epoch:91/100]: loss1:0.2169 loss2:0.9764 main_loss:1.2628 | AUC:0.6207 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:30:23,231][main.py][line:76][INFO] [Epoch:92/100]: loss1:0.2004 loss2:0.9620 main_loss:1.2320 | AUC:0.7438 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:31:48,744][main.py][line:76][INFO] [Epoch:93/100]: loss1:0.2409 loss2:0.9891 main_loss:1.2994 | AUC:0.7477 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:33:15,328][main.py][line:76][INFO] [Epoch:94/100]: loss1:0.2448 loss2:1.0021 main_loss:1.3162 | AUC:0.6361 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:34:46,153][main.py][line:76][INFO] [Epoch:95/100]: loss1:0.3872 loss2:1.0493 main_loss:1.5059 | AUC:0.5861 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:36:13,505][main.py][line:76][INFO] [Epoch:96/100]: loss1:0.2966 loss2:1.0213 main_loss:1.3872 | AUC:0.5754 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:37:38,969][main.py][line:76][INFO] [Epoch:97/100]: loss1:0.2610 loss2:1.0074 main_loss:1.3378 | AUC:0.5068 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:39:04,630][main.py][line:76][INFO] [Epoch:98/100]: loss1:0.2694 loss2:1.0143 main_loss:1.3531 | AUC:0.5118 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:40:32,506][main.py][line:76][INFO] [Epoch:99/100]: loss1:0.2808 loss2:1.0180 main_loss:1.3681 | AUC:0.5554 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:41:59,684][main.py][line:76][INFO] [Epoch:100/100]: loss1:0.2762 loss2:1.0143 main_loss:1.3599 | AUC:0.5292 AUC2:0.8411 FAR:0.00000
[2023-07-21 02:41:59,808][main.py][line:82][INFO] Training completes in 154m 21s | best AUC:0.8411 FAR:0.00007

[2023-07-21 07:09:52,700][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.01, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:09:52,883][main.py][line:116][INFO] total params:27.1990M
[2023-07-21 07:09:52,883][main.py][line:119][INFO] Training Mode
[2023-07-21 07:09:52,883][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:09:52,883][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.01
    lr: 0.01
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:10:12,326][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 07:11:37,049][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.7744 loss2:1.2974 main_loss:2.4210 | AUC:0.8082 AUC2:0.8082 FAR:0.02208
[2023-07-21 07:13:02,633][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.4365 loss2:1.1233 main_loss:1.9065 | AUC:0.7915 AUC2:0.8082 FAR:0.04535
[2023-07-21 07:14:28,635][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.4073 loss2:1.0743 main_loss:1.8282 | AUC:0.7899 AUC2:0.8082 FAR:0.02114
[2023-07-21 07:14:35,571][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:14:35,756][main.py][line:116][INFO] total params:27.1990M
[2023-07-21 07:14:35,756][main.py][line:119][INFO] Training Mode
[2023-07-21 07:14:35,757][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-1): 2 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:14:35,757][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:14:55,361][main.py][line:53][INFO] Random initialize AUC:0.5452 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 07:16:31,730][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3729 loss2:1.0986 main_loss:1.7109 | AUC:0.8270 AUC2:0.8271 FAR:0.00583
[2023-07-21 07:18:08,419][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1468 loss2:0.8741 main_loss:1.1814 | AUC:0.8538 AUC2:0.8501 FAR:0.00603
[2023-07-21 07:19:44,625][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0684 loss2:0.7777 main_loss:0.9736 | AUC:0.8485 AUC2:0.8501 FAR:0.00832
[2023-07-21 07:21:17,937][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0314 loss2:0.7010 main_loss:0.8391 | AUC:0.8548 AUC2:0.8486 FAR:0.00326
[2023-07-21 07:22:55,214][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0191 loss2:0.6276 main_loss:0.7481 | AUC:0.8519 AUC2:0.8486 FAR:0.00168
[2023-07-21 07:24:38,573][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0402 loss2:0.5925 main_loss:0.7369 | AUC:0.8527 AUC2:0.8486 FAR:0.00440
[2023-07-21 07:26:16,110][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0187 loss2:0.5309 main_loss:0.6517 | AUC:0.8555 AUC2:0.8439 FAR:0.00232
[2023-07-21 07:26:53,106][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:26:53,290][main.py][line:116][INFO] total params:27.1990M
[2023-07-21 07:26:53,291][main.py][line:123][INFO] Test Mode
[2023-07-21 07:26:53,291][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-21 07:26:53,397][main.py][line:32][INFO] bert.embedding.learnedPosition.pe size mismatch: load torch.Size([1, 101, 1024]) given torch.Size([1, 201, 1024])
[2023-07-21 07:26:53,397][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.0.weight not found in model dict.
[2023-07-21 07:26:53,397][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.0.bias not found in model dict.
[2023-07-21 07:26:53,397][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.1.weight not found in model dict.
[2023-07-21 07:26:53,397][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.1.bias not found in model dict.
[2023-07-21 07:26:53,397][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.2.weight not found in model dict.
[2023-07-21 07:26:53,397][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.2.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.attention.output_linear.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.attention.output_linear.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_1.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_1.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_2.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_2.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.input_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.input_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.output_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.2.output_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.0.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.0.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.1.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.1.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.2.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.2.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.output_linear.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.attention.output_linear.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_1.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_1.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_2.weight not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_2.bias not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.input_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.input_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.output_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:26:53,398][main.py][line:35][INFO] bert.transformer_blocks.3.output_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:29:19,714][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8617.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:29:19,864][main.py][line:116][INFO] total params:27.1990M
[2023-07-21 07:29:19,865][main.py][line:123][INFO] Test Mode
[2023-07-21 07:29:19,865][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8617.pkl.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.0.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.0.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.1.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.1.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.2.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.linear_layers.2.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.output_linear.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.attention.output_linear.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_1.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_1.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_2.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.feed_forward.w_2.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.input_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.input_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.output_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.2.output_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.0.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.0.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.1.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.1.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.2.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.linear_layers.2.bias not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.output_linear.weight not found in model dict.
[2023-07-21 07:29:19,971][main.py][line:35][INFO] bert.transformer_blocks.3.attention.output_linear.bias not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_1.weight not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_1.bias not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_2.weight not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.feed_forward.w_2.bias not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.input_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.input_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.output_sublayer.norm.a_2 not found in model dict.
[2023-07-21 07:29:19,972][main.py][line:35][INFO] bert.transformer_blocks.3.output_sublayer.norm.b_2 not found in model dict.
[2023-07-21 07:29:39,551][infer_bert.py][line:65][INFO] offline AUC:0.8623 AUC2:0.8623 AP:0.3394 FAR:0.0011 | Complete in 0m 20s

[2023-07-21 07:31:12,970][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:31:13,205][main.py][line:116][INFO] total params:52.3915M
[2023-07-21 07:31:13,205][main.py][line:123][INFO] Test Mode
[2023-07-21 07:31:13,205][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-21 07:31:13,267][main.py][line:32][INFO] bert.embedding.learnedPosition.pe size mismatch: load torch.Size([1, 101, 1024]) given torch.Size([1, 201, 1024])
[2023-07-21 07:31:34,493][infer_bert.py][line:65][INFO] offline AUC:0.8601 AUC2:0.8558 AP:0.3281 FAR:0.0014 | Complete in 0m 21s

[2023-07-21 07:32:37,754][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:32:37,978][main.py][line:116][INFO] total params:52.2891M
[2023-07-21 07:32:37,978][main.py][line:123][INFO] Test Mode
[2023-07-21 07:32:37,978][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-21 07:32:51,628][infer_bert.py][line:65][INFO] offline AUC:0.8638 AUC2:0.8558 AP:0.3289 FAR:0.0014 | Complete in 0m 14s

[2023-07-21 07:36:38,085][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:36:38,319][main.py][line:116][INFO] total params:52.2891M
[2023-07-21 07:36:38,319][main.py][line:123][INFO] Test Mode
[2023-07-21 07:36:38,319][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-21 07:36:52,072][infer_bert.py][line:66][INFO] offline AUC:0.8638 AUC2:0.8558 AP:0.3289 FAR:0.0014 | Complete in 0m 14s

[2023-07-21 07:39:31,241][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:39:31,463][main.py][line:116][INFO] total params:52.2891M
[2023-07-21 07:39:31,464][main.py][line:123][INFO] Test Mode
[2023-07-21 07:39:31,464][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-21 07:42:36,303][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:42:36,527][main.py][line:116][INFO] total params:52.2891M
[2023-07-21 07:42:36,527][main.py][line:123][INFO] Test Mode
[2023-07-21 07:42:36,527][main.py][line:22][INFO] loading pretrained checkpoint from ./ckpt/ucf__8638.pkl.
[2023-07-21 07:45:10,554][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:45:10,770][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:45:10,770][main.py][line:119][INFO] Training Mode
[2023-07-21 07:45:10,771][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:45:10,771][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:45:45,073][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:45:45,305][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:45:45,305][main.py][line:119][INFO] Training Mode
[2023-07-21 07:45:45,306][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:45:45,306][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:46:13,025][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:46:13,253][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:46:13,253][main.py][line:119][INFO] Training Mode
[2023-07-21 07:46:13,254][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:46:13,254][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:47:29,414][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:47:29,631][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:47:29,631][main.py][line:119][INFO] Training Mode
[2023-07-21 07:47:29,631][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:47:29,631][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:47:37,174][main.py][line:53][INFO] Random initialize AUC:0.5445 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 07:51:23,960][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:51:24,193][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:51:24,193][main.py][line:119][INFO] Training Mode
[2023-07-21 07:51:24,193][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:51:24,193][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:52:24,654][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 100, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:52:24,892][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:52:24,892][main.py][line:119][INFO] Training Mode
[2023-07-21 07:52:24,893][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:52:24,893][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:52:32,510][main.py][line:53][INFO] Random initialize AUC:0.5445 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 07:53:40,428][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:53:40,652][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:53:40,652][main.py][line:119][INFO] Training Mode
[2023-07-21 07:53:40,652][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:53:40,652][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:53:48,151][main.py][line:53][INFO] Random initialize AUC:0.5445 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 07:55:50,690][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 07:55:50,930][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 07:55:50,930][main.py][line:119][INFO] Training Mode
[2023-07-21 07:55:50,931][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 07:55:50,931][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 07:55:58,500][main.py][line:53][INFO] Random initialize AUC:0.5445 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 07:57:03,192][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3674 loss2:1.0975 main_loss:1.7620 | AUC:0.8312 AUC2:0.8341 FAR:0.00632
[2023-07-21 07:58:07,551][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1423 loss2:0.8743 main_loss:1.1856 | AUC:0.8502 AUC2:0.8497 FAR:0.00491
[2023-07-21 07:59:12,432][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0602 loss2:0.7808 main_loss:1.0242 | AUC:0.8416 AUC2:0.8497 FAR:0.00235
[2023-07-21 08:00:18,535][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0475 loss2:0.7119 main_loss:0.9152 | AUC:0.8495 AUC2:0.8497 FAR:0.00595
[2023-07-21 08:01:26,665][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0257 loss2:0.6487 main_loss:0.8159 | AUC:0.8558 AUC2:0.8514 FAR:0.00185
[2023-07-21 08:02:33,454][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0211 loss2:0.5865 main_loss:0.7438 | AUC:0.8531 AUC2:0.8514 FAR:0.00961
[2023-07-21 08:03:37,377][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0152 loss2:0.5311 main_loss:0.6717 | AUC:0.8501 AUC2:0.8514 FAR:0.00519
[2023-07-21 08:04:40,253][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0155 loss2:0.4769 main_loss:0.6136 | AUC:0.8447 AUC2:0.8514 FAR:0.00593
[2023-07-21 08:05:46,919][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0231 loss2:0.4407 main_loss:0.5780 | AUC:0.8545 AUC2:0.8514 FAR:0.00696
[2023-07-21 08:06:55,159][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0127 loss2:0.3883 main_loss:0.5159 | AUC:0.8424 AUC2:0.8514 FAR:0.00291
[2023-07-21 08:08:00,282][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.0078 loss2:0.3309 main_loss:0.4446 | AUC:0.8492 AUC2:0.8514 FAR:0.00306
[2023-07-21 08:09:06,910][main.py][line:76][INFO] [Epoch:12/100]: loss1:0.0064 loss2:0.2811 main_loss:0.3884 | AUC:0.8443 AUC2:0.8514 FAR:0.00126
[2023-07-21 08:10:11,947][main.py][line:76][INFO] [Epoch:13/100]: loss1:0.0067 loss2:0.2447 main_loss:0.3535 | AUC:0.8505 AUC2:0.8514 FAR:0.00326
[2023-07-21 08:11:19,804][main.py][line:76][INFO] [Epoch:14/100]: loss1:0.0053 loss2:0.2033 main_loss:0.3156 | AUC:0.8492 AUC2:0.8514 FAR:0.00393
[2023-07-21 08:12:27,146][main.py][line:76][INFO] [Epoch:15/100]: loss1:0.0047 loss2:0.1689 main_loss:0.2876 | AUC:0.8520 AUC2:0.8514 FAR:0.00336
[2023-07-21 08:13:32,940][main.py][line:76][INFO] [Epoch:16/100]: loss1:0.0046 loss2:0.1405 main_loss:0.2417 | AUC:0.8478 AUC2:0.8514 FAR:0.00237
[2023-07-21 08:14:38,298][main.py][line:76][INFO] [Epoch:17/100]: loss1:0.0053 loss2:0.1200 main_loss:0.2177 | AUC:0.8474 AUC2:0.8514 FAR:0.00247
[2023-07-21 08:15:42,761][main.py][line:76][INFO] [Epoch:18/100]: loss1:0.0549 loss2:0.2049 main_loss:0.3492 | AUC:0.8378 AUC2:0.8514 FAR:0.00393
[2023-07-21 08:16:45,499][main.py][line:76][INFO] [Epoch:19/100]: loss1:0.0133 loss2:0.1330 main_loss:0.2316 | AUC:0.8444 AUC2:0.8514 FAR:0.00511
[2023-07-21 08:17:50,153][main.py][line:76][INFO] [Epoch:20/100]: loss1:0.0170 loss2:0.1153 main_loss:0.2154 | AUC:0.8443 AUC2:0.8514 FAR:0.00309
[2023-07-21 08:18:55,819][main.py][line:76][INFO] [Epoch:21/100]: loss1:0.0035 loss2:0.0713 main_loss:0.1533 | AUC:0.8440 AUC2:0.8514 FAR:0.00301
[2023-07-21 08:20:02,027][main.py][line:76][INFO] [Epoch:22/100]: loss1:0.0024 loss2:0.0573 main_loss:0.1412 | AUC:0.8466 AUC2:0.8514 FAR:0.00388
[2023-07-21 08:21:05,546][main.py][line:76][INFO] [Epoch:23/100]: loss1:0.0021 loss2:0.0515 main_loss:0.1280 | AUC:0.8450 AUC2:0.8514 FAR:0.00358
[2023-07-21 09:18:34,480][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 09:18:34,749][main.py][line:116][INFO] total params:52.1969M
[2023-07-21 09:18:34,749][main.py][line:119][INFO] Training Mode
[2023-07-21 09:18:34,749][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 09:18:34,749][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 09:19:35,800][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 09:19:36,035][main.py][line:116][INFO] total params:52.2195M
[2023-07-21 09:19:36,035][main.py][line:119][INFO] Training Mode
[2023-07-21 09:19:36,035][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 09:19:36,035][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 09:19:57,275][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 09:19:57,510][main.py][line:116][INFO] total params:52.2195M
[2023-07-21 09:19:57,510][main.py][line:119][INFO] Training Mode
[2023-07-21 09:19:57,511][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 09:19:57,511][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 09:20:18,725][main.py][line:90][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 09:20:18,957][main.py][line:116][INFO] total params:52.2195M
[2023-07-21 09:20:18,958][main.py][line:119][INFO] Training Mode
[2023-07-21 09:20:18,958][main.py][line:49][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 09:20:18,958][main.py][line:50][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 09:20:27,190][main.py][line:53][INFO] Random initialize AUC:0.5448 initial_AUC2:0.5444 FAR:0.67905
[2023-07-21 09:21:21,093][main.py][line:76][INFO] [Epoch:1/100]: loss1:0.3930 loss2:1.1859 main_loss:1.9055 | AUC:0.8045 AUC2:0.8102 FAR:0.01499
[2023-07-21 09:22:14,818][main.py][line:76][INFO] [Epoch:2/100]: loss1:0.1667 loss2:0.9458 main_loss:1.4324 | AUC:0.8342 AUC2:0.8332 FAR:0.00563
[2023-07-21 09:23:09,000][main.py][line:76][INFO] [Epoch:3/100]: loss1:0.0713 loss2:0.8367 main_loss:1.1644 | AUC:0.8362 AUC2:0.8328 FAR:0.00237
[2023-07-21 09:24:03,497][main.py][line:76][INFO] [Epoch:4/100]: loss1:0.0419 loss2:0.7443 main_loss:0.9675 | AUC:0.8446 AUC2:0.8394 FAR:0.00193
[2023-07-21 09:24:57,712][main.py][line:76][INFO] [Epoch:5/100]: loss1:0.0287 loss2:0.6708 main_loss:0.8435 | AUC:0.8523 AUC2:0.8473 FAR:0.00121
[2023-07-21 09:25:51,635][main.py][line:76][INFO] [Epoch:6/100]: loss1:0.0238 loss2:0.6029 main_loss:0.7490 | AUC:0.8517 AUC2:0.8473 FAR:0.00259
[2023-07-21 09:26:45,682][main.py][line:76][INFO] [Epoch:7/100]: loss1:0.0182 loss2:0.5426 main_loss:0.6660 | AUC:0.8505 AUC2:0.8473 FAR:0.00143
[2023-07-21 09:27:39,810][main.py][line:76][INFO] [Epoch:8/100]: loss1:0.0146 loss2:0.4737 main_loss:0.5836 | AUC:0.8460 AUC2:0.8473 FAR:0.00306
[2023-07-21 09:28:34,163][main.py][line:76][INFO] [Epoch:9/100]: loss1:0.0156 loss2:0.4290 main_loss:0.5333 | AUC:0.8535 AUC2:0.8443 FAR:0.00131
[2023-07-21 09:29:28,086][main.py][line:76][INFO] [Epoch:10/100]: loss1:0.0129 loss2:0.3660 main_loss:0.4684 | AUC:0.8502 AUC2:0.8443 FAR:0.00163
[2023-07-21 09:30:22,157][main.py][line:76][INFO] [Epoch:11/100]: loss1:0.0112 loss2:0.3342 main_loss:0.4228 | AUC:0.8472 AUC2:0.8443 FAR:0.00215
[2023-07-21 09:31:17,036][main.py][line:76][INFO] [Epoch:12/100]: loss1:0.0099 loss2:0.2940 main_loss:0.4149 | AUC:0.8533 AUC2:0.8443 FAR:0.00237
[2023-07-21 09:32:11,066][main.py][line:76][INFO] [Epoch:13/100]: loss1:0.0077 loss2:0.2522 main_loss:0.3523 | AUC:0.8476 AUC2:0.8443 FAR:0.00116
[2023-07-21 09:33:05,658][main.py][line:76][INFO] [Epoch:14/100]: loss1:0.0085 loss2:0.2193 main_loss:0.2988 | AUC:0.8579 AUC2:0.8462 FAR:0.00106
[2023-07-21 09:33:59,988][main.py][line:76][INFO] [Epoch:15/100]: loss1:0.0100 loss2:0.1900 main_loss:0.2637 | AUC:0.8447 AUC2:0.8462 FAR:0.00044
[2023-07-21 09:34:54,318][main.py][line:76][INFO] [Epoch:16/100]: loss1:0.0274 loss2:0.2005 main_loss:0.2879 | AUC:0.8539 AUC2:0.8462 FAR:0.00111
[2023-07-21 09:35:48,318][main.py][line:76][INFO] [Epoch:17/100]: loss1:0.0060 loss2:0.1352 main_loss:0.1914 | AUC:0.8521 AUC2:0.8462 FAR:0.00077
[2023-07-21 09:36:42,565][main.py][line:76][INFO] [Epoch:18/100]: loss1:0.0046 loss2:0.1112 main_loss:0.1618 | AUC:0.8563 AUC2:0.8462 FAR:0.00116
[2023-07-21 09:37:36,771][main.py][line:76][INFO] [Epoch:19/100]: loss1:0.0038 loss2:0.0980 main_loss:0.1390 | AUC:0.8555 AUC2:0.8462 FAR:0.00077
[2023-07-21 09:38:30,857][main.py][line:76][INFO] [Epoch:20/100]: loss1:0.0039 loss2:0.0823 main_loss:0.1175 | AUC:0.8536 AUC2:0.8462 FAR:0.00133
[2023-07-21 09:39:25,208][main.py][line:76][INFO] [Epoch:21/100]: loss1:0.0064 loss2:0.0801 main_loss:0.1189 | AUC:0.8557 AUC2:0.8462 FAR:0.00133
[2023-07-21 09:40:19,740][main.py][line:76][INFO] [Epoch:22/100]: loss1:0.0038 loss2:0.0646 main_loss:0.1000 | AUC:0.8591 AUC2:0.8525 FAR:0.00099
[2023-07-21 09:41:13,936][main.py][line:76][INFO] [Epoch:23/100]: loss1:0.0043 loss2:0.0571 main_loss:0.0927 | AUC:0.8525 AUC2:0.8525 FAR:0.00091
[2023-07-21 09:42:08,273][main.py][line:76][INFO] [Epoch:24/100]: loss1:0.0030 loss2:0.0484 main_loss:0.1361 | AUC:0.8481 AUC2:0.8525 FAR:0.00089
[2023-07-21 09:43:02,133][main.py][line:76][INFO] [Epoch:25/100]: loss1:0.0020 loss2:0.0434 main_loss:0.0984 | AUC:0.8546 AUC2:0.8525 FAR:0.00074
[2023-07-21 09:43:56,149][main.py][line:76][INFO] [Epoch:26/100]: loss1:0.0024 loss2:0.0388 main_loss:0.0811 | AUC:0.8518 AUC2:0.8525 FAR:0.00077
[2023-07-21 09:44:49,970][main.py][line:76][INFO] [Epoch:27/100]: loss1:0.0026 loss2:0.0372 main_loss:0.1137 | AUC:0.8518 AUC2:0.8525 FAR:0.00082
[2023-07-21 09:45:43,979][main.py][line:76][INFO] [Epoch:28/100]: loss1:0.0017 loss2:0.0330 main_loss:0.0909 | AUC:0.8500 AUC2:0.8525 FAR:0.00089
[2023-07-21 09:46:38,038][main.py][line:76][INFO] [Epoch:29/100]: loss1:0.0011 loss2:0.0264 main_loss:0.0666 | AUC:0.8526 AUC2:0.8525 FAR:0.00079
[2023-07-21 09:47:31,992][main.py][line:76][INFO] [Epoch:30/100]: loss1:0.0010 loss2:0.0249 main_loss:0.0630 | AUC:0.8490 AUC2:0.8525 FAR:0.00096
[2023-07-21 09:48:25,853][main.py][line:76][INFO] [Epoch:31/100]: loss1:0.0017 loss2:0.0249 main_loss:0.0625 | AUC:0.8519 AUC2:0.8525 FAR:0.00114
[2023-07-21 09:49:19,886][main.py][line:76][INFO] [Epoch:32/100]: loss1:0.0012 loss2:0.0222 main_loss:0.0565 | AUC:0.8522 AUC2:0.8525 FAR:0.00094
[2023-07-21 09:50:13,768][main.py][line:76][INFO] [Epoch:33/100]: loss1:0.0013 loss2:0.0190 main_loss:0.0464 | AUC:0.8529 AUC2:0.8525 FAR:0.00188
[2023-07-21 09:51:07,723][main.py][line:76][INFO] [Epoch:34/100]: loss1:0.0016 loss2:0.0210 main_loss:0.0480 | AUC:0.8559 AUC2:0.8525 FAR:0.00109
[2023-07-21 09:52:02,144][main.py][line:76][INFO] [Epoch:35/100]: loss1:0.0029 loss2:0.0242 main_loss:0.0515 | AUC:0.8538 AUC2:0.8525 FAR:0.00165
[2023-07-21 09:52:56,033][main.py][line:76][INFO] [Epoch:36/100]: loss1:0.0016 loss2:0.0199 main_loss:0.0497 | AUC:0.8501 AUC2:0.8525 FAR:0.00084
[2023-07-21 09:53:49,924][main.py][line:76][INFO] [Epoch:37/100]: loss1:0.0010 loss2:0.0170 main_loss:0.0441 | AUC:0.8501 AUC2:0.8525 FAR:0.00153
[2023-07-21 09:54:43,625][main.py][line:76][INFO] [Epoch:38/100]: loss1:0.0007 loss2:0.0131 main_loss:0.0360 | AUC:0.8497 AUC2:0.8525 FAR:0.00089
[2023-07-21 09:55:37,556][main.py][line:76][INFO] [Epoch:39/100]: loss1:0.0007 loss2:0.0145 main_loss:0.0362 | AUC:0.8513 AUC2:0.8525 FAR:0.00091
[2023-07-21 09:56:31,557][main.py][line:76][INFO] [Epoch:40/100]: loss1:0.0006 loss2:0.0115 main_loss:0.0308 | AUC:0.8511 AUC2:0.8525 FAR:0.00089
[2023-07-21 09:57:25,658][main.py][line:76][INFO] [Epoch:41/100]: loss1:0.0005 loss2:0.0103 main_loss:0.0299 | AUC:0.8499 AUC2:0.8525 FAR:0.00074
[2023-07-21 09:58:19,318][main.py][line:76][INFO] [Epoch:42/100]: loss1:0.0006 loss2:0.0118 main_loss:0.0284 | AUC:0.8524 AUC2:0.8525 FAR:0.00096
[2023-07-21 09:59:13,132][main.py][line:76][INFO] [Epoch:43/100]: loss1:0.0010 loss2:0.0113 main_loss:0.0294 | AUC:0.8474 AUC2:0.8525 FAR:0.00146
[2023-07-21 10:00:07,668][main.py][line:76][INFO] [Epoch:44/100]: loss1:0.0005 loss2:0.0102 main_loss:0.0271 | AUC:0.8482 AUC2:0.8525 FAR:0.00091
[2023-07-21 10:01:01,547][main.py][line:76][INFO] [Epoch:45/100]: loss1:0.0005 loss2:0.0100 main_loss:0.0251 | AUC:0.8495 AUC2:0.8525 FAR:0.00099
[2023-07-21 10:01:55,378][main.py][line:76][INFO] [Epoch:46/100]: loss1:0.0004 loss2:0.0099 main_loss:0.0244 | AUC:0.8510 AUC2:0.8525 FAR:0.00089
[2023-07-21 10:02:49,524][main.py][line:76][INFO] [Epoch:47/100]: loss1:0.0004 loss2:0.0093 main_loss:0.0255 | AUC:0.8507 AUC2:0.8525 FAR:0.00091
[2023-07-21 10:03:43,680][main.py][line:76][INFO] [Epoch:48/100]: loss1:0.0004 loss2:0.0087 main_loss:0.0226 | AUC:0.8517 AUC2:0.8525 FAR:0.00099
[2023-07-21 10:04:37,608][main.py][line:76][INFO] [Epoch:49/100]: loss1:0.0004 loss2:0.0079 main_loss:0.0208 | AUC:0.8490 AUC2:0.8525 FAR:0.00074
[2023-07-21 10:05:31,589][main.py][line:76][INFO] [Epoch:50/100]: loss1:0.0004 loss2:0.0084 main_loss:0.0219 | AUC:0.8507 AUC2:0.8525 FAR:0.00079
[2023-07-21 10:06:25,412][main.py][line:76][INFO] [Epoch:51/100]: loss1:0.0004 loss2:0.0087 main_loss:0.0220 | AUC:0.8510 AUC2:0.8525 FAR:0.00089
[2023-07-21 10:07:19,456][main.py][line:76][INFO] [Epoch:52/100]: loss1:0.0004 loss2:0.0090 main_loss:0.0200 | AUC:0.8498 AUC2:0.8525 FAR:0.00077
[2023-07-21 10:08:13,786][main.py][line:76][INFO] [Epoch:53/100]: loss1:0.0004 loss2:0.0083 main_loss:0.0201 | AUC:0.8504 AUC2:0.8525 FAR:0.00086
[2023-07-21 10:09:07,621][main.py][line:76][INFO] [Epoch:54/100]: loss1:0.0003 loss2:0.0081 main_loss:0.0195 | AUC:0.8510 AUC2:0.8525 FAR:0.00086
[2023-07-21 10:10:01,789][main.py][line:76][INFO] [Epoch:55/100]: loss1:0.0003 loss2:0.0091 main_loss:0.0207 | AUC:0.8508 AUC2:0.8525 FAR:0.00086
[2023-07-21 10:10:56,634][main.py][line:76][INFO] [Epoch:56/100]: loss1:0.0004 loss2:0.0071 main_loss:0.0182 | AUC:0.8511 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:11:50,877][main.py][line:76][INFO] [Epoch:57/100]: loss1:0.0003 loss2:0.0078 main_loss:0.0184 | AUC:0.8510 AUC2:0.8525 FAR:0.00086
[2023-07-21 10:12:44,697][main.py][line:76][INFO] [Epoch:58/100]: loss1:0.0003 loss2:0.0083 main_loss:0.0191 | AUC:0.8511 AUC2:0.8525 FAR:0.00082
[2023-07-21 10:13:38,848][main.py][line:76][INFO] [Epoch:59/100]: loss1:0.0003 loss2:0.0082 main_loss:0.0186 | AUC:0.8511 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:14:32,741][main.py][line:76][INFO] [Epoch:60/100]: loss1:0.0003 loss2:0.0075 main_loss:0.0186 | AUC:0.8511 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:15:26,831][main.py][line:76][INFO] [Epoch:61/100]: loss1:0.0003 loss2:0.0079 main_loss:0.0188 | AUC:0.8511 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:16:21,254][main.py][line:76][INFO] [Epoch:62/100]: loss1:0.0003 loss2:0.0082 main_loss:0.0191 | AUC:0.8511 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:17:15,153][main.py][line:76][INFO] [Epoch:63/100]: loss1:0.0003 loss2:0.0083 main_loss:0.0186 | AUC:0.8510 AUC2:0.8525 FAR:0.00086
[2023-07-21 10:18:09,031][main.py][line:76][INFO] [Epoch:64/100]: loss1:0.0003 loss2:0.0080 main_loss:0.0185 | AUC:0.8508 AUC2:0.8525 FAR:0.00077
[2023-07-21 10:19:03,030][main.py][line:76][INFO] [Epoch:65/100]: loss1:0.0003 loss2:0.0074 main_loss:0.0187 | AUC:0.8509 AUC2:0.8525 FAR:0.00089
[2023-07-21 10:19:57,013][main.py][line:76][INFO] [Epoch:66/100]: loss1:0.0003 loss2:0.0077 main_loss:0.0183 | AUC:0.8508 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:20:50,899][main.py][line:76][INFO] [Epoch:67/100]: loss1:0.0003 loss2:0.0075 main_loss:0.0186 | AUC:0.8505 AUC2:0.8525 FAR:0.00074
[2023-07-21 10:21:44,821][main.py][line:76][INFO] [Epoch:68/100]: loss1:0.0003 loss2:0.0066 main_loss:0.0190 | AUC:0.8515 AUC2:0.8525 FAR:0.00091
[2023-07-21 10:22:38,812][main.py][line:76][INFO] [Epoch:69/100]: loss1:0.0004 loss2:0.0065 main_loss:0.0179 | AUC:0.8512 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:23:33,065][main.py][line:76][INFO] [Epoch:70/100]: loss1:0.0003 loss2:0.0073 main_loss:0.0178 | AUC:0.8511 AUC2:0.8525 FAR:0.00086
[2023-07-21 10:24:27,106][main.py][line:76][INFO] [Epoch:71/100]: loss1:0.0003 loss2:0.0068 main_loss:0.0185 | AUC:0.8527 AUC2:0.8525 FAR:0.00091
[2023-07-21 10:25:21,327][main.py][line:76][INFO] [Epoch:72/100]: loss1:0.0004 loss2:0.0079 main_loss:0.0173 | AUC:0.8504 AUC2:0.8525 FAR:0.00082
[2023-07-21 10:26:15,608][main.py][line:76][INFO] [Epoch:73/100]: loss1:0.0004 loss2:0.0076 main_loss:0.0183 | AUC:0.8523 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:27:09,780][main.py][line:76][INFO] [Epoch:74/100]: loss1:0.0005 loss2:0.0074 main_loss:0.0215 | AUC:0.8517 AUC2:0.8525 FAR:0.00089
[2023-07-21 10:28:03,815][main.py][line:76][INFO] [Epoch:75/100]: loss1:0.0004 loss2:0.0055 main_loss:0.0166 | AUC:0.8533 AUC2:0.8525 FAR:0.00094
[2023-07-21 10:28:58,129][main.py][line:76][INFO] [Epoch:76/100]: loss1:0.0008 loss2:0.0052 main_loss:0.0180 | AUC:0.8555 AUC2:0.8525 FAR:0.00084
[2023-07-21 10:29:52,156][main.py][line:76][INFO] [Epoch:77/100]: loss1:0.0012 loss2:0.0108 main_loss:0.0236 | AUC:0.8531 AUC2:0.8525 FAR:0.00074
[2023-07-21 10:30:46,142][main.py][line:76][INFO] [Epoch:78/100]: loss1:0.0004 loss2:0.0071 main_loss:0.0172 | AUC:0.8498 AUC2:0.8525 FAR:0.00044
[2023-07-21 10:31:04,712][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 10:31:05,090][main.py][line:144][INFO] total params:52.2195M
[2023-07-21 10:31:05,090][main.py][line:147][INFO] Training Mode
[2023-07-21 10:32:07,909][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 10:32:08,246][main.py][line:144][INFO] total params:52.2195M
[2023-07-21 10:32:08,246][main.py][line:147][INFO] Training Mode
[2023-07-21 10:32:08,247][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 10:32:08,247][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 10:32:08,247][main.py][line:75][INFO] Optimizer_bert:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0

Parameter Group 3
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0
)

[2023-07-21 10:32:16,429][main.py][line:79][INFO] Random initialize AUC:0.6173 initial_AUC2:0.6194 FAR:0.02739
[2023-07-21 10:33:11,936][main.py][line:104][INFO] [Epoch:1/100]: loss1:0.3887 loss2:1.1476 main_loss:1.5362 | AUC:0.8213 AUC2:0.8190 FAR:0.00373
[2023-07-21 10:34:09,680][main.py][line:104][INFO] [Epoch:2/100]: loss1:0.1699 loss2:0.9332 main_loss:1.1031 | AUC:0.8308 AUC2:0.8277 FAR:0.00269
[2023-07-21 10:35:05,940][main.py][line:104][INFO] [Epoch:3/100]: loss1:0.0681 loss2:0.8294 main_loss:0.8975 | AUC:0.8470 AUC2:0.8370 FAR:0.00267
[2023-07-21 10:36:04,019][main.py][line:104][INFO] [Epoch:4/100]: loss1:0.0391 loss2:0.7387 main_loss:0.7778 | AUC:0.8359 AUC2:0.8370 FAR:0.00067
[2023-07-21 10:37:00,015][main.py][line:104][INFO] [Epoch:5/100]: loss1:0.0278 loss2:0.6635 main_loss:0.6913 | AUC:0.8391 AUC2:0.8370 FAR:0.00215
[2023-07-21 10:37:55,044][main.py][line:104][INFO] [Epoch:6/100]: loss1:0.0222 loss2:0.5996 main_loss:0.6218 | AUC:0.8330 AUC2:0.8370 FAR:0.00247
[2023-07-21 10:38:51,410][main.py][line:104][INFO] [Epoch:7/100]: loss1:0.0173 loss2:0.5342 main_loss:0.5515 | AUC:0.8353 AUC2:0.8370 FAR:0.00163
[2023-07-21 10:39:47,834][main.py][line:104][INFO] [Epoch:8/100]: loss1:0.0157 loss2:0.4846 main_loss:0.5004 | AUC:0.8234 AUC2:0.8370 FAR:0.00082
[2023-07-21 10:40:44,137][main.py][line:104][INFO] [Epoch:9/100]: loss1:0.0170 loss2:0.4337 main_loss:0.4507 | AUC:0.8350 AUC2:0.8370 FAR:0.00282
[2023-07-21 10:41:21,919][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 32, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 10:41:22,301][main.py][line:144][INFO] total params:52.2195M
[2023-07-21 10:41:22,301][main.py][line:147][INFO] Training Mode
[2023-07-21 10:41:22,310][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 10:41:22,310][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 10:41:22,310][main.py][line:75][INFO] Optimizer_bert:Adagrad (
Parameter Group 0
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513

Parameter Group 1
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513

Parameter Group 2
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513

Parameter Group 3
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513
)

[2023-07-21 10:41:31,509][main.py][line:79][INFO] Random initialize AUC:0.6173 initial_AUC2:0.6194 FAR:0.02739
[2023-07-21 10:42:35,059][main.py][line:104][INFO] [Epoch:1/100]: loss1:0.3887 loss2:1.1476 main_loss:1.5362 | AUC:0.8206 AUC2:0.8190 FAR:0.00373
[2023-07-21 10:43:38,581][main.py][line:104][INFO] [Epoch:2/100]: loss1:0.1699 loss2:0.9332 main_loss:1.1031 | AUC:0.8306 AUC2:0.8277 FAR:0.00269
[2023-07-21 10:44:43,329][main.py][line:104][INFO] [Epoch:3/100]: loss1:0.0681 loss2:0.8294 main_loss:0.8975 | AUC:0.8407 AUC2:0.8370 FAR:0.00267
[2023-07-21 10:45:47,146][main.py][line:104][INFO] [Epoch:4/100]: loss1:0.0391 loss2:0.7387 main_loss:0.7778 | AUC:0.8341 AUC2:0.8370 FAR:0.00067
[2023-07-21 10:46:52,733][main.py][line:104][INFO] [Epoch:5/100]: loss1:0.0278 loss2:0.6635 main_loss:0.6913 | AUC:0.8388 AUC2:0.8370 FAR:0.00215
[2023-07-21 10:47:54,386][main.py][line:104][INFO] [Epoch:6/100]: loss1:0.0222 loss2:0.5996 main_loss:0.6218 | AUC:0.8354 AUC2:0.8370 FAR:0.00247
[2023-07-21 10:48:56,829][main.py][line:104][INFO] [Epoch:7/100]: loss1:0.0173 loss2:0.5342 main_loss:0.5515 | AUC:0.8390 AUC2:0.8370 FAR:0.00163
[2023-07-21 10:49:59,302][main.py][line:104][INFO] [Epoch:8/100]: loss1:0.0157 loss2:0.4846 main_loss:0.5004 | AUC:0.8322 AUC2:0.8370 FAR:0.00082
[2023-07-21 10:50:06,734][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8638.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 10:50:07,110][main.py][line:144][INFO] total params:52.3915M
[2023-07-21 10:50:07,110][main.py][line:147][INFO] Training Mode
[2023-07-21 10:50:07,119][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 10:50:07,119][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-07-21 10:50:07,119][main.py][line:75][INFO] Optimizer_bert:Adagrad (
Parameter Group 0
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513

Parameter Group 1
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513

Parameter Group 2
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513

Parameter Group 3
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513
)

[2023-07-21 10:50:27,766][main.py][line:79][INFO] Random initialize AUC:0.6172 initial_AUC2:0.6194 FAR:0.02739
[2023-07-21 10:52:25,267][main.py][line:104][INFO] [Epoch:1/100]: loss1:0.3669 loss2:1.0650 main_loss:1.4319 | AUC:0.8283 AUC2:0.8286 FAR:0.01242
[2023-07-21 10:54:32,214][main.py][line:104][INFO] [Epoch:2/100]: loss1:0.1425 loss2:0.8575 main_loss:1.0000 | AUC:0.8376 AUC2:0.8338 FAR:0.00220
[2023-07-21 10:56:46,426][main.py][line:104][INFO] [Epoch:3/100]: loss1:0.0624 loss2:0.7667 main_loss:0.8291 | AUC:0.8480 AUC2:0.8458 FAR:0.01097
[2023-07-21 10:58:51,953][main.py][line:104][INFO] [Epoch:4/100]: loss1:0.0381 loss2:0.6961 main_loss:0.7342 | AUC:0.8472 AUC2:0.8458 FAR:0.00294
[2023-07-21 11:00:58,932][main.py][line:104][INFO] [Epoch:5/100]: loss1:0.0275 loss2:0.6346 main_loss:0.6621 | AUC:0.8454 AUC2:0.8458 FAR:0.00188
[2023-07-21 11:03:05,773][main.py][line:104][INFO] [Epoch:6/100]: loss1:0.0161 loss2:0.5695 main_loss:0.5855 | AUC:0.8407 AUC2:0.8458 FAR:0.00190
[2023-07-21 11:22:57,879][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 11:22:58,243][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 11:22:58,243][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 11:22:58,243][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 11:22:58,255][main_bert_v2.py][line:56][INFO] Model:BertModel(
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 11:22:58,255][main_bert_v2.py][line:57][INFO] Optimizer:Adagrad (
Parameter Group 0
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513
)

[2023-07-21 11:23:19,600][main_bert_v2.py][line:60][INFO] Random initialize AUC:0.8632 initial_AUC2:0.8635 FAR:0.00620
[2023-07-21 11:25:19,932][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 11:25:20,277][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 11:25:20,277][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 11:25:20,277][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 11:25:20,286][main_bert_v2.py][line:56][INFO] Model:BertModel(
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 11:25:20,286][main_bert_v2.py][line:57][INFO] Optimizer:Adagrad (
Parameter Group 0
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513
)

[2023-07-21 11:25:40,699][main_bert_v2.py][line:60][INFO] Random initialize AUC:0.8632 initial_AUC2:0.8635 FAR:0.00620
[2023-07-21 11:27:01,163][main_bert_v2.py][line:77][INFO] [Epoch:1/100]: loss:0.4221 | AUC:0.8614 AUC2:0.8632 FAR:0.00622
[2023-07-21 11:28:28,119][main_bert_v2.py][line:77][INFO] [Epoch:2/100]: loss:0.3021 | AUC:0.8619 AUC2:0.8634 FAR:0.00605
[2023-07-21 11:30:02,078][main_bert_v2.py][line:77][INFO] [Epoch:3/100]: loss:0.2497 | AUC:0.8634 AUC2:0.8634 FAR:0.00613
[2023-07-21 11:31:32,117][main_bert_v2.py][line:77][INFO] [Epoch:4/100]: loss:0.2055 | AUC:0.8604 AUC2:0.8634 FAR:0.00622
[2023-07-21 11:33:07,122][main_bert_v2.py][line:77][INFO] [Epoch:5/100]: loss:0.1723 | AUC:0.8636 AUC2:0.8630 FAR:0.00637
[2023-07-21 11:34:31,500][main_bert_v2.py][line:77][INFO] [Epoch:6/100]: loss:0.1488 | AUC:0.8639 AUC2:0.8630 FAR:0.00605
[2023-07-21 11:36:02,252][main_bert_v2.py][line:77][INFO] [Epoch:7/100]: loss:0.1259 | AUC:0.8634 AUC2:0.8630 FAR:0.00615
[2023-07-21 11:37:35,404][main_bert_v2.py][line:77][INFO] [Epoch:8/100]: loss:0.1096 | AUC:0.8648 AUC2:0.8631 FAR:0.00625
[2023-07-21 11:39:07,112][main_bert_v2.py][line:77][INFO] [Epoch:9/100]: loss:0.0971 | AUC:0.8645 AUC2:0.8631 FAR:0.00608
[2023-07-21 11:40:37,911][main_bert_v2.py][line:77][INFO] [Epoch:10/100]: loss:0.0833 | AUC:0.8641 AUC2:0.8631 FAR:0.00605
[2023-07-21 11:42:04,388][main_bert_v2.py][line:77][INFO] [Epoch:11/100]: loss:0.0769 | AUC:0.8649 AUC2:0.8634 FAR:0.00627
[2023-07-21 11:43:29,072][main_bert_v2.py][line:77][INFO] [Epoch:12/100]: loss:0.0672 | AUC:0.8640 AUC2:0.8634 FAR:0.00647
[2023-07-21 11:44:54,760][main_bert_v2.py][line:77][INFO] [Epoch:13/100]: loss:0.0640 | AUC:0.8646 AUC2:0.8634 FAR:0.00627
[2023-07-21 11:46:33,040][main_bert_v2.py][line:77][INFO] [Epoch:14/100]: loss:0.0559 | AUC:0.8641 AUC2:0.8634 FAR:0.00613
[2023-07-21 11:47:54,192][main_bert_v2.py][line:77][INFO] [Epoch:15/100]: loss:0.0525 | AUC:0.8638 AUC2:0.8634 FAR:0.00650
[2023-07-21 11:49:28,451][main_bert_v2.py][line:77][INFO] [Epoch:16/100]: loss:0.0473 | AUC:0.8646 AUC2:0.8634 FAR:0.00632
[2023-07-21 11:51:05,548][main_bert_v2.py][line:77][INFO] [Epoch:17/100]: loss:0.0454 | AUC:0.8638 AUC2:0.8634 FAR:0.00617
[2023-07-21 11:52:37,344][main_bert_v2.py][line:77][INFO] [Epoch:18/100]: loss:0.0401 | AUC:0.8645 AUC2:0.8634 FAR:0.00620
[2023-07-21 11:54:03,999][main_bert_v2.py][line:77][INFO] [Epoch:19/100]: loss:0.0362 | AUC:0.8631 AUC2:0.8634 FAR:0.00605
[2023-07-21 11:55:34,457][main_bert_v2.py][line:77][INFO] [Epoch:20/100]: loss:0.0349 | AUC:0.8642 AUC2:0.8634 FAR:0.00605
[2023-07-21 11:57:00,297][main_bert_v2.py][line:77][INFO] [Epoch:21/100]: loss:0.0303 | AUC:0.8648 AUC2:0.8634 FAR:0.00613
[2023-07-21 11:58:45,875][main_bert_v2.py][line:77][INFO] [Epoch:22/100]: loss:0.0296 | AUC:0.8639 AUC2:0.8634 FAR:0.00603
[2023-07-21 12:00:19,824][main_bert_v2.py][line:77][INFO] [Epoch:23/100]: loss:0.0293 | AUC:0.8633 AUC2:0.8634 FAR:0.00645
[2023-07-21 12:01:57,359][main_bert_v2.py][line:77][INFO] [Epoch:24/100]: loss:0.0270 | AUC:0.8633 AUC2:0.8634 FAR:0.00613
[2023-07-21 12:03:10,606][main_bert_v2.py][line:77][INFO] [Epoch:25/100]: loss:0.0253 | AUC:0.8639 AUC2:0.8634 FAR:0.00605
[2023-07-21 12:04:23,636][main_bert_v2.py][line:77][INFO] [Epoch:26/100]: loss:0.0224 | AUC:0.8638 AUC2:0.8634 FAR:0.00595
[2023-07-21 12:05:45,357][main_bert_v2.py][line:77][INFO] [Epoch:27/100]: loss:0.0211 | AUC:0.8636 AUC2:0.8634 FAR:0.00627
[2023-07-21 12:10:18,807][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 12:10:19,178][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 12:10:19,178][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 12:10:19,178][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 12:10:19,192][main_bert_v2.py][line:56][INFO] Model:BertModel(
  (bert): BERT5(
    (embedding): BERTEmbedding2(
      (learnedPosition): LearnedPositionalEmbedding2()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0-3): 4 x TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0-2): 3 x Linear(in_features=1024, out_features=1024, bias=True)
          )
          (output_linear): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): Attention()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU()
        )
        (input_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output_sublayer): SublayerConnection(
          (norm): LayerNorm()
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc1_2): Linear(in_features=1024, out_features=512, bias=True)
  (fc2_2): Linear(in_features=512, out_features=128, bias=True)
  (fc3_2): Linear(in_features=128, out_features=1, bias=True)
  (drop_out): Dropout(p=0.1, inplace=False)
  (relu): ReLU()
  (sigmoid): Sigmoid()
)

[2023-07-21 12:10:19,192][main_bert_v2.py][line:57][INFO] Optimizer:Adagrad (
Parameter Group 0
    differentiable: False
    eps: 1e-10
    foreach: None
    initial_accumulator_value: 0
    initial_lr: 0.0001
    lr: 0.0001
    lr_decay: 0
    maximize: False
    weight_decay: 0.0010000000474974513
)

[2023-07-21 12:10:39,916][main_bert_v2.py][line:60][INFO] Random initialize AUC:0.8632 initial_AUC2:0.8635 FAR:0.00620
[2023-07-21 12:11:49,155][main_bert_v2.py][line:77][INFO] [Epoch:1/100]: loss:0.4221 | AUC:0.8618 AUC2:0.8632 FAR:0.00622
[2023-07-21 12:13:00,472][main_bert_v2.py][line:77][INFO] [Epoch:2/100]: loss:0.3021 | AUC:0.8622 AUC2:0.8634 FAR:0.00605
[2023-07-21 12:14:16,661][main_bert_v2.py][line:77][INFO] [Epoch:3/100]: loss:0.2497 | AUC:0.8637 AUC2:0.8634 FAR:0.00613
[2023-07-21 12:15:35,593][main_bert_v2.py][line:77][INFO] [Epoch:4/100]: loss:0.2055 | AUC:0.8609 AUC2:0.8634 FAR:0.00622
[2023-07-21 12:16:48,682][main_bert_v2.py][line:77][INFO] [Epoch:5/100]: loss:0.1723 | AUC:0.8637 AUC2:0.8634 FAR:0.00637
[2023-07-21 12:18:04,078][main_bert_v2.py][line:77][INFO] [Epoch:6/100]: loss:0.1488 | AUC:0.8641 AUC2:0.8630 FAR:0.00605
[2023-07-21 12:19:17,052][main_bert_v2.py][line:77][INFO] [Epoch:7/100]: loss:0.1259 | AUC:0.8633 AUC2:0.8630 FAR:0.00615
[2023-07-21 12:20:33,945][main_bert_v2.py][line:77][INFO] [Epoch:8/100]: loss:0.1096 | AUC:0.8648 AUC2:0.8631 FAR:0.00625
[2023-07-21 12:21:49,245][main_bert_v2.py][line:77][INFO] [Epoch:9/100]: loss:0.0971 | AUC:0.8644 AUC2:0.8631 FAR:0.00608
[2023-07-21 12:23:06,691][main_bert_v2.py][line:77][INFO] [Epoch:10/100]: loss:0.0833 | AUC:0.8638 AUC2:0.8631 FAR:0.00605
[2023-07-21 12:24:22,233][main_bert_v2.py][line:77][INFO] [Epoch:11/100]: loss:0.0769 | AUC:0.8647 AUC2:0.8631 FAR:0.00627
[2023-07-21 12:25:36,995][main_bert_v2.py][line:77][INFO] [Epoch:12/100]: loss:0.0672 | AUC:0.8641 AUC2:0.8631 FAR:0.00647
[2023-07-21 12:26:55,316][main_bert_v2.py][line:77][INFO] [Epoch:13/100]: loss:0.0640 | AUC:0.8646 AUC2:0.8631 FAR:0.00627
[2023-07-21 12:28:14,837][main_bert_v2.py][line:77][INFO] [Epoch:14/100]: loss:0.0559 | AUC:0.8641 AUC2:0.8631 FAR:0.00613
[2023-07-21 12:29:26,429][main_bert_v2.py][line:77][INFO] [Epoch:15/100]: loss:0.0525 | AUC:0.8631 AUC2:0.8631 FAR:0.00650
[2023-07-21 12:30:46,305][main_bert_v2.py][line:77][INFO] [Epoch:16/100]: loss:0.0473 | AUC:0.8645 AUC2:0.8631 FAR:0.00632
[2023-07-21 12:32:08,301][main_bert_v2.py][line:77][INFO] [Epoch:17/100]: loss:0.0454 | AUC:0.8641 AUC2:0.8631 FAR:0.00617
[2023-07-21 12:33:25,809][main_bert_v2.py][line:77][INFO] [Epoch:18/100]: loss:0.0401 | AUC:0.8654 AUC2:0.8633 FAR:0.00620
[2023-07-21 12:34:38,302][main_bert_v2.py][line:77][INFO] [Epoch:19/100]: loss:0.0362 | AUC:0.8630 AUC2:0.8633 FAR:0.00605
[2023-07-21 12:35:53,679][main_bert_v2.py][line:77][INFO] [Epoch:20/100]: loss:0.0349 | AUC:0.8645 AUC2:0.8633 FAR:0.00605
[2023-07-21 12:37:08,452][main_bert_v2.py][line:77][INFO] [Epoch:21/100]: loss:0.0303 | AUC:0.8649 AUC2:0.8633 FAR:0.00613
[2023-07-21 12:38:26,095][main_bert_v2.py][line:77][INFO] [Epoch:22/100]: loss:0.0296 | AUC:0.8645 AUC2:0.8633 FAR:0.00603
[2023-07-21 12:39:38,170][main_bert_v2.py][line:77][INFO] [Epoch:23/100]: loss:0.0293 | AUC:0.8639 AUC2:0.8633 FAR:0.00645
[2023-07-21 12:40:57,825][main_bert_v2.py][line:77][INFO] [Epoch:24/100]: loss:0.0270 | AUC:0.8637 AUC2:0.8633 FAR:0.00613
[2023-07-21 12:42:13,320][main_bert_v2.py][line:77][INFO] [Epoch:25/100]: loss:0.0253 | AUC:0.8639 AUC2:0.8633 FAR:0.00605
[2023-07-21 12:43:27,084][main_bert_v2.py][line:77][INFO] [Epoch:26/100]: loss:0.0224 | AUC:0.8639 AUC2:0.8633 FAR:0.00595
[2023-07-21 12:44:48,822][main_bert_v2.py][line:77][INFO] [Epoch:27/100]: loss:0.0211 | AUC:0.8639 AUC2:0.8633 FAR:0.00627
[2023-07-21 12:46:03,003][main_bert_v2.py][line:77][INFO] [Epoch:28/100]: loss:0.0213 | AUC:0.8642 AUC2:0.8633 FAR:0.00610
[2023-07-21 12:47:20,929][main_bert_v2.py][line:77][INFO] [Epoch:29/100]: loss:0.0207 | AUC:0.8647 AUC2:0.8633 FAR:0.00613
[2023-07-21 12:48:37,354][main_bert_v2.py][line:77][INFO] [Epoch:30/100]: loss:0.0191 | AUC:0.8640 AUC2:0.8633 FAR:0.00615
[2023-07-21 12:49:58,085][main_bert_v2.py][line:77][INFO] [Epoch:31/100]: loss:0.0166 | AUC:0.8652 AUC2:0.8633 FAR:0.00613
[2023-07-21 12:51:15,001][main_bert_v2.py][line:77][INFO] [Epoch:32/100]: loss:0.0167 | AUC:0.8642 AUC2:0.8633 FAR:0.00603
[2023-07-21 12:52:30,839][main_bert_v2.py][line:77][INFO] [Epoch:33/100]: loss:0.0153 | AUC:0.8640 AUC2:0.8633 FAR:0.00620
[2023-07-21 12:53:42,291][main_bert_v2.py][line:77][INFO] [Epoch:34/100]: loss:0.0134 | AUC:0.8641 AUC2:0.8633 FAR:0.00635
[2023-07-21 12:54:55,279][main_bert_v2.py][line:77][INFO] [Epoch:35/100]: loss:0.0140 | AUC:0.8623 AUC2:0.8633 FAR:0.00610
[2023-07-21 12:56:10,793][main_bert_v2.py][line:77][INFO] [Epoch:36/100]: loss:0.0123 | AUC:0.8634 AUC2:0.8633 FAR:0.00620
[2023-07-21 12:57:24,189][main_bert_v2.py][line:77][INFO] [Epoch:37/100]: loss:0.0126 | AUC:0.8634 AUC2:0.8633 FAR:0.00615
[2023-07-21 12:58:44,226][main_bert_v2.py][line:77][INFO] [Epoch:38/100]: loss:0.0119 | AUC:0.8620 AUC2:0.8633 FAR:0.00603
[2023-07-21 13:00:00,323][main_bert_v2.py][line:77][INFO] [Epoch:39/100]: loss:0.0095 | AUC:0.8627 AUC2:0.8633 FAR:0.00615
[2023-07-21 13:01:15,377][main_bert_v2.py][line:77][INFO] [Epoch:40/100]: loss:0.0091 | AUC:0.8615 AUC2:0.8633 FAR:0.00647
[2023-07-21 13:02:35,897][main_bert_v2.py][line:77][INFO] [Epoch:41/100]: loss:0.0090 | AUC:0.8613 AUC2:0.8633 FAR:0.00637
[2023-07-21 13:03:50,985][main_bert_v2.py][line:77][INFO] [Epoch:42/100]: loss:0.0078 | AUC:0.8621 AUC2:0.8633 FAR:0.00620
[2023-07-21 13:05:05,282][main_bert_v2.py][line:77][INFO] [Epoch:43/100]: loss:0.0077 | AUC:0.8630 AUC2:0.8633 FAR:0.00615
[2023-07-21 13:06:23,773][main_bert_v2.py][line:77][INFO] [Epoch:44/100]: loss:0.0077 | AUC:0.8633 AUC2:0.8633 FAR:0.00625
[2023-07-21 13:07:42,038][main_bert_v2.py][line:77][INFO] [Epoch:45/100]: loss:0.0076 | AUC:0.8621 AUC2:0.8633 FAR:0.00635
[2023-07-21 13:09:00,992][main_bert_v2.py][line:77][INFO] [Epoch:46/100]: loss:0.0080 | AUC:0.8609 AUC2:0.8633 FAR:0.00598
[2023-07-21 13:10:19,820][main_bert_v2.py][line:77][INFO] [Epoch:47/100]: loss:0.0072 | AUC:0.8608 AUC2:0.8633 FAR:0.00630
[2023-07-21 13:11:32,110][main_bert_v2.py][line:77][INFO] [Epoch:48/100]: loss:0.0065 | AUC:0.8623 AUC2:0.8633 FAR:0.00630
[2023-07-21 13:12:43,274][main_bert_v2.py][line:77][INFO] [Epoch:49/100]: loss:0.0063 | AUC:0.8616 AUC2:0.8633 FAR:0.00627
[2023-07-21 13:14:07,146][main_bert_v2.py][line:77][INFO] [Epoch:50/100]: loss:0.0064 | AUC:0.8621 AUC2:0.8633 FAR:0.00608
[2023-07-21 13:15:24,131][main_bert_v2.py][line:77][INFO] [Epoch:51/100]: loss:0.0061 | AUC:0.8619 AUC2:0.8633 FAR:0.00613
[2023-07-21 13:16:43,668][main_bert_v2.py][line:77][INFO] [Epoch:52/100]: loss:0.0062 | AUC:0.8619 AUC2:0.8633 FAR:0.00605
[2023-07-21 13:17:56,111][main_bert_v2.py][line:77][INFO] [Epoch:53/100]: loss:0.0058 | AUC:0.8619 AUC2:0.8633 FAR:0.00595
[2023-07-21 13:19:22,414][main_bert_v2.py][line:77][INFO] [Epoch:54/100]: loss:0.0059 | AUC:0.8624 AUC2:0.8633 FAR:0.00625
[2023-07-21 13:20:34,040][main_bert_v2.py][line:77][INFO] [Epoch:55/100]: loss:0.0055 | AUC:0.8627 AUC2:0.8633 FAR:0.00617
[2023-07-21 13:21:50,759][main_bert_v2.py][line:77][INFO] [Epoch:56/100]: loss:0.0054 | AUC:0.8623 AUC2:0.8633 FAR:0.00615
[2023-07-21 13:23:11,155][main_bert_v2.py][line:77][INFO] [Epoch:57/100]: loss:0.0057 | AUC:0.8622 AUC2:0.8633 FAR:0.00615
[2023-07-21 13:24:28,553][main_bert_v2.py][line:77][INFO] [Epoch:58/100]: loss:0.0054 | AUC:0.8623 AUC2:0.8633 FAR:0.00598
[2023-07-21 13:25:38,015][main_bert_v2.py][line:77][INFO] [Epoch:59/100]: loss:0.0057 | AUC:0.8623 AUC2:0.8633 FAR:0.00650
[2023-07-21 13:26:56,183][main_bert_v2.py][line:77][INFO] [Epoch:60/100]: loss:0.0059 | AUC:0.8624 AUC2:0.8633 FAR:0.00640
[2023-07-21 13:28:17,323][main_bert_v2.py][line:77][INFO] [Epoch:61/100]: loss:0.0059 | AUC:0.8628 AUC2:0.8633 FAR:0.00608
[2023-07-21 13:29:30,246][main_bert_v2.py][line:77][INFO] [Epoch:62/100]: loss:0.0056 | AUC:0.8628 AUC2:0.8633 FAR:0.00615
[2023-07-21 13:30:45,683][main_bert_v2.py][line:77][INFO] [Epoch:63/100]: loss:0.0055 | AUC:0.8628 AUC2:0.8633 FAR:0.00625
[2023-07-21 13:31:59,473][main_bert_v2.py][line:77][INFO] [Epoch:64/100]: loss:0.0059 | AUC:0.8625 AUC2:0.8633 FAR:0.00605
[2023-07-21 13:33:15,335][main_bert_v2.py][line:77][INFO] [Epoch:65/100]: loss:0.0057 | AUC:0.8626 AUC2:0.8633 FAR:0.00598
[2023-07-21 13:36:44,123][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:36:44,500][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:36:44,500][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:36:44,500][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:36:44,506][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:37:01,026][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:37:01,361][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:37:01,361][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:37:01,361][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:37:01,364][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:37:35,773][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:37:36,095][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:37:36,095][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:37:36,095][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:37:36,098][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:38:12,482][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:38:12,807][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:38:12,807][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:38:12,807][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:38:12,809][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:38:29,800][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:38:30,135][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:38:30,135][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:38:30,135][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:38:30,138][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:39:02,876][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:39:03,216][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:39:03,216][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:39:03,216][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:39:03,218][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:39:20,767][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-21 13:39:21,100][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-21 13:39:21,100][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-21 13:39:21,100][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-21 13:39:21,102][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-21 13:39:42,610][infer_bert_v2.py][line:70][INFO] offline AUC:0.8681 AUC2:0.8676 AP:0.3320 FAR:0.0050 | Complete in 0m 21s

[2023-07-22 11:44:14,991][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-22 11:44:15,325][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-22 11:44:15,325][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-22 11:44:15,325][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-22 11:44:15,327][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-22 11:44:41,184][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-22 11:44:41,521][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-22 11:44:41,521][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-22 11:44:41,521][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-22 11:44:41,524][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-22 11:45:02,663][infer_bert_v2.py][line:71][INFO] offline AUC:0.8667 AUC2:0.8676 AP:0.3294 FAR:0.0050 | Complete in 0m 21s

[2023-07-22 11:46:43,072][main_bert_v2.py][line:91][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-07-22 11:46:43,399][main_bert_v2.py][line:119][INFO] total params:51.1823M
[2023-07-22 11:46:43,400][main_bert_v2.py][line:121][INFO] Train BERT Mode
[2023-07-22 11:46:43,400][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-07-22 11:46:43,402][main_bert_v2.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/bert_current.pkl.
[2023-07-22 11:47:04,663][infer_bert_v2.py][line:70][INFO] offline AUC:0.8681 AUC2:0.8676 AP:0.3320 FAR:0.0050 | Complete in 0m 21s

[2023-08-21 18:10:41,056][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:10:41,157][main.py][line:120][INFO] total params:1.2091M
[2023-08-21 18:10:41,157][main.py][line:123][INFO] Training Mode
[2023-08-21 18:10:41,157][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 18:10:41,157][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 18:11:33,067][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:11:33,160][main.py][line:120][INFO] total params:1.2091M
[2023-08-21 18:11:33,160][main.py][line:123][INFO] Training Mode
[2023-08-21 18:11:33,161][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 18:11:33,161][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 18:42:46,239][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:43:34,870][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:45:12,918][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:46:06,383][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:46:24,920][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:47:05,726][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:48:16,614][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 18:48:16,689][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 18:48:16,689][main.py][line:129][INFO] Training Mode
[2023-08-21 20:49:21,258][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 20:49:21,330][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 20:49:21,330][main.py][line:129][INFO] Training Mode
[2023-08-21 20:49:21,330][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 20:49:21,330][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 20:55:09,587][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 20:55:09,663][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 20:55:09,664][main.py][line:129][INFO] Training Mode
[2023-08-21 20:55:09,664][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 20:55:09,664][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 20:58:58,676][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 20:58:58,751][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 20:58:58,751][main.py][line:129][INFO] Training Mode
[2023-08-21 20:58:58,751][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 20:58:58,751][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 20:59:34,705][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 20:59:34,776][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 20:59:34,776][main.py][line:129][INFO] Training Mode
[2023-08-21 20:59:34,777][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 20:59:34,777][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 21:00:49,663][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 21:00:49,736][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 21:00:49,736][main.py][line:129][INFO] Training Mode
[2023-08-21 21:00:49,736][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 21:00:49,736][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 21:01:05,612][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 21:01:05,705][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 21:01:05,705][main.py][line:129][INFO] Training Mode
[2023-08-21 21:01:05,705][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 21:01:05,705][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 21:01:10,471][main.py][line:58][INFO] Random initialize AUCAUC:0.4984 Anomaly AUC:0.51606
[2023-08-21 21:01:25,712][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 32, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 21:01:25,797][main.py][line:126][INFO] total params:0.8156M
[2023-08-21 21:01:25,797][main.py][line:129][INFO] Training Mode
[2023-08-21 21:01:25,797][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=32, bias=True)
      (k): Linear(in_features=1024, out_features=32, bias=True)
      (v): Linear(in_features=1024, out_features=32, bias=True)
      (o): Linear(in_features=32, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 21:01:25,797][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 21:01:31,054][main.py][line:58][INFO] Random initialize AUCAUC:0.4984 Anomaly AUC:0.51606
[2023-08-21 21:04:44,119][main.py][line:79][INFO] [Epoch:1/100]: loss1:0.4626 loss2:1.2024 | AUC:0.8174 Anomaly AUC:0.6256
[2023-08-21 21:07:50,306][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 21:07:50,411][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 21:07:50,411][main.py][line:129][INFO] Training Mode
[2023-08-21 21:07:50,411][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 21:07:50,411][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 21:07:57,117][main.py][line:58][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-21 21:09:08,992][main.py][line:79][INFO] [Epoch:1/100]: loss1:0.3366 loss2:1.0685 | AUC:0.8315 Anomaly AUC:0.6543
[2023-08-21 21:09:59,396][main.py][line:79][INFO] [Epoch:2/100]: loss1:0.1250 loss2:0.7849 | AUC:0.8364 Anomaly AUC:0.6499
[2023-08-21 21:10:51,534][main.py][line:79][INFO] [Epoch:3/100]: loss1:0.0539 loss2:0.6563 | AUC:0.8493 Anomaly AUC:0.6732
[2023-08-21 21:11:41,092][main.py][line:79][INFO] [Epoch:4/100]: loss1:0.0427 loss2:0.5588 | AUC:0.8462 Anomaly AUC:0.6737
[2023-08-21 21:12:37,708][main.py][line:79][INFO] [Epoch:5/100]: loss1:0.0229 loss2:0.4578 | AUC:0.8386 Anomaly AUC:0.6760
[2023-08-21 21:13:43,294][main.py][line:79][INFO] [Epoch:6/100]: loss1:0.0144 loss2:0.3663 | AUC:0.8453 Anomaly AUC:0.6733
[2023-08-21 21:14:47,188][main.py][line:79][INFO] [Epoch:7/100]: loss1:0.0263 loss2:0.2968 | AUC:0.8472 Anomaly AUC:0.6736
[2023-08-21 21:15:41,436][main.py][line:79][INFO] [Epoch:8/100]: loss1:0.0574 loss2:0.2714 | AUC:0.8369 Anomaly AUC:0.6742
[2023-08-21 21:16:29,087][main.py][line:79][INFO] [Epoch:9/100]: loss1:0.0127 loss2:0.1906 | AUC:0.8404 Anomaly AUC:0.6762
[2023-08-21 21:17:29,845][main.py][line:79][INFO] [Epoch:10/100]: loss1:0.0054 loss2:0.1243 | AUC:0.8458 Anomaly AUC:0.6842
[2023-08-21 21:18:24,022][main.py][line:79][INFO] [Epoch:11/100]: loss1:0.0042 loss2:0.0863 | AUC:0.8439 Anomaly AUC:0.6832
[2023-08-21 21:19:23,438][main.py][line:79][INFO] [Epoch:12/100]: loss1:0.0362 loss2:0.0881 | AUC:0.8327 Anomaly AUC:0.6650
[2023-08-21 21:20:09,829][main.py][line:79][INFO] [Epoch:13/100]: loss1:0.0355 loss2:0.1113 | AUC:0.8353 Anomaly AUC:0.6659
[2023-08-21 21:21:05,556][main.py][line:79][INFO] [Epoch:14/100]: loss1:0.0084 loss2:0.0572 | AUC:0.8442 Anomaly AUC:0.6780
[2023-08-21 21:21:54,361][main.py][line:79][INFO] [Epoch:15/100]: loss1:0.0034 loss2:0.0339 | AUC:0.8385 Anomaly AUC:0.6704
[2023-08-21 21:22:52,837][main.py][line:79][INFO] [Epoch:16/100]: loss1:0.0020 loss2:0.0224 | AUC:0.8348 Anomaly AUC:0.6702
[2023-08-21 21:23:52,318][main.py][line:79][INFO] [Epoch:17/100]: loss1:0.0018 loss2:0.0183 | AUC:0.8449 Anomaly AUC:0.6826
[2023-08-21 21:24:38,397][main.py][line:79][INFO] [Epoch:18/100]: loss1:0.0012 loss2:0.0130 | AUC:0.8427 Anomaly AUC:0.6795
[2023-08-21 21:25:37,275][main.py][line:79][INFO] [Epoch:19/100]: loss1:0.0012 loss2:0.0108 | AUC:0.8382 Anomaly AUC:0.6770
[2023-08-21 21:26:26,963][main.py][line:79][INFO] [Epoch:20/100]: loss1:0.0178 loss2:0.0370 | AUC:0.8336 Anomaly AUC:0.6821
[2023-08-21 21:27:20,921][main.py][line:79][INFO] [Epoch:21/100]: loss1:0.0320 loss2:0.0692 | AUC:0.8288 Anomaly AUC:0.6550
[2023-08-21 21:28:28,370][main.py][line:79][INFO] [Epoch:22/100]: loss1:0.0070 loss2:0.0212 | AUC:0.8351 Anomaly AUC:0.6676
[2023-08-21 21:29:33,088][main.py][line:79][INFO] [Epoch:23/100]: loss1:0.0032 loss2:0.0125 | AUC:0.8418 Anomaly AUC:0.6813
[2023-08-21 21:30:31,686][main.py][line:79][INFO] [Epoch:24/100]: loss1:0.0012 loss2:0.0077 | AUC:0.8442 Anomaly AUC:0.6816
[2023-08-21 21:31:49,098][main.py][line:79][INFO] [Epoch:25/100]: loss1:0.0014 loss2:0.0068 | AUC:0.8431 Anomaly AUC:0.6786
[2023-08-21 21:32:47,413][main.py][line:79][INFO] [Epoch:26/100]: loss1:0.0011 loss2:0.0062 | AUC:0.8448 Anomaly AUC:0.6805
[2023-08-21 21:33:52,751][main.py][line:79][INFO] [Epoch:27/100]: loss1:0.0006 loss2:0.0048 | AUC:0.8458 Anomaly AUC:0.6815
[2023-08-21 21:34:43,746][main.py][line:79][INFO] [Epoch:28/100]: loss1:0.0006 loss2:0.0040 | AUC:0.8468 Anomaly AUC:0.6815
[2023-08-21 21:35:31,864][main.py][line:79][INFO] [Epoch:29/100]: loss1:0.0005 loss2:0.0035 | AUC:0.8456 Anomaly AUC:0.6795
[2023-08-21 21:36:32,262][main.py][line:79][INFO] [Epoch:30/100]: loss1:0.0009 loss2:0.0039 | AUC:0.8454 Anomaly AUC:0.6796
[2023-08-21 21:37:37,272][main.py][line:79][INFO] [Epoch:31/100]: loss1:0.0011 loss2:0.0037 | AUC:0.8390 Anomaly AUC:0.6713
[2023-08-21 21:38:34,665][main.py][line:79][INFO] [Epoch:32/100]: loss1:0.0021 loss2:0.0053 | AUC:0.8396 Anomaly AUC:0.6740
[2023-08-21 21:39:27,859][main.py][line:79][INFO] [Epoch:33/100]: loss1:0.0204 loss2:0.0270 | AUC:0.8449 Anomaly AUC:0.6851
[2023-08-21 21:40:18,511][main.py][line:79][INFO] [Epoch:34/100]: loss1:0.0180 loss2:0.0233 | AUC:0.8383 Anomaly AUC:0.6715
[2023-08-21 21:41:07,438][main.py][line:79][INFO] [Epoch:35/100]: loss1:0.0020 loss2:0.0063 | AUC:0.8388 Anomaly AUC:0.6756
[2023-08-21 21:42:12,290][main.py][line:79][INFO] [Epoch:36/100]: loss1:0.0007 loss2:0.0034 | AUC:0.8397 Anomaly AUC:0.6750
[2023-08-21 21:43:12,682][main.py][line:79][INFO] [Epoch:37/100]: loss1:0.0006 loss2:0.0032 | AUC:0.8407 Anomaly AUC:0.6770
[2023-08-21 21:44:16,445][main.py][line:79][INFO] [Epoch:38/100]: loss1:0.0013 loss2:0.0046 | AUC:0.8371 Anomaly AUC:0.6764
[2023-08-21 21:45:09,606][main.py][line:79][INFO] [Epoch:39/100]: loss1:0.0008 loss2:0.0033 | AUC:0.8407 Anomaly AUC:0.6771
[2023-08-21 21:46:07,405][main.py][line:79][INFO] [Epoch:40/100]: loss1:0.0004 loss2:0.0024 | AUC:0.8407 Anomaly AUC:0.6770
[2023-08-21 21:47:00,869][main.py][line:79][INFO] [Epoch:41/100]: loss1:0.0004 loss2:0.0024 | AUC:0.8389 Anomaly AUC:0.6753
[2023-08-21 21:47:51,161][main.py][line:79][INFO] [Epoch:42/100]: loss1:0.0003 loss2:0.0021 | AUC:0.8395 Anomaly AUC:0.6755
[2023-08-21 21:48:37,310][main.py][line:79][INFO] [Epoch:43/100]: loss1:0.0003 loss2:0.0022 | AUC:0.8400 Anomaly AUC:0.6756
[2023-08-21 21:49:36,293][main.py][line:79][INFO] [Epoch:44/100]: loss1:0.0009 loss2:0.0026 | AUC:0.8364 Anomaly AUC:0.6727
[2023-08-21 21:50:36,070][main.py][line:79][INFO] [Epoch:45/100]: loss1:0.0013 loss2:0.0025 | AUC:0.8371 Anomaly AUC:0.6706
[2023-08-21 21:51:39,438][main.py][line:79][INFO] [Epoch:46/100]: loss1:0.0004 loss2:0.0021 | AUC:0.8388 Anomaly AUC:0.6720
[2023-08-21 21:52:35,727][main.py][line:79][INFO] [Epoch:47/100]: loss1:0.0003 loss2:0.0019 | AUC:0.8389 Anomaly AUC:0.6723
[2023-08-21 21:53:39,237][main.py][line:79][INFO] [Epoch:48/100]: loss1:0.0002 loss2:0.0019 | AUC:0.8390 Anomaly AUC:0.6724
[2023-08-21 21:54:30,594][main.py][line:79][INFO] [Epoch:49/100]: loss1:0.0002 loss2:0.0017 | AUC:0.8394 Anomaly AUC:0.6731
[2023-08-21 21:55:26,494][main.py][line:79][INFO] [Epoch:50/100]: loss1:0.0002 loss2:0.0020 | AUC:0.8374 Anomaly AUC:0.6699
[2023-08-21 21:56:13,604][main.py][line:79][INFO] [Epoch:51/100]: loss1:0.0002 loss2:0.0018 | AUC:0.8387 Anomaly AUC:0.6715
[2023-08-21 21:57:31,084][main.py][line:79][INFO] [Epoch:52/100]: loss1:0.0002 loss2:0.0014 | AUC:0.8389 Anomaly AUC:0.6722
[2023-08-21 21:58:20,736][main.py][line:79][INFO] [Epoch:53/100]: loss1:0.0002 loss2:0.0016 | AUC:0.8392 Anomaly AUC:0.6722
[2023-08-21 21:59:30,424][main.py][line:79][INFO] [Epoch:54/100]: loss1:0.0002 loss2:0.0014 | AUC:0.8391 Anomaly AUC:0.6719
[2023-08-21 22:00:19,558][main.py][line:79][INFO] [Epoch:55/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8392 Anomaly AUC:0.6721
[2023-08-21 22:01:15,660][main.py][line:79][INFO] [Epoch:56/100]: loss1:0.0002 loss2:0.0014 | AUC:0.8395 Anomaly AUC:0.6725
[2023-08-21 22:02:02,454][main.py][line:79][INFO] [Epoch:57/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8396 Anomaly AUC:0.6727
[2023-08-21 22:02:56,631][main.py][line:79][INFO] [Epoch:58/100]: loss1:0.0002 loss2:0.0015 | AUC:0.8395 Anomaly AUC:0.6724
[2023-08-21 22:03:57,567][main.py][line:79][INFO] [Epoch:59/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8396 Anomaly AUC:0.6725
[2023-08-21 22:04:49,610][main.py][line:79][INFO] [Epoch:60/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8396 Anomaly AUC:0.6725
[2023-08-21 22:05:32,754][main.py][line:79][INFO] [Epoch:61/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8396 Anomaly AUC:0.6725
[2023-08-21 22:06:19,706][main.py][line:79][INFO] [Epoch:62/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8396 Anomaly AUC:0.6726
[2023-08-21 22:07:04,406][main.py][line:79][INFO] [Epoch:63/100]: loss1:0.0002 loss2:0.0013 | AUC:0.8397 Anomaly AUC:0.6727
[2023-08-21 22:08:18,526][main.py][line:79][INFO] [Epoch:64/100]: loss1:0.0001 loss2:0.0014 | AUC:0.8398 Anomaly AUC:0.6730
[2023-08-21 22:09:14,245][main.py][line:79][INFO] [Epoch:65/100]: loss1:0.0002 loss2:0.0014 | AUC:0.8400 Anomaly AUC:0.6733
[2023-08-21 22:10:12,190][main.py][line:79][INFO] [Epoch:66/100]: loss1:0.0001 loss2:0.0014 | AUC:0.8400 Anomaly AUC:0.6734
[2023-08-21 22:10:54,825][main.py][line:79][INFO] [Epoch:67/100]: loss1:0.0001 loss2:0.0013 | AUC:0.8403 Anomaly AUC:0.6742
[2023-08-21 22:11:47,832][main.py][line:79][INFO] [Epoch:68/100]: loss1:0.0001 loss2:0.0013 | AUC:0.8405 Anomaly AUC:0.6751
[2023-08-21 22:12:29,084][main.py][line:79][INFO] [Epoch:69/100]: loss1:0.0001 loss2:0.0015 | AUC:0.8406 Anomaly AUC:0.6744
[2023-08-21 22:13:24,524][main.py][line:79][INFO] [Epoch:70/100]: loss1:0.0002 loss2:0.0016 | AUC:0.8400 Anomaly AUC:0.6738
[2023-08-21 22:14:08,934][main.py][line:79][INFO] [Epoch:71/100]: loss1:0.0001 loss2:0.0015 | AUC:0.8397 Anomaly AUC:0.6732
[2023-08-21 22:14:36,084][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 22:14:36,201][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 22:14:36,201][main.py][line:129][INFO] Training Mode
[2023-08-21 22:14:36,202][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 22:14:36,202][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 22:14:44,649][main.py][line:58][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-21 22:15:32,487][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 22:15:32,579][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 22:15:32,579][main.py][line:129][INFO] Training Mode
[2023-08-21 22:15:32,579][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 22:15:32,579][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 22:15:38,300][main.py][line:58][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-21 22:16:47,517][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 22:16:47,593][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 22:16:47,593][main.py][line:129][INFO] Training Mode
[2023-08-21 22:16:47,594][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 22:16:47,594][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 22:43:12,850][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 22:43:12,937][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 22:43:12,937][main.py][line:129][INFO] Training Mode
[2023-08-21 22:43:12,937][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 22:43:12,937][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 22:43:30,925][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 22:43:31,013][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 22:43:31,013][main.py][line:129][INFO] Training Mode
[2023-08-21 22:43:31,013][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 22:43:31,013][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 23:51:18,169][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 23:51:18,245][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 23:51:18,245][main.py][line:129][INFO] Training Mode
[2023-08-21 23:51:18,245][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 23:51:18,245][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 23:51:33,625][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 23:51:33,702][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 23:51:33,702][main.py][line:129][INFO] Training Mode
[2023-08-21 23:51:33,702][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 23:51:33,702][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 23:53:25,133][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 23:53:25,219][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 23:53:25,219][main.py][line:129][INFO] Training Mode
[2023-08-21 23:53:25,219][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 23:53:25,219][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-21 23:53:48,587][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-21 23:53:48,678][main.py][line:126][INFO] total params:1.2091M
[2023-08-21 23:53:48,678][main.py][line:129][INFO] Training Mode
[2023-08-21 23:53:48,678][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-21 23:53:48,678][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:15:03,101][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:15:03,175][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:15:03,175][main.py][line:129][INFO] Training Mode
[2023-08-22 14:15:03,175][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:15:03,175][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:15:17,234][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:15:17,309][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:15:17,309][main.py][line:129][INFO] Training Mode
[2023-08-22 14:15:17,310][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:15:17,310][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:15:29,645][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:15:29,741][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:15:29,741][main.py][line:129][INFO] Training Mode
[2023-08-22 14:15:29,741][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:15:29,741][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:15:55,510][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:15:55,600][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:15:55,601][main.py][line:129][INFO] Training Mode
[2023-08-22 14:15:55,601][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:15:55,601][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:16:01,068][main.py][line:58][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-22 14:17:29,826][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:17:29,914][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:17:29,914][main.py][line:129][INFO] Training Mode
[2023-08-22 14:17:29,914][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:17:29,914][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:17:35,655][main.py][line:58][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-22 14:21:28,515][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:21:28,591][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:21:28,591][main.py][line:129][INFO] Training Mode
[2023-08-22 14:21:28,591][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:21:28,591][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:21:34,038][main.py][line:58][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-22 14:33:44,271][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:33:44,362][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:33:44,363][main.py][line:129][INFO] Training Mode
[2023-08-22 14:33:44,363][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:33:44,363][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:44:40,677][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:44:40,751][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:44:40,751][main.py][line:129][INFO] Training Mode
[2023-08-22 14:44:40,751][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:44:40,751][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:45:26,739][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:45:26,822][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:45:26,823][main.py][line:129][INFO] Training Mode
[2023-08-22 14:45:26,823][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:45:26,823][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:46:26,120][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:46:26,214][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:46:26,214][main.py][line:129][INFO] Training Mode
[2023-08-22 14:46:26,214][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:46:26,214][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:46:41,612][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:46:41,697][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:46:41,698][main.py][line:129][INFO] Training Mode
[2023-08-22 14:46:41,698][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:46:41,698][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:47:19,590][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:47:19,663][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:47:19,663][main.py][line:129][INFO] Training Mode
[2023-08-22 14:47:19,663][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:47:19,663][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:58:55,623][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:58:55,723][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:58:55,723][main.py][line:129][INFO] Training Mode
[2023-08-22 14:58:55,723][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:58:55,724][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 14:59:53,137][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 14:59:53,224][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 14:59:53,224][main.py][line:129][INFO] Training Mode
[2023-08-22 14:59:53,224][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 14:59:53,224][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:24:59,800][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:24:59,890][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 15:24:59,890][main.py][line:129][INFO] Training Mode
[2023-08-22 15:24:59,890][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:24:59,890][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:25:18,793][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:25:18,877][main.py][line:126][INFO] total params:1.2091M
[2023-08-22 15:25:18,877][main.py][line:129][INFO] Training Mode
[2023-08-22 15:25:18,877][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:25:18,877][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:31:03,186][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:31:03,402][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 15:31:03,402][main.py][line:129][INFO] Training Mode
[2023-08-22 15:31:03,403][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:31:03,403][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:31:25,132][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:31:25,359][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 15:31:25,359][main.py][line:129][INFO] Training Mode
[2023-08-22 15:31:25,360][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:31:25,360][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:32:30,787][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:32:31,018][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 15:32:31,018][main.py][line:129][INFO] Training Mode
[2023-08-22 15:32:31,019][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:32:31,019][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:32:55,369][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:32:55,587][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 15:32:55,587][main.py][line:129][INFO] Training Mode
[2023-08-22 15:32:55,588][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:32:55,588][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:33:12,547][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:33:12,777][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 15:33:12,777][main.py][line:129][INFO] Training Mode
[2023-08-22 15:33:12,778][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:33:12,778][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:34:16,415][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.5291 loss2:1.1079 | AUC:0.7878 Anomaly AUC:0.5955
[2023-08-22 15:35:33,222][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.2797 loss2:0.9397 | AUC:0.8299 Anomaly AUC:0.6277
[2023-08-22 15:36:51,435][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.2284 loss2:0.8902 | AUC:0.8146 Anomaly AUC:0.6305
[2023-08-22 15:38:03,392][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.1698 loss2:0.8393 | AUC:0.8225 Anomaly AUC:0.6173
[2023-08-22 15:39:22,837][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.1352 loss2:0.8013 | AUC:0.8001 Anomaly AUC:0.5925
[2023-08-22 15:40:42,534][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.1091 loss2:0.7481 | AUC:0.8121 Anomaly AUC:0.6450
[2023-08-22 15:42:03,536][main.py][line:79][INFO] [Epoch:7/50]: loss1:0.0863 loss2:0.7036 | AUC:0.7751 Anomaly AUC:0.6031
[2023-08-22 15:43:26,839][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 15:43:27,096][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 15:43:27,096][main.py][line:129][INFO] Training Mode
[2023-08-22 15:43:27,097][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 15:43:27,097][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 15:43:42,326][main.py][line:58][INFO] Random initialize AUCAUC:0.5207 Anomaly AUC:0.49284
[2023-08-22 15:45:09,309][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.5284 loss2:1.1158 | AUC:0.7895 Anomaly AUC:0.6070
[2023-08-22 15:46:31,387][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.2972 loss2:0.9482 | AUC:0.8030 Anomaly AUC:0.6189
[2023-08-22 15:48:24,060][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.2318 loss2:0.8927 | AUC:0.8057 Anomaly AUC:0.6106
[2023-08-22 15:49:45,231][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.1893 loss2:0.8514 | AUC:0.8126 Anomaly AUC:0.6227
[2023-08-22 15:51:44,901][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.1677 loss2:0.8316 | AUC:0.8143 Anomaly AUC:0.6164
[2023-08-22 15:54:10,612][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.1285 loss2:0.7901 | AUC:0.8204 Anomaly AUC:0.6360
[2023-08-22 15:57:02,359][main.py][line:79][INFO] [Epoch:7/50]: loss1:0.1470 loss2:0.8084 | AUC:0.8240 Anomaly AUC:0.6357
[2023-08-22 15:59:52,520][main.py][line:79][INFO] [Epoch:8/50]: loss1:0.0994 loss2:0.7644 | AUC:0.8214 Anomaly AUC:0.6447
[2023-08-22 16:02:44,358][main.py][line:79][INFO] [Epoch:9/50]: loss1:0.2130 loss2:0.8535 | AUC:0.8159 Anomaly AUC:0.6351
[2023-08-22 16:05:48,470][main.py][line:79][INFO] [Epoch:10/50]: loss1:0.0958 loss2:0.7714 | AUC:0.8145 Anomaly AUC:0.6175
[2023-08-22 16:07:27,091][main.py][line:79][INFO] [Epoch:11/50]: loss1:0.0680 loss2:0.7473 | AUC:0.8207 Anomaly AUC:0.6292
[2023-08-22 16:09:21,036][main.py][line:79][INFO] [Epoch:12/50]: loss1:0.0686 loss2:0.7400 | AUC:0.8148 Anomaly AUC:0.6264
[2023-08-22 16:10:10,946][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 16:10:11,195][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 16:10:11,195][main.py][line:129][INFO] Training Mode
[2023-08-22 16:10:11,196][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 16:10:11,196][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 16:10:26,665][main.py][line:58][INFO] Random initialize AUCAUC:0.4799 Anomaly AUC:0.48599
[2023-08-22 16:11:41,367][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.4653 loss2:1.0844 | AUC:0.8193 Anomaly AUC:0.6050
[2023-08-22 16:12:46,103][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.2521 loss2:0.9401 | AUC:0.8317 Anomaly AUC:0.6113
[2023-08-22 16:13:45,193][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.2027 loss2:0.8953 | AUC:0.8134 Anomaly AUC:0.5985
[2023-08-22 16:14:47,537][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.1585 loss2:0.8505 | AUC:0.8192 Anomaly AUC:0.6002
[2023-08-22 16:15:48,389][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.1353 loss2:0.8321 | AUC:0.8213 Anomaly AUC:0.6078
[2023-08-22 16:17:33,354][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.1075 loss2:0.8016 | AUC:0.8234 Anomaly AUC:0.6184
[2023-08-22 16:18:54,738][main.py][line:79][INFO] [Epoch:7/50]: loss1:0.1007 loss2:0.7958 | AUC:0.7887 Anomaly AUC:0.5715
[2023-08-22 16:19:11,351][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 16:19:11,620][main.py][line:126][INFO] total params:29.6643M
[2023-08-22 16:19:11,620][main.py][line:129][INFO] Training Mode
[2023-08-22 16:19:11,621][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 16:19:11,621][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 16:19:28,156][main.py][line:58][INFO] Random initialize AUCAUC:0.4799 Anomaly AUC:0.48599
[2023-08-22 16:21:00,035][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.4653 loss2:1.0844 | AUC:0.8193 Anomaly AUC:0.6050
[2023-08-22 16:22:00,015][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.2525 loss2:0.9398 | AUC:0.8275 Anomaly AUC:0.6164
[2023-08-22 16:22:56,587][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.1939 loss2:0.8851 | AUC:0.7909 Anomaly AUC:0.5909
[2023-08-22 16:23:52,841][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.1698 loss2:0.8617 | AUC:0.8185 Anomaly AUC:0.5991
[2023-08-22 16:24:54,427][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.1382 loss2:0.8301 | AUC:0.8020 Anomaly AUC:0.5949
[2023-08-22 16:25:56,518][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.1133 loss2:0.8035 | AUC:0.7570 Anomaly AUC:0.5827
[2023-08-22 16:26:58,836][main.py][line:79][INFO] [Epoch:7/50]: loss1:0.0960 loss2:0.7933 | AUC:0.7882 Anomaly AUC:0.5825
[2023-08-22 16:28:01,080][main.py][line:79][INFO] [Epoch:8/50]: loss1:0.0842 loss2:0.7790 | AUC:0.7950 Anomaly AUC:0.5973
[2023-08-22 16:29:00,570][main.py][line:79][INFO] [Epoch:9/50]: loss1:0.0736 loss2:0.7715 | AUC:0.7032 Anomaly AUC:0.5236
[2023-08-22 16:30:16,135][main.py][line:79][INFO] [Epoch:10/50]: loss1:0.0679 loss2:0.7622 | AUC:0.7361 Anomaly AUC:0.5550
[2023-08-22 16:31:25,493][main.py][line:79][INFO] [Epoch:11/50]: loss1:0.0616 loss2:0.7598 | AUC:0.8188 Anomaly AUC:0.5961
[2023-08-22 16:32:37,494][main.py][line:79][INFO] [Epoch:12/50]: loss1:0.0563 loss2:0.7531 | AUC:0.7694 Anomaly AUC:0.5834
[2023-08-22 16:33:46,372][main.py][line:79][INFO] [Epoch:13/50]: loss1:0.0541 loss2:0.7462 | AUC:0.7896 Anomaly AUC:0.5704
[2023-08-22 16:35:01,388][main.py][line:79][INFO] [Epoch:14/50]: loss1:0.0498 loss2:0.7446 | AUC:0.7626 Anomaly AUC:0.5686
[2023-08-22 16:35:58,388][main.py][line:79][INFO] [Epoch:15/50]: loss1:0.0432 loss2:0.7372 | AUC:0.7018 Anomaly AUC:0.5250
[2023-08-22 16:36:57,424][main.py][line:79][INFO] [Epoch:16/50]: loss1:0.0289 loss2:0.7181 | AUC:0.7141 Anomaly AUC:0.5372
[2023-08-22 16:37:56,009][main.py][line:79][INFO] [Epoch:17/50]: loss1:0.0435 loss2:0.7147 | AUC:0.6209 Anomaly AUC:0.5287
[2023-08-22 16:39:00,810][main.py][line:79][INFO] [Epoch:18/50]: loss1:0.0288 loss2:0.6796 | AUC:0.7296 Anomaly AUC:0.5608
[2023-08-22 16:40:00,471][main.py][line:79][INFO] [Epoch:19/50]: loss1:0.0267 loss2:0.7138 | AUC:0.6997 Anomaly AUC:0.5538
[2023-08-22 16:41:02,929][main.py][line:79][INFO] [Epoch:20/50]: loss1:0.0337 loss2:0.3968 | AUC:0.6351 Anomaly AUC:0.5293
[2023-08-22 16:42:01,620][main.py][line:79][INFO] [Epoch:21/50]: loss1:0.0357 loss2:0.4270 | AUC:0.7870 Anomaly AUC:0.5884
[2023-08-22 16:42:55,778][main.py][line:79][INFO] [Epoch:22/50]: loss1:0.0315 loss2:0.7139 | AUC:0.7658 Anomaly AUC:0.5745
[2023-08-22 16:43:54,755][main.py][line:79][INFO] [Epoch:23/50]: loss1:0.0372 loss2:0.7153 | AUC:0.7096 Anomaly AUC:0.5381
[2023-08-22 16:44:58,445][main.py][line:79][INFO] [Epoch:24/50]: loss1:0.0172 loss2:0.6971 | AUC:0.6917 Anomaly AUC:0.5371
[2023-08-22 16:46:06,180][main.py][line:79][INFO] [Epoch:25/50]: loss1:0.0212 loss2:0.6937 | AUC:0.7009 Anomaly AUC:0.5524
[2023-08-22 16:47:11,957][main.py][line:79][INFO] [Epoch:26/50]: loss1:0.0221 loss2:0.6843 | AUC:0.6903 Anomaly AUC:0.5040
[2023-08-22 16:48:12,953][main.py][line:79][INFO] [Epoch:27/50]: loss1:0.0258 loss2:0.6939 | AUC:0.7496 Anomaly AUC:0.5617
[2023-08-22 16:49:16,792][main.py][line:79][INFO] [Epoch:28/50]: loss1:0.0165 loss2:0.3971 | AUC:0.7166 Anomaly AUC:0.5498
[2023-08-22 16:50:24,675][main.py][line:79][INFO] [Epoch:29/50]: loss1:0.0244 loss2:0.6573 | AUC:0.6108 Anomaly AUC:0.5172
[2023-08-22 16:51:26,759][main.py][line:79][INFO] [Epoch:30/50]: loss1:0.0140 loss2:0.0854 | AUC:0.7101 Anomaly AUC:0.5694
[2023-08-22 16:52:29,628][main.py][line:79][INFO] [Epoch:31/50]: loss1:0.0058 loss2:0.0000 | AUC:0.7177 Anomaly AUC:0.5592
[2023-08-22 16:53:36,748][main.py][line:79][INFO] [Epoch:32/50]: loss1:0.0053 loss2:0.0000 | AUC:0.7165 Anomaly AUC:0.5615
[2023-08-22 16:54:40,805][main.py][line:79][INFO] [Epoch:33/50]: loss1:0.0303 loss2:0.1773 | AUC:0.6839 Anomaly AUC:0.5333
[2023-08-22 16:55:50,390][main.py][line:79][INFO] [Epoch:34/50]: loss1:0.0150 loss2:0.0328 | AUC:0.7414 Anomaly AUC:0.5647
[2023-08-22 16:57:05,273][main.py][line:79][INFO] [Epoch:35/50]: loss1:0.0095 loss2:0.1357 | AUC:0.7135 Anomaly AUC:0.5320
[2023-08-22 16:58:18,149][main.py][line:79][INFO] [Epoch:36/50]: loss1:0.0214 loss2:0.5387 | AUC:0.7551 Anomaly AUC:0.5697
[2023-08-22 16:59:16,671][main.py][line:79][INFO] [Epoch:37/50]: loss1:0.0267 loss2:0.5094 | AUC:0.8103 Anomaly AUC:0.6045
[2023-08-22 17:00:23,683][main.py][line:79][INFO] [Epoch:38/50]: loss1:0.0240 loss2:0.6549 | AUC:0.7330 Anomaly AUC:0.5538
[2023-08-22 17:01:34,196][main.py][line:79][INFO] [Epoch:39/50]: loss1:0.0178 loss2:0.1634 | AUC:0.7818 Anomaly AUC:0.5913
[2023-08-22 17:02:39,222][main.py][line:79][INFO] [Epoch:40/50]: loss1:0.0082 loss2:0.0000 | AUC:0.7503 Anomaly AUC:0.5663
[2023-08-22 17:03:43,802][main.py][line:79][INFO] [Epoch:41/50]: loss1:0.0032 loss2:0.0000 | AUC:0.7637 Anomaly AUC:0.5617
[2023-08-22 17:04:38,684][main.py][line:79][INFO] [Epoch:42/50]: loss1:0.0100 loss2:0.0058 | AUC:0.7976 Anomaly AUC:0.5814
[2023-08-22 17:05:37,188][main.py][line:79][INFO] [Epoch:43/50]: loss1:0.0122 loss2:0.0000 | AUC:0.6854 Anomaly AUC:0.5290
[2023-08-22 17:06:39,172][main.py][line:79][INFO] [Epoch:44/50]: loss1:0.0078 loss2:0.0000 | AUC:0.8014 Anomaly AUC:0.5856
[2023-08-22 17:07:43,899][main.py][line:79][INFO] [Epoch:45/50]: loss1:0.0163 loss2:0.1228 | AUC:0.6047 Anomaly AUC:0.5057
[2023-08-22 17:08:45,101][main.py][line:79][INFO] [Epoch:46/50]: loss1:0.0261 loss2:0.3563 | AUC:0.7133 Anomaly AUC:0.5738
[2023-08-22 17:10:02,337][main.py][line:79][INFO] [Epoch:47/50]: loss1:0.0165 loss2:0.2264 | AUC:0.7102 Anomaly AUC:0.5779
[2023-08-22 17:11:08,294][main.py][line:79][INFO] [Epoch:48/50]: loss1:0.0171 loss2:0.4511 | AUC:0.7006 Anomaly AUC:0.5404
[2023-08-22 17:12:23,264][main.py][line:79][INFO] [Epoch:49/50]: loss1:0.0231 loss2:0.2798 | AUC:0.6701 Anomaly AUC:0.5261
[2023-08-22 17:13:29,103][main.py][line:79][INFO] [Epoch:50/50]: loss1:0.0107 loss2:0.1794 | AUC:0.6652 Anomaly AUC:0.5235
[2023-08-22 17:13:29,184][main.py][line:87][INFO] Training completes in 54m 1s | best AUCAUC:0.8275 Anomaly AUC:0.6164

[2023-08-22 21:28:01,399][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 21:28:01,658][main.py][line:126][INFO] total params:31.7625M
[2023-08-22 21:28:01,658][main.py][line:129][INFO] Training Mode
[2023-08-22 21:28:01,659][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 21:28:01,659][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 22:21:10,443][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 22:21:10,681][main.py][line:126][INFO] total params:31.7625M
[2023-08-22 22:21:10,681][main.py][line:129][INFO] Training Mode
[2023-08-22 22:21:10,682][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 22:21:10,682][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 22:21:27,690][main.py][line:58][INFO] Random initialize AUCAUC:0.5448 Anomaly AUC:0.46826
[2023-08-22 22:23:01,323][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.7651 loss2:1.3625 | AUC:0.6168 Anomaly AUC:0.5372
[2023-08-22 22:24:20,255][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.6975 loss2:1.3257 | AUC:0.5417 Anomaly AUC:0.4861
[2023-08-22 22:25:42,783][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.6950 loss2:1.3233 | AUC:0.4876 Anomaly AUC:0.4996
[2023-08-22 22:26:52,998][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.6981 loss2:1.3540 | AUC:0.5729 Anomaly AUC:0.5137
[2023-08-22 22:28:18,624][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.7021 loss2:1.3698 | AUC:0.3997 Anomaly AUC:0.4822
[2023-08-22 22:29:28,636][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.6938 loss2:1.3674 | AUC:0.6133 Anomaly AUC:0.5533
[2023-08-22 22:30:47,265][main.py][line:79][INFO] [Epoch:7/50]: loss1:0.6933 loss2:1.3644 | AUC:0.6042 Anomaly AUC:0.5290
[2023-08-22 22:31:13,263][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 22:31:13,541][main.py][line:126][INFO] total params:31.7625M
[2023-08-22 22:31:13,541][main.py][line:129][INFO] Training Mode
[2023-08-22 22:31:13,542][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 22:31:13,542][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 22:31:28,826][main.py][line:58][INFO] Random initialize AUCAUC:0.5448 Anomaly AUC:0.46826
[2023-08-22 22:32:50,271][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.7651 loss2:1.3625 | AUC:0.6168 Anomaly AUC:0.5372
[2023-08-22 22:34:10,953][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.6975 loss2:1.3257 | AUC:0.5417 Anomaly AUC:0.4861
[2023-08-22 22:35:36,778][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.6950 loss2:1.3233 | AUC:0.4876 Anomaly AUC:0.4996
[2023-08-22 22:36:50,104][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.6981 loss2:1.3540 | AUC:0.5729 Anomaly AUC:0.5137
[2023-08-22 22:38:25,261][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.7021 loss2:1.3698 | AUC:0.3997 Anomaly AUC:0.4822
[2023-08-22 22:39:39,069][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.6938 loss2:1.3674 | AUC:0.6133 Anomaly AUC:0.5533
[2023-08-22 22:54:31,529][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 22:54:31,797][main.py][line:126][INFO] total params:31.7625M
[2023-08-22 22:54:31,797][main.py][line:129][INFO] Training Mode
[2023-08-22 22:54:31,798][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 22:54:31,798][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 22:54:36,207][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 22:54:36,446][main.py][line:126][INFO] total params:31.7625M
[2023-08-22 22:54:36,447][main.py][line:129][INFO] Training Mode
[2023-08-22 22:54:36,447][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 22:54:36,447][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 22:54:49,111][main.py][line:58][INFO] Random initialize AUCAUC:0.5015 Anomaly AUC:0.46777
[2023-08-22 22:56:00,870][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.5957 loss2:1.1727 | AUC:0.7856 Anomaly AUC:0.5994
[2023-08-22 22:57:08,881][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.3159 loss2:1.0080 | AUC:0.8204 Anomaly AUC:0.6148
[2023-08-22 22:58:39,875][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.4640 loss2:1.0691 | AUC:0.2166 Anomaly AUC:0.3722
[2023-08-22 22:59:49,518][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.7066 loss2:1.3956 | AUC:0.2594 Anomaly AUC:0.4255
[2023-08-22 23:00:15,637][main.py][line:94][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:00:15,908][main.py][line:126][INFO] total params:31.7625M
[2023-08-22 23:00:15,908][main.py][line:129][INFO] Training Mode
[2023-08-22 23:00:15,909][main.py][line:54][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 23:00:15,909][main.py][line:55][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 23:00:30,637][main.py][line:58][INFO] Random initialize AUCAUC:0.4867 Anomaly AUC:0.45064
[2023-08-22 23:01:41,623][main.py][line:79][INFO] [Epoch:1/50]: loss1:0.7299 loss2:1.2352 | AUC:0.4333 Anomaly AUC:0.5232
[2023-08-22 23:03:15,178][main.py][line:79][INFO] [Epoch:2/50]: loss1:0.6949 loss2:1.1918 | AUC:0.5297 Anomaly AUC:0.5097
[2023-08-22 23:04:47,037][main.py][line:79][INFO] [Epoch:3/50]: loss1:0.7035 loss2:1.2269 | AUC:0.5202 Anomaly AUC:0.5244
[2023-08-22 23:05:56,294][main.py][line:79][INFO] [Epoch:4/50]: loss1:0.7038 loss2:1.2389 | AUC:0.5190 Anomaly AUC:0.5241
[2023-08-22 23:07:06,195][main.py][line:79][INFO] [Epoch:5/50]: loss1:0.6960 loss2:1.2351 | AUC:0.5101 Anomaly AUC:0.5208
[2023-08-22 23:08:22,068][main.py][line:79][INFO] [Epoch:6/50]: loss1:0.6962 loss2:1.2255 | AUC:0.5223 Anomaly AUC:0.5293
[2023-08-22 23:09:28,571][main.py][line:79][INFO] [Epoch:7/50]: loss1:0.7108 loss2:1.2588 | AUC:0.5087 Anomaly AUC:0.5186
[2023-08-22 23:10:24,853][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:10:25,123][main.py][line:132][INFO] total params:31.7625M
[2023-08-22 23:10:25,123][main.py][line:135][INFO] Training Mode
[2023-08-22 23:10:58,946][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:10:59,173][main.py][line:132][INFO] total params:31.7625M
[2023-08-22 23:10:59,174][main.py][line:135][INFO] Training Mode
[2023-08-22 23:11:23,979][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:11:24,206][main.py][line:132][INFO] total params:31.7625M
[2023-08-22 23:11:24,206][main.py][line:135][INFO] Training Mode
[2023-08-22 23:11:24,207][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 23:11:24,207][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 23:12:09,677][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:12:09,916][main.py][line:132][INFO] total params:31.7625M
[2023-08-22 23:12:09,916][main.py][line:135][INFO] Training Mode
[2023-08-22 23:12:09,916][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 23:12:09,916][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 23:12:19,154][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:12:19,395][main.py][line:132][INFO] total params:31.7625M
[2023-08-22 23:12:19,395][main.py][line:135][INFO] Training Mode
[2023-08-22 23:12:19,395][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 23:12:19,396][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 23:12:33,855][main.py][line:64][INFO] Random initialize AUCAUC:0.4850 Anomaly AUC:0.44875
[2023-08-22 23:14:04,149][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7289 loss2:1.2727 | AUC:0.7528 Anomaly AUC:0.6237
[2023-08-22 23:15:31,768][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.6964 loss2:1.2416 | AUC:0.6945 Anomaly AUC:0.5584
[2023-08-22 23:16:48,333][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.4665 loss2:1.0619 | AUC:0.8103 Anomaly AUC:0.6125
[2023-08-22 23:18:16,906][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.3042 loss2:0.9422 | AUC:0.7844 Anomaly AUC:0.5919
[2023-08-22 23:19:44,676][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.2382 loss2:0.8985 | AUC:0.8111 Anomaly AUC:0.6076
[2023-08-22 23:21:03,203][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.2085 loss2:0.8806 | AUC:0.7899 Anomaly AUC:0.5961
[2023-08-22 23:22:15,843][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.1593 loss2:0.8428 | AUC:0.7848 Anomaly AUC:0.5910
[2023-08-22 23:23:33,089][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.1393 loss2:0.8164 | AUC:0.7867 Anomaly AUC:0.5848
[2023-08-22 23:24:49,469][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.1168 loss2:0.7976 | AUC:0.7988 Anomaly AUC:0.5798
[2023-08-22 23:26:14,525][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0973 loss2:0.7758 | AUC:0.7974 Anomaly AUC:0.6075
[2023-08-22 23:28:16,467][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0947 loss2:0.7753 | AUC:0.7853 Anomaly AUC:0.6025
[2023-08-22 23:29:41,136][main.py][line:85][INFO] [Epoch:12/50]: loss1:0.0694 loss2:0.7551 | AUC:0.7752 Anomaly AUC:0.5947
[2023-08-22 23:31:05,768][main.py][line:85][INFO] [Epoch:13/50]: loss1:0.0684 loss2:0.7411 | AUC:0.7741 Anomaly AUC:0.5918
[2023-08-22 23:31:58,348][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-22 23:31:58,617][main.py][line:132][INFO] total params:31.8628M
[2023-08-22 23:31:58,617][main.py][line:135][INFO] Training Mode
[2023-08-22 23:31:58,618][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-22 23:31:58,618][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-22 23:32:11,825][main.py][line:64][INFO] Random initialize AUCAUC:0.5067 Anomaly AUC:0.48278
[2023-08-22 23:33:46,364][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.5412 loss2:1.1277 | AUC:0.7916 Anomaly AUC:0.6048
[2023-08-22 23:35:22,275][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.2703 loss2:0.9359 | AUC:0.8089 Anomaly AUC:0.6005
[2023-08-22 23:36:42,478][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2175 loss2:0.8859 | AUC:0.7935 Anomaly AUC:0.5938
[2023-08-22 23:38:02,245][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1836 loss2:0.8635 | AUC:0.8129 Anomaly AUC:0.5935
[2023-08-22 23:40:15,147][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1458 loss2:0.8063 | AUC:0.8077 Anomaly AUC:0.5787
[2023-08-22 23:41:59,311][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1202 loss2:0.7640 | AUC:0.8103 Anomaly AUC:0.5900
[2023-08-22 23:43:43,548][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.0936 loss2:0.7193 | AUC:0.8144 Anomaly AUC:0.5965
[2023-08-22 23:45:26,799][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0780 loss2:0.6740 | AUC:0.8097 Anomaly AUC:0.5915
[2023-08-22 23:47:03,893][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0750 loss2:0.6518 | AUC:0.8173 Anomaly AUC:0.5940
[2023-08-22 23:48:21,968][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0634 loss2:0.6219 | AUC:0.8263 Anomaly AUC:0.6016
[2023-08-22 23:50:02,215][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0519 loss2:0.5833 | AUC:0.8099 Anomaly AUC:0.5992
[2023-08-22 23:51:30,303][main.py][line:85][INFO] [Epoch:12/50]: loss1:0.0407 loss2:0.5432 | AUC:0.8100 Anomaly AUC:0.5945
[2023-08-22 23:52:37,037][main.py][line:85][INFO] [Epoch:13/50]: loss1:0.0487 loss2:0.5281 | AUC:0.8095 Anomaly AUC:0.6017
[2023-08-22 23:53:53,253][main.py][line:85][INFO] [Epoch:14/50]: loss1:0.0439 loss2:0.5056 | AUC:0.8174 Anomaly AUC:0.5920
[2023-08-22 23:54:54,500][main.py][line:85][INFO] [Epoch:15/50]: loss1:0.0352 loss2:0.4784 | AUC:0.8112 Anomaly AUC:0.5747
[2023-08-22 23:56:11,311][main.py][line:85][INFO] [Epoch:16/50]: loss1:0.0331 loss2:0.4534 | AUC:0.8087 Anomaly AUC:0.5891
[2023-08-22 23:57:36,012][main.py][line:85][INFO] [Epoch:17/50]: loss1:0.0315 loss2:0.4341 | AUC:0.8187 Anomaly AUC:0.5884
[2023-08-22 23:59:08,409][main.py][line:85][INFO] [Epoch:18/50]: loss1:0.0333 loss2:0.4212 | AUC:0.8134 Anomaly AUC:0.6090
[2023-08-23 00:00:38,588][main.py][line:85][INFO] [Epoch:19/50]: loss1:0.0277 loss2:0.4011 | AUC:0.8165 Anomaly AUC:0.5939
[2023-08-23 00:02:13,208][main.py][line:85][INFO] [Epoch:20/50]: loss1:0.0263 loss2:0.3888 | AUC:0.8157 Anomaly AUC:0.6002
[2023-08-23 00:03:30,646][main.py][line:85][INFO] [Epoch:21/50]: loss1:0.0292 loss2:0.3796 | AUC:0.8118 Anomaly AUC:0.5993
[2023-08-23 00:04:39,894][main.py][line:85][INFO] [Epoch:22/50]: loss1:0.0186 loss2:0.3502 | AUC:0.8050 Anomaly AUC:0.5947
[2023-08-23 00:05:59,675][main.py][line:85][INFO] [Epoch:23/50]: loss1:0.0256 loss2:0.3406 | AUC:0.8227 Anomaly AUC:0.6084
[2023-08-23 00:07:18,011][main.py][line:85][INFO] [Epoch:24/50]: loss1:0.0235 loss2:0.3356 | AUC:0.8147 Anomaly AUC:0.6049
[2023-08-23 00:08:30,618][main.py][line:85][INFO] [Epoch:25/50]: loss1:0.0201 loss2:0.3037 | AUC:0.8090 Anomaly AUC:0.5800
[2023-08-23 00:09:47,156][main.py][line:85][INFO] [Epoch:26/50]: loss1:0.0201 loss2:0.3108 | AUC:0.8005 Anomaly AUC:0.5900
[2023-08-23 00:11:15,618][main.py][line:85][INFO] [Epoch:27/50]: loss1:0.0186 loss2:0.2865 | AUC:0.8204 Anomaly AUC:0.5966
[2023-08-23 00:12:44,011][main.py][line:85][INFO] [Epoch:28/50]: loss1:0.0212 loss2:0.2759 | AUC:0.8215 Anomaly AUC:0.6058
[2023-08-23 00:14:05,006][main.py][line:85][INFO] [Epoch:29/50]: loss1:0.0198 loss2:0.2665 | AUC:0.8214 Anomaly AUC:0.6053
[2023-08-23 00:15:24,976][main.py][line:85][INFO] [Epoch:30/50]: loss1:0.0134 loss2:0.2578 | AUC:0.8169 Anomaly AUC:0.5932
[2023-08-23 00:17:02,227][main.py][line:85][INFO] [Epoch:31/50]: loss1:0.0134 loss2:0.2327 | AUC:0.8193 Anomaly AUC:0.5931
[2023-08-23 00:18:58,137][main.py][line:85][INFO] [Epoch:32/50]: loss1:0.0133 loss2:0.2256 | AUC:0.8156 Anomaly AUC:0.5966
[2023-08-23 00:20:23,981][main.py][line:85][INFO] [Epoch:33/50]: loss1:0.0168 loss2:0.2075 | AUC:0.8161 Anomaly AUC:0.5901
[2023-08-23 00:21:56,547][main.py][line:85][INFO] [Epoch:34/50]: loss1:0.0086 loss2:0.0711 | AUC:0.8160 Anomaly AUC:0.5937
[2023-08-23 00:23:23,267][main.py][line:85][INFO] [Epoch:35/50]: loss1:0.0204 loss2:0.2308 | AUC:0.8194 Anomaly AUC:0.5912
[2023-08-23 00:25:02,546][main.py][line:85][INFO] [Epoch:36/50]: loss1:0.0152 loss2:0.2013 | AUC:0.8104 Anomaly AUC:0.6015
[2023-08-23 00:26:28,160][main.py][line:85][INFO] [Epoch:37/50]: loss1:0.0249 loss2:0.2853 | AUC:0.8175 Anomaly AUC:0.6054
[2023-08-23 00:27:48,133][main.py][line:85][INFO] [Epoch:38/50]: loss1:0.0122 loss2:0.2486 | AUC:0.7953 Anomaly AUC:0.5811
[2023-08-23 00:29:13,234][main.py][line:85][INFO] [Epoch:39/50]: loss1:0.0146 loss2:0.2102 | AUC:0.8179 Anomaly AUC:0.5889
[2023-08-23 00:30:33,688][main.py][line:85][INFO] [Epoch:40/50]: loss1:0.0089 loss2:0.1883 | AUC:0.8056 Anomaly AUC:0.5965
[2023-08-23 00:32:03,358][main.py][line:85][INFO] [Epoch:41/50]: loss1:0.0115 loss2:0.1740 | AUC:0.8054 Anomaly AUC:0.5830
[2023-08-23 00:33:20,422][main.py][line:85][INFO] [Epoch:42/50]: loss1:0.0084 loss2:0.1403 | AUC:0.8195 Anomaly AUC:0.5893
[2023-08-23 00:34:40,794][main.py][line:85][INFO] [Epoch:43/50]: loss1:0.0067 loss2:0.0541 | AUC:0.8230 Anomaly AUC:0.5974
[2023-08-23 00:35:54,182][main.py][line:85][INFO] [Epoch:44/50]: loss1:0.0075 loss2:0.1510 | AUC:0.8173 Anomaly AUC:0.6110
[2023-08-23 00:37:27,428][main.py][line:85][INFO] [Epoch:45/50]: loss1:0.0074 loss2:0.1461 | AUC:0.8096 Anomaly AUC:0.5767
[2023-08-23 00:38:47,201][main.py][line:85][INFO] [Epoch:46/50]: loss1:0.0127 loss2:0.1416 | AUC:0.8161 Anomaly AUC:0.5889
[2023-08-23 00:40:01,160][main.py][line:85][INFO] [Epoch:47/50]: loss1:0.0073 loss2:0.1353 | AUC:0.8161 Anomaly AUC:0.5935
[2023-08-23 00:41:20,846][main.py][line:85][INFO] [Epoch:48/50]: loss1:0.0086 loss2:0.1361 | AUC:0.8192 Anomaly AUC:0.5996
[2023-08-23 00:42:51,281][main.py][line:85][INFO] [Epoch:49/50]: loss1:0.0055 loss2:0.1093 | AUC:0.8148 Anomaly AUC:0.5890
[2023-08-23 00:44:09,013][main.py][line:85][INFO] [Epoch:50/50]: loss1:0.0100 loss2:0.1236 | AUC:0.8094 Anomaly AUC:0.5883
[2023-08-23 00:44:09,099][main.py][line:93][INFO] Training completes in 71m 57s | best AUCAUC:0.8263 Anomaly AUC:0.6016

[2023-08-23 10:06:58,585][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:06:58,882][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:06:58,883][main.py][line:135][INFO] Training Mode
[2023-08-23 10:06:58,883][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:06:58,883][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:08:50,897][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:08:51,129][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:08:51,129][main.py][line:135][INFO] Training Mode
[2023-08-23 10:08:51,129][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:08:51,129][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:09:45,782][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:09:46,027][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:09:46,027][main.py][line:135][INFO] Training Mode
[2023-08-23 10:09:46,028][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:09:46,028][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:10:41,492][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:10:41,727][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:10:41,727][main.py][line:135][INFO] Training Mode
[2023-08-23 10:10:41,728][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:10:41,728][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:11:09,362][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:11:09,608][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:11:09,608][main.py][line:135][INFO] Training Mode
[2023-08-23 10:11:09,609][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:11:09,609][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:12:31,546][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:12:31,795][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:12:31,795][main.py][line:135][INFO] Training Mode
[2023-08-23 10:12:31,796][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:12:31,796][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:14:20,618][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:14:20,859][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:14:20,859][main.py][line:135][INFO] Training Mode
[2023-08-23 10:14:20,859][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:14:20,859][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:16:04,560][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:16:04,806][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:16:04,806][main.py][line:135][INFO] Training Mode
[2023-08-23 10:16:04,806][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:16:04,806][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:16:31,855][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:16:32,097][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:16:32,097][main.py][line:135][INFO] Training Mode
[2023-08-23 10:16:32,098][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:16:32,098][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:19:55,155][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:19:55,395][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:19:55,395][main.py][line:135][INFO] Training Mode
[2023-08-23 10:19:55,395][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:19:55,395][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:20:04,091][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:22:33,987][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:22:34,221][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:22:34,221][main.py][line:135][INFO] Training Mode
[2023-08-23 10:22:34,222][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:22:34,222][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:22:42,829][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:24:19,101][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:24:19,336][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:24:19,336][main.py][line:135][INFO] Training Mode
[2023-08-23 10:24:19,337][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:24:19,337][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:24:27,869][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:26:51,283][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:26:51,535][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:26:51,535][main.py][line:135][INFO] Training Mode
[2023-08-23 10:26:51,536][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-23 10:26:51,536][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:26:59,734][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:32:25,830][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:32:26,072][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:32:26,072][main.py][line:135][INFO] Training Mode
[2023-08-23 10:32:26,073][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 10:32:26,073][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:32:34,639][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:35:36,168][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:35:36,415][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:35:36,415][main.py][line:135][INFO] Training Mode
[2023-08-23 10:35:36,415][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 10:35:36,415][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:35:44,579][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:38:08,768][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:38:09,007][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:38:09,007][main.py][line:135][INFO] Training Mode
[2023-08-23 10:38:09,007][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 10:38:09,007][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:38:17,201][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:43:15,165][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:43:15,412][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:43:15,412][main.py][line:135][INFO] Training Mode
[2023-08-23 10:43:15,412][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 10:43:15,413][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:43:24,019][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 10:46:50,178][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 10:46:50,423][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 10:46:50,423][main.py][line:135][INFO] Training Mode
[2023-08-23 10:46:50,423][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 10:46:50,423][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 10:46:59,011][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:10:03,009][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:10:03,265][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:10:03,265][main.py][line:135][INFO] Training Mode
[2023-08-23 11:10:03,266][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:10:03,266][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:10:11,808][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:12:56,387][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:12:56,632][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:12:56,632][main.py][line:135][INFO] Training Mode
[2023-08-23 11:12:56,633][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:12:56,633][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:13:04,835][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:20:38,261][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:20:38,518][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:20:38,518][main.py][line:135][INFO] Training Mode
[2023-08-23 11:20:38,519][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:20:38,519][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:20:46,756][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:21:32,733][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:21:32,988][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:21:32,988][main.py][line:135][INFO] Training Mode
[2023-08-23 11:21:32,989][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:21:32,989][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:21:41,271][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:24:28,950][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:24:29,194][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:24:29,194][main.py][line:135][INFO] Training Mode
[2023-08-23 11:24:29,195][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:24:29,195][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:24:37,661][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:31:52,042][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:31:52,270][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:31:52,270][main.py][line:135][INFO] Training Mode
[2023-08-23 11:31:52,271][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:31:52,271][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:32:00,562][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:34:01,706][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:34:01,953][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:34:01,953][main.py][line:135][INFO] Training Mode
[2023-08-23 11:34:01,954][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:34:01,954][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:34:10,457][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:36:08,660][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:36:08,893][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:36:08,893][main.py][line:135][INFO] Training Mode
[2023-08-23 11:36:08,893][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:36:08,894][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:36:17,379][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:42:35,070][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:42:35,313][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:42:35,313][main.py][line:135][INFO] Training Mode
[2023-08-23 11:42:35,314][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:42:35,314][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:42:43,788][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:47:41,027][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:47:41,271][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:47:41,271][main.py][line:135][INFO] Training Mode
[2023-08-23 11:47:41,272][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:47:41,272][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:47:49,881][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:48:29,948][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:48:30,196][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:48:30,196][main.py][line:135][INFO] Training Mode
[2023-08-23 11:48:30,197][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:48:30,197][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:48:38,731][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:51:56,260][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:51:56,494][main.py][line:135][INFO] total params:31.8628M
[2023-08-23 11:51:56,494][main.py][line:138][INFO] Training Mode
[2023-08-23 11:51:56,494][main.py][line:63][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:51:56,494][main.py][line:64][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:52:06,355][main.py][line:67][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:55:17,139][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:55:17,386][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:55:17,386][main.py][line:135][INFO] Training Mode
[2023-08-23 11:55:17,387][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:55:17,387][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:55:26,168][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 11:58:47,480][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 11:58:47,725][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 11:58:47,725][main.py][line:135][INFO] Training Mode
[2023-08-23 11:58:47,725][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 11:58:47,725][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 11:58:56,265][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 12:00:04,864][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:00:05,099][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 12:00:05,099][main.py][line:135][INFO] Training Mode
[2023-08-23 12:00:05,099][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:00:05,099][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:00:13,590][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 12:04:31,253][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:04:31,492][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 12:04:31,492][main.py][line:135][INFO] Training Mode
[2023-08-23 12:04:31,493][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:04:31,493][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:04:40,534][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 12:05:01,328][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:05:01,565][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 12:05:01,565][main.py][line:135][INFO] Training Mode
[2023-08-23 12:05:01,566][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:05:01,566][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:05:09,693][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 12:05:50,111][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:05:50,355][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 12:05:50,355][main.py][line:135][INFO] Training Mode
[2023-08-23 12:05:50,355][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:05:50,355][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:05:59,114][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 12:06:50,819][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:06:51,065][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 12:06:51,065][main.py][line:135][INFO] Training Mode
[2023-08-23 12:06:51,065][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:06:51,065][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:06:59,815][main.py][line:64][INFO] Random initialize AUCAUC:0.5079 Anomaly AUC:0.48225
[2023-08-23 12:09:02,390][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:09:02,643][main.py][line:132][INFO] total params:31.8628M
[2023-08-23 12:09:02,643][main.py][line:135][INFO] Training Mode
[2023-08-23 12:09:02,644][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:09:02,644][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:09:11,086][main.py][line:64][INFO] Random initialize AUCAUC:0.5087 Anomaly AUC:0.51898
[2023-08-23 12:10:44,562][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:10:44,798][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:10:44,798][main.py][line:135][INFO] Training Mode
[2023-08-23 12:10:44,799][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:10:44,799][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:10:54,132][main.py][line:64][INFO] Random initialize AUCAUC:0.4951 Anomaly AUC:0.42579
[2023-08-23 12:10:59,539][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:10:59,771][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:10:59,771][main.py][line:135][INFO] Training Mode
[2023-08-23 12:10:59,772][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:10:59,772][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:11:08,888][main.py][line:64][INFO] Random initialize AUCAUC:0.4951 Anomaly AUC:0.42579
[2023-08-23 12:11:36,721][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:11:36,963][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:11:36,963][main.py][line:135][INFO] Training Mode
[2023-08-23 12:11:36,964][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:11:36,964][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:11:41,814][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:12:05,777][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:12:06,029][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:12:06,029][main.py][line:135][INFO] Training Mode
[2023-08-23 12:12:06,030][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:12:06,030][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:12:11,423][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:12:37,125][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:12:37,370][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:12:37,370][main.py][line:135][INFO] Training Mode
[2023-08-23 12:12:37,371][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:12:37,371][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:12:42,273][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:23:56,160][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:23:56,408][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:23:56,408][main.py][line:135][INFO] Training Mode
[2023-08-23 12:23:56,408][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:23:56,408][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:24:01,098][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:27:00,188][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:27:00,430][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:27:00,430][main.py][line:135][INFO] Training Mode
[2023-08-23 12:27:00,431][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:27:00,431][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:27:06,007][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:28:49,289][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:28:49,536][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:28:49,536][main.py][line:135][INFO] Training Mode
[2023-08-23 12:28:49,537][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:28:49,537][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:28:54,246][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:29:22,118][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:29:22,359][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:29:22,359][main.py][line:135][INFO] Training Mode
[2023-08-23 12:29:22,360][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:29:22,360][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:29:27,116][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:30:20,465][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.3283 loss2:0.9883 | AUC:0.8307 Anomaly AUC:0.6599
[2023-08-23 12:31:15,326][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.1163 loss2:0.7613 | AUC:0.8246 Anomaly AUC:0.6487
[2023-08-23 12:32:26,361][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.0523 loss2:0.6460 | AUC:0.8289 Anomaly AUC:0.6505
[2023-08-23 12:33:11,522][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:33:11,786][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:33:11,787][main.py][line:135][INFO] Training Mode
[2023-08-23 12:33:11,787][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:33:11,788][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:33:18,862][main.py][line:64][INFO] Random initialize AUCAUC:0.5380 Anomaly AUC:0.46431
[2023-08-23 12:33:42,574][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 12:33:42,827][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 12:33:42,827][main.py][line:135][INFO] Training Mode
[2023-08-23 12:33:42,827][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 12:33:42,827][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 12:33:54,789][main.py][line:64][INFO] Random initialize AUCAUC:0.4951 Anomaly AUC:0.42579
[2023-08-23 12:35:11,550][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.4526 loss2:1.0572 | AUC:0.8180 Anomaly AUC:0.6408
[2023-08-23 12:36:24,419][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.2722 loss2:0.9257 | AUC:0.8366 Anomaly AUC:0.6615
[2023-08-23 12:37:55,188][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2043 loss2:0.8762 | AUC:0.8234 Anomaly AUC:0.6336
[2023-08-23 12:39:09,427][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1645 loss2:0.8418 | AUC:0.8253 Anomaly AUC:0.6332
[2023-08-23 12:40:57,322][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1287 loss2:0.8114 | AUC:0.8349 Anomaly AUC:0.6591
[2023-08-23 12:42:35,077][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1156 loss2:0.7760 | AUC:0.8441 Anomaly AUC:0.6770
[2023-08-23 12:44:26,024][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.0994 loss2:0.7288 | AUC:0.8364 Anomaly AUC:0.6547
[2023-08-23 12:45:59,181][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0926 loss2:0.6939 | AUC:0.8418 Anomaly AUC:0.6545
[2023-08-23 12:47:22,424][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0805 loss2:0.6599 | AUC:0.8440 Anomaly AUC:0.6691
[2023-08-23 12:48:40,623][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0656 loss2:0.6315 | AUC:0.8363 Anomaly AUC:0.6521
[2023-08-23 12:50:27,315][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0680 loss2:0.6213 | AUC:0.8292 Anomaly AUC:0.6376
[2023-08-23 12:51:39,829][main.py][line:85][INFO] [Epoch:12/50]: loss1:0.0545 loss2:0.5922 | AUC:0.8441 Anomaly AUC:0.6534
[2023-08-23 12:53:16,843][main.py][line:85][INFO] [Epoch:13/50]: loss1:0.0456 loss2:0.5663 | AUC:0.8385 Anomaly AUC:0.6509
[2023-08-23 12:55:01,404][main.py][line:85][INFO] [Epoch:14/50]: loss1:0.0468 loss2:0.5530 | AUC:0.8316 Anomaly AUC:0.6464
[2023-08-23 12:56:07,298][main.py][line:85][INFO] [Epoch:15/50]: loss1:0.0422 loss2:0.5420 | AUC:0.8251 Anomaly AUC:0.6524
[2023-08-23 12:57:46,729][main.py][line:85][INFO] [Epoch:16/50]: loss1:0.0381 loss2:0.5264 | AUC:0.8348 Anomaly AUC:0.6513
[2023-08-23 12:59:36,446][main.py][line:85][INFO] [Epoch:17/50]: loss1:0.0364 loss2:0.5150 | AUC:0.8113 Anomaly AUC:0.6403
[2023-08-23 13:01:04,218][main.py][line:85][INFO] [Epoch:18/50]: loss1:0.0349 loss2:0.4926 | AUC:0.8391 Anomaly AUC:0.6511
[2023-08-23 13:03:32,343][main.py][line:85][INFO] [Epoch:19/50]: loss1:0.0253 loss2:0.2780 | AUC:0.8063 Anomaly AUC:0.6414
[2023-08-23 13:04:57,617][main.py][line:85][INFO] [Epoch:20/50]: loss1:0.0422 loss2:0.4752 | AUC:0.7996 Anomaly AUC:0.6305
[2023-08-23 13:06:25,599][main.py][line:85][INFO] [Epoch:21/50]: loss1:0.0304 loss2:0.4516 | AUC:0.8195 Anomaly AUC:0.6405
[2023-08-23 13:07:55,798][main.py][line:85][INFO] [Epoch:22/50]: loss1:0.0257 loss2:0.4317 | AUC:0.8308 Anomaly AUC:0.6484
[2023-08-23 13:09:32,449][main.py][line:85][INFO] [Epoch:23/50]: loss1:0.0250 loss2:0.4057 | AUC:0.8264 Anomaly AUC:0.6323
[2023-08-23 13:10:06,477][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 13:10:06,751][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 13:10:06,751][main.py][line:135][INFO] Training Mode
[2023-08-23 13:10:06,752][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 13:10:06,752][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 13:10:15,831][main.py][line:64][INFO] Random initialize AUCAUC:0.4951 Anomaly AUC:0.42579
[2023-08-23 13:11:46,964][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.4526 loss2:1.0572 | AUC:0.8180 Anomaly AUC:0.6408
[2023-08-23 13:13:05,615][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.2778 loss2:0.9282 | AUC:0.8294 Anomaly AUC:0.6475
[2023-08-23 13:14:22,539][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2129 loss2:0.8841 | AUC:0.8240 Anomaly AUC:0.6346
[2023-08-23 13:15:31,022][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1666 loss2:0.8454 | AUC:0.8332 Anomaly AUC:0.6453
[2023-08-23 13:16:40,233][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1250 loss2:0.8134 | AUC:0.8363 Anomaly AUC:0.6453
[2023-08-23 13:17:44,651][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1053 loss2:0.7923 | AUC:0.8232 Anomaly AUC:0.6744
[2023-08-23 13:18:53,995][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.1172 loss2:0.7657 | AUC:0.8442 Anomaly AUC:0.6587
[2023-08-23 13:20:05,850][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0858 loss2:0.7160 | AUC:0.8338 Anomaly AUC:0.6486
[2023-08-23 13:21:29,042][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0766 loss2:0.6784 | AUC:0.8239 Anomaly AUC:0.6378
[2023-08-23 13:23:05,838][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0644 loss2:0.6510 | AUC:0.8432 Anomaly AUC:0.6679
[2023-08-23 13:24:13,376][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0476 loss2:0.6195 | AUC:0.8442 Anomaly AUC:0.6706
[2023-08-23 13:25:26,818][main.py][line:85][INFO] [Epoch:12/50]: loss1:0.0492 loss2:0.6079 | AUC:0.8376 Anomaly AUC:0.6736
[2023-08-23 13:26:51,107][main.py][line:85][INFO] [Epoch:13/50]: loss1:0.0382 loss2:0.5744 | AUC:0.8380 Anomaly AUC:0.6636
[2023-08-23 13:28:10,854][main.py][line:85][INFO] [Epoch:14/50]: loss1:0.0346 loss2:0.5567 | AUC:0.8439 Anomaly AUC:0.6841
[2023-08-23 13:29:11,713][main.py][line:85][INFO] [Epoch:15/50]: loss1:0.0294 loss2:0.5388 | AUC:0.8498 Anomaly AUC:0.6777
[2023-08-23 13:30:31,014][main.py][line:85][INFO] [Epoch:16/50]: loss1:0.0283 loss2:0.5247 | AUC:0.8266 Anomaly AUC:0.6517
[2023-08-23 13:32:05,880][main.py][line:85][INFO] [Epoch:17/50]: loss1:0.0210 loss2:0.4944 | AUC:0.8152 Anomaly AUC:0.6501
[2023-08-23 13:33:13,962][main.py][line:85][INFO] [Epoch:18/50]: loss1:0.0313 loss2:0.4869 | AUC:0.8319 Anomaly AUC:0.6466
[2023-08-23 13:34:20,211][main.py][line:85][INFO] [Epoch:19/50]: loss1:0.0229 loss2:0.4618 | AUC:0.8498 Anomaly AUC:0.6691
[2023-08-23 13:35:35,425][main.py][line:85][INFO] [Epoch:20/50]: loss1:0.0221 loss2:0.4330 | AUC:0.8399 Anomaly AUC:0.6739
[2023-08-23 13:36:46,010][main.py][line:85][INFO] [Epoch:21/50]: loss1:0.0222 loss2:0.4139 | AUC:0.8318 Anomaly AUC:0.6580
[2023-08-23 13:37:55,925][main.py][line:85][INFO] [Epoch:22/50]: loss1:0.0184 loss2:0.3837 | AUC:0.8477 Anomaly AUC:0.6728
[2023-08-23 13:39:09,798][main.py][line:85][INFO] [Epoch:23/50]: loss1:0.0124 loss2:0.3497 | AUC:0.8264 Anomaly AUC:0.6485
[2023-08-23 13:40:29,734][main.py][line:85][INFO] [Epoch:24/50]: loss1:0.0110 loss2:0.3362 | AUC:0.8343 Anomaly AUC:0.6653
[2023-08-23 13:42:10,623][main.py][line:85][INFO] [Epoch:25/50]: loss1:0.0096 loss2:0.3059 | AUC:0.8345 Anomaly AUC:0.6562
[2023-08-23 13:43:06,282][main.py][line:85][INFO] [Epoch:26/50]: loss1:0.0104 loss2:0.2847 | AUC:0.8344 Anomaly AUC:0.6700
[2023-08-23 13:44:33,177][main.py][line:85][INFO] [Epoch:27/50]: loss1:0.0115 loss2:0.2725 | AUC:0.8512 Anomaly AUC:0.6789
[2023-08-23 13:46:16,422][main.py][line:85][INFO] [Epoch:28/50]: loss1:0.0123 loss2:0.2452 | AUC:0.8466 Anomaly AUC:0.6736
[2023-08-23 13:47:17,125][main.py][line:85][INFO] [Epoch:29/50]: loss1:0.0117 loss2:0.2375 | AUC:0.8418 Anomaly AUC:0.6663
[2023-08-23 13:48:36,918][main.py][line:85][INFO] [Epoch:30/50]: loss1:0.0099 loss2:0.2187 | AUC:0.8402 Anomaly AUC:0.6589
[2023-08-23 13:49:56,139][main.py][line:85][INFO] [Epoch:31/50]: loss1:0.0085 loss2:0.1983 | AUC:0.8397 Anomaly AUC:0.6612
[2023-08-23 13:51:07,655][main.py][line:85][INFO] [Epoch:32/50]: loss1:0.0065 loss2:0.1808 | AUC:0.8462 Anomaly AUC:0.6696
[2023-08-23 13:52:14,641][main.py][line:85][INFO] [Epoch:33/50]: loss1:0.0043 loss2:0.1559 | AUC:0.8479 Anomaly AUC:0.6716
[2023-08-23 13:53:27,379][main.py][line:85][INFO] [Epoch:34/50]: loss1:0.0031 loss2:0.1447 | AUC:0.8418 Anomaly AUC:0.6602
[2023-08-23 13:54:24,310][main.py][line:85][INFO] [Epoch:35/50]: loss1:0.0059 loss2:0.1420 | AUC:0.8435 Anomaly AUC:0.6685
[2023-08-23 13:55:30,669][main.py][line:85][INFO] [Epoch:36/50]: loss1:0.0058 loss2:0.1289 | AUC:0.8468 Anomaly AUC:0.6704
[2023-08-23 13:56:31,910][main.py][line:85][INFO] [Epoch:37/50]: loss1:0.0055 loss2:0.1129 | AUC:0.8418 Anomaly AUC:0.6676
[2023-08-23 13:57:41,121][main.py][line:85][INFO] [Epoch:38/50]: loss1:0.0032 loss2:0.1036 | AUC:0.8449 Anomaly AUC:0.6675
[2023-08-23 13:59:12,671][main.py][line:85][INFO] [Epoch:39/50]: loss1:0.0024 loss2:0.0925 | AUC:0.8491 Anomaly AUC:0.6774
[2023-08-23 14:00:13,325][main.py][line:85][INFO] [Epoch:40/50]: loss1:0.0034 loss2:0.0860 | AUC:0.8457 Anomaly AUC:0.6706
[2023-08-23 14:01:55,067][main.py][line:85][INFO] [Epoch:41/50]: loss1:0.0023 loss2:0.0746 | AUC:0.8460 Anomaly AUC:0.6723
[2023-08-23 14:02:56,796][main.py][line:85][INFO] [Epoch:42/50]: loss1:0.0016 loss2:0.0639 | AUC:0.8456 Anomaly AUC:0.6729
[2023-08-23 14:04:00,223][main.py][line:85][INFO] [Epoch:43/50]: loss1:0.0013 loss2:0.0508 | AUC:0.8391 Anomaly AUC:0.6632
[2023-08-23 14:05:12,322][main.py][line:85][INFO] [Epoch:44/50]: loss1:0.0015 loss2:0.0490 | AUC:0.8442 Anomaly AUC:0.6674
[2023-08-23 14:06:15,939][main.py][line:85][INFO] [Epoch:45/50]: loss1:0.0017 loss2:0.0446 | AUC:0.8456 Anomaly AUC:0.6713
[2023-08-23 14:07:31,933][main.py][line:85][INFO] [Epoch:46/50]: loss1:0.0014 loss2:0.0397 | AUC:0.8447 Anomaly AUC:0.6700
[2023-08-23 14:09:02,415][main.py][line:85][INFO] [Epoch:47/50]: loss1:0.0013 loss2:0.0356 | AUC:0.8440 Anomaly AUC:0.6672
[2023-08-23 14:10:06,756][main.py][line:85][INFO] [Epoch:48/50]: loss1:0.0015 loss2:0.0316 | AUC:0.8445 Anomaly AUC:0.6697
[2023-08-23 14:11:11,127][main.py][line:85][INFO] [Epoch:49/50]: loss1:0.0011 loss2:0.0291 | AUC:0.8474 Anomaly AUC:0.6714
[2023-08-23 14:12:19,293][main.py][line:85][INFO] [Epoch:50/50]: loss1:0.0008 loss2:0.0256 | AUC:0.8443 Anomaly AUC:0.6707
[2023-08-23 14:12:19,384][main.py][line:93][INFO] Training completes in 62m 3s | best AUCAUC:0.8512 Anomaly AUC:0.6789

[2023-08-23 14:13:29,131][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:13:29,390][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:13:44,779][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8636.pkl', 'ckpt_bert_path': './ckpt/bert_current.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:13:45,011][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:13:45,011][main.py][line:139][INFO] Test Mode
[2023-08-23 14:13:45,012][main.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8636.pkl.
[2023-08-23 14:14:01,094][infer.py][line:47][INFO] offline AUC:0.4178 AP:0.0605 FAR:0.7759 | Complete in 0m 16s

[2023-08-23 14:14:48,685][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:14:48,909][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:14:48,909][main.py][line:139][INFO] Test Mode
[2023-08-23 14:14:48,909][main.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__8512.pkl.
[2023-08-23 14:14:48,946][main.py][line:40][INFO] self_attention.concat.weight not found in model dict.
[2023-08-23 14:14:48,946][main.py][line:40][INFO] self_attention.concat.bias not found in model dict.
[2023-08-23 14:15:03,775][infer.py][line:47][INFO] offline AUC:0.8500 AP:0.2825 FAR:0.0082 | Complete in 0m 15s

[2023-08-23 14:16:38,631][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'fixed', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:16:38,854][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:16:38,854][main.py][line:135][INFO] Training Mode
[2023-08-23 14:16:38,854][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 14:16:38,855][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 14:16:52,109][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 14:18:13,198][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7414 loss2:1.2705 | AUC:0.7595 Anomaly AUC:0.5646
[2023-08-23 14:19:18,785][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.3728 loss2:1.0045 | AUC:0.8189 Anomaly AUC:0.6231
[2023-08-23 14:20:32,242][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2502 loss2:0.9108 | AUC:0.7978 Anomaly AUC:0.5998
[2023-08-23 14:21:43,481][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1882 loss2:0.8702 | AUC:0.8226 Anomaly AUC:0.6137
[2023-08-23 14:23:00,682][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1474 loss2:0.8428 | AUC:0.7908 Anomaly AUC:0.5421
[2023-08-23 14:23:14,385][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:23:14,643][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:23:14,643][main.py][line:135][INFO] Training Mode
[2023-08-23 14:23:14,644][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 14:23:14,644][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 14:23:28,424][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 14:24:36,718][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7414 loss2:1.2705 | AUC:0.7595 Anomaly AUC:0.5646
[2023-08-23 14:25:42,490][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.3728 loss2:1.0045 | AUC:0.8189 Anomaly AUC:0.6231
[2023-08-23 14:26:43,646][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2502 loss2:0.9108 | AUC:0.7978 Anomaly AUC:0.5998
[2023-08-23 14:27:46,418][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1882 loss2:0.8702 | AUC:0.8226 Anomaly AUC:0.6137
[2023-08-23 14:28:59,735][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1474 loss2:0.8428 | AUC:0.7908 Anomaly AUC:0.5421
[2023-08-23 14:30:25,092][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1164 loss2:0.8120 | AUC:0.8317 Anomaly AUC:0.6236
[2023-08-23 14:32:01,516][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.0924 loss2:0.7898 | AUC:0.8393 Anomaly AUC:0.6325
[2023-08-23 14:33:27,178][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0729 loss2:0.7697 | AUC:0.7842 Anomaly AUC:0.5910
[2023-08-23 14:35:08,850][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0728 loss2:0.7678 | AUC:0.8355 Anomaly AUC:0.6372
[2023-08-23 14:37:09,837][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0629 loss2:0.7566 | AUC:0.8112 Anomaly AUC:0.6096
[2023-08-23 14:38:29,233][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0609 loss2:0.7588 | AUC:0.8278 Anomaly AUC:0.6081
[2023-08-23 14:39:23,489][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:39:23,740][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:39:23,740][main.py][line:135][INFO] Training Mode
[2023-08-23 14:39:23,741][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 14:39:23,741][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 14:39:36,640][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 14:41:05,002][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7414 loss2:1.2705 | AUC:0.7595 Anomaly AUC:0.5646
[2023-08-23 14:41:09,287][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:41:09,523][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:41:09,523][main.py][line:135][INFO] Training Mode
[2023-08-23 14:41:09,524][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 14:41:09,524][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 14:41:23,437][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 14:42:43,246][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7414 loss2:1.2705 | AUC:0.7595 Anomaly AUC:0.5646
[2023-08-23 14:44:06,145][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.3728 loss2:1.0045 | AUC:0.8189 Anomaly AUC:0.6231
[2023-08-23 14:45:21,723][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2502 loss2:0.9108 | AUC:0.7978 Anomaly AUC:0.5998
[2023-08-23 14:46:32,399][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1882 loss2:0.8702 | AUC:0.8226 Anomaly AUC:0.6137
[2023-08-23 14:48:14,898][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1474 loss2:0.8428 | AUC:0.7908 Anomaly AUC:0.5421
[2023-08-23 14:49:35,639][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1164 loss2:0.8120 | AUC:0.8317 Anomaly AUC:0.6236
[2023-08-23 14:52:01,255][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.0924 loss2:0.7898 | AUC:0.8393 Anomaly AUC:0.6325
[2023-08-23 14:53:26,457][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0729 loss2:0.7697 | AUC:0.7842 Anomaly AUC:0.5910
[2023-08-23 14:55:47,959][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0728 loss2:0.7678 | AUC:0.8355 Anomaly AUC:0.6372
[2023-08-23 14:58:05,882][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 14:58:06,141][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 14:58:06,141][main.py][line:135][INFO] Training Mode
[2023-08-23 14:58:06,142][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 14:58:06,142][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 14:58:19,764][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 14:59:37,099][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7414 loss2:1.2705 | AUC:0.7595 Anomaly AUC:0.5646
[2023-08-23 15:00:54,988][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.3728 loss2:1.0045 | AUC:0.8189 Anomaly AUC:0.6231
[2023-08-23 15:02:09,035][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2502 loss2:0.9108 | AUC:0.7978 Anomaly AUC:0.5998
[2023-08-23 15:03:33,805][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1882 loss2:0.8702 | AUC:0.8226 Anomaly AUC:0.6137
[2023-08-23 15:05:10,986][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1474 loss2:0.8428 | AUC:0.7908 Anomaly AUC:0.5421
[2023-08-23 15:06:36,724][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1164 loss2:0.8120 | AUC:0.8317 Anomaly AUC:0.6236
[2023-08-23 15:08:07,176][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.0924 loss2:0.7898 | AUC:0.8393 Anomaly AUC:0.6325
[2023-08-23 15:09:32,420][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0729 loss2:0.7697 | AUC:0.7842 Anomaly AUC:0.5910
[2023-08-23 15:10:55,325][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0728 loss2:0.7678 | AUC:0.8355 Anomaly AUC:0.6372
[2023-08-23 15:12:34,651][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0629 loss2:0.7566 | AUC:0.8112 Anomaly AUC:0.6096
[2023-08-23 15:13:50,979][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0609 loss2:0.7588 | AUC:0.8278 Anomaly AUC:0.6081
[2023-08-23 15:15:15,086][main.py][line:85][INFO] [Epoch:12/50]: loss1:0.0496 loss2:0.7422 | AUC:0.8112 Anomaly AUC:0.6022
[2023-08-23 15:16:40,944][main.py][line:85][INFO] [Epoch:13/50]: loss1:0.0677 loss2:0.7713 | AUC:0.8355 Anomaly AUC:0.6253
[2023-08-23 15:18:22,819][main.py][line:85][INFO] [Epoch:14/50]: loss1:0.0390 loss2:0.7396 | AUC:0.8016 Anomaly AUC:0.5937
[2023-08-23 15:19:46,870][main.py][line:85][INFO] [Epoch:15/50]: loss1:0.0420 loss2:0.7513 | AUC:0.8110 Anomaly AUC:0.5968
[2023-08-23 15:21:30,291][main.py][line:85][INFO] [Epoch:16/50]: loss1:0.0263 loss2:0.7251 | AUC:0.8300 Anomaly AUC:0.6094
[2023-08-23 15:22:53,225][main.py][line:85][INFO] [Epoch:17/50]: loss1:0.0236 loss2:0.7098 | AUC:0.8053 Anomaly AUC:0.5769
[2023-08-23 15:24:14,938][main.py][line:85][INFO] [Epoch:18/50]: loss1:0.0297 loss2:0.7117 | AUC:0.8250 Anomaly AUC:0.5884
[2023-08-23 15:25:32,612][main.py][line:85][INFO] [Epoch:19/50]: loss1:0.0257 loss2:0.7024 | AUC:0.8412 Anomaly AUC:0.6078
[2023-08-23 15:27:00,561][main.py][line:85][INFO] [Epoch:20/50]: loss1:0.0255 loss2:0.6906 | AUC:0.8223 Anomaly AUC:0.6047
[2023-08-23 15:28:22,015][main.py][line:85][INFO] [Epoch:21/50]: loss1:0.0230 loss2:0.6824 | AUC:0.8290 Anomaly AUC:0.5963
[2023-08-23 15:29:54,073][main.py][line:85][INFO] [Epoch:22/50]: loss1:0.0203 loss2:0.6693 | AUC:0.8228 Anomaly AUC:0.6165
[2023-08-23 15:31:24,484][main.py][line:85][INFO] [Epoch:23/50]: loss1:0.0218 loss2:0.6599 | AUC:0.8451 Anomaly AUC:0.6176
[2023-08-23 15:31:40,196][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 15:31:40,464][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 15:31:40,464][main.py][line:135][INFO] Training Mode
[2023-08-23 15:31:40,465][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 15:31:40,465][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 15:31:56,249][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 15:33:26,170][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.7414 loss2:1.2705 | AUC:0.7595 Anomaly AUC:0.5646
[2023-08-23 15:34:42,227][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.3728 loss2:1.0045 | AUC:0.8189 Anomaly AUC:0.6231
[2023-08-23 15:35:57,787][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2502 loss2:0.9108 | AUC:0.7978 Anomaly AUC:0.5998
[2023-08-23 15:37:05,094][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1882 loss2:0.8702 | AUC:0.8226 Anomaly AUC:0.6137
[2023-08-23 15:38:14,966][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1474 loss2:0.8428 | AUC:0.7908 Anomaly AUC:0.5421
[2023-08-23 15:39:27,598][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1164 loss2:0.8120 | AUC:0.8317 Anomaly AUC:0.6236
[2023-08-23 15:40:48,348][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.0924 loss2:0.7898 | AUC:0.8393 Anomaly AUC:0.6325
[2023-08-23 15:42:08,676][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0729 loss2:0.7697 | AUC:0.7842 Anomaly AUC:0.5910
[2023-08-23 15:42:43,601][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 15:42:43,863][main.py][line:132][INFO] total params:31.7625M
[2023-08-23 15:42:43,863][main.py][line:135][INFO] Training Mode
[2023-08-23 15:42:43,864][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (concat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 15:42:43,864][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 15:43:01,588][main.py][line:64][INFO] Random initialize AUCAUC:0.4951 Anomaly AUC:0.42579
[2023-08-23 15:44:34,271][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.4526 loss2:1.0572 | AUC:0.8180 Anomaly AUC:0.6408
[2023-08-23 15:45:57,498][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.2778 loss2:0.9282 | AUC:0.8294 Anomaly AUC:0.6475
[2023-08-23 15:47:46,034][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.2129 loss2:0.8841 | AUC:0.8240 Anomaly AUC:0.6346
[2023-08-23 15:49:14,265][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.1666 loss2:0.8454 | AUC:0.8332 Anomaly AUC:0.6453
[2023-08-23 15:50:34,587][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.1250 loss2:0.8134 | AUC:0.8363 Anomaly AUC:0.6453
[2023-08-23 15:53:04,001][main.py][line:85][INFO] [Epoch:6/50]: loss1:0.1053 loss2:0.7923 | AUC:0.8232 Anomaly AUC:0.6744
[2023-08-23 15:55:05,793][main.py][line:85][INFO] [Epoch:7/50]: loss1:0.1172 loss2:0.7657 | AUC:0.8442 Anomaly AUC:0.6587
[2023-08-23 15:57:01,202][main.py][line:85][INFO] [Epoch:8/50]: loss1:0.0858 loss2:0.7160 | AUC:0.8338 Anomaly AUC:0.6486
[2023-08-23 15:58:32,526][main.py][line:85][INFO] [Epoch:9/50]: loss1:0.0766 loss2:0.6784 | AUC:0.8239 Anomaly AUC:0.6378
[2023-08-23 16:00:14,991][main.py][line:85][INFO] [Epoch:10/50]: loss1:0.0644 loss2:0.6510 | AUC:0.8432 Anomaly AUC:0.6679
[2023-08-23 16:02:18,566][main.py][line:85][INFO] [Epoch:11/50]: loss1:0.0476 loss2:0.6195 | AUC:0.8442 Anomaly AUC:0.6706
[2023-08-23 16:03:44,663][main.py][line:85][INFO] [Epoch:12/50]: loss1:0.0492 loss2:0.6079 | AUC:0.8376 Anomaly AUC:0.6736
[2023-08-23 16:05:42,344][main.py][line:85][INFO] [Epoch:13/50]: loss1:0.0382 loss2:0.5744 | AUC:0.8380 Anomaly AUC:0.6636
[2023-08-23 16:07:33,921][main.py][line:85][INFO] [Epoch:14/50]: loss1:0.0346 loss2:0.5567 | AUC:0.8439 Anomaly AUC:0.6841
[2023-08-23 16:09:18,911][main.py][line:85][INFO] [Epoch:15/50]: loss1:0.0294 loss2:0.5388 | AUC:0.8498 Anomaly AUC:0.6777
[2023-08-23 16:11:47,877][main.py][line:85][INFO] [Epoch:16/50]: loss1:0.0283 loss2:0.5247 | AUC:0.8266 Anomaly AUC:0.6517
[2023-08-23 16:12:43,840][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 16:12:44,090][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 16:12:44,090][main.py][line:135][INFO] Training Mode
[2023-08-23 16:12:44,091][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 16:12:44,091][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 16:13:07,034][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 16:13:07,259][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 16:13:07,259][main.py][line:135][INFO] Training Mode
[2023-08-23 16:13:07,260][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 16:13:07,260][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 16:13:27,647][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 16:16:32,469][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 16:16:32,691][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 16:16:32,691][main.py][line:135][INFO] Training Mode
[2023-08-23 16:16:32,692][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 16:16:32,692][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 16:16:54,605][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:21:26,334][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:21:26,570][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:21:26,570][main.py][line:135][INFO] Training Mode
[2023-08-23 20:21:26,570][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:21:26,570][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:21:35,969][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:35:35,427][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:35:35,653][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:35:35,653][main.py][line:135][INFO] Training Mode
[2023-08-23 20:35:35,654][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:35:35,654][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:35:45,315][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:36:03,472][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:36:03,704][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:36:03,704][main.py][line:135][INFO] Training Mode
[2023-08-23 20:36:03,705][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:36:03,705][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:36:13,402][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:36:17,597][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:36:17,824][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:36:17,824][main.py][line:135][INFO] Training Mode
[2023-08-23 20:36:17,825][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:36:17,825][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:36:27,392][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:37:03,315][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:37:03,550][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:37:03,550][main.py][line:135][INFO] Training Mode
[2023-08-23 20:37:03,551][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:37:03,551][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:37:13,205][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:39:48,352][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:39:48,576][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:39:48,576][main.py][line:135][INFO] Training Mode
[2023-08-23 20:39:48,577][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:39:48,577][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:39:58,343][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:41:10,872][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:41:11,111][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:41:11,111][main.py][line:135][INFO] Training Mode
[2023-08-23 20:41:11,112][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:41:11,112][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:41:20,522][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 20:41:37,892][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 20:41:38,119][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 20:41:38,119][main.py][line:135][INFO] Training Mode
[2023-08-23 20:41:38,120][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 20:41:38,120][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 20:41:47,001][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 23:40:01,040][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:40:01,281][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 23:40:01,281][main.py][line:135][INFO] Training Mode
[2023-08-23 23:40:01,282][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:40:01,282][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:40:19,747][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 23:41:09,206][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:41:09,440][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 23:41:09,440][main.py][line:135][INFO] Training Mode
[2023-08-23 23:41:09,441][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:41:09,441][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:41:30,221][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 23:43:49,954][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:43:50,184][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 23:43:50,184][main.py][line:135][INFO] Training Mode
[2023-08-23 23:43:50,185][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:43:50,185][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:43:59,213][main.py][line:64][INFO] Random initialize AUCAUC:0.4063 Anomaly AUC:0.45062
[2023-08-23 23:49:45,256][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:49:45,489][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 23:49:45,489][main.py][line:135][INFO] Training Mode
[2023-08-23 23:49:45,489][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:49:45,490][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:50:03,596][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:50:03,828][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 23:50:03,828][main.py][line:135][INFO] Training Mode
[2023-08-23 23:50:03,829][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:50:03,829][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:50:22,848][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:50:23,078][main.py][line:132][INFO] total params:29.6643M
[2023-08-23 23:50:23,078][main.py][line:135][INFO] Training Mode
[2023-08-23 23:50:23,079][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:50:23,079][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:51:26,165][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.8372 loss2:1.3623 | AUC:0.4006 Anomaly AUC:0.4915
[2023-08-23 23:52:32,759][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.7829 loss2:1.3646 | AUC:0.4396 Anomaly AUC:0.4910
[2023-08-23 23:53:43,501][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.7754 loss2:1.3621 | AUC:0.3802 Anomaly AUC:0.4527
[2023-08-23 23:54:20,640][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:54:20,917][main.py][line:132][INFO] total params:33.1046M
[2023-08-23 23:54:20,917][main.py][line:135][INFO] Training Mode
[2023-08-23 23:54:20,918][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:54:20,918][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:54:34,705][main.py][line:64][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-23 23:55:52,129][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.8231 loss2:1.3628 | AUC:0.5189 Anomaly AUC:0.4953
[2023-08-23 23:57:07,085][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.7788 loss2:1.3645 | AUC:0.5000 Anomaly AUC:0.4649
[2023-08-23 23:57:46,123][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:57:46,393][main.py][line:132][INFO] total params:33.1046M
[2023-08-23 23:57:46,393][main.py][line:135][INFO] Training Mode
[2023-08-23 23:57:46,393][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:57:46,394][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:58:01,219][main.py][line:64][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-23 23:58:43,672][main.py][line:100][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'bert': True, 'beta': 0.5, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-23 23:58:43,908][main.py][line:132][INFO] total params:33.1046M
[2023-08-23 23:58:43,908][main.py][line:135][INFO] Training Mode
[2023-08-23 23:58:43,909][main.py][line:60][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-23 23:58:43,909][main.py][line:61][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-23 23:58:58,197][main.py][line:64][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:00:29,790][main.py][line:85][INFO] [Epoch:1/50]: loss1:0.8767 loss2:1.3670 loss3:130.0225 | AUC:0.3420 Anomaly AUC:0.3604
[2023-08-24 00:01:37,525][main.py][line:85][INFO] [Epoch:2/50]: loss1:0.7915 loss2:1.3684 loss3:4.3023 | AUC:0.3806 Anomaly AUC:0.3818
[2023-08-24 00:02:42,235][main.py][line:85][INFO] [Epoch:3/50]: loss1:0.7774 loss2:1.3695 loss3:0.6928 | AUC:0.4105 Anomaly AUC:0.3926
[2023-08-24 00:04:01,188][main.py][line:85][INFO] [Epoch:4/50]: loss1:0.7738 loss2:1.3649 loss3:0.6444 | AUC:0.4215 Anomaly AUC:0.4052
[2023-08-24 00:05:18,812][main.py][line:85][INFO] [Epoch:5/50]: loss1:0.7733 loss2:1.3666 loss3:0.5813 | AUC:0.4251 Anomaly AUC:0.4158
[2023-08-24 00:05:29,713][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:05:30,002][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:05:30,002][main.py][line:136][INFO] Training Mode
[2023-08-24 00:05:30,003][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:05:30,003][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:05:43,385][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:07:05,599][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.8244 loss2:1.3628 loss3:70.7159 | AUC:0.4055 Anomaly AUC:0.4500
[2023-08-24 00:08:19,205][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.7735 loss2:1.3645 loss3:31.9993 | AUC:0.3996 Anomaly AUC:0.4697
[2023-08-24 00:09:22,196][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.7709 loss2:1.3646 loss3:14.3353 | AUC:0.3843 Anomaly AUC:0.4894
[2023-08-24 00:10:29,834][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.7658 loss2:1.3600 loss3:11.1641 | AUC:0.3712 Anomaly AUC:0.4666
[2023-08-24 00:11:36,841][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.7600 loss2:1.3633 loss3:17.6810 | AUC:0.3600 Anomaly AUC:0.4473
[2023-08-24 00:12:20,670][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:12:20,938][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:12:20,938][main.py][line:136][INFO] Training Mode
[2023-08-24 00:12:20,939][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:12:20,939][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:12:35,186][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:12:53,397][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:12:53,636][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:12:53,636][main.py][line:136][INFO] Training Mode
[2023-08-24 00:12:53,637][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:12:53,637][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:13:10,305][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:14:25,738][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:14:25,989][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:14:25,989][main.py][line:136][INFO] Training Mode
[2023-08-24 00:14:25,990][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:14:25,990][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:14:39,755][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:14:40,004][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:14:40,004][main.py][line:136][INFO] Training Mode
[2023-08-24 00:14:40,005][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:14:40,005][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:14:54,739][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:16:37,638][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.4924 loss2:1.0877 loss3:0.0000 | AUC:0.8103 Anomaly AUC:0.6490
[2023-08-24 00:17:52,926][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.2977 loss2:0.9143 loss3:0.0000 | AUC:0.8237 Anomaly AUC:0.6434
[2023-08-24 00:19:04,439][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2416 loss2:0.8692 loss3:0.0000 | AUC:0.8361 Anomaly AUC:0.6642
[2023-08-24 00:20:07,493][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.1900 loss2:0.8299 loss3:0.0000 | AUC:0.8464 Anomaly AUC:0.6708
[2023-08-24 00:21:23,198][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.1573 loss2:0.8029 loss3:0.0000 | AUC:0.8253 Anomaly AUC:0.6573
[2023-08-24 00:22:29,131][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1610 loss2:0.8087 loss3:0.0000 | AUC:0.8381 Anomaly AUC:0.6559
[2023-08-24 00:23:37,691][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1175 loss2:0.7704 loss3:0.0000 | AUC:0.8336 Anomaly AUC:0.6591
[2023-08-24 00:25:11,022][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.1070 loss2:0.6287 loss3:0.0000 | AUC:0.8276 Anomaly AUC:0.6590
[2023-08-24 00:26:42,652][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:26:42,937][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:26:42,937][main.py][line:136][INFO] Training Mode
[2023-08-24 00:26:42,938][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:26:42,938][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:26:59,074][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:28:15,101][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.4924 loss2:1.0877 loss3:0.0000 | AUC:0.8103 Anomaly AUC:0.6490
[2023-08-24 00:29:32,058][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.2856 loss2:0.9073 loss3:0.0000 | AUC:0.8375 Anomaly AUC:0.6653
[2023-08-24 00:30:53,776][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2280 loss2:0.8611 loss3:0.0000 | AUC:0.8237 Anomaly AUC:0.6456
[2023-08-24 00:32:26,717][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.1953 loss2:0.8347 loss3:0.0000 | AUC:0.8364 Anomaly AUC:0.6556
[2023-08-24 00:33:57,271][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.1683 loss2:0.8132 loss3:0.0000 | AUC:0.8347 Anomaly AUC:0.6543
[2023-08-24 00:35:23,567][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1535 loss2:0.7885 loss3:0.0000 | AUC:0.8245 Anomaly AUC:0.6412
[2023-08-24 00:37:01,853][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1337 loss2:0.7653 loss3:0.0000 | AUC:0.8286 Anomaly AUC:0.6409
[2023-08-24 00:38:37,008][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.1162 loss2:0.7081 loss3:0.0000 | AUC:0.7105 Anomaly AUC:0.5791
[2023-08-24 00:40:28,476][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.0956 loss2:0.6530 loss3:0.0000 | AUC:0.7854 Anomaly AUC:0.6361
[2023-08-24 00:42:13,767][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.0588 loss2:0.0968 loss3:0.0000 | AUC:0.7965 Anomaly AUC:0.6271
[2023-08-24 00:44:42,770][main.py][line:86][INFO] [Epoch:11/50]: loss1:0.0591 loss2:0.5062 loss3:0.0000 | AUC:0.7732 Anomaly AUC:0.6147
[2023-08-24 00:46:17,118][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:46:17,398][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:46:17,399][main.py][line:136][INFO] Training Mode
[2023-08-24 00:46:17,399][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:46:17,399][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:46:31,248][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:47:52,883][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.7311 loss2:1.3631 loss3:0.0000 | AUC:0.6047 Anomaly AUC:0.5156
[2023-08-24 00:50:18,527][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.6954 loss2:1.3651 loss3:0.0000 | AUC:0.5938 Anomaly AUC:0.4978
[2023-08-24 00:51:41,243][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.6942 loss2:1.3652 loss3:0.0000 | AUC:0.5225 Anomaly AUC:0.4752
[2023-08-24 00:52:39,456][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:52:39,717][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:52:39,717][main.py][line:136][INFO] Training Mode
[2023-08-24 00:52:39,718][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:52:39,718][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:52:53,613][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:54:27,308][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.7311 loss2:1.3631 loss3:6.9438 | AUC:0.6047 Anomaly AUC:0.5156
[2023-08-24 00:56:58,027][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.6954 loss2:1.3651 loss3:3.7214 | AUC:0.5938 Anomaly AUC:0.4978
[2023-08-24 00:57:52,827][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 00:57:53,104][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 00:57:53,104][main.py][line:136][INFO] Training Mode
[2023-08-24 00:57:53,105][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 00:57:53,105][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 00:58:10,374][main.py][line:65][INFO] Random initialize AUCAUC:0.5525 Anomaly AUC:0.54508
[2023-08-24 00:59:51,951][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.6929 loss2:1.2011 loss3:0.0941 | AUC:0.8136 Anomaly AUC:0.6271
[2023-08-24 01:01:20,540][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.3362 loss2:0.9693 loss3:0.0695 | AUC:0.8036 Anomaly AUC:0.6307
[2023-08-24 01:03:32,752][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2652 loss2:0.8991 loss3:0.0598 | AUC:0.8067 Anomaly AUC:0.6507
[2023-08-24 01:04:17,443][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 01:04:17,712][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 01:04:17,712][main.py][line:136][INFO] Training Mode
[2023-08-24 01:04:17,713][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 01:04:17,713][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 01:04:27,359][main.py][line:65][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 01:05:29,645][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.4297 loss2:1.0381 loss3:0.0860 | AUC:0.8130 Anomaly AUC:0.6581
[2023-08-24 01:06:33,232][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.3021 loss2:0.9350 loss3:0.0650 | AUC:0.7851 Anomaly AUC:0.6225
[2023-08-24 01:07:34,740][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2439 loss2:0.8846 loss3:0.0567 | AUC:0.8149 Anomaly AUC:0.6326
[2023-08-24 01:08:41,877][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.2082 loss2:0.8511 loss3:0.0478 | AUC:0.7689 Anomaly AUC:0.6392
[2023-08-24 01:09:49,970][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.1683 loss2:0.8149 loss3:0.0432 | AUC:0.7471 Anomaly AUC:0.6340
[2023-08-24 01:11:05,099][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1565 loss2:0.7756 loss3:0.0419 | AUC:0.7882 Anomaly AUC:0.6490
[2023-08-24 01:12:34,023][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1232 loss2:0.7246 loss3:0.0360 | AUC:0.8293 Anomaly AUC:0.6420
[2023-08-24 01:14:05,624][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.1029 loss2:0.6830 loss3:0.0324 | AUC:0.7812 Anomaly AUC:0.6175
[2023-08-24 01:15:12,113][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.0823 loss2:0.6499 loss3:0.0284 | AUC:0.6624 Anomaly AUC:0.6173
[2023-08-24 01:16:46,243][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.0723 loss2:0.5876 loss3:0.0263 | AUC:0.7500 Anomaly AUC:0.6285
[2023-08-24 01:17:48,098][main.py][line:86][INFO] [Epoch:11/50]: loss1:0.0525 loss2:0.5885 loss3:0.0237 | AUC:0.7611 Anomaly AUC:0.6416
[2023-08-24 01:19:09,209][main.py][line:86][INFO] [Epoch:12/50]: loss1:0.0460 loss2:0.5739 loss3:0.0212 | AUC:0.7288 Anomaly AUC:0.6073
[2023-08-24 01:20:39,963][main.py][line:86][INFO] [Epoch:13/50]: loss1:0.0473 loss2:0.5566 loss3:0.0216 | AUC:0.8260 Anomaly AUC:0.6603
[2023-08-24 01:21:59,630][main.py][line:86][INFO] [Epoch:14/50]: loss1:0.0439 loss2:0.5236 loss3:0.0213 | AUC:0.7372 Anomaly AUC:0.6185
[2023-08-24 01:23:20,252][main.py][line:86][INFO] [Epoch:15/50]: loss1:0.0419 loss2:0.4730 loss3:0.0198 | AUC:0.7539 Anomaly AUC:0.6263
[2023-08-24 01:24:49,133][main.py][line:86][INFO] [Epoch:16/50]: loss1:0.0265 loss2:0.4265 loss3:0.0177 | AUC:0.7376 Anomaly AUC:0.6319
[2023-08-24 01:25:59,626][main.py][line:86][INFO] [Epoch:17/50]: loss1:0.0267 loss2:0.3142 loss3:0.0169 | AUC:0.8201 Anomaly AUC:0.6450
[2023-08-24 01:27:11,941][main.py][line:86][INFO] [Epoch:18/50]: loss1:0.0269 loss2:0.4103 loss3:0.0170 | AUC:0.7255 Anomaly AUC:0.6271
[2023-08-24 01:28:19,028][main.py][line:86][INFO] [Epoch:19/50]: loss1:0.0266 loss2:0.3900 loss3:0.0166 | AUC:0.7366 Anomaly AUC:0.6281
[2023-08-24 01:29:40,693][main.py][line:86][INFO] [Epoch:20/50]: loss1:0.0194 loss2:0.3652 loss3:0.0152 | AUC:0.8135 Anomaly AUC:0.6513
[2023-08-24 01:30:54,168][main.py][line:86][INFO] [Epoch:21/50]: loss1:0.0313 loss2:0.3306 loss3:0.0169 | AUC:0.7350 Anomaly AUC:0.6362
[2023-08-24 01:32:10,071][main.py][line:86][INFO] [Epoch:22/50]: loss1:0.0147 loss2:0.3491 loss3:0.0135 | AUC:0.6987 Anomaly AUC:0.6236
[2023-08-24 01:33:22,544][main.py][line:86][INFO] [Epoch:23/50]: loss1:0.0180 loss2:0.3277 loss3:0.0134 | AUC:0.7576 Anomaly AUC:0.6441
[2023-08-24 01:34:34,425][main.py][line:86][INFO] [Epoch:24/50]: loss1:0.0138 loss2:0.2756 loss3:0.0128 | AUC:0.7333 Anomaly AUC:0.6075
[2023-08-24 01:36:03,050][main.py][line:86][INFO] [Epoch:25/50]: loss1:0.0332 loss2:0.2078 loss3:0.0178 | AUC:0.7356 Anomaly AUC:0.6270
[2023-08-24 01:37:13,712][main.py][line:86][INFO] [Epoch:26/50]: loss1:0.0103 loss2:0.2969 loss3:0.0127 | AUC:0.6971 Anomaly AUC:0.6211
[2023-08-24 01:38:29,783][main.py][line:86][INFO] [Epoch:27/50]: loss1:0.0166 loss2:0.2622 loss3:0.0125 | AUC:0.6549 Anomaly AUC:0.6083
[2023-08-24 01:39:49,298][main.py][line:86][INFO] [Epoch:28/50]: loss1:0.0142 loss2:0.2722 loss3:0.0115 | AUC:0.7490 Anomaly AUC:0.6232
[2023-08-24 01:40:58,684][main.py][line:86][INFO] [Epoch:29/50]: loss1:0.0121 loss2:0.2358 loss3:0.0121 | AUC:0.6929 Anomaly AUC:0.6143
[2023-08-24 01:42:24,210][main.py][line:86][INFO] [Epoch:30/50]: loss1:0.0103 loss2:0.2071 loss3:0.0114 | AUC:0.7646 Anomaly AUC:0.6224
[2023-08-24 01:43:29,891][main.py][line:86][INFO] [Epoch:31/50]: loss1:0.0185 loss2:0.1169 loss3:0.0135 | AUC:0.6579 Anomaly AUC:0.5656
[2023-08-24 01:44:40,825][main.py][line:86][INFO] [Epoch:32/50]: loss1:0.0216 loss2:0.2104 loss3:0.0138 | AUC:0.7273 Anomaly AUC:0.6123
[2023-08-24 01:45:56,137][main.py][line:86][INFO] [Epoch:33/50]: loss1:0.0067 loss2:0.1904 loss3:0.0103 | AUC:0.6534 Anomaly AUC:0.5718
[2023-08-24 01:47:23,046][main.py][line:86][INFO] [Epoch:34/50]: loss1:0.0100 loss2:0.1849 loss3:0.0111 | AUC:0.6208 Anomaly AUC:0.5597
[2023-08-24 01:48:34,277][main.py][line:86][INFO] [Epoch:35/50]: loss1:0.0148 loss2:0.0900 loss3:0.0115 | AUC:0.7562 Anomaly AUC:0.6233
[2023-08-24 01:49:38,863][main.py][line:86][INFO] [Epoch:36/50]: loss1:0.0116 loss2:0.1745 loss3:0.0128 | AUC:0.6892 Anomaly AUC:0.6129
[2023-08-24 01:50:58,841][main.py][line:86][INFO] [Epoch:37/50]: loss1:0.0154 loss2:0.1366 loss3:0.0115 | AUC:0.7242 Anomaly AUC:0.6208
[2023-08-24 01:52:17,119][main.py][line:86][INFO] [Epoch:38/50]: loss1:0.0114 loss2:0.1816 loss3:0.0111 | AUC:0.8138 Anomaly AUC:0.6522
[2023-08-24 01:53:30,860][main.py][line:86][INFO] [Epoch:39/50]: loss1:0.0112 loss2:0.1496 loss3:0.0114 | AUC:0.7800 Anomaly AUC:0.6481
[2023-08-24 01:54:49,637][main.py][line:86][INFO] [Epoch:40/50]: loss1:0.0082 loss2:0.1544 loss3:0.0103 | AUC:0.6947 Anomaly AUC:0.5942
[2023-08-24 01:55:58,762][main.py][line:86][INFO] [Epoch:41/50]: loss1:0.0061 loss2:0.1445 loss3:0.0108 | AUC:0.7746 Anomaly AUC:0.6424
[2023-08-24 01:57:14,613][main.py][line:86][INFO] [Epoch:42/50]: loss1:0.0071 loss2:0.1326 loss3:0.0106 | AUC:0.7904 Anomaly AUC:0.6499
[2023-08-24 01:58:21,768][main.py][line:86][INFO] [Epoch:43/50]: loss1:0.0108 loss2:0.1198 loss3:0.0108 | AUC:0.8040 Anomaly AUC:0.6367
[2023-08-24 01:59:57,697][main.py][line:86][INFO] [Epoch:44/50]: loss1:0.0112 loss2:0.0757 loss3:0.0108 | AUC:0.7890 Anomaly AUC:0.6465
[2023-08-24 02:01:14,036][main.py][line:86][INFO] [Epoch:45/50]: loss1:0.0058 loss2:0.0941 loss3:0.0091 | AUC:0.6735 Anomaly AUC:0.6039
[2023-08-24 02:02:33,278][main.py][line:86][INFO] [Epoch:46/50]: loss1:0.0055 loss2:0.0933 loss3:0.0094 | AUC:0.7404 Anomaly AUC:0.6227
[2023-08-24 02:03:56,822][main.py][line:86][INFO] [Epoch:47/50]: loss1:0.0179 loss2:0.0976 loss3:0.0117 | AUC:0.6789 Anomaly AUC:0.5974
[2023-08-24 02:05:08,714][main.py][line:86][INFO] [Epoch:48/50]: loss1:0.0152 loss2:0.1081 loss3:0.0124 | AUC:0.7119 Anomaly AUC:0.6149
[2023-08-24 02:06:33,822][main.py][line:86][INFO] [Epoch:49/50]: loss1:0.0032 loss2:0.0818 loss3:0.0078 | AUC:0.7129 Anomaly AUC:0.6110
[2023-08-24 02:07:48,896][main.py][line:86][INFO] [Epoch:50/50]: loss1:0.0048 loss2:0.0877 loss3:0.0083 | AUC:0.6390 Anomaly AUC:0.5932
[2023-08-24 02:07:49,058][main.py][line:94][INFO] Training completes in 63m 22s | best AUCAUC:0.8293 Anomaly AUC:0.6420

[2023-08-24 11:12:53,052][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 11:12:53,314][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 11:12:53,314][main.py][line:136][INFO] Training Mode
[2023-08-24 11:12:53,315][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 11:12:53,315][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 11:13:03,435][main.py][line:65][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 11:14:22,077][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.4266 loss2:1.0636 loss3:9.8777 | AUC:0.8128 Anomaly AUC:0.6397
[2023-08-24 11:15:37,746][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.2718 loss2:0.9309 loss3:5.8223 | AUC:0.8355 Anomaly AUC:0.6530
[2023-08-24 11:16:53,473][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2052 loss2:0.8790 loss3:3.8110 | AUC:0.8436 Anomaly AUC:0.6620
[2023-08-24 11:18:13,821][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.1897 loss2:0.8637 loss3:3.4181 | AUC:0.8186 Anomaly AUC:0.6383
[2023-08-24 11:19:36,529][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.1509 loss2:0.8272 loss3:2.3678 | AUC:0.8100 Anomaly AUC:0.6487
[2023-08-24 11:20:48,260][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1229 loss2:0.7835 loss3:0.8246 | AUC:0.7785 Anomaly AUC:0.6381
[2023-08-24 11:22:21,257][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1033 loss2:0.7380 loss3:0.5844 | AUC:0.8282 Anomaly AUC:0.6609
[2023-08-24 11:23:34,823][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.0956 loss2:0.7119 loss3:0.4397 | AUC:0.7317 Anomaly AUC:0.6142
[2023-08-24 11:24:49,831][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.0811 loss2:0.6759 loss3:0.3929 | AUC:0.7968 Anomaly AUC:0.6320
[2023-08-24 11:24:54,327][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 11:24:54,588][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 11:24:54,588][main.py][line:136][INFO] Training Mode
[2023-08-24 11:24:54,589][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 11:24:54,589][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 11:25:10,124][main.py][line:65][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 11:26:40,039][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.4413 loss2:1.0750 loss3:2.6328 | AUC:0.8175 Anomaly AUC:0.6370
[2023-08-24 11:27:46,031][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.2754 loss2:0.9368 loss3:2.2506 | AUC:0.8325 Anomaly AUC:0.6420
[2023-08-24 11:28:59,299][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2110 loss2:0.8834 loss3:1.5978 | AUC:0.8375 Anomaly AUC:0.6568
[2023-08-24 11:30:24,155][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.1718 loss2:0.8459 loss3:1.5268 | AUC:0.8331 Anomaly AUC:0.6701
[2023-08-24 11:31:34,516][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.1348 loss2:0.8033 loss3:1.0052 | AUC:0.8339 Anomaly AUC:0.6757
[2023-08-24 11:32:47,274][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1174 loss2:0.7718 loss3:0.8542 | AUC:0.8325 Anomaly AUC:0.6832
[2023-08-24 11:34:01,884][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.0954 loss2:0.7262 loss3:1.1347 | AUC:0.8350 Anomaly AUC:0.6720
[2023-08-24 11:35:35,633][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.0821 loss2:0.6815 loss3:1.1260 | AUC:0.8326 Anomaly AUC:0.6647
[2023-08-24 11:36:40,285][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.0704 loss2:0.6437 loss3:1.0620 | AUC:0.8350 Anomaly AUC:0.6887
[2023-08-24 11:38:06,278][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.0737 loss2:0.6209 loss3:1.3017 | AUC:0.8263 Anomaly AUC:0.6707
[2023-08-24 11:39:25,989][main.py][line:86][INFO] [Epoch:11/50]: loss1:0.0646 loss2:0.5874 loss3:1.5445 | AUC:0.8491 Anomaly AUC:0.6777
[2023-08-24 11:40:37,086][main.py][line:86][INFO] [Epoch:12/50]: loss1:0.0513 loss2:0.5467 loss3:1.2927 | AUC:0.8308 Anomaly AUC:0.6601
[2023-08-24 11:41:46,612][main.py][line:86][INFO] [Epoch:13/50]: loss1:0.0518 loss2:0.5333 loss3:1.4075 | AUC:0.8064 Anomaly AUC:0.6561
[2023-08-24 11:42:41,201][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 11:42:41,467][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 11:42:41,467][main.py][line:136][INFO] Training Mode
[2023-08-24 11:42:41,468][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 11:42:41,468][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 11:42:55,559][main.py][line:65][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 11:44:26,354][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.7356 loss2:1.3626 loss3:0.8016 | AUC:0.5695 Anomaly AUC:0.5454
[2023-08-24 11:45:32,649][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.4798 loss2:1.1922 loss3:4.7718 | AUC:0.8179 Anomaly AUC:0.6475
[2023-08-24 11:46:54,168][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.3154 loss2:1.0415 loss3:2.6776 | AUC:0.8151 Anomaly AUC:0.6489
[2023-08-24 11:48:43,896][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.2951 loss2:1.0069 loss3:2.9946 | AUC:0.8198 Anomaly AUC:0.6335
[2023-08-24 11:50:17,426][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.2721 loss2:0.9862 loss3:6.1035 | AUC:0.8241 Anomaly AUC:0.6474
[2023-08-24 11:51:34,175][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.2337 loss2:0.9520 loss3:6.6279 | AUC:0.8229 Anomaly AUC:0.6525
[2023-08-24 11:53:21,815][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1908 loss2:0.9022 loss3:7.0849 | AUC:0.8223 Anomaly AUC:0.6635
[2023-08-24 11:54:58,435][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.1623 loss2:0.8527 loss3:6.8297 | AUC:0.8416 Anomaly AUC:0.6905
[2023-08-24 11:56:42,891][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.1533 loss2:0.8405 loss3:10.2995 | AUC:0.8214 Anomaly AUC:0.6828
[2023-08-24 11:58:23,797][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.1171 loss2:0.8058 loss3:8.5518 | AUC:0.8310 Anomaly AUC:0.6889
[2023-08-24 12:00:29,458][main.py][line:86][INFO] [Epoch:11/50]: loss1:0.0922 loss2:0.7883 loss3:6.5858 | AUC:0.8305 Anomaly AUC:0.6869
[2023-08-24 12:01:55,580][main.py][line:86][INFO] [Epoch:12/50]: loss1:0.0838 loss2:0.7815 loss3:5.5844 | AUC:0.8338 Anomaly AUC:0.6792
[2023-08-24 12:03:14,917][main.py][line:86][INFO] [Epoch:13/50]: loss1:0.0706 loss2:0.7743 loss3:5.7199 | AUC:0.8338 Anomaly AUC:0.6793
[2023-08-24 12:04:41,979][main.py][line:86][INFO] [Epoch:14/50]: loss1:0.0584 loss2:0.7635 loss3:4.8520 | AUC:0.8288 Anomaly AUC:0.6921
[2023-08-24 12:06:00,607][main.py][line:86][INFO] [Epoch:15/50]: loss1:0.0573 loss2:0.7612 loss3:5.4772 | AUC:0.8420 Anomaly AUC:0.7004
[2023-08-24 12:07:15,565][main.py][line:86][INFO] [Epoch:16/50]: loss1:0.0476 loss2:0.7524 loss3:3.9879 | AUC:0.8403 Anomaly AUC:0.7025
[2023-08-24 12:09:16,855][main.py][line:86][INFO] [Epoch:17/50]: loss1:0.0527 loss2:0.7536 loss3:3.5919 | AUC:0.8267 Anomaly AUC:0.6858
[2023-08-24 12:10:42,568][main.py][line:86][INFO] [Epoch:18/50]: loss1:0.0450 loss2:0.7495 loss3:3.1058 | AUC:0.8423 Anomaly AUC:0.6893
[2023-08-24 12:11:50,818][main.py][line:86][INFO] [Epoch:19/50]: loss1:0.0532 loss2:0.7551 loss3:3.5232 | AUC:0.8283 Anomaly AUC:0.6688
[2023-08-24 12:13:15,204][main.py][line:86][INFO] [Epoch:20/50]: loss1:0.0486 loss2:0.7496 loss3:3.3942 | AUC:0.8376 Anomaly AUC:0.6742
[2023-08-24 12:14:48,197][main.py][line:86][INFO] [Epoch:21/50]: loss1:0.0317 loss2:0.7345 loss3:2.1571 | AUC:0.8340 Anomaly AUC:0.6769
[2023-08-24 12:16:24,487][main.py][line:86][INFO] [Epoch:22/50]: loss1:0.0438 loss2:0.7405 loss3:3.5391 | AUC:0.8360 Anomaly AUC:0.6717
[2023-08-24 12:17:37,767][main.py][line:86][INFO] [Epoch:23/50]: loss1:0.0347 loss2:0.7336 loss3:2.8642 | AUC:0.8427 Anomaly AUC:0.6799
[2023-08-24 12:19:26,824][main.py][line:86][INFO] [Epoch:24/50]: loss1:0.0274 loss2:0.7223 loss3:2.2579 | AUC:0.8404 Anomaly AUC:0.6692
[2023-08-24 12:21:25,487][main.py][line:86][INFO] [Epoch:25/50]: loss1:0.0264 loss2:0.7218 loss3:1.9061 | AUC:0.8169 Anomaly AUC:0.6527
[2023-08-24 12:22:51,025][main.py][line:86][INFO] [Epoch:26/50]: loss1:0.0274 loss2:0.7161 loss3:1.9684 | AUC:0.8364 Anomaly AUC:0.6713
[2023-08-24 12:24:38,968][main.py][line:86][INFO] [Epoch:27/50]: loss1:0.0230 loss2:0.7094 loss3:1.7238 | AUC:0.8208 Anomaly AUC:0.6602
[2023-08-24 12:26:07,806][main.py][line:86][INFO] [Epoch:28/50]: loss1:0.0245 loss2:0.7119 loss3:1.6434 | AUC:0.8252 Anomaly AUC:0.6637
[2023-08-24 12:27:52,803][main.py][line:86][INFO] [Epoch:29/50]: loss1:0.0244 loss2:0.7009 loss3:1.6920 | AUC:0.8316 Anomaly AUC:0.6841
[2023-08-24 12:29:11,584][main.py][line:86][INFO] [Epoch:30/50]: loss1:0.0247 loss2:0.7078 loss3:1.3264 | AUC:0.8218 Anomaly AUC:0.6624
[2023-08-24 12:30:41,732][main.py][line:86][INFO] [Epoch:31/50]: loss1:0.0215 loss2:0.7010 loss3:1.6958 | AUC:0.8383 Anomaly AUC:0.6751
[2023-08-24 12:32:24,974][main.py][line:86][INFO] [Epoch:32/50]: loss1:0.0212 loss2:0.6968 loss3:1.3279 | AUC:0.8302 Anomaly AUC:0.6724
[2023-08-24 12:33:53,159][main.py][line:86][INFO] [Epoch:33/50]: loss1:0.0176 loss2:0.6786 loss3:1.1573 | AUC:0.8137 Anomaly AUC:0.6525
[2023-08-24 12:35:03,369][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 12:35:03,643][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 12:35:03,643][main.py][line:136][INFO] Training Mode
[2023-08-24 12:35:03,644][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 12:35:03,644][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 12:35:20,480][main.py][line:65][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 12:37:17,391][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.6147 loss2:1.2621 loss3:2.4868 | AUC:0.7473 Anomaly AUC:0.6073
[2023-08-24 12:39:12,375][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.3261 loss2:0.9876 loss3:6.6096 | AUC:0.8188 Anomaly AUC:0.6418
[2023-08-24 12:40:51,409][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.2680 loss2:0.9260 loss3:6.0100 | AUC:0.8248 Anomaly AUC:0.6575
[2023-08-24 12:42:35,720][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.2328 loss2:0.8860 loss3:6.4154 | AUC:0.8190 Anomaly AUC:0.6405
[2023-08-24 12:44:32,005][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.2060 loss2:0.8618 loss3:7.2182 | AUC:0.8335 Anomaly AUC:0.6595
[2023-08-24 12:46:19,280][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1808 loss2:0.8335 loss3:7.5785 | AUC:0.8422 Anomaly AUC:0.6685
[2023-08-24 12:48:27,296][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1486 loss2:0.8137 loss3:6.7784 | AUC:0.8306 Anomaly AUC:0.6640
[2023-08-24 12:50:01,970][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.1246 loss2:0.7959 loss3:6.9324 | AUC:0.8367 Anomaly AUC:0.6543
[2023-08-24 12:51:38,958][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.1116 loss2:0.7843 loss3:6.6179 | AUC:0.8311 Anomaly AUC:0.6584
[2023-08-24 12:53:39,164][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.0903 loss2:0.7652 loss3:5.5816 | AUC:0.8329 Anomaly AUC:0.6723
[2023-08-24 12:54:14,362][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 12:54:14,641][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 12:54:14,641][main.py][line:136][INFO] Training Mode
[2023-08-24 12:54:14,642][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 12:54:14,642][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 12:54:30,717][main.py][line:65][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 12:56:00,298][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.7402 loss2:1.3491 loss3:0.3008 | AUC:0.3521 Anomaly AUC:0.4160
[2023-08-24 12:57:12,625][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.5131 loss2:1.1973 loss3:0.2659 | AUC:0.8115 Anomaly AUC:0.6267
[2023-08-24 12:58:29,993][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.3483 loss2:1.0807 loss3:0.1090 | AUC:0.8248 Anomaly AUC:0.6279
[2023-08-24 12:59:47,729][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.2919 loss2:1.0147 loss3:0.0870 | AUC:0.8177 Anomaly AUC:0.6337
[2023-08-24 13:01:14,784][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.2400 loss2:0.9687 loss3:0.0767 | AUC:0.8261 Anomaly AUC:0.6695
[2023-08-24 13:02:26,699][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.1865 loss2:0.9275 loss3:0.0668 | AUC:0.8349 Anomaly AUC:0.6735
[2023-08-24 13:03:44,382][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.1613 loss2:0.9051 loss3:0.0636 | AUC:0.8275 Anomaly AUC:0.6543
[2023-08-24 13:05:08,813][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.1288 loss2:0.8797 loss3:0.0549 | AUC:0.8311 Anomaly AUC:0.6781
[2023-08-24 13:06:17,782][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.1065 loss2:0.8715 loss3:0.0512 | AUC:0.8097 Anomaly AUC:0.6759
[2023-08-24 13:07:51,641][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.0937 loss2:0.8629 loss3:0.0497 | AUC:0.8202 Anomaly AUC:0.6667
[2023-08-24 13:09:28,612][main.py][line:86][INFO] [Epoch:11/50]: loss1:0.0782 loss2:0.8563 loss3:0.0450 | AUC:0.8080 Anomaly AUC:0.6668
[2023-08-24 13:10:59,687][main.py][line:86][INFO] [Epoch:12/50]: loss1:0.0750 loss2:0.8545 loss3:0.0427 | AUC:0.8235 Anomaly AUC:0.6878
[2023-08-24 13:12:03,664][main.py][line:86][INFO] [Epoch:13/50]: loss1:0.0641 loss2:0.8478 loss3:0.0409 | AUC:0.8258 Anomaly AUC:0.6829
[2023-08-24 13:14:03,616][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:14:03,891][main.py][line:133][INFO] total params:33.1046M
[2023-08-24 13:14:03,892][main.py][line:136][INFO] Training Mode
[2023-08-24 13:14:03,892][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 13:14:03,893][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 13:14:10,523][main.py][line:65][INFO] Random initialize AUCAUC:0.5163 Anomaly AUC:0.51203
[2023-08-24 13:15:16,792][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.3323 loss2:0.9888 loss3:1.7664 | AUC:0.8233 Anomaly AUC:0.6335
[2023-08-24 13:16:27,059][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.1161 loss2:0.7668 loss3:1.6040 | AUC:0.8388 Anomaly AUC:0.6695
[2023-08-24 13:17:53,354][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.0490 loss2:0.6488 loss3:1.6170 | AUC:0.8013 Anomaly AUC:0.6472
[2023-08-24 13:19:06,502][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.0343 loss2:0.5562 loss3:1.5597 | AUC:0.8152 Anomaly AUC:0.6514
[2023-08-24 13:20:36,289][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.0189 loss2:0.4567 loss3:1.5423 | AUC:0.8122 Anomaly AUC:0.6492
[2023-08-24 13:21:46,674][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:21:46,790][main.py][line:133][INFO] total params:1.2091M
[2023-08-24 13:21:46,790][main.py][line:136][INFO] Training Mode
[2023-08-24 13:23:00,352][main.py][line:101][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:23:00,440][main.py][line:133][INFO] total params:1.2091M
[2023-08-24 13:23:00,440][main.py][line:136][INFO] Training Mode
[2023-08-24 13:23:00,440][main.py][line:61][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 13:23:00,440][main.py][line:62][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 13:23:12,297][main.py][line:65][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-24 13:24:20,740][main.py][line:86][INFO] [Epoch:1/50]: loss1:0.3315 loss2:1.0616 loss3:1.5397 | AUC:0.8268 Anomaly AUC:0.6456
[2023-08-24 13:25:16,585][main.py][line:86][INFO] [Epoch:2/50]: loss1:0.1175 loss2:0.7792 loss3:1.5869 | AUC:0.8454 Anomaly AUC:0.6655
[2023-08-24 13:26:36,736][main.py][line:86][INFO] [Epoch:3/50]: loss1:0.0632 loss2:0.6582 loss3:1.6591 | AUC:0.8494 Anomaly AUC:0.6842
[2023-08-24 13:27:42,369][main.py][line:86][INFO] [Epoch:4/50]: loss1:0.0384 loss2:0.5558 loss3:1.6162 | AUC:0.8444 Anomaly AUC:0.6694
[2023-08-24 13:28:47,426][main.py][line:86][INFO] [Epoch:5/50]: loss1:0.0184 loss2:0.4480 loss3:1.5468 | AUC:0.8352 Anomaly AUC:0.6673
[2023-08-24 13:30:11,122][main.py][line:86][INFO] [Epoch:6/50]: loss1:0.0367 loss2:0.3960 loss3:1.6147 | AUC:0.8447 Anomaly AUC:0.6751
[2023-08-24 13:31:22,517][main.py][line:86][INFO] [Epoch:7/50]: loss1:0.0116 loss2:0.2893 loss3:1.5783 | AUC:0.8483 Anomaly AUC:0.6744
[2023-08-24 13:33:16,143][main.py][line:86][INFO] [Epoch:8/50]: loss1:0.0118 loss2:0.2191 loss3:1.5513 | AUC:0.8417 Anomaly AUC:0.6750
[2023-08-24 13:34:15,103][main.py][line:86][INFO] [Epoch:9/50]: loss1:0.0348 loss2:0.2196 loss3:1.7634 | AUC:0.8377 Anomaly AUC:0.6766
[2023-08-24 13:35:07,737][main.py][line:86][INFO] [Epoch:10/50]: loss1:0.0113 loss2:0.1440 loss3:1.6544 | AUC:0.8462 Anomaly AUC:0.6757
[2023-08-24 13:36:48,227][main.py][line:86][INFO] [Epoch:11/50]: loss1:0.0047 loss2:0.0912 loss3:1.6441 | AUC:0.8453 Anomaly AUC:0.6746
[2023-08-24 13:37:51,419][main.py][line:86][INFO] [Epoch:12/50]: loss1:0.0033 loss2:0.0621 loss3:1.5058 | AUC:0.8417 Anomaly AUC:0.6664
[2023-08-24 13:38:54,002][main.py][line:86][INFO] [Epoch:13/50]: loss1:0.0025 loss2:0.0436 loss3:1.4328 | AUC:0.8423 Anomaly AUC:0.6707
[2023-08-24 13:40:22,527][main.py][line:86][INFO] [Epoch:14/50]: loss1:0.0022 loss2:0.0321 loss3:1.3552 | AUC:0.8395 Anomaly AUC:0.6672
[2023-08-24 13:41:09,985][main.py][line:86][INFO] [Epoch:15/50]: loss1:0.0394 loss2:0.0551 loss3:1.7060 | AUC:0.8127 Anomaly AUC:0.6361
[2023-08-24 13:42:07,566][main.py][line:86][INFO] [Epoch:16/50]: loss1:0.0328 loss2:0.0856 loss3:2.1785 | AUC:0.8371 Anomaly AUC:0.6634
[2023-08-24 13:42:58,510][main.py][line:86][INFO] [Epoch:17/50]: loss1:0.0115 loss2:0.0412 loss3:1.9268 | AUC:0.8344 Anomaly AUC:0.6589
[2023-08-24 13:43:24,116][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:43:24,242][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 13:43:24,242][main.py][line:142][INFO] Training Mode
[2023-08-24 13:43:24,243][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 13:43:24,243][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 13:44:06,668][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:44:06,753][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 13:44:06,753][main.py][line:142][INFO] Training Mode
[2023-08-24 13:44:06,754][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 13:44:06,754][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 13:44:15,798][main.py][line:66][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-24 13:46:53,554][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 32, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:46:53,641][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 13:46:53,641][main.py][line:142][INFO] Training Mode
[2023-08-24 13:46:53,641][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 13:46:53,641][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 13:47:05,831][main.py][line:66][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-24 13:48:27,477][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.3180 loss2:0.9280 loss3:0.0000 | AUC:0.8379 Anomaly AUC:0.6586
[2023-08-24 13:49:22,385][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.1117 loss2:0.6212 loss3:0.0000 | AUC:0.8499 Anomaly AUC:0.6878
[2023-08-24 13:50:22,755][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.0688 loss2:0.4802 loss3:0.0000 | AUC:0.8353 Anomaly AUC:0.6665
[2023-08-24 13:51:10,005][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.0348 loss2:0.3385 loss3:0.0000 | AUC:0.8373 Anomaly AUC:0.6675
[2023-08-24 13:51:58,512][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.0339 loss2:0.2433 loss3:0.0000 | AUC:0.8360 Anomaly AUC:0.6667
[2023-08-24 13:53:10,417][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.0373 loss2:0.1733 loss3:0.0000 | AUC:0.8382 Anomaly AUC:0.6682
[2023-08-24 13:54:14,752][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.0204 loss2:0.1089 loss3:0.0000 | AUC:0.8115 Anomaly AUC:0.6487
[2023-08-24 13:54:50,578][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8512.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 13:54:50,693][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 13:54:50,693][main.py][line:142][INFO] Training Mode
[2023-08-24 13:54:50,693][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 13:54:50,693][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 13:54:56,923][main.py][line:66][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-24 13:56:34,368][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.3879 loss2:1.1027 loss3:0.0000 | AUC:0.8336 Anomaly AUC:0.6379
[2023-08-24 13:58:13,584][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.1527 loss2:0.8754 loss3:0.0000 | AUC:0.8478 Anomaly AUC:0.6749
[2023-08-24 13:59:57,350][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.0687 loss2:0.7828 loss3:0.0000 | AUC:0.8501 Anomaly AUC:0.6836
[2023-08-24 14:01:31,894][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.0321 loss2:0.7052 loss3:0.0000 | AUC:0.8399 Anomaly AUC:0.6791
[2023-08-24 14:03:12,162][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.0314 loss2:0.6430 loss3:0.0000 | AUC:0.8498 Anomaly AUC:0.6837
[2023-08-24 14:04:51,943][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.0181 loss2:0.5795 loss3:0.0000 | AUC:0.8480 Anomaly AUC:0.6754
[2023-08-24 14:06:57,752][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.0212 loss2:0.5285 loss3:0.0000 | AUC:0.8466 Anomaly AUC:0.6851
[2023-08-24 14:08:43,510][main.py][line:88][INFO] [Epoch:8/50]: loss1:0.0159 loss2:0.4758 loss3:0.0000 | AUC:0.8555 Anomaly AUC:0.6892
[2023-08-24 14:10:41,487][main.py][line:88][INFO] [Epoch:9/50]: loss1:0.0088 loss2:0.4122 loss3:0.0000 | AUC:0.8528 Anomaly AUC:0.6866
[2023-08-24 14:12:32,917][main.py][line:88][INFO] [Epoch:10/50]: loss1:0.0073 loss2:0.3574 loss3:0.0000 | AUC:0.8525 Anomaly AUC:0.6875
[2023-08-24 14:14:23,875][main.py][line:88][INFO] [Epoch:11/50]: loss1:0.0073 loss2:0.3065 loss3:0.0000 | AUC:0.8539 Anomaly AUC:0.6874
[2023-08-24 14:16:12,888][main.py][line:88][INFO] [Epoch:12/50]: loss1:0.0269 loss2:0.3021 loss3:0.0000 | AUC:0.8450 Anomaly AUC:0.6814
[2023-08-24 14:17:59,702][main.py][line:88][INFO] [Epoch:13/50]: loss1:0.0334 loss2:0.3015 loss3:0.0000 | AUC:0.8441 Anomaly AUC:0.6781
[2023-08-24 14:19:47,153][main.py][line:88][INFO] [Epoch:14/50]: loss1:0.0095 loss2:0.2221 loss3:0.0000 | AUC:0.8484 Anomaly AUC:0.6807
[2023-08-24 14:21:35,957][main.py][line:88][INFO] [Epoch:15/50]: loss1:0.0046 loss2:0.1767 loss3:0.0000 | AUC:0.8530 Anomaly AUC:0.6882
[2023-08-24 14:23:19,732][main.py][line:88][INFO] [Epoch:16/50]: loss1:0.0042 loss2:0.1476 loss3:0.0000 | AUC:0.8486 Anomaly AUC:0.6799
[2023-08-24 14:25:03,287][main.py][line:88][INFO] [Epoch:17/50]: loss1:0.0034 loss2:0.1240 loss3:0.0000 | AUC:0.8532 Anomaly AUC:0.6894
[2023-08-24 14:27:01,998][main.py][line:88][INFO] [Epoch:18/50]: loss1:0.0029 loss2:0.1020 loss3:0.0000 | AUC:0.8527 Anomaly AUC:0.6916
[2023-08-24 14:28:45,540][main.py][line:88][INFO] [Epoch:19/50]: loss1:0.0032 loss2:0.0894 loss3:0.0000 | AUC:0.8403 Anomaly AUC:0.6784
[2023-08-24 14:30:22,851][main.py][line:88][INFO] [Epoch:20/50]: loss1:0.0481 loss2:0.1458 loss3:0.0000 | AUC:0.8383 Anomaly AUC:0.6747
[2023-08-24 14:32:05,009][main.py][line:88][INFO] [Epoch:21/50]: loss1:0.0077 loss2:0.0949 loss3:0.0000 | AUC:0.8430 Anomaly AUC:0.6789
[2023-08-24 14:34:08,517][main.py][line:88][INFO] [Epoch:22/50]: loss1:0.0033 loss2:0.0716 loss3:0.0000 | AUC:0.8446 Anomaly AUC:0.6811
[2023-08-24 14:35:47,698][main.py][line:88][INFO] [Epoch:23/50]: loss1:0.0024 loss2:0.0579 loss3:0.0000 | AUC:0.8456 Anomaly AUC:0.6863
[2023-08-24 14:37:29,556][main.py][line:88][INFO] [Epoch:24/50]: loss1:0.0019 loss2:0.0479 loss3:0.0000 | AUC:0.8460 Anomaly AUC:0.6845
[2023-08-24 14:39:10,924][main.py][line:88][INFO] [Epoch:25/50]: loss1:0.0016 loss2:0.0416 loss3:0.0000 | AUC:0.8445 Anomaly AUC:0.6824
[2023-08-24 14:40:54,654][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8555.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 14:40:54,772][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 14:40:54,772][main.py][line:147][INFO] Test Mode
[2023-08-24 14:40:54,772][main.py][line:42][INFO] Not found pretrained checkpoint file.
[2023-08-24 14:41:00,704][infer.py][line:47][INFO] offline AUC:0.5516 AP:0.0907 FAR:0.6865 | Complete in 0m 6s

[2023-08-24 14:42:05,459][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8555.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 14:42:05,545][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 14:42:05,545][main.py][line:147][INFO] Test Mode
[2023-08-24 14:42:05,545][main.py][line:42][INFO] Not found pretrained checkpoint file.
[2023-08-24 14:42:10,995][infer.py][line:47][INFO] offline AUC:0.5516 AP:0.0907 FAR:0.6865 | Complete in 0m 5s

[2023-08-24 14:43:28,450][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 14:43:28,548][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 14:43:28,548][main.py][line:147][INFO] Test Mode
[2023-08-24 14:43:28,548][main.py][line:27][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-24 14:43:34,008][infer.py][line:47][INFO] offline AUC:0.8622 AP:0.3341 FAR:0.0016 | Complete in 0m 5s

[2023-08-24 14:46:21,927][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 14:46:22,175][main.py][line:139][INFO] total params:33.1046M
[2023-08-24 14:46:22,175][main.py][line:142][INFO] Training Mode
[2023-08-24 14:46:22,176][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.0, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.0, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.0, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 14:46:22,176][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 14:46:32,298][main.py][line:66][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 14:48:33,816][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.4623 loss2:1.1118 loss3:0.0000 | AUC:0.8028 Anomaly AUC:0.6294
[2023-08-24 14:51:17,516][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.2898 loss2:0.9832 loss3:0.0000 | AUC:0.8281 Anomaly AUC:0.6569
[2023-08-24 14:53:48,290][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.2198 loss2:0.9233 loss3:0.0000 | AUC:0.8279 Anomaly AUC:0.6554
[2023-08-24 14:56:13,833][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.1708 loss2:0.8558 loss3:0.0000 | AUC:0.8395 Anomaly AUC:0.6716
[2023-08-24 14:58:40,756][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.1492 loss2:0.8175 loss3:0.0000 | AUC:0.7899 Anomaly AUC:0.6480
[2023-08-24 15:01:11,262][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.1045 loss2:0.7629 loss3:0.0000 | AUC:0.8198 Anomaly AUC:0.6636
[2023-08-24 15:03:28,726][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.0828 loss2:0.7087 loss3:0.0000 | AUC:0.8223 Anomaly AUC:0.6654
[2023-08-24 15:05:46,305][main.py][line:88][INFO] [Epoch:8/50]: loss1:0.0622 loss2:0.6615 loss3:0.0000 | AUC:0.8168 Anomaly AUC:0.6510
[2023-08-24 15:07:10,075][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 15:07:10,348][main.py][line:139][INFO] total params:33.1046M
[2023-08-24 15:07:10,348][main.py][line:142][INFO] Training Mode
[2023-08-24 15:07:10,349][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.0, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.0, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.0, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 15:07:10,349][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 15:07:24,552][main.py][line:66][INFO] Random initialize AUCAUC:0.6143 Anomaly AUC:0.58483
[2023-08-24 15:11:07,753][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7805 loss2:1.4003 loss3:0.0000 | AUC:0.7518 Anomaly AUC:0.6536
[2023-08-24 15:15:39,898][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.6983 loss2:1.4029 loss3:0.0000 | AUC:0.7677 Anomaly AUC:0.6638
[2023-08-24 15:19:04,435][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.6487 loss2:1.3038 loss3:0.0000 | AUC:0.4571 Anomaly AUC:0.4288
[2023-08-24 15:22:23,110][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.3835 loss2:1.1058 loss3:0.0000 | AUC:0.8178 Anomaly AUC:0.6449
[2023-08-24 15:25:19,931][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.3267 loss2:1.0631 loss3:0.0000 | AUC:0.7987 Anomaly AUC:0.6292
[2023-08-24 15:28:13,430][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.3074 loss2:1.0735 loss3:0.0000 | AUC:0.8118 Anomaly AUC:0.6345
[2023-08-24 15:30:22,523][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.2914 loss2:1.0683 loss3:0.0000 | AUC:0.8031 Anomaly AUC:0.6178
[2023-08-24 15:33:16,167][main.py][line:88][INFO] [Epoch:8/50]: loss1:0.2777 loss2:1.0562 loss3:0.0000 | AUC:0.7081 Anomaly AUC:0.5441
[2023-08-24 15:35:34,380][main.py][line:88][INFO] [Epoch:9/50]: loss1:0.2372 loss2:1.0930 loss3:0.0000 | AUC:0.8180 Anomaly AUC:0.6514
[2023-08-24 15:38:00,919][main.py][line:88][INFO] [Epoch:10/50]: loss1:0.2521 loss2:1.0620 loss3:0.0000 | AUC:0.3753 Anomaly AUC:0.4292
[2023-08-24 15:40:38,069][main.py][line:88][INFO] [Epoch:11/50]: loss1:0.4009 loss2:1.1277 loss3:0.0000 | AUC:0.1932 Anomaly AUC:0.3758
[2023-08-24 15:43:21,129][main.py][line:88][INFO] [Epoch:12/50]: loss1:0.2953 loss2:1.1087 loss3:0.0000 | AUC:0.8265 Anomaly AUC:0.6491
[2023-08-24 15:45:47,884][main.py][line:88][INFO] [Epoch:13/50]: loss1:0.2335 loss2:1.0407 loss3:0.0000 | AUC:0.8158 Anomaly AUC:0.6590
[2023-08-24 15:48:06,528][main.py][line:88][INFO] [Epoch:14/50]: loss1:0.2130 loss2:0.9833 loss3:0.0000 | AUC:0.8177 Anomaly AUC:0.6622
[2023-08-24 15:50:23,939][main.py][line:88][INFO] [Epoch:15/50]: loss1:0.1892 loss2:0.9562 loss3:0.0000 | AUC:0.8203 Anomaly AUC:0.6724
[2023-08-24 15:52:56,939][main.py][line:88][INFO] [Epoch:16/50]: loss1:0.1786 loss2:0.9409 loss3:0.0000 | AUC:0.8190 Anomaly AUC:0.6585
[2023-08-24 15:55:10,022][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 15:55:10,297][main.py][line:139][INFO] total params:30.1014M
[2023-08-24 15:55:10,297][main.py][line:142][INFO] Training Mode
[2023-08-24 15:55:10,298][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 128, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(128, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(8, 8, kernel_size=(5,), stride=(1,), padding=(2,), groups=8)
                  (to_out): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 128, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 15:55:10,298][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 15:55:24,519][main.py][line:66][INFO] Random initialize AUCAUC:0.4535 Anomaly AUC:0.46468
[2023-08-24 15:57:50,881][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7511 loss2:1.3009 loss3:0.0000 | AUC:0.5178 Anomaly AUC:0.5096
[2023-08-24 16:00:53,808][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.6971 loss2:1.2423 loss3:0.0000 | AUC:0.4557 Anomaly AUC:0.4696
[2023-08-24 16:03:13,161][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.6971 loss2:1.2623 loss3:0.0000 | AUC:0.5545 Anomaly AUC:0.5247
[2023-08-24 16:05:31,823][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.6978 loss2:1.3055 loss3:0.0000 | AUC:0.4780 Anomaly AUC:0.4786
[2023-08-24 16:08:14,929][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.6992 loss2:1.2563 loss3:0.0000 | AUC:0.4910 Anomaly AUC:0.5003
[2023-08-24 16:10:40,496][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.6962 loss2:1.2397 loss3:0.0000 | AUC:0.5227 Anomaly AUC:0.5301
[2023-08-24 16:11:47,207][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 16:11:47,483][main.py][line:139][INFO] total params:29.6643M
[2023-08-24 16:11:47,483][main.py][line:142][INFO] Training Mode
[2023-08-24 16:11:47,484][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 16:11:47,484][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 16:12:00,926][main.py][line:66][INFO] Random initialize AUCAUC:0.4659 Anomaly AUC:0.54638
[2023-08-24 16:13:58,155][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7513 loss2:1.4025 loss3:0.0000 | AUC:0.5148 Anomaly AUC:0.5268
[2023-08-24 16:16:31,361][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.7057 loss2:1.4002 loss3:0.0000 | AUC:0.4505 Anomaly AUC:0.3932
[2023-08-24 16:19:42,842][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.6577 loss2:1.3402 loss3:0.0000 | AUC:0.7227 Anomaly AUC:0.5598
[2023-08-24 16:22:27,552][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.3808 loss2:1.1063 loss3:0.0000 | AUC:0.8146 Anomaly AUC:0.6198
[2023-08-24 16:25:30,357][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.3171 loss2:1.0306 loss3:0.0000 | AUC:0.7298 Anomaly AUC:0.5844
[2023-08-24 16:29:06,289][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.2790 loss2:0.9817 loss3:0.0000 | AUC:0.7848 Anomaly AUC:0.6141
[2023-08-24 16:31:07,484][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.2471 loss2:0.9517 loss3:0.0000 | AUC:0.7944 Anomaly AUC:0.6142
[2023-08-24 16:34:29,199][main.py][line:88][INFO] [Epoch:8/50]: loss1:0.2294 loss2:0.9310 loss3:0.0000 | AUC:0.8166 Anomaly AUC:0.6191
[2023-08-24 16:37:45,400][main.py][line:88][INFO] [Epoch:9/50]: loss1:0.2079 loss2:0.9073 loss3:0.0000 | AUC:0.8348 Anomaly AUC:0.6451
[2023-08-24 16:40:17,546][main.py][line:88][INFO] [Epoch:10/50]: loss1:0.2038 loss2:0.9012 loss3:0.0000 | AUC:0.8083 Anomaly AUC:0.6037
[2023-08-24 16:49:37,841][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 128, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 16:49:38,100][main.py][line:139][INFO] total params:29.6643M
[2023-08-24 16:49:38,100][main.py][line:142][INFO] Training Mode
[2023-08-24 16:49:38,101][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 16:49:38,101][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 16:49:52,731][main.py][line:66][INFO] Random initialize AUCAUC:0.4659 Anomaly AUC:0.54638
[2023-08-24 16:58:48,975][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7561 loss2:1.4201 loss3:0.0000 | AUC:0.6275 Anomaly AUC:0.5444
[2023-08-24 16:59:12,081][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 16:59:12,329][main.py][line:139][INFO] total params:29.6643M
[2023-08-24 16:59:12,329][main.py][line:142][INFO] Training Mode
[2023-08-24 16:59:12,330][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(64, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(256, 64, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(16, 16, kernel_size=(5,), stride=(1,), padding=(2,), groups=16)
                  (to_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.7, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 16:59:12,330][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 16:59:21,549][main.py][line:66][INFO] Random initialize AUCAUC:0.4659 Anomaly AUC:0.54638
[2023-08-24 17:01:53,988][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7341 loss2:1.4007 loss3:0.0000 | AUC:0.5050 Anomaly AUC:0.5172
[2023-08-24 17:03:14,015][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 32, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 17:03:14,310][main.py][line:139][INFO] total params:35.9893M
[2023-08-24 17:03:14,311][main.py][line:142][INFO] Training Mode
[2023-08-24 17:03:14,311][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(512, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 512, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(2, 2, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)
                  (to_out): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 512, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 17:03:14,311][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 17:03:25,566][main.py][line:66][INFO] Random initialize AUCAUC:0.5148 Anomaly AUC:0.51334
[2023-08-24 17:05:22,316][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7299 loss2:1.2687 loss3:0.0000 | AUC:0.6886 Anomaly AUC:0.5402
[2023-08-24 17:07:23,347][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.6700 loss2:1.2399 loss3:0.0000 | AUC:0.8006 Anomaly AUC:0.5941
[2023-08-24 17:09:26,275][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.3292 loss2:0.9911 loss3:0.0000 | AUC:0.7457 Anomaly AUC:0.5871
[2023-08-24 17:11:28,951][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.2440 loss2:0.9235 loss3:0.0000 | AUC:0.7824 Anomaly AUC:0.6024
[2023-08-24 17:14:06,041][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.2022 loss2:0.8879 loss3:0.0000 | AUC:0.8015 Anomaly AUC:0.5922
[2023-08-24 17:16:42,471][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.1647 loss2:0.8585 loss3:0.0000 | AUC:0.7856 Anomaly AUC:0.5941
[2023-08-24 17:18:53,746][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.1385 loss2:0.8396 loss3:0.0000 | AUC:0.7949 Anomaly AUC:0.5976
[2023-08-24 17:21:07,518][main.py][line:88][INFO] [Epoch:8/50]: loss1:0.1015 loss2:0.8127 loss3:0.0000 | AUC:0.6707 Anomaly AUC:0.5585
[2023-08-24 17:23:10,525][main.py][line:88][INFO] [Epoch:9/50]: loss1:0.0743 loss2:0.7953 loss3:0.0000 | AUC:0.7459 Anomaly AUC:0.6078
[2023-08-24 17:25:25,568][main.py][line:88][INFO] [Epoch:10/50]: loss1:0.0628 loss2:0.7805 loss3:0.0000 | AUC:0.7126 Anomaly AUC:0.5723
[2023-08-24 17:28:06,500][main.py][line:88][INFO] [Epoch:11/50]: loss1:0.0474 loss2:0.7637 loss3:0.0000 | AUC:0.7423 Anomaly AUC:0.5934
[2023-08-24 17:30:13,947][main.py][line:88][INFO] [Epoch:12/50]: loss1:0.0310 loss2:0.7389 loss3:0.0000 | AUC:0.7289 Anomaly AUC:0.5804
[2023-08-24 17:32:30,973][main.py][line:88][INFO] [Epoch:13/50]: loss1:0.0348 loss2:0.7318 loss3:0.0000 | AUC:0.6353 Anomaly AUC:0.5607
[2023-08-24 17:34:37,409][main.py][line:88][INFO] [Epoch:14/50]: loss1:0.0274 loss2:0.6726 loss3:0.0000 | AUC:0.7321 Anomaly AUC:0.5876
[2023-08-24 17:34:43,311][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 32, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 17:34:43,581][main.py][line:139][INFO] total params:33.7275M
[2023-08-24 17:34:43,582][main.py][line:142][INFO] Training Mode
[2023-08-24 17:34:43,582][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,), groups=4)
                  (to_out): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 17:34:43,582][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 17:34:58,247][main.py][line:66][INFO] Random initialize AUCAUC:0.5238 Anomaly AUC:0.53492
[2023-08-24 17:36:53,783][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.7389 loss2:1.2825 loss3:0.0000 | AUC:0.4931 Anomaly AUC:0.4742
[2023-08-24 17:38:42,787][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.6981 loss2:1.2295 loss3:0.0000 | AUC:0.4201 Anomaly AUC:0.4588
[2023-08-24 17:40:30,612][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.6960 loss2:1.2279 loss3:0.0000 | AUC:0.4506 Anomaly AUC:0.4567
[2023-08-24 17:42:18,855][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.6943 loss2:1.2259 loss3:0.0000 | AUC:0.4133 Anomaly AUC:0.4542
[2023-08-24 17:44:09,997][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.6937 loss2:1.2252 loss3:0.0000 | AUC:0.4367 Anomaly AUC:0.4484
[2023-08-24 17:46:11,709][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.6935 loss2:1.2259 loss3:0.0000 | AUC:0.4744 Anomaly AUC:0.4877
[2023-08-24 17:48:10,090][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.6934 loss2:1.2244 loss3:0.0000 | AUC:0.5731 Anomaly AUC:0.5113
[2023-08-24 17:48:52,762][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 32, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 17:48:53,044][main.py][line:139][INFO] total params:33.7275M
[2023-08-24 17:48:53,044][main.py][line:142][INFO] Training Mode
[2023-08-24 17:48:53,045][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (mgfn): mgfn(
      (to_tokens): Conv1d(1024, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (stages): ModuleList(
        (0): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): GLANCE(
                  (norm): LayerNorm()
                  (to_qkv): Conv1d(32, 192, kernel_size=(1,), stride=(1,), bias=False)
                  (to_out): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
        )
        (1): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-2): 3 x ModuleList(
                (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,), groups=4)
                  (to_out): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): Sequential(
            (0): LayerNorm()
            (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))
          )
        )
        (2): ModuleList(
          (0): Backbone(
            (layers): ModuleList(
              (0-1): 2 x ModuleList(
                (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
                (1): FOCUS(
                  (norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (to_v): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
                  (rel_pos): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=32)
                  (to_out): Conv1d(2048, 1024, kernel_size=(1,), stride=(1,))
                )
                (2): Sequential(
                  (0): LayerNorm()
                  (1): Conv1d(1024, 4096, kernel_size=(1,), stride=(1,))
                  (2): GELU(approximate='none')
                  (3): Dropout(p=0.1, inplace=False)
                  (4): Conv1d(4096, 1024, kernel_size=(1,), stride=(1,))
                )
              )
            )
          )
          (1): None
        )
      )
      (to_logits): Sequential(
        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (to_mag): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 17:48:53,045][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.005
    lr: 0.005
    maximize: False
    weight_decay: 0
)

[2023-08-24 17:49:08,177][main.py][line:66][INFO] Random initialize AUCAUC:0.5238 Anomaly AUC:0.53492
[2023-08-24 17:51:12,529][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.4881 loss2:1.1281 loss3:134.6923 | AUC:0.7305 Anomaly AUC:0.5887
[2023-08-24 17:53:55,497][main.py][line:88][INFO] [Epoch:2/50]: loss1:0.2149 loss2:0.9256 loss3:186.3966 | AUC:0.8230 Anomaly AUC:0.6373
[2023-08-24 17:56:19,499][main.py][line:88][INFO] [Epoch:3/50]: loss1:0.1481 loss2:0.8727 loss3:183.0580 | AUC:0.8032 Anomaly AUC:0.6096
[2023-08-24 17:58:19,837][main.py][line:88][INFO] [Epoch:4/50]: loss1:0.0999 loss2:0.8334 loss3:143.1277 | AUC:0.8298 Anomaly AUC:0.6423
[2023-08-24 17:59:58,679][main.py][line:88][INFO] [Epoch:5/50]: loss1:0.0895 loss2:0.8189 loss3:127.5040 | AUC:0.8015 Anomaly AUC:0.6218
[2023-08-24 18:01:50,420][main.py][line:88][INFO] [Epoch:6/50]: loss1:0.0644 loss2:0.7333 loss3:181.7980 | AUC:0.8307 Anomaly AUC:0.6776
[2023-08-24 18:04:21,601][main.py][line:88][INFO] [Epoch:7/50]: loss1:0.0537 loss2:0.6312 loss3:161.9659 | AUC:0.8235 Anomaly AUC:0.6643
[2023-08-24 18:06:00,066][main.py][line:88][INFO] [Epoch:8/50]: loss1:0.0470 loss2:0.6933 loss3:124.9404 | AUC:0.8147 Anomaly AUC:0.6652
[2023-08-24 18:07:41,419][main.py][line:88][INFO] [Epoch:9/50]: loss1:0.0665 loss2:0.6860 loss3:127.8434 | AUC:0.7973 Anomaly AUC:0.6567
[2023-08-24 18:09:21,258][main.py][line:88][INFO] [Epoch:10/50]: loss1:0.0346 loss2:0.7578 loss3:138.1157 | AUC:0.8272 Anomaly AUC:0.6652
[2023-08-24 18:11:05,899][main.py][line:88][INFO] [Epoch:11/50]: loss1:0.0396 loss2:0.7042 loss3:203.8456 | AUC:0.8341 Anomaly AUC:0.6833
[2023-08-24 18:12:50,211][main.py][line:88][INFO] [Epoch:12/50]: loss1:0.0916 loss2:0.3610 loss3:539.6075 | AUC:0.5244 Anomaly AUC:0.5163
[2023-08-24 18:14:34,578][main.py][line:88][INFO] [Epoch:13/50]: loss1:0.6748 loss2:1.1061 loss3:245.6854 | AUC:0.3813 Anomaly AUC:0.4770
[2023-08-24 18:45:13,066][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 18:45:13,173][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 18:45:13,173][main.py][line:142][INFO] Training Mode
[2023-08-24 18:45:34,792][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 18:45:34,877][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 18:45:34,877][main.py][line:142][INFO] Training Mode
[2023-08-24 18:45:34,877][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.7, inplace=False)
)

[2023-08-24 18:45:34,877][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 18:45:40,796][main.py][line:66][INFO] Random initialize AUCAUC:0.5444 Anomaly AUC:0.53443
[2023-08-24 18:46:30,622][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 18:46:30,717][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 18:46:30,717][main.py][line:142][INFO] Training Mode
[2023-08-24 18:46:30,717][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 18:46:30,717][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 18:49:16,109][main.py][line:88][INFO] [Epoch:1/50]: loss1:0.2677 loss2:0.9842 loss3:0.0000 | AUC:0.8356 Anomaly AUC:0.6522
[2023-08-24 18:52:15,164][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 18:52:15,273][main.py][line:139][INFO] total params:1.2091M
[2023-08-24 18:52:15,273][main.py][line:142][INFO] Training Mode
[2023-08-24 18:52:15,273][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 18:52:15,273][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 18:58:30,221][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 18:58:30,333][main.py][line:139][INFO] total params:7.7021M
[2023-08-24 18:58:30,333][main.py][line:142][INFO] Training Mode
[2023-08-24 18:58:30,334][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (cls_head): ADCLS_head(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 18:58:30,334][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 18:59:31,411][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 18:59:31,538][main.py][line:139][INFO] total params:7.7021M
[2023-08-24 18:59:31,538][main.py][line:142][INFO] Training Mode
[2023-08-24 18:59:31,539][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (cls_head): ADCLS_head(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 18:59:31,539][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:09:14,662][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:09:14,772][main.py][line:139][INFO] total params:7.5707M
[2023-08-24 19:09:14,772][main.py][line:142][INFO] Training Mode
[2023-08-24 19:09:14,772][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:09:14,772][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:09:26,360][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:09:26,487][main.py][line:139][INFO] total params:7.5707M
[2023-08-24 19:09:26,487][main.py][line:142][INFO] Training Mode
[2023-08-24 19:09:26,487][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:09:26,487][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:10:21,243][main.py][line:103][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:10:21,366][main.py][line:139][INFO] total params:7.5707M
[2023-08-24 19:10:21,367][main.py][line:142][INFO] Training Mode
[2023-08-24 19:10:21,367][main.py][line:62][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:10:21,367][main.py][line:63][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:12:15,767][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:12:15,897][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:12:15,897][main.py][line:145][INFO] Training Mode
[2023-08-24 19:12:15,898][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:12:15,898][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:14:10,006][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:14:10,116][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:14:10,116][main.py][line:145][INFO] Training Mode
[2023-08-24 19:14:10,117][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:14:10,117][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:18:34,195][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:18:34,323][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:18:34,324][main.py][line:145][INFO] Training Mode
[2023-08-24 19:18:34,324][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:18:34,324][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:23:44,732][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 16, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:23:44,883][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:23:44,883][main.py][line:145][INFO] Training Mode
[2023-08-24 19:23:44,884][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:23:44,884][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:37:49,977][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:37:50,117][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:37:50,118][main.py][line:145][INFO] Training Mode
[2023-08-24 19:37:50,118][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:37:50,118][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:38:12,984][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:38:13,103][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:38:13,103][main.py][line:145][INFO] Training Mode
[2023-08-24 19:38:13,103][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:38:13,103][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:38:43,150][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:38:43,272][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:38:43,272][main.py][line:145][INFO] Training Mode
[2023-08-24 19:38:43,273][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:38:43,273][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:38:55,563][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:38:55,681][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:38:55,681][main.py][line:145][INFO] Training Mode
[2023-08-24 19:38:55,681][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:38:55,681][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:39:13,683][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:39:13,805][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:39:13,805][main.py][line:145][INFO] Training Mode
[2023-08-24 19:39:13,805][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:39:13,805][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:39:31,852][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 19:39:31,976][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 19:39:31,977][main.py][line:145][INFO] Training Mode
[2023-08-24 19:39:31,977][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 19:39:31,977][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-24 19:39:39,478][main.py][line:69][INFO] Random initialize AUCAUC:0.4034 Anomaly AUC:0.48216
[2023-08-24 19:43:45,403][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.3824 loss2:0.9943 loss3:0.3244 | AUC:0.8248 Anomaly AUC:0.6711
[2023-08-24 19:47:43,497][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1385 loss2:0.7168 loss3:0.1913 | AUC:0.8525 Anomaly AUC:0.6857
[2023-08-24 19:50:49,804][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.0550 loss2:0.5504 loss3:0.0844 | AUC:0.8351 Anomaly AUC:0.6613
[2023-08-24 19:53:57,324][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.0201 loss2:0.3480 loss3:0.0721 | AUC:0.8210 Anomaly AUC:0.6337
[2023-08-24 19:57:58,815][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0187 loss2:0.2016 loss3:0.0701 | AUC:0.8268 Anomaly AUC:0.6420
[2023-08-24 20:02:10,281][main.py][line:91][INFO] [Epoch:6/50]: loss1:0.0199 loss2:0.1201 loss3:0.0699 | AUC:0.8346 Anomaly AUC:0.6722
[2023-08-24 20:06:02,091][main.py][line:91][INFO] [Epoch:7/50]: loss1:0.0148 loss2:0.0647 loss3:0.0688 | AUC:0.8161 Anomaly AUC:0.6260
[2023-08-24 20:09:54,174][main.py][line:91][INFO] [Epoch:8/50]: loss1:0.0043 loss2:0.0314 loss3:0.0656 | AUC:0.8302 Anomaly AUC:0.6315
[2023-08-24 20:13:48,385][main.py][line:91][INFO] [Epoch:9/50]: loss1:0.0071 loss2:0.0277 loss3:0.0653 | AUC:0.8326 Anomaly AUC:0.6492
[2023-08-24 20:17:51,965][main.py][line:91][INFO] [Epoch:10/50]: loss1:0.0096 loss2:0.0306 loss3:0.0664 | AUC:0.8291 Anomaly AUC:0.6396
[2023-08-24 20:21:43,674][main.py][line:91][INFO] [Epoch:11/50]: loss1:0.0104 loss2:0.0316 loss3:0.0662 | AUC:0.8390 Anomaly AUC:0.6518
[2023-08-24 20:25:33,460][main.py][line:91][INFO] [Epoch:12/50]: loss1:0.0004 loss2:0.0069 loss3:0.0631 | AUC:0.8389 Anomaly AUC:0.6508
[2023-08-24 20:29:05,710][main.py][line:91][INFO] [Epoch:13/50]: loss1:0.0004 loss2:0.0050 loss3:0.0627 | AUC:0.8349 Anomaly AUC:0.6367
[2023-08-24 20:32:43,758][main.py][line:91][INFO] [Epoch:14/50]: loss1:0.0001 loss2:0.0034 loss3:0.0624 | AUC:0.8449 Anomaly AUC:0.6549
[2023-08-24 20:36:39,194][main.py][line:91][INFO] [Epoch:15/50]: loss1:0.0001 loss2:0.0031 loss3:0.0620 | AUC:0.8460 Anomaly AUC:0.6647
[2023-08-24 20:40:06,542][main.py][line:91][INFO] [Epoch:16/50]: loss1:0.0002 loss2:0.0034 loss3:0.0618 | AUC:0.8372 Anomaly AUC:0.6544
[2023-08-24 20:44:13,691][main.py][line:91][INFO] [Epoch:17/50]: loss1:0.0280 loss2:0.0562 loss3:0.0685 | AUC:0.7830 Anomaly AUC:0.6153
[2023-08-24 20:47:58,752][main.py][line:91][INFO] [Epoch:18/50]: loss1:0.0052 loss2:0.0156 loss3:0.0645 | AUC:0.8374 Anomaly AUC:0.6375
[2023-08-24 20:51:45,833][main.py][line:91][INFO] [Epoch:19/50]: loss1:0.0024 loss2:0.0086 loss3:0.0634 | AUC:0.8379 Anomaly AUC:0.6494
[2023-08-24 20:55:20,780][main.py][line:91][INFO] [Epoch:20/50]: loss1:0.0034 loss2:0.0047 loss3:0.0633 | AUC:0.8375 Anomaly AUC:0.6550
[2023-08-24 20:59:08,326][main.py][line:91][INFO] [Epoch:21/50]: loss1:0.0100 loss2:0.0162 loss3:0.0650 | AUC:0.8416 Anomaly AUC:0.6400
[2023-08-24 21:02:43,115][main.py][line:91][INFO] [Epoch:22/50]: loss1:0.0001 loss2:0.0023 loss3:0.0624 | AUC:0.8402 Anomaly AUC:0.6540
[2023-08-24 21:06:05,202][main.py][line:91][INFO] [Epoch:23/50]: loss1:0.0001 loss2:0.0011 loss3:0.0619 | AUC:0.8477 Anomaly AUC:0.6578
[2023-08-24 21:09:50,110][main.py][line:91][INFO] [Epoch:24/50]: loss1:0.0001 loss2:0.0004 loss3:0.0617 | AUC:0.8482 Anomaly AUC:0.6568
[2023-08-24 21:13:45,338][main.py][line:91][INFO] [Epoch:25/50]: loss1:0.0000 loss2:0.0003 loss3:0.0613 | AUC:0.8432 Anomaly AUC:0.6544
[2023-08-24 21:17:38,813][main.py][line:91][INFO] [Epoch:26/50]: loss1:0.0000 loss2:0.0003 loss3:0.0610 | AUC:0.8427 Anomaly AUC:0.6524
[2023-08-24 21:18:00,775][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 21:18:00,940][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 21:18:00,940][main.py][line:145][INFO] Training Mode
[2023-08-24 21:18:00,941][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 21:18:00,941][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0
)

[2023-08-24 21:18:08,680][main.py][line:69][INFO] Random initialize AUCAUC:0.4034 Anomaly AUC:0.48216
[2023-08-24 21:20:26,838][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.3713 loss2:0.9697 loss3:0.3805 | AUC:0.8331 Anomaly AUC:0.6707
[2023-08-24 21:22:42,318][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1080 loss2:0.6650 loss3:0.3640 | AUC:0.8031 Anomaly AUC:0.6663
[2023-08-24 21:24:42,006][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.0286 loss2:0.4815 loss3:0.3484 | AUC:0.7940 Anomaly AUC:0.6330
[2023-08-24 21:26:43,974][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.0242 loss2:0.3371 loss3:0.3282 | AUC:0.8293 Anomaly AUC:0.6633
[2023-08-24 21:28:55,475][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0124 loss2:0.2030 loss3:0.3040 | AUC:0.8095 Anomaly AUC:0.6583
[2023-08-24 21:29:07,869][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 21:29:08,015][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 21:29:08,015][main.py][line:145][INFO] Training Mode
[2023-08-24 21:29:08,015][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 21:29:08,016][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)

[2023-08-24 21:29:18,659][main.py][line:69][INFO] Random initialize AUCAUC:0.4034 Anomaly AUC:0.48216
[2023-08-24 21:32:07,116][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.4647 loss2:1.0762 loss3:0.1938 | AUC:0.7989 Anomaly AUC:0.6214
[2023-08-24 21:34:32,729][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.2083 loss2:0.7833 loss3:0.0668 | AUC:0.7797 Anomaly AUC:0.6037
[2023-08-24 21:36:42,965][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.1094 loss2:0.6202 loss3:0.0649 | AUC:0.7698 Anomaly AUC:0.6179
[2023-08-24 21:36:52,896][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 21:36:53,041][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 21:36:53,041][main.py][line:145][INFO] Training Mode
[2023-08-24 21:36:53,042][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 21:36:53,042][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-24 21:37:00,634][main.py][line:69][INFO] Random initialize AUCAUC:0.4034 Anomaly AUC:0.48216
[2023-08-24 21:40:14,380][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.3846 loss2:0.9814 loss3:0.3597 | AUC:0.8234 Anomaly AUC:0.6894
[2023-08-24 21:43:27,443][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1089 loss2:0.6697 loss3:0.2349 | AUC:0.8287 Anomaly AUC:0.6820
[2023-08-24 21:45:54,659][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.0313 loss2:0.4741 loss3:0.1024 | AUC:0.8274 Anomaly AUC:0.6720
[2023-08-24 21:48:26,595][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.0156 loss2:0.2929 loss3:0.0889 | AUC:0.8468 Anomaly AUC:0.6829
[2023-08-24 21:51:25,944][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0189 loss2:0.1790 loss3:0.0837 | AUC:0.8492 Anomaly AUC:0.6956
[2023-08-24 21:54:45,458][main.py][line:91][INFO] [Epoch:6/50]: loss1:0.0068 loss2:0.0828 loss3:0.0743 | AUC:0.8361 Anomaly AUC:0.6784
[2023-08-24 21:57:42,931][main.py][line:91][INFO] [Epoch:7/50]: loss1:0.0122 loss2:0.0701 loss3:0.0720 | AUC:0.8565 Anomaly AUC:0.7041
[2023-08-24 22:00:37,459][main.py][line:91][INFO] [Epoch:8/50]: loss1:0.0036 loss2:0.0413 loss3:0.0690 | AUC:0.8447 Anomaly AUC:0.6987
[2023-08-24 22:04:09,431][main.py][line:91][INFO] [Epoch:9/50]: loss1:0.0094 loss2:0.0419 loss3:0.0685 | AUC:0.8501 Anomaly AUC:0.6899
[2023-08-24 22:07:04,392][main.py][line:91][INFO] [Epoch:10/50]: loss1:0.0118 loss2:0.0394 loss3:0.0695 | AUC:0.8363 Anomaly AUC:0.6809
[2023-08-24 22:09:57,464][main.py][line:91][INFO] [Epoch:11/50]: loss1:0.0056 loss2:0.0220 loss3:0.0658 | AUC:0.8503 Anomaly AUC:0.7057
[2023-08-24 22:12:56,081][main.py][line:91][INFO] [Epoch:12/50]: loss1:0.0002 loss2:0.0072 loss3:0.0630 | AUC:0.8445 Anomaly AUC:0.7060
[2023-08-24 22:16:03,660][main.py][line:91][INFO] [Epoch:13/50]: loss1:0.0001 loss2:0.0055 loss3:0.0622 | AUC:0.8421 Anomaly AUC:0.7050
[2023-08-24 22:19:29,072][main.py][line:91][INFO] [Epoch:14/50]: loss1:0.0001 loss2:0.0043 loss3:0.0617 | AUC:0.8409 Anomaly AUC:0.6985
[2023-08-24 22:22:40,902][main.py][line:91][INFO] [Epoch:15/50]: loss1:0.0001 loss2:0.0037 loss3:0.0615 | AUC:0.8345 Anomaly AUC:0.6860
[2023-08-24 22:25:32,381][main.py][line:91][INFO] [Epoch:16/50]: loss1:0.0001 loss2:0.0033 loss3:0.0611 | AUC:0.8238 Anomaly AUC:0.6762
[2023-08-24 22:28:52,212][main.py][line:91][INFO] [Epoch:17/50]: loss1:0.0001 loss2:0.0027 loss3:0.0609 | AUC:0.8243 Anomaly AUC:0.6816
[2023-08-24 22:31:50,004][main.py][line:91][INFO] [Epoch:18/50]: loss1:0.0001 loss2:0.0024 loss3:0.0608 | AUC:0.8111 Anomaly AUC:0.6695
[2023-08-24 22:35:01,221][main.py][line:91][INFO] [Epoch:19/50]: loss1:0.0001 loss2:0.0023 loss3:0.0606 | AUC:0.8197 Anomaly AUC:0.6684
[2023-08-24 22:38:06,480][main.py][line:91][INFO] [Epoch:20/50]: loss1:0.0001 loss2:0.0020 loss3:0.0603 | AUC:0.8114 Anomaly AUC:0.6596
[2023-08-24 22:41:02,054][main.py][line:91][INFO] [Epoch:21/50]: loss1:0.0001 loss2:0.0018 loss3:0.0605 | AUC:0.8100 Anomaly AUC:0.6566
[2023-08-24 22:44:08,650][main.py][line:91][INFO] [Epoch:22/50]: loss1:0.0001 loss2:0.0016 loss3:0.0602 | AUC:0.8199 Anomaly AUC:0.6602
[2023-08-24 22:47:51,966][main.py][line:91][INFO] [Epoch:23/50]: loss1:0.0723 loss2:0.1058 loss3:0.0755 | AUC:0.8351 Anomaly AUC:0.6633
[2023-08-24 22:51:16,994][main.py][line:91][INFO] [Epoch:24/50]: loss1:0.0005 loss2:0.0048 loss3:0.0638 | AUC:0.8342 Anomaly AUC:0.6583
[2023-08-24 22:54:28,618][main.py][line:91][INFO] [Epoch:25/50]: loss1:0.0002 loss2:0.0020 loss3:0.0619 | AUC:0.8386 Anomaly AUC:0.6570
[2023-08-24 22:57:44,451][main.py][line:91][INFO] [Epoch:26/50]: loss1:0.0001 loss2:0.0017 loss3:0.0611 | AUC:0.8345 Anomaly AUC:0.6508
[2023-08-24 23:01:08,533][main.py][line:91][INFO] [Epoch:27/50]: loss1:0.0001 loss2:0.0013 loss3:0.0605 | AUC:0.8340 Anomaly AUC:0.6478
[2023-08-24 23:04:14,982][main.py][line:91][INFO] [Epoch:28/50]: loss1:0.0001 loss2:0.0011 loss3:0.0604 | AUC:0.8282 Anomaly AUC:0.6335
[2023-08-24 23:06:41,535][main.py][line:91][INFO] [Epoch:29/50]: loss1:0.0001 loss2:0.0009 loss3:0.0601 | AUC:0.8314 Anomaly AUC:0.6379
[2023-08-24 23:09:46,293][main.py][line:91][INFO] [Epoch:30/50]: loss1:0.0001 loss2:0.0008 loss3:0.0598 | AUC:0.8335 Anomaly AUC:0.6402
[2023-08-24 23:12:37,910][main.py][line:91][INFO] [Epoch:31/50]: loss1:0.0001 loss2:0.0005 loss3:0.0598 | AUC:0.8396 Anomaly AUC:0.6428
[2023-08-24 23:16:00,109][main.py][line:91][INFO] [Epoch:32/50]: loss1:0.0001 loss2:0.0006 loss3:0.0598 | AUC:0.8423 Anomaly AUC:0.6402
[2023-08-24 23:18:44,463][main.py][line:91][INFO] [Epoch:33/50]: loss1:0.0001 loss2:0.0002 loss3:0.0597 | AUC:0.8411 Anomaly AUC:0.6349
[2023-08-24 23:21:00,592][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-24 23:21:00,755][main.py][line:142][INFO] total params:7.5707M
[2023-08-24 23:21:00,755][main.py][line:145][INFO] Training Mode
[2023-08-24 23:21:00,755][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-24 23:21:00,756][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-24 23:21:12,887][main.py][line:69][INFO] Random initialize AUCAUC:0.4034 Anomaly AUC:0.48216
[2023-08-24 23:24:58,720][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.3846 loss2:0.9814 loss3:0.3597 | AUC:0.8234 Anomaly AUC:0.6894
[2023-08-24 23:28:41,243][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1055 loss2:0.6643 loss3:0.2345 | AUC:0.8069 Anomaly AUC:0.6795
[2023-08-24 23:31:28,549][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.0330 loss2:0.4696 loss3:0.1020 | AUC:0.8251 Anomaly AUC:0.6829
[2023-08-24 23:34:06,799][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.0209 loss2:0.3011 loss3:0.0879 | AUC:0.8313 Anomaly AUC:0.6729
[2023-08-24 23:39:59,409][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0071 loss2:0.1499 loss3:0.0801 | AUC:0.8392 Anomaly AUC:0.6701
[2023-08-24 23:44:21,195][main.py][line:91][INFO] [Epoch:6/50]: loss1:0.0006 loss2:0.0587 loss3:0.0697 | AUC:0.8503 Anomaly AUC:0.6741
[2023-08-24 23:47:50,229][main.py][line:91][INFO] [Epoch:7/50]: loss1:0.0003 loss2:0.0332 loss3:0.0667 | AUC:0.8466 Anomaly AUC:0.6666
[2023-08-24 23:52:59,547][main.py][line:91][INFO] [Epoch:8/50]: loss1:0.0002 loss2:0.0218 loss3:0.0649 | AUC:0.8514 Anomaly AUC:0.6778
[2023-08-24 23:58:23,063][main.py][line:91][INFO] [Epoch:9/50]: loss1:0.0002 loss2:0.0151 loss3:0.0636 | AUC:0.8503 Anomaly AUC:0.6741
[2023-08-25 00:03:06,644][main.py][line:91][INFO] [Epoch:10/50]: loss1:0.0002 loss2:0.0115 loss3:0.0626 | AUC:0.8504 Anomaly AUC:0.6773
[2023-08-25 00:07:24,983][main.py][line:91][INFO] [Epoch:11/50]: loss1:0.0598 loss2:0.1997 loss3:0.0730 | AUC:0.8326 Anomaly AUC:0.6767
[2023-08-25 00:10:29,260][main.py][line:91][INFO] [Epoch:12/50]: loss1:0.0189 loss2:0.0635 loss3:0.0692 | AUC:0.8413 Anomaly AUC:0.6801
[2023-08-25 00:13:53,825][main.py][line:91][INFO] [Epoch:13/50]: loss1:0.0092 loss2:0.0321 loss3:0.0657 | AUC:0.8250 Anomaly AUC:0.6738
[2023-08-25 00:17:19,649][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:17:19,794][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:17:19,794][main.py][line:145][INFO] Training Mode
[2023-08-25 00:17:19,795][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:17:19,795][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:17:28,828][main.py][line:69][INFO] Random initialize AUCAUC:0.4034 Anomaly AUC:0.48216
[2023-08-25 00:20:59,742][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.3890 loss2:0.9953 loss3:0.3382 | AUC:0.8300 Anomaly AUC:0.6413
[2023-08-25 00:23:48,791][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1312 loss2:0.7113 loss3:0.2083 | AUC:0.8378 Anomaly AUC:0.6818
[2023-08-25 00:26:24,778][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.0397 loss2:0.5203 loss3:0.1199 | AUC:0.8202 Anomaly AUC:0.6694
[2023-08-25 00:28:54,364][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.0220 loss2:0.3225 loss3:0.0813 | AUC:0.8325 Anomaly AUC:0.6688
[2023-08-25 00:32:06,014][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0167 loss2:0.1722 loss3:0.0754 | AUC:0.8256 Anomaly AUC:0.6255
[2023-08-25 00:35:41,280][main.py][line:91][INFO] [Epoch:6/50]: loss1:0.0146 loss2:0.0991 loss3:0.0727 | AUC:0.8202 Anomaly AUC:0.6335
[2023-08-25 00:40:00,439][main.py][line:91][INFO] [Epoch:7/50]: loss1:0.0325 loss2:0.0954 loss3:0.0737 | AUC:0.8454 Anomaly AUC:0.6581
[2023-08-25 00:43:33,776][main.py][line:91][INFO] [Epoch:8/50]: loss1:0.0165 loss2:0.0564 loss3:0.0714 | AUC:0.8177 Anomaly AUC:0.6384
[2023-08-25 00:46:42,367][main.py][line:91][INFO] [Epoch:9/50]: loss1:0.0066 loss2:0.0289 loss3:0.0685 | AUC:0.8192 Anomaly AUC:0.6161
[2023-08-25 00:47:55,676][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:47:55,831][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:47:55,831][main.py][line:145][INFO] Training Mode
[2023-08-25 00:47:55,832][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:47:55,832][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:48:27,333][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:48:27,454][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:48:27,454][main.py][line:145][INFO] Training Mode
[2023-08-25 00:48:27,455][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:48:27,455][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:49:59,028][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:49:59,138][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:49:59,138][main.py][line:145][INFO] Training Mode
[2023-08-25 00:49:59,139][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:49:59,139][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:50:15,071][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:50:15,197][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:50:15,197][main.py][line:145][INFO] Training Mode
[2023-08-25 00:50:15,198][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:50:15,198][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:53:42,635][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:53:42,755][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:53:42,756][main.py][line:145][INFO] Training Mode
[2023-08-25 00:53:42,756][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (embedding): Temporal(
      (conv_1): Sequential(
        (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
        (1): ReLU()
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:53:42,756][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:55:08,265][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:55:08,388][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:55:08,388][main.py][line:145][INFO] Training Mode
[2023-08-25 00:55:08,388][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:55:08,388][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:55:52,026][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 00:55:52,148][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 00:55:52,149][main.py][line:145][INFO] Training Mode
[2023-08-25 00:55:52,149][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 00:55:52,149][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 00:55:58,429][main.py][line:69][INFO] Random initialize AUCAUC:0.4396 Anomaly AUC:0.41765
[2023-08-25 00:59:33,002][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.4214 loss2:1.1170 loss3:0.3832 | AUC:0.8218 Anomaly AUC:0.6353
[2023-08-25 01:02:39,727][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.2577 loss2:0.8440 loss3:0.3760 | AUC:0.8147 Anomaly AUC:0.6250
[2023-08-25 01:05:39,966][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.1789 loss2:0.7106 loss3:0.3748 | AUC:0.8354 Anomaly AUC:0.6513
[2023-08-25 01:08:18,770][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.1041 loss2:0.5879 loss3:0.3740 | AUC:0.8386 Anomaly AUC:0.6625
[2023-08-25 01:12:33,703][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0473 loss2:0.4616 loss3:0.3727 | AUC:0.8311 Anomaly AUC:0.6432
[2023-08-25 01:15:56,993][main.py][line:91][INFO] [Epoch:6/50]: loss1:0.0275 loss2:0.3516 loss3:0.3708 | AUC:0.8370 Anomaly AUC:0.6526
[2023-08-25 01:20:59,349][main.py][line:91][INFO] [Epoch:7/50]: loss1:0.0253 loss2:0.2599 loss3:0.3683 | AUC:0.8357 Anomaly AUC:0.6515
[2023-08-25 01:25:01,790][main.py][line:91][INFO] [Epoch:8/50]: loss1:0.0069 loss2:0.1639 loss3:0.3649 | AUC:0.8440 Anomaly AUC:0.6671
[2023-08-25 01:28:44,876][main.py][line:91][INFO] [Epoch:9/50]: loss1:0.0040 loss2:0.0995 loss3:0.3604 | AUC:0.8433 Anomaly AUC:0.6695
[2023-08-25 01:32:46,257][main.py][line:91][INFO] [Epoch:10/50]: loss1:0.0025 loss2:0.0583 loss3:0.3552 | AUC:0.8418 Anomaly AUC:0.6674
[2023-08-25 01:36:45,269][main.py][line:91][INFO] [Epoch:11/50]: loss1:0.0337 loss2:0.0658 loss3:0.3507 | AUC:0.8352 Anomaly AUC:0.6637
[2023-08-25 01:37:41,938][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 01:37:42,093][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 01:37:42,093][main.py][line:145][INFO] Training Mode
[2023-08-25 01:37:42,094][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 01:37:42,094][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 01:38:40,331][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 01:38:40,441][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 01:38:40,441][main.py][line:145][INFO] Training Mode
[2023-08-25 01:38:40,441][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 01:38:40,441][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 01:38:48,570][main.py][line:69][INFO] Random initialize AUCAUC:0.4188 Anomaly AUC:0.46923
[2023-08-25 01:42:20,534][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.4515 loss2:1.0476 loss3:0.3178 | AUC:0.8201 Anomaly AUC:0.6451
[2023-08-25 01:45:19,238][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1922 loss2:0.7789 loss3:0.1378 | AUC:0.8353 Anomaly AUC:0.6491
[2023-08-25 01:47:52,944][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.1749 loss2:0.7203 loss3:0.1000 | AUC:0.7823 Anomaly AUC:0.5959
[2023-08-25 01:50:22,413][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.3045 loss2:0.8133 loss3:0.1158 | AUC:0.7833 Anomaly AUC:0.5922
[2023-08-25 01:53:27,821][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 01:53:27,981][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 01:53:27,981][main.py][line:145][INFO] Training Mode
[2023-08-25 01:53:27,982][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 01:53:27,982][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 01:53:36,500][main.py][line:69][INFO] Random initialize AUCAUC:0.4188 Anomaly AUC:0.46923
[2023-08-25 01:57:20,897][main.py][line:91][INFO] [Epoch:1/50]: loss1:0.3904 loss2:0.9960 loss3:0.3593 | AUC:0.8345 Anomaly AUC:0.6562
[2023-08-25 02:00:30,150][main.py][line:91][INFO] [Epoch:2/50]: loss1:0.1443 loss2:0.7151 loss3:0.2408 | AUC:0.8498 Anomaly AUC:0.6874
[2023-08-25 02:03:07,903][main.py][line:91][INFO] [Epoch:3/50]: loss1:0.0663 loss2:0.5670 loss3:0.1036 | AUC:0.8401 Anomaly AUC:0.6852
[2023-08-25 02:05:47,643][main.py][line:91][INFO] [Epoch:4/50]: loss1:0.0396 loss2:0.4472 loss3:0.0884 | AUC:0.8445 Anomaly AUC:0.6806
[2023-08-25 02:08:48,110][main.py][line:91][INFO] [Epoch:5/50]: loss1:0.0223 loss2:0.3157 loss3:0.0800 | AUC:0.8496 Anomaly AUC:0.6860
[2023-08-25 02:11:49,247][main.py][line:91][INFO] [Epoch:6/50]: loss1:0.0156 loss2:0.2037 loss3:0.0727 | AUC:0.8565 Anomaly AUC:0.6718
[2023-08-25 02:15:13,977][main.py][line:91][INFO] [Epoch:7/50]: loss1:0.0150 loss2:0.1250 loss3:0.0703 | AUC:0.8214 Anomaly AUC:0.6810
[2023-08-25 02:18:17,437][main.py][line:91][INFO] [Epoch:8/50]: loss1:0.0168 loss2:0.1041 loss3:0.0695 | AUC:0.8525 Anomaly AUC:0.6775
[2023-08-25 02:21:19,279][main.py][line:91][INFO] [Epoch:9/50]: loss1:0.0154 loss2:0.0810 loss3:0.0686 | AUC:0.7828 Anomaly AUC:0.6280
[2023-08-25 02:24:39,433][main.py][line:91][INFO] [Epoch:10/50]: loss1:0.0143 loss2:0.0712 loss3:0.0693 | AUC:0.8343 Anomaly AUC:0.6659
[2023-08-25 02:28:11,965][main.py][line:91][INFO] [Epoch:11/50]: loss1:0.0114 loss2:0.0427 loss3:0.0657 | AUC:0.8381 Anomaly AUC:0.6632
[2023-08-25 02:31:04,930][main.py][line:91][INFO] [Epoch:12/50]: loss1:0.0033 loss2:0.0200 loss3:0.0643 | AUC:0.7966 Anomaly AUC:0.6089
[2023-08-25 02:34:20,554][main.py][line:91][INFO] [Epoch:13/50]: loss1:0.0128 loss2:0.0502 loss3:0.0665 | AUC:0.8289 Anomaly AUC:0.6448
[2023-08-25 02:37:41,619][main.py][line:91][INFO] [Epoch:14/50]: loss1:0.0104 loss2:0.0361 loss3:0.0663 | AUC:0.8454 Anomaly AUC:0.6790
[2023-08-25 02:40:54,927][main.py][line:91][INFO] [Epoch:15/50]: loss1:0.0003 loss2:0.0074 loss3:0.0628 | AUC:0.8395 Anomaly AUC:0.6610
[2023-08-25 02:44:14,735][main.py][line:91][INFO] [Epoch:16/50]: loss1:0.0028 loss2:0.0139 loss3:0.0626 | AUC:0.8361 Anomaly AUC:0.6737
[2023-08-25 02:47:39,609][main.py][line:91][INFO] [Epoch:17/50]: loss1:0.0172 loss2:0.0443 loss3:0.0652 | AUC:0.8558 Anomaly AUC:0.6808
[2023-08-25 02:50:44,730][main.py][line:91][INFO] [Epoch:18/50]: loss1:0.0106 loss2:0.0466 loss3:0.0649 | AUC:0.8295 Anomaly AUC:0.6663
[2023-08-25 02:53:43,745][main.py][line:91][INFO] [Epoch:19/50]: loss1:0.0006 loss2:0.0062 loss3:0.0627 | AUC:0.8422 Anomaly AUC:0.6697
[2023-08-25 02:57:06,372][main.py][line:91][INFO] [Epoch:20/50]: loss1:0.0001 loss2:0.0027 loss3:0.0616 | AUC:0.8468 Anomaly AUC:0.6789
[2023-08-25 03:00:25,273][main.py][line:91][INFO] [Epoch:21/50]: loss1:0.0001 loss2:0.0030 loss3:0.0613 | AUC:0.8518 Anomaly AUC:0.6820
[2023-08-25 03:03:31,887][main.py][line:91][INFO] [Epoch:22/50]: loss1:0.0001 loss2:0.0031 loss3:0.0610 | AUC:0.8473 Anomaly AUC:0.6720
[2023-08-25 03:06:46,147][main.py][line:91][INFO] [Epoch:23/50]: loss1:0.0001 loss2:0.0026 loss3:0.0608 | AUC:0.8422 Anomaly AUC:0.6666
[2023-08-25 03:10:25,891][main.py][line:91][INFO] [Epoch:24/50]: loss1:0.0001 loss2:0.0018 loss3:0.0606 | AUC:0.8397 Anomaly AUC:0.6533
[2023-08-25 03:13:52,747][main.py][line:91][INFO] [Epoch:25/50]: loss1:0.0004 loss2:0.0023 loss3:0.0607 | AUC:0.8395 Anomaly AUC:0.6528
[2023-08-25 03:17:11,829][main.py][line:91][INFO] [Epoch:26/50]: loss1:0.0144 loss2:0.0432 loss3:0.0658 | AUC:0.8458 Anomaly AUC:0.6880
[2023-08-25 03:20:10,240][main.py][line:91][INFO] [Epoch:27/50]: loss1:0.0148 loss2:0.0342 loss3:0.0657 | AUC:0.8326 Anomaly AUC:0.6608
[2023-08-25 03:22:49,182][main.py][line:91][INFO] [Epoch:28/50]: loss1:0.0005 loss2:0.0030 loss3:0.0623 | AUC:0.8404 Anomaly AUC:0.6628
[2023-08-25 03:25:36,536][main.py][line:91][INFO] [Epoch:29/50]: loss1:0.0002 loss2:0.0017 loss3:0.0614 | AUC:0.8444 Anomaly AUC:0.6574
[2023-08-25 03:28:36,116][main.py][line:91][INFO] [Epoch:30/50]: loss1:0.0001 loss2:0.0012 loss3:0.0608 | AUC:0.8391 Anomaly AUC:0.6537
[2023-08-25 03:31:56,636][main.py][line:91][INFO] [Epoch:31/50]: loss1:0.0001 loss2:0.0007 loss3:0.0605 | AUC:0.8425 Anomaly AUC:0.6554
[2023-08-25 03:35:22,636][main.py][line:91][INFO] [Epoch:32/50]: loss1:0.0001 loss2:0.0009 loss3:0.0604 | AUC:0.8442 Anomaly AUC:0.6570
[2023-08-25 03:38:40,490][main.py][line:91][INFO] [Epoch:33/50]: loss1:0.0001 loss2:0.0009 loss3:0.0601 | AUC:0.8432 Anomaly AUC:0.6549
[2023-08-25 03:41:26,205][main.py][line:91][INFO] [Epoch:34/50]: loss1:0.0001 loss2:0.0014 loss3:0.0601 | AUC:0.8410 Anomaly AUC:0.6573
[2023-08-25 03:44:33,515][main.py][line:91][INFO] [Epoch:35/50]: loss1:0.0001 loss2:0.0009 loss3:0.0600 | AUC:0.8395 Anomaly AUC:0.6523
[2023-08-25 03:48:00,659][main.py][line:91][INFO] [Epoch:36/50]: loss1:0.0001 loss2:0.0009 loss3:0.0600 | AUC:0.8435 Anomaly AUC:0.6569
[2023-08-25 03:51:20,117][main.py][line:91][INFO] [Epoch:37/50]: loss1:0.0001 loss2:0.0012 loss3:0.0600 | AUC:0.8460 Anomaly AUC:0.6662
[2023-08-25 03:54:25,727][main.py][line:91][INFO] [Epoch:38/50]: loss1:0.0001 loss2:0.0011 loss3:0.0599 | AUC:0.8455 Anomaly AUC:0.6609
[2023-08-25 03:57:41,107][main.py][line:91][INFO] [Epoch:39/50]: loss1:0.0001 loss2:0.0012 loss3:0.0599 | AUC:0.8461 Anomaly AUC:0.6632
[2023-08-25 04:01:07,689][main.py][line:91][INFO] [Epoch:40/50]: loss1:0.0043 loss2:0.0111 loss3:0.0620 | AUC:0.8437 Anomaly AUC:0.6712
[2023-08-25 04:04:05,839][main.py][line:91][INFO] [Epoch:41/50]: loss1:0.0004 loss2:0.0029 loss3:0.0616 | AUC:0.8495 Anomaly AUC:0.6779
[2023-08-25 04:07:06,317][main.py][line:91][INFO] [Epoch:42/50]: loss1:0.0001 loss2:0.0012 loss3:0.0604 | AUC:0.8480 Anomaly AUC:0.6728
[2023-08-25 04:10:02,348][main.py][line:91][INFO] [Epoch:43/50]: loss1:0.0001 loss2:0.0012 loss3:0.0600 | AUC:0.8482 Anomaly AUC:0.6709
[2023-08-25 04:12:58,921][main.py][line:91][INFO] [Epoch:44/50]: loss1:0.0001 loss2:0.0011 loss3:0.0598 | AUC:0.8483 Anomaly AUC:0.6710
[2023-08-25 04:15:38,488][main.py][line:91][INFO] [Epoch:45/50]: loss1:0.0001 loss2:0.0010 loss3:0.0597 | AUC:0.8527 Anomaly AUC:0.6760
[2023-08-25 04:18:37,687][main.py][line:91][INFO] [Epoch:46/50]: loss1:0.0001 loss2:0.0009 loss3:0.0598 | AUC:0.8505 Anomaly AUC:0.6706
[2023-08-25 04:21:29,175][main.py][line:91][INFO] [Epoch:47/50]: loss1:0.0001 loss2:0.0009 loss3:0.0596 | AUC:0.8522 Anomaly AUC:0.6736
[2023-08-25 04:24:30,964][main.py][line:91][INFO] [Epoch:48/50]: loss1:0.0001 loss2:0.0009 loss3:0.0597 | AUC:0.8519 Anomaly AUC:0.6714
[2023-08-25 04:27:31,777][main.py][line:91][INFO] [Epoch:49/50]: loss1:0.0001 loss2:0.0010 loss3:0.0597 | AUC:0.8560 Anomaly AUC:0.6806
[2023-08-25 04:30:36,752][main.py][line:91][INFO] [Epoch:50/50]: loss1:0.0000 loss2:0.0006 loss3:0.0598 | AUC:0.8557 Anomaly AUC:0.6830
[2023-08-25 04:30:36,782][main.py][line:99][INFO] Training completes in 157m 0s | best AUCAUC:0.8565 Anomaly AUC:0.6718

[2023-08-25 11:27:01,282][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 11:27:01,429][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 11:27:01,429][main.py][line:150][INFO] Test Mode
[2023-08-25 11:27:01,429][main.py][line:29][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-25 11:27:10,592][infer.py][line:47][INFO] offline AUC:0.8582 AP:0.3178 FAR:0.0068 | Complete in 0m 9s

[2023-08-25 11:28:49,924][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 11:28:50,047][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 11:28:50,048][main.py][line:150][INFO] Test Mode
[2023-08-25 11:28:50,048][main.py][line:29][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-25 11:28:58,982][infer.py][line:47][INFO] offline AUC:0.8582 AP:0.3178 FAR:0.0068 | Complete in 0m 9s

[2023-08-25 11:29:47,635][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 11:29:47,746][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 11:29:47,746][main.py][line:145][INFO] Training Mode
[2023-08-25 11:29:47,746][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 11:29:47,746][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 11:29:55,829][main.py][line:69][INFO] Random initialize AUCAUC:0.4188 Anomaly AUC:0.46923
[2023-08-25 11:32:09,089][main.py][line:91][INFO] [Epoch:1/100]: loss1:0.4515 loss2:1.0476 loss3:0.3178 | AUC:0.8201 Anomaly AUC:0.6451
[2023-08-25 11:34:23,495][main.py][line:91][INFO] [Epoch:2/100]: loss1:0.1922 loss2:0.7793 loss3:0.1408 | AUC:0.8180 Anomaly AUC:0.6376
[2023-08-25 11:36:28,343][main.py][line:91][INFO] [Epoch:3/100]: loss1:0.0956 loss2:0.6360 loss3:0.0783 | AUC:0.7975 Anomaly AUC:0.6315
[2023-08-25 11:38:32,745][main.py][line:91][INFO] [Epoch:4/100]: loss1:0.0529 loss2:0.5152 loss3:0.0714 | AUC:0.7990 Anomaly AUC:0.6251
[2023-08-25 11:40:45,909][main.py][line:91][INFO] [Epoch:5/100]: loss1:0.0329 loss2:0.4006 loss3:0.0687 | AUC:0.8060 Anomaly AUC:0.6150
[2023-08-25 11:43:10,232][main.py][line:91][INFO] [Epoch:6/100]: loss1:0.0200 loss2:0.2910 loss3:0.0675 | AUC:0.8121 Anomaly AUC:0.6200
[2023-08-25 11:45:43,166][main.py][line:91][INFO] [Epoch:7/100]: loss1:0.0166 loss2:0.1993 loss3:0.0674 | AUC:0.8319 Anomaly AUC:0.6404
[2023-08-25 11:48:09,551][main.py][line:91][INFO] [Epoch:8/100]: loss1:0.0120 loss2:0.1355 loss3:0.0672 | AUC:0.8222 Anomaly AUC:0.6422
[2023-08-25 11:50:21,591][main.py][line:91][INFO] [Epoch:9/100]: loss1:0.0202 loss2:0.1112 loss3:0.0680 | AUC:0.7924 Anomaly AUC:0.6169
[2023-08-25 11:52:55,843][main.py][line:91][INFO] [Epoch:10/100]: loss1:0.0015 loss2:0.0384 loss3:0.0647 | AUC:0.8052 Anomaly AUC:0.6234
[2023-08-25 11:55:17,289][main.py][line:91][INFO] [Epoch:11/100]: loss1:0.0133 loss2:0.0781 loss3:0.0658 | AUC:0.8067 Anomaly AUC:0.6203
[2023-08-25 11:57:35,840][main.py][line:91][INFO] [Epoch:12/100]: loss1:0.0164 loss2:0.0674 loss3:0.0672 | AUC:0.8192 Anomaly AUC:0.6221
[2023-08-25 11:59:54,104][main.py][line:91][INFO] [Epoch:13/100]: loss1:0.0102 loss2:0.0361 loss3:0.0650 | AUC:0.8262 Anomaly AUC:0.6085
[2023-08-25 12:02:23,858][main.py][line:91][INFO] [Epoch:14/100]: loss1:0.0039 loss2:0.0213 loss3:0.0639 | AUC:0.7771 Anomaly AUC:0.6058
[2023-08-25 12:04:49,697][main.py][line:91][INFO] [Epoch:15/100]: loss1:0.0199 loss2:0.0571 loss3:0.0668 | AUC:0.8084 Anomaly AUC:0.6315
[2023-08-25 12:07:04,166][main.py][line:91][INFO] [Epoch:16/100]: loss1:0.0043 loss2:0.0170 loss3:0.0642 | AUC:0.8226 Anomaly AUC:0.6122
[2023-08-25 12:09:33,593][main.py][line:91][INFO] [Epoch:17/100]: loss1:0.0007 loss2:0.0071 loss3:0.0630 | AUC:0.8145 Anomaly AUC:0.6128
[2023-08-25 12:11:53,598][main.py][line:91][INFO] [Epoch:18/100]: loss1:0.0001 loss2:0.0017 loss3:0.0627 | AUC:0.7892 Anomaly AUC:0.6139
[2023-08-25 12:14:01,310][main.py][line:91][INFO] [Epoch:19/100]: loss1:0.0030 loss2:0.0044 loss3:0.0622 | AUC:0.8167 Anomaly AUC:0.6139
[2023-08-25 12:16:23,776][main.py][line:91][INFO] [Epoch:20/100]: loss1:0.0114 loss2:0.0351 loss3:0.0633 | AUC:0.8017 Anomaly AUC:0.6317
[2023-08-25 12:17:15,491][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 12:17:15,657][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 12:17:15,657][main.py][line:145][INFO] Training Mode
[2023-08-25 12:17:15,658][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 12:17:15,658][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-08-25 12:17:24,086][main.py][line:69][INFO] Random initialize AUCAUC:0.4188 Anomaly AUC:0.46923
[2023-08-25 12:21:22,133][main.py][line:91][INFO] [Epoch:1/100]: loss1:0.4515 loss2:1.0476 loss3:0.3178 | AUC:0.8201 Anomaly AUC:0.6451
[2023-08-25 12:25:46,474][main.py][line:91][INFO] [Epoch:2/100]: loss1:0.1922 loss2:0.7793 loss3:0.1408 | AUC:0.8180 Anomaly AUC:0.6376
[2023-08-25 12:28:39,035][main.py][line:91][INFO] [Epoch:3/100]: loss1:0.0956 loss2:0.6360 loss3:0.0783 | AUC:0.7975 Anomaly AUC:0.6315
[2023-08-25 12:31:26,480][main.py][line:91][INFO] [Epoch:4/100]: loss1:0.0529 loss2:0.5152 loss3:0.0714 | AUC:0.7990 Anomaly AUC:0.6251
[2023-08-25 12:35:03,135][main.py][line:91][INFO] [Epoch:5/100]: loss1:0.0329 loss2:0.4006 loss3:0.0687 | AUC:0.8060 Anomaly AUC:0.6150
[2023-08-25 12:38:39,918][main.py][line:91][INFO] [Epoch:6/100]: loss1:0.0200 loss2:0.2910 loss3:0.0675 | AUC:0.8121 Anomaly AUC:0.6200
[2023-08-25 12:42:29,655][main.py][line:91][INFO] [Epoch:7/100]: loss1:0.0166 loss2:0.1993 loss3:0.0674 | AUC:0.8319 Anomaly AUC:0.6404
[2023-08-25 12:47:14,205][main.py][line:91][INFO] [Epoch:8/100]: loss1:0.0120 loss2:0.1355 loss3:0.0672 | AUC:0.8222 Anomaly AUC:0.6422
[2023-08-25 12:51:20,930][main.py][line:91][INFO] [Epoch:9/100]: loss1:0.0202 loss2:0.1112 loss3:0.0680 | AUC:0.7924 Anomaly AUC:0.6169
[2023-08-25 12:56:21,915][main.py][line:91][INFO] [Epoch:10/100]: loss1:0.0015 loss2:0.0384 loss3:0.0647 | AUC:0.8052 Anomaly AUC:0.6234
[2023-08-25 13:01:00,007][main.py][line:91][INFO] [Epoch:11/100]: loss1:0.0133 loss2:0.0781 loss3:0.0658 | AUC:0.8067 Anomaly AUC:0.6203
[2023-08-25 13:04:31,990][main.py][line:91][INFO] [Epoch:12/100]: loss1:0.0164 loss2:0.0674 loss3:0.0672 | AUC:0.8192 Anomaly AUC:0.6221
[2023-08-25 13:08:14,328][main.py][line:91][INFO] [Epoch:13/100]: loss1:0.0102 loss2:0.0361 loss3:0.0650 | AUC:0.8262 Anomaly AUC:0.6085
[2023-08-25 13:12:03,329][main.py][line:91][INFO] [Epoch:14/100]: loss1:0.0039 loss2:0.0213 loss3:0.0639 | AUC:0.7771 Anomaly AUC:0.6058
[2023-08-25 13:12:52,892][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 13:12:53,045][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 13:12:53,045][main.py][line:145][INFO] Training Mode
[2023-08-25 13:12:53,045][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 13:12:53,046][main.py][line:66][INFO] Optimizer:RAdam (
Parameter Group 0
    betas: (0.9, 0.999)
    differentiable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0003
    lr: 0.0003
    weight_decay: 0
)

[2023-08-25 13:13:01,183][main.py][line:69][INFO] Random initialize AUCAUC:0.4188 Anomaly AUC:0.46923
[2023-08-25 13:16:07,317][main.py][line:91][INFO] [Epoch:1/100]: loss1:0.5019 loss2:1.2058 loss3:0.3864 | AUC:0.8425 Anomaly AUC:0.6591
[2023-08-25 13:19:20,144][main.py][line:91][INFO] [Epoch:2/100]: loss1:0.2024 loss2:0.8302 loss3:0.3792 | AUC:0.8269 Anomaly AUC:0.6457
[2023-08-25 13:21:47,803][main.py][line:91][INFO] [Epoch:3/100]: loss1:0.0815 loss2:0.6743 loss3:0.3617 | AUC:0.8380 Anomaly AUC:0.6473
[2023-08-25 13:24:17,147][main.py][line:91][INFO] [Epoch:4/100]: loss1:0.0317 loss2:0.5536 loss3:0.3215 | AUC:0.8222 Anomaly AUC:0.6058
[2023-08-25 13:27:15,737][main.py][line:91][INFO] [Epoch:5/100]: loss1:0.0141 loss2:0.4448 loss3:0.1855 | AUC:0.8001 Anomaly AUC:0.5377
[2023-08-25 13:30:53,933][main.py][line:91][INFO] [Epoch:6/100]: loss1:0.0247 loss2:0.3541 loss3:0.1029 | AUC:0.7851 Anomaly AUC:0.5983
[2023-08-25 13:34:43,752][main.py][line:91][INFO] [Epoch:7/100]: loss1:0.0315 loss2:0.3263 loss3:0.0814 | AUC:0.7948 Anomaly AUC:0.5807
[2023-08-25 13:35:00,593][main.py][line:106][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 9, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 13:35:00,760][main.py][line:142][INFO] total params:7.5707M
[2023-08-25 13:35:00,760][main.py][line:145][INFO] Training Mode
[2023-08-25 13:35:00,760][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 13:35:00,760][main.py][line:66][INFO] Optimizer:RAdam (
Parameter Group 0
    betas: (0.9, 0.999)
    differentiable: False
    eps: 1e-08
    foreach: None
    lr: 0.0003
    weight_decay: 0
)

[2023-08-25 13:35:08,581][main.py][line:69][INFO] Random initialize AUCAUC:0.4188 Anomaly AUC:0.46923
[2023-08-25 13:37:40,815][main.py][line:91][INFO] [Epoch:1/100]: loss1:0.5019 loss2:1.2058 loss3:0.3864 | AUC:0.8425 Anomaly AUC:0.6591
[2023-08-25 13:40:14,334][main.py][line:91][INFO] [Epoch:2/100]: loss1:0.2000 loss2:0.8273 loss3:0.3790 | AUC:0.8185 Anomaly AUC:0.6317
[2023-08-25 13:42:23,394][main.py][line:91][INFO] [Epoch:3/100]: loss1:0.0856 loss2:0.6777 loss3:0.3618 | AUC:0.8248 Anomaly AUC:0.6290
[2023-08-25 13:44:26,052][main.py][line:91][INFO] [Epoch:4/100]: loss1:0.0276 loss2:0.5468 loss3:0.3186 | AUC:0.8386 Anomaly AUC:0.6344
[2023-08-25 13:47:03,550][main.py][line:91][INFO] [Epoch:5/100]: loss1:0.0076 loss2:0.4169 loss3:0.1751 | AUC:0.8122 Anomaly AUC:0.5544
[2023-08-25 13:49:26,017][main.py][line:91][INFO] [Epoch:6/100]: loss1:0.0516 loss2:0.3839 loss3:0.0974 | AUC:0.8012 Anomaly AUC:0.5598
[2023-08-25 13:51:53,957][main.py][line:91][INFO] [Epoch:7/100]: loss1:0.0244 loss2:0.3138 loss3:0.0763 | AUC:0.8233 Anomaly AUC:0.5903
[2023-08-25 13:54:56,643][main.py][line:91][INFO] [Epoch:8/100]: loss1:0.0307 loss2:0.2726 loss3:0.0739 | AUC:0.7490 Anomaly AUC:0.5573
[2023-08-25 13:57:25,772][main.py][line:91][INFO] [Epoch:9/100]: loss1:0.0056 loss2:0.1720 loss3:0.0687 | AUC:0.7969 Anomaly AUC:0.5234
[2023-08-25 14:00:17,862][main.py][line:91][INFO] [Epoch:10/100]: loss1:0.0525 loss2:0.2139 loss3:0.0732 | AUC:0.8009 Anomaly AUC:0.5845
[2023-08-25 14:03:24,765][main.py][line:91][INFO] [Epoch:11/100]: loss1:0.0224 loss2:0.2062 loss3:0.0692 | AUC:0.7952 Anomaly AUC:0.5674
[2023-08-25 14:06:00,791][main.py][line:91][INFO] [Epoch:12/100]: loss1:0.3899 loss2:0.7356 loss3:0.1015 | AUC:0.7821 Anomaly AUC:0.5645
[2023-08-25 14:08:29,549][main.py][line:91][INFO] [Epoch:13/100]: loss1:0.3405 loss2:0.9288 loss3:0.0849 | AUC:0.7903 Anomaly AUC:0.5849
[2023-08-25 14:10:53,966][main.py][line:91][INFO] [Epoch:14/100]: loss1:0.2194 loss2:0.7684 loss3:0.0787 | AUC:0.7727 Anomaly AUC:0.5812
[2023-08-25 14:13:16,601][main.py][line:91][INFO] [Epoch:15/100]: loss1:0.1507 loss2:0.6555 loss3:0.0765 | AUC:0.7783 Anomaly AUC:0.5751
[2023-08-25 14:15:43,175][main.py][line:91][INFO] [Epoch:16/100]: loss1:0.1041 loss2:0.5710 loss3:0.0752 | AUC:0.7762 Anomaly AUC:0.5709
[2023-08-25 14:18:27,924][main.py][line:91][INFO] [Epoch:17/100]: loss1:0.0760 loss2:0.5091 loss3:0.0742 | AUC:0.7852 Anomaly AUC:0.5686
[2023-08-25 14:21:08,185][main.py][line:91][INFO] [Epoch:18/100]: loss1:0.0486 loss2:0.4457 loss3:0.0741 | AUC:0.7744 Anomaly AUC:0.5697
[2023-08-25 14:23:27,753][main.py][line:91][INFO] [Epoch:19/100]: loss1:0.0423 loss2:0.3958 loss3:0.0738 | AUC:0.7689 Anomaly AUC:0.5676
[2023-08-25 14:25:49,408][main.py][line:91][INFO] [Epoch:20/100]: loss1:0.0277 loss2:0.3251 loss3:0.0735 | AUC:0.7732 Anomaly AUC:0.5615
[2023-08-25 14:28:31,883][main.py][line:91][INFO] [Epoch:21/100]: loss1:0.0188 loss2:0.2673 loss3:0.0732 | AUC:0.7775 Anomaly AUC:0.5705
[2023-08-25 14:30:57,308][main.py][line:91][INFO] [Epoch:22/100]: loss1:0.0254 loss2:0.2470 loss3:0.0729 | AUC:0.7936 Anomaly AUC:0.5715
[2023-08-25 14:33:28,933][main.py][line:91][INFO] [Epoch:23/100]: loss1:0.0169 loss2:0.2158 loss3:0.0726 | AUC:0.7744 Anomaly AUC:0.5743
[2023-08-25 14:35:59,036][main.py][line:91][INFO] [Epoch:24/100]: loss1:0.0065 loss2:0.1350 loss3:0.0722 | AUC:0.7664 Anomaly AUC:0.5723
[2023-08-25 14:38:26,767][main.py][line:91][INFO] [Epoch:25/100]: loss1:0.0146 loss2:0.1094 loss3:0.0718 | AUC:0.7843 Anomaly AUC:0.5751
[2023-08-25 14:43:58,307][main.py][line:107][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 14:43:58,449][main.py][line:143][INFO] total params:7.5707M
[2023-08-25 14:43:58,449][main.py][line:146][INFO] Training Mode
[2023-08-25 14:43:58,449][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 14:43:58,450][main.py][line:66][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 14:44:07,210][main.py][line:69][INFO] Random initialize AUCAUC:0.5717 Anomaly AUC:0.56752
[2023-08-25 14:46:35,952][main.py][line:92][INFO] [Epoch:1/0.0003]: lr:100.00000 | loss1:0.3979 loss2:1.0254 loss3:0.3533 | AUC:0.8224 Anomaly AUC:0.6491
[2023-08-25 14:49:34,304][main.py][line:92][INFO] [Epoch:2/0.0003]: lr:100.00000 | loss1:0.1663 loss2:0.7739 loss3:0.2175 | AUC:0.8328 Anomaly AUC:0.6921
[2023-08-25 14:52:04,705][main.py][line:92][INFO] [Epoch:3/0.0003]: lr:100.00000 | loss1:0.0759 loss2:0.6609 loss3:0.0991 | AUC:0.8465 Anomaly AUC:0.6988
[2023-08-25 14:54:24,908][main.py][line:92][INFO] [Epoch:4/0.0003]: lr:100.00000 | loss1:0.1072 loss2:0.6565 loss3:0.0903 | AUC:0.8365 Anomaly AUC:0.6644
[2023-08-25 14:57:22,889][main.py][line:92][INFO] [Epoch:5/0.0003]: lr:100.00000 | loss1:0.0867 loss2:0.6049 loss3:0.0817 | AUC:0.8509 Anomaly AUC:0.6963
[2023-08-25 15:00:26,756][main.py][line:92][INFO] [Epoch:6/0.0003]: lr:100.00000 | loss1:0.0301 loss2:0.4864 loss3:0.0721 | AUC:0.8584 Anomaly AUC:0.6855
[2023-08-25 15:03:19,284][main.py][line:92][INFO] [Epoch:7/0.0003]: lr:100.00000 | loss1:0.0196 loss2:0.4067 loss3:0.0706 | AUC:0.8476 Anomaly AUC:0.6661
[2023-08-25 15:06:21,223][main.py][line:92][INFO] [Epoch:8/0.0003]: lr:100.00000 | loss1:0.0133 loss2:0.3347 loss3:0.0704 | AUC:0.8554 Anomaly AUC:0.6827
[2023-08-25 15:09:22,736][main.py][line:92][INFO] [Epoch:9/0.0003]: lr:100.00000 | loss1:0.0053 loss2:0.2460 loss3:0.0680 | AUC:0.8369 Anomaly AUC:0.6588
[2023-08-25 15:12:05,916][main.py][line:92][INFO] [Epoch:10/0.0003]: lr:100.00000 | loss1:0.2834 loss2:0.8893 loss3:0.1712 | AUC:0.8239 Anomaly AUC:0.6219
[2023-08-25 15:14:47,974][main.py][line:92][INFO] [Epoch:11/0.0003]: lr:100.00000 | loss1:0.1783 loss2:0.7501 loss3:0.1529 | AUC:0.8200 Anomaly AUC:0.6029
[2023-08-25 15:17:41,791][main.py][line:92][INFO] [Epoch:12/0.0003]: lr:100.00000 | loss1:0.1374 loss2:0.6013 loss3:0.1452 | AUC:0.8242 Anomaly AUC:0.6119
[2023-08-25 15:20:47,950][main.py][line:92][INFO] [Epoch:13/0.0003]: lr:100.00000 | loss1:0.1123 loss2:0.5360 loss3:0.1455 | AUC:0.8267 Anomaly AUC:0.6159
[2023-08-25 15:24:03,568][main.py][line:92][INFO] [Epoch:14/0.0003]: lr:100.00000 | loss1:0.0861 loss2:0.5981 loss3:0.1414 | AUC:0.8276 Anomaly AUC:0.6170
[2023-08-25 15:27:04,582][main.py][line:92][INFO] [Epoch:15/0.0003]: lr:100.00000 | loss1:0.0675 loss2:0.5785 loss3:0.1227 | AUC:0.8290 Anomaly AUC:0.6173
[2023-08-25 15:30:14,095][main.py][line:92][INFO] [Epoch:16/0.0003]: lr:100.00000 | loss1:0.0598 loss2:0.5491 loss3:0.1058 | AUC:0.8363 Anomaly AUC:0.6334
[2023-08-25 15:33:00,004][main.py][line:92][INFO] [Epoch:17/0.0003]: lr:100.00000 | loss1:0.0476 loss2:0.5151 loss3:0.0948 | AUC:0.8286 Anomaly AUC:0.6166
[2023-08-25 15:36:21,651][main.py][line:92][INFO] [Epoch:18/0.0003]: lr:100.00000 | loss1:0.0336 loss2:0.4809 loss3:0.0896 | AUC:0.8330 Anomaly AUC:0.6237
[2023-08-25 15:39:17,425][main.py][line:92][INFO] [Epoch:19/0.0003]: lr:100.00000 | loss1:0.0309 loss2:0.4300 loss3:0.0875 | AUC:0.8373 Anomaly AUC:0.6267
[2023-08-25 15:42:00,145][main.py][line:92][INFO] [Epoch:20/0.0003]: lr:100.00000 | loss1:0.0263 loss2:0.3993 loss3:0.0860 | AUC:0.8391 Anomaly AUC:0.6314
[2023-08-25 15:44:26,672][main.py][line:92][INFO] [Epoch:21/0.0003]: lr:100.00000 | loss1:0.0216 loss2:0.3315 loss3:0.0843 | AUC:0.8376 Anomaly AUC:0.6258
[2023-08-25 15:46:56,242][main.py][line:92][INFO] [Epoch:22/0.0003]: lr:100.00000 | loss1:0.0171 loss2:0.2583 loss3:0.0832 | AUC:0.8393 Anomaly AUC:0.6305
[2023-08-25 15:49:30,301][main.py][line:92][INFO] [Epoch:23/0.0003]: lr:100.00000 | loss1:0.0168 loss2:0.2180 loss3:0.0819 | AUC:0.8350 Anomaly AUC:0.6194
[2023-08-25 15:52:31,191][main.py][line:92][INFO] [Epoch:24/0.0003]: lr:100.00000 | loss1:0.0125 loss2:0.0832 loss3:0.0804 | AUC:0.8367 Anomaly AUC:0.6245
[2023-08-25 15:55:10,664][main.py][line:92][INFO] [Epoch:25/0.0003]: lr:100.00000 | loss1:0.0089 loss2:0.0597 loss3:0.0797 | AUC:0.8403 Anomaly AUC:0.6341
[2023-08-25 15:57:43,393][main.py][line:92][INFO] [Epoch:26/0.0003]: lr:100.00000 | loss1:0.0124 loss2:0.0425 loss3:0.0790 | AUC:0.8398 Anomaly AUC:0.6415
[2023-08-25 16:00:34,522][main.py][line:92][INFO] [Epoch:27/0.0003]: lr:100.00000 | loss1:0.0208 loss2:0.0924 loss3:0.0784 | AUC:0.8320 Anomaly AUC:0.6185
[2023-08-25 16:03:09,801][main.py][line:92][INFO] [Epoch:28/0.0003]: lr:100.00000 | loss1:0.0073 loss2:0.0019 loss3:0.0781 | AUC:0.8315 Anomaly AUC:0.6208
[2023-08-25 16:05:46,488][main.py][line:92][INFO] [Epoch:29/0.0003]: lr:100.00000 | loss1:0.0148 loss2:0.0621 loss3:0.0783 | AUC:0.8331 Anomaly AUC:0.6215
[2023-08-25 16:08:18,299][main.py][line:107][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 16:08:18,449][main.py][line:143][INFO] total params:7.5707M
[2023-08-25 16:08:18,449][main.py][line:146][INFO] Training Mode
[2023-08-25 16:08:18,450][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 16:08:18,450][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 16:08:26,387][main.py][line:69][INFO] Random initialize AUCAUC:0.5717 Anomaly AUC:0.56752
[2023-08-25 16:10:07,606][main.py][line:107][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 16:10:07,734][main.py][line:143][INFO] total params:7.5707M
[2023-08-25 16:10:07,735][main.py][line:146][INFO] Training Mode
[2023-08-25 16:10:07,735][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 16:10:07,735][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 16:10:16,335][main.py][line:69][INFO] Random initialize AUCAUC:0.5711 Anomaly AUC:0.56142
[2023-08-25 16:10:43,473][main.py][line:107][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 16:10:43,606][main.py][line:143][INFO] total params:7.0451M
[2023-08-25 16:10:43,606][main.py][line:146][INFO] Training Mode
[2023-08-25 16:10:43,607][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 16:10:43,607][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 16:10:51,055][main.py][line:69][INFO] Random initialize AUCAUC:0.6062 Anomaly AUC:0.57717
[2023-08-25 16:14:00,008][main.py][line:92][INFO] [Epoch:1/100]: lr:0.00030 | loss1:0.3917 loss2:1.4090 loss3:0.3668 | AUC:0.7836 Anomaly AUC:0.5674
[2023-08-25 16:16:29,258][main.py][line:92][INFO] [Epoch:2/100]: lr:0.00030 | loss1:0.1930 loss2:1.4025 loss3:0.2054 | AUC:0.7664 Anomaly AUC:0.5479
[2023-08-25 16:18:41,710][main.py][line:92][INFO] [Epoch:3/100]: lr:0.00030 | loss1:0.1029 loss2:1.3924 loss3:0.0844 | AUC:0.7681 Anomaly AUC:0.5257
[2023-08-25 16:20:47,554][main.py][line:92][INFO] [Epoch:4/100]: lr:0.00030 | loss1:0.0648 loss2:1.3901 loss3:0.0721 | AUC:0.7703 Anomaly AUC:0.5411
[2023-08-25 16:23:07,135][main.py][line:92][INFO] [Epoch:5/100]: lr:0.00030 | loss1:0.0270 loss2:1.3864 loss3:0.0675 | AUC:0.7893 Anomaly AUC:0.5438
[2023-08-25 16:25:59,466][main.py][line:92][INFO] [Epoch:6/100]: lr:0.00030 | loss1:0.0303 loss2:1.3784 loss3:0.0664 | AUC:0.7901 Anomaly AUC:0.5564
[2023-08-25 16:28:49,590][main.py][line:92][INFO] [Epoch:7/100]: lr:0.00030 | loss1:0.0298 loss2:1.3654 loss3:0.0659 | AUC:0.7845 Anomaly AUC:0.5550
[2023-08-25 16:30:24,650][main.py][line:107][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 16:30:24,771][main.py][line:143][INFO] total params:3.3693M
[2023-08-25 16:30:24,771][main.py][line:146][INFO] Training Mode
[2023-08-25 16:30:24,771][main.py][line:65][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 16:30:24,771][main.py][line:66][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 16:30:35,226][main.py][line:69][INFO] Random initialize AUCAUC:0.4335 Anomaly AUC:0.46871
[2023-08-25 16:34:41,835][main.py][line:92][INFO] [Epoch:1/100]: lr:0.00030 | loss1:0.4552 loss2:1.1334 loss3:0.3805 | AUC:0.8316 Anomaly AUC:0.6520
[2023-08-25 16:41:13,370][main.py][line:92][INFO] [Epoch:2/100]: lr:0.00030 | loss1:0.2714 loss2:0.9384 loss3:0.3773 | AUC:0.8278 Anomaly AUC:0.6344
[2023-08-25 16:44:29,882][main.py][line:92][INFO] [Epoch:3/100]: lr:0.00030 | loss1:0.2153 loss2:0.8643 loss3:0.3750 | AUC:0.8332 Anomaly AUC:0.6402
[2023-08-25 16:47:11,975][main.py][line:92][INFO] [Epoch:4/100]: lr:0.00030 | loss1:0.1791 loss2:0.8085 loss3:0.3729 | AUC:0.8325 Anomaly AUC:0.6359
[2023-08-25 16:51:57,416][main.py][line:92][INFO] [Epoch:5/100]: lr:0.00030 | loss1:0.1433 loss2:0.7497 loss3:0.3704 | AUC:0.8401 Anomaly AUC:0.6432
[2023-08-25 16:58:53,555][main.py][line:92][INFO] [Epoch:6/100]: lr:0.00030 | loss1:0.1106 loss2:0.6932 loss3:0.3676 | AUC:0.8295 Anomaly AUC:0.6262
[2023-08-25 17:05:58,347][main.py][line:92][INFO] [Epoch:7/100]: lr:0.00030 | loss1:0.1085 loss2:0.6574 loss3:0.3654 | AUC:0.8345 Anomaly AUC:0.6387
[2023-08-25 17:12:14,267][main.py][line:92][INFO] [Epoch:8/100]: lr:0.00030 | loss1:0.0830 loss2:0.5991 loss3:0.3628 | AUC:0.8409 Anomaly AUC:0.6460
[2023-08-25 17:19:36,953][main.py][line:92][INFO] [Epoch:9/100]: lr:0.00030 | loss1:0.0737 loss2:0.5556 loss3:0.3610 | AUC:0.8312 Anomaly AUC:0.6305
[2023-08-25 17:24:57,535][main.py][line:92][INFO] [Epoch:10/100]: lr:0.00030 | loss1:0.0687 loss2:0.5247 loss3:0.3597 | AUC:0.8402 Anomaly AUC:0.6408
[2023-08-25 17:29:58,173][main.py][line:92][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0594 loss2:0.4606 loss3:0.3584 | AUC:0.8407 Anomaly AUC:0.6336
[2023-08-25 17:35:18,893][main.py][line:92][INFO] [Epoch:12/100]: lr:0.00030 | loss1:0.0473 loss2:0.3745 loss3:0.3570 | AUC:0.8419 Anomaly AUC:0.6414
[2023-08-25 17:42:14,707][main.py][line:92][INFO] [Epoch:13/100]: lr:0.00030 | loss1:0.0528 loss2:0.3514 loss3:0.3559 | AUC:0.8382 Anomaly AUC:0.6384
[2023-08-25 17:47:25,696][main.py][line:92][INFO] [Epoch:14/100]: lr:0.00030 | loss1:0.0443 loss2:0.2817 loss3:0.3548 | AUC:0.8430 Anomaly AUC:0.6499
[2023-08-25 17:51:54,289][main.py][line:92][INFO] [Epoch:15/100]: lr:0.00030 | loss1:0.0222 loss2:0.0938 loss3:0.3535 | AUC:0.8457 Anomaly AUC:0.6525
[2023-08-25 17:55:38,820][main.py][line:92][INFO] [Epoch:16/100]: lr:0.00030 | loss1:0.0359 loss2:0.1970 loss3:0.3515 | AUC:0.8449 Anomaly AUC:0.6527
[2023-08-25 18:00:31,228][main.py][line:92][INFO] [Epoch:17/100]: lr:0.00030 | loss1:0.0218 loss2:0.1432 loss3:0.3503 | AUC:0.8445 Anomaly AUC:0.6519
[2023-08-25 18:04:50,718][main.py][line:92][INFO] [Epoch:18/100]: lr:0.00030 | loss1:0.0302 loss2:0.1784 loss3:0.3472 | AUC:0.8328 Anomaly AUC:0.6462
[2023-08-25 18:08:23,619][main.py][line:92][INFO] [Epoch:19/100]: lr:0.00030 | loss1:0.0287 loss2:0.2525 loss3:0.3453 | AUC:0.8445 Anomaly AUC:0.6551
[2023-08-25 18:13:24,360][main.py][line:92][INFO] [Epoch:20/100]: lr:0.00030 | loss1:0.0320 loss2:0.1855 loss3:0.3431 | AUC:0.8332 Anomaly AUC:0.6376
[2023-08-25 18:19:48,798][main.py][line:92][INFO] [Epoch:21/100]: lr:0.00030 | loss1:0.0216 loss2:0.1322 loss3:0.3390 | AUC:0.8341 Anomaly AUC:0.6499
[2023-08-25 18:24:15,877][main.py][line:92][INFO] [Epoch:22/100]: lr:0.00030 | loss1:0.0215 loss2:0.2269 loss3:0.3343 | AUC:0.8356 Anomaly AUC:0.6571
[2023-08-25 18:27:26,367][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 18:27:26,502][main.py][line:145][INFO] total params:3.3693M
[2023-08-25 18:27:26,502][main.py][line:148][INFO] Training Mode
[2023-08-25 18:27:26,503][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 18:27:26,503][main.py][line:68][INFO] Optimizer:Lamb (
Parameter Group 0
    betas: (0.9, 0.999)
    eps: 1e-06
    lr: 0.0025
    weight_decay: 0.01
)

[2023-08-25 18:27:34,300][main.py][line:71][INFO] Random initialize AUCAUC:0.4335 Anomaly AUC:0.46871
[2023-08-25 18:31:01,616][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00250 | loss1:0.4763 loss2:1.1321 loss3:0.3785 | AUC:0.8359 Anomaly AUC:0.6420
[2023-08-25 18:36:27,112][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00250 | loss1:0.2849 loss2:0.8079 loss3:0.3769 | AUC:0.8295 Anomaly AUC:0.6491
[2023-08-25 18:39:11,694][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00250 | loss1:0.2149 loss2:0.6290 loss3:0.3770 | AUC:0.8380 Anomaly AUC:0.6631
[2023-08-25 18:41:39,181][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00250 | loss1:0.1808 loss2:0.4572 loss3:0.3756 | AUC:0.8390 Anomaly AUC:0.6537
[2023-08-25 18:47:08,640][main.py][line:94][INFO] [Epoch:5/100]: lr:0.00250 | loss1:0.1481 loss2:0.2552 loss3:0.3737 | AUC:0.8396 Anomaly AUC:0.6478
[2023-08-25 18:52:13,206][main.py][line:94][INFO] [Epoch:6/100]: lr:0.00250 | loss1:0.1426 loss2:0.2675 loss3:0.3716 | AUC:0.8325 Anomaly AUC:0.6585
[2023-08-25 18:58:44,099][main.py][line:94][INFO] [Epoch:7/100]: lr:0.00250 | loss1:0.1201 loss2:0.2806 loss3:0.3685 | AUC:0.8420 Anomaly AUC:0.6654
[2023-08-25 19:04:41,330][main.py][line:94][INFO] [Epoch:8/100]: lr:0.00250 | loss1:0.0995 loss2:0.2605 loss3:0.3635 | AUC:0.8394 Anomaly AUC:0.6587
[2023-08-25 19:08:02,103][main.py][line:94][INFO] [Epoch:9/100]: lr:0.00250 | loss1:0.0942 loss2:0.3046 loss3:0.3581 | AUC:0.8391 Anomaly AUC:0.6733
[2023-08-25 19:11:02,617][main.py][line:94][INFO] [Epoch:10/100]: lr:0.00250 | loss1:0.0830 loss2:0.3512 loss3:0.3551 | AUC:0.8457 Anomaly AUC:0.6766
[2023-08-25 19:14:55,796][main.py][line:94][INFO] [Epoch:11/100]: lr:0.00250 | loss1:0.0723 loss2:0.3356 loss3:0.3557 | AUC:0.8386 Anomaly AUC:0.6691
[2023-08-25 19:19:06,569][main.py][line:94][INFO] [Epoch:12/100]: lr:0.00250 | loss1:0.0691 loss2:0.3048 loss3:0.3582 | AUC:0.8253 Anomaly AUC:0.6655
[2023-08-25 19:23:16,031][main.py][line:94][INFO] [Epoch:13/100]: lr:0.00250 | loss1:0.0451 loss2:0.2616 loss3:0.3587 | AUC:0.8415 Anomaly AUC:0.6773
[2023-08-25 19:28:14,905][main.py][line:94][INFO] [Epoch:14/100]: lr:0.00250 | loss1:0.0416 loss2:0.2298 loss3:0.3584 | AUC:0.8397 Anomaly AUC:0.6716
[2023-08-25 19:32:55,246][main.py][line:94][INFO] [Epoch:15/100]: lr:0.00250 | loss1:0.0339 loss2:0.1740 loss3:0.3572 | AUC:0.8235 Anomaly AUC:0.6671
[2023-08-25 19:35:03,207][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.3, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 19:35:03,347][main.py][line:145][INFO] total params:3.3693M
[2023-08-25 19:35:03,347][main.py][line:148][INFO] Training Mode
[2023-08-25 19:35:03,348][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 19:35:03,348][main.py][line:68][INFO] Optimizer:Lamb (
Parameter Group 0
    betas: (0.9, 0.999)
    eps: 1e-06
    lr: 0.0025
    weight_decay: 0.01
)

[2023-08-25 19:35:09,780][main.py][line:71][INFO] Random initialize AUCAUC:0.4335 Anomaly AUC:0.46871
[2023-08-25 19:36:10,964][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00250 | loss1:0.1027 loss2:0.9825 loss3:0.3885 | AUC:0.6861 Anomaly AUC:0.6019
[2023-08-25 19:37:22,718][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00250 | loss1:0.0012 loss2:0.5886 loss3:0.3861 | AUC:0.6257 Anomaly AUC:0.5636
[2023-08-25 19:38:53,484][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.3, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 19:38:53,606][main.py][line:145][INFO] total params:3.3693M
[2023-08-25 19:38:53,606][main.py][line:148][INFO] Training Mode
[2023-08-25 19:38:53,607][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 19:38:53,607][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 19:39:00,187][main.py][line:71][INFO] Random initialize AUCAUC:0.4335 Anomaly AUC:0.46871
[2023-08-25 19:40:36,028][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0429 loss2:0.9083 loss3:0.3877 | AUC:0.7043 Anomaly AUC:0.6145
[2023-08-25 19:42:43,413][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0016 loss2:0.7236 loss3:0.3874 | AUC:0.6952 Anomaly AUC:0.6167
[2023-08-25 19:44:17,025][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0008 loss2:0.6622 loss3:0.3868 | AUC:0.6721 Anomaly AUC:0.5998
[2023-08-25 19:45:45,454][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00049 | loss1:0.0005 loss2:0.6164 loss3:0.3868 | AUC:0.6779 Anomaly AUC:0.6026
[2023-08-25 19:46:57,300][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 19:46:57,450][main.py][line:145][INFO] total params:7.5707M
[2023-08-25 19:46:57,450][main.py][line:148][INFO] Training Mode
[2023-08-25 19:46:57,451][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 19:46:57,451][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 19:47:05,540][main.py][line:71][INFO] Random initialize AUCAUC:0.5671 Anomaly AUC:0.56435
[2023-08-25 19:48:43,335][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4960 loss2:1.1234 loss3:0.3142 | AUC:0.8177 Anomaly AUC:0.6264
[2023-08-25 19:50:30,599][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1679 loss2:0.8386 loss3:0.1966 | AUC:0.8299 Anomaly AUC:0.6782
[2023-08-25 19:51:47,769][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0159 loss2:0.6718 loss3:0.0996 | AUC:0.8266 Anomaly AUC:0.6626
[2023-08-25 19:53:05,990][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00049 | loss1:0.0106 loss2:0.5897 loss3:0.0635 | AUC:0.8336 Anomaly AUC:0.6662
[2023-08-25 19:54:44,730][main.py][line:94][INFO] [Epoch:5/100]: lr:0.00049 | loss1:0.0061 loss2:0.4992 loss3:0.0450 | AUC:0.8266 Anomaly AUC:0.6584
[2023-08-25 19:56:37,818][main.py][line:94][INFO] [Epoch:6/100]: lr:0.00049 | loss1:0.0061 loss2:0.4273 loss3:0.0480 | AUC:0.8187 Anomaly AUC:0.6439
[2023-08-25 19:58:17,490][main.py][line:94][INFO] [Epoch:7/100]: lr:0.00048 | loss1:0.0032 loss2:0.3227 loss3:0.0303 | AUC:0.8187 Anomaly AUC:0.6568
[2023-08-25 20:00:35,051][main.py][line:94][INFO] [Epoch:8/100]: lr:0.00048 | loss1:0.0039 loss2:0.2462 loss3:0.0325 | AUC:0.7601 Anomaly AUC:0.6613
[2023-08-25 20:02:32,505][main.py][line:94][INFO] [Epoch:9/100]: lr:0.00047 | loss1:0.0040 loss2:0.2072 loss3:0.0342 | AUC:0.8380 Anomaly AUC:0.6763
[2023-08-25 20:04:02,790][main.py][line:94][INFO] [Epoch:10/100]: lr:0.00047 | loss1:0.0026 loss2:0.1226 loss3:0.0180 | AUC:0.8391 Anomaly AUC:0.6928
[2023-08-25 20:05:53,402][main.py][line:94][INFO] [Epoch:11/100]: lr:0.00046 | loss1:0.0031 loss2:0.1189 loss3:0.0279 | AUC:0.8400 Anomaly AUC:0.6691
[2023-08-25 20:07:42,124][main.py][line:94][INFO] [Epoch:12/100]: lr:0.00045 | loss1:0.0043 loss2:0.0984 loss3:0.0251 | AUC:0.8354 Anomaly AUC:0.6705
[2023-08-25 20:09:41,466][main.py][line:94][INFO] [Epoch:13/100]: lr:0.00044 | loss1:0.0038 loss2:0.0689 loss3:0.0236 | AUC:0.8264 Anomaly AUC:0.6982
[2023-08-25 20:11:26,352][main.py][line:94][INFO] [Epoch:14/100]: lr:0.00044 | loss1:0.0014 loss2:0.0500 loss3:0.0146 | AUC:0.8342 Anomaly AUC:0.6837
[2023-08-25 20:13:19,148][main.py][line:94][INFO] [Epoch:15/100]: lr:0.00043 | loss1:0.0093 loss2:0.1016 loss3:0.0475 | AUC:0.8226 Anomaly AUC:0.7008
[2023-08-25 20:15:10,902][main.py][line:94][INFO] [Epoch:16/100]: lr:0.00042 | loss1:0.0031 loss2:0.0569 loss3:0.0226 | AUC:0.8308 Anomaly AUC:0.6702
[2023-08-25 20:17:11,156][main.py][line:94][INFO] [Epoch:17/100]: lr:0.00041 | loss1:0.0016 loss2:0.0317 loss3:0.0133 | AUC:0.8214 Anomaly AUC:0.6819
[2023-08-25 20:18:43,172][main.py][line:94][INFO] [Epoch:18/100]: lr:0.00040 | loss1:0.0034 loss2:0.0526 loss3:0.0278 | AUC:0.8306 Anomaly AUC:0.6691
[2023-08-25 20:20:34,555][main.py][line:94][INFO] [Epoch:19/100]: lr:0.00039 | loss1:0.0009 loss2:0.0233 loss3:0.0110 | AUC:0.8340 Anomaly AUC:0.6600
[2023-08-25 20:22:17,230][main.py][line:94][INFO] [Epoch:20/100]: lr:0.00038 | loss1:0.0004 loss2:0.0136 loss3:0.0063 | AUC:0.8199 Anomaly AUC:0.6447
[2023-08-25 20:24:08,636][main.py][line:94][INFO] [Epoch:21/100]: lr:0.00036 | loss1:0.0004 loss2:0.0131 loss3:0.0054 | AUC:0.8274 Anomaly AUC:0.6700
[2023-08-25 20:25:27,969][main.py][line:94][INFO] [Epoch:22/100]: lr:0.00035 | loss1:0.0010 loss2:0.0166 loss3:0.0071 | AUC:0.8382 Anomaly AUC:0.6751
[2023-08-25 20:27:00,425][main.py][line:94][INFO] [Epoch:23/100]: lr:0.00034 | loss1:0.0002 loss2:0.0082 loss3:0.0033 | AUC:0.8402 Anomaly AUC:0.6650
[2023-08-25 20:28:32,333][main.py][line:94][INFO] [Epoch:24/100]: lr:0.00033 | loss1:0.0021 loss2:0.0205 loss3:0.0116 | AUC:0.8217 Anomaly AUC:0.6731
[2023-08-25 20:30:33,404][main.py][line:94][INFO] [Epoch:25/100]: lr:0.00031 | loss1:0.0002 loss2:0.0104 loss3:0.0041 | AUC:0.8294 Anomaly AUC:0.6659
[2023-08-25 20:31:57,586][main.py][line:94][INFO] [Epoch:26/100]: lr:0.00030 | loss1:0.0001 loss2:0.0056 loss3:0.0018 | AUC:0.8330 Anomaly AUC:0.6619
[2023-08-25 20:33:49,426][main.py][line:94][INFO] [Epoch:27/100]: lr:0.00029 | loss1:0.0001 loss2:0.0051 loss3:0.0012 | AUC:0.8328 Anomaly AUC:0.6713
[2023-08-25 20:35:41,405][main.py][line:94][INFO] [Epoch:28/100]: lr:0.00028 | loss1:0.0005 loss2:0.0047 loss3:0.0030 | AUC:0.8218 Anomaly AUC:0.6958
[2023-08-25 20:37:16,387][main.py][line:94][INFO] [Epoch:29/100]: lr:0.00026 | loss1:0.0003 loss2:0.0070 loss3:0.0037 | AUC:0.8299 Anomaly AUC:0.6614
[2023-08-25 20:38:39,554][main.py][line:94][INFO] [Epoch:30/100]: lr:0.00025 | loss1:0.0055 loss2:0.0440 loss3:0.0389 | AUC:0.8410 Anomaly AUC:0.6813
[2023-08-25 20:40:19,282][main.py][line:94][INFO] [Epoch:31/100]: lr:0.00024 | loss1:0.0012 loss2:0.0191 loss3:0.0108 | AUC:0.8311 Anomaly AUC:0.6667
[2023-08-25 20:41:58,587][main.py][line:94][INFO] [Epoch:32/100]: lr:0.00022 | loss1:0.0007 loss2:0.0163 loss3:0.0085 | AUC:0.8128 Anomaly AUC:0.6691
[2023-08-25 20:43:54,932][main.py][line:94][INFO] [Epoch:33/100]: lr:0.00021 | loss1:0.0008 loss2:0.0070 loss3:0.0077 | AUC:0.8212 Anomaly AUC:0.6635
[2023-08-25 20:45:30,910][main.py][line:94][INFO] [Epoch:34/100]: lr:0.00020 | loss1:0.0001 loss2:0.0043 loss3:0.0030 | AUC:0.8345 Anomaly AUC:0.6681
[2023-08-25 20:47:00,181][main.py][line:94][INFO] [Epoch:35/100]: lr:0.00019 | loss1:0.0001 loss2:0.0035 loss3:0.0019 | AUC:0.8351 Anomaly AUC:0.6674
[2023-08-25 20:48:39,883][main.py][line:94][INFO] [Epoch:36/100]: lr:0.00017 | loss1:0.0001 loss2:0.0028 loss3:0.0014 | AUC:0.8355 Anomaly AUC:0.6656
[2023-08-25 20:50:44,824][main.py][line:94][INFO] [Epoch:37/100]: lr:0.00016 | loss1:0.0001 loss2:0.0028 loss3:0.0011 | AUC:0.8367 Anomaly AUC:0.6667
[2023-08-25 20:52:35,538][main.py][line:94][INFO] [Epoch:38/100]: lr:0.00015 | loss1:0.0001 loss2:0.0028 loss3:0.0010 | AUC:0.8351 Anomaly AUC:0.6663
[2023-08-25 20:54:31,708][main.py][line:94][INFO] [Epoch:39/100]: lr:0.00014 | loss1:0.0001 loss2:0.0025 loss3:0.0009 | AUC:0.8347 Anomaly AUC:0.6681
[2023-08-25 20:56:02,743][main.py][line:94][INFO] [Epoch:40/100]: lr:0.00013 | loss1:0.0001 loss2:0.0024 loss3:0.0009 | AUC:0.8352 Anomaly AUC:0.6676
[2023-08-25 20:57:19,828][main.py][line:94][INFO] [Epoch:41/100]: lr:0.00011 | loss1:0.0001 loss2:0.0024 loss3:0.0009 | AUC:0.8324 Anomaly AUC:0.6614
[2023-08-25 20:59:00,302][main.py][line:94][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0001 loss2:0.0024 loss3:0.0008 | AUC:0.8335 Anomaly AUC:0.6662
[2023-08-25 20:59:14,515][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 20:59:14,663][main.py][line:145][INFO] total params:7.0451M
[2023-08-25 20:59:14,663][main.py][line:148][INFO] Training Mode
[2023-08-25 20:59:14,664][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 20:59:14,664][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 20:59:22,193][main.py][line:71][INFO] Random initialize AUCAUC:0.6062 Anomaly AUC:0.57717
[2023-08-25 21:00:40,428][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5442 loss2:1.2163 loss3:0.3408 | AUC:0.8203 Anomaly AUC:0.6233
[2023-08-25 21:02:02,619][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.3075 loss2:0.9655 loss3:0.1318 | AUC:0.8199 Anomaly AUC:0.6419
[2023-08-25 21:03:26,579][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2074 loss2:0.8476 loss3:0.0503 | AUC:0.8298 Anomaly AUC:0.6707
[2023-08-25 21:04:41,182][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00049 | loss1:0.1691 loss2:0.7859 loss3:0.0375 | AUC:0.8409 Anomaly AUC:0.6867
[2023-08-25 21:06:03,525][main.py][line:94][INFO] [Epoch:5/100]: lr:0.00049 | loss1:0.1316 loss2:0.7255 loss3:0.0252 | AUC:0.8126 Anomaly AUC:0.6794
[2023-08-25 21:07:11,544][main.py][line:94][INFO] [Epoch:6/100]: lr:0.00049 | loss1:0.0996 loss2:0.6586 loss3:0.0190 | AUC:0.8442 Anomaly AUC:0.6780
[2023-08-25 21:08:37,036][main.py][line:94][INFO] [Epoch:7/100]: lr:0.00048 | loss1:0.0896 loss2:0.6197 loss3:0.0176 | AUC:0.8149 Anomaly AUC:0.6588
[2023-08-25 21:09:54,450][main.py][line:94][INFO] [Epoch:8/100]: lr:0.00048 | loss1:0.0573 loss2:0.5533 loss3:0.0107 | AUC:0.8109 Anomaly AUC:0.6364
[2023-08-25 21:11:29,273][main.py][line:94][INFO] [Epoch:9/100]: lr:0.00047 | loss1:0.0311 loss2:0.4877 loss3:0.0066 | AUC:0.8385 Anomaly AUC:0.6647
[2023-08-25 21:13:22,377][main.py][line:94][INFO] [Epoch:10/100]: lr:0.00047 | loss1:0.0525 loss2:0.4807 loss3:0.0107 | AUC:0.8315 Anomaly AUC:0.6581
[2023-08-25 21:14:59,105][main.py][line:94][INFO] [Epoch:11/100]: lr:0.00046 | loss1:0.0237 loss2:0.4008 loss3:0.0057 | AUC:0.8428 Anomaly AUC:0.6825
[2023-08-25 21:16:16,810][main.py][line:94][INFO] [Epoch:12/100]: lr:0.00045 | loss1:0.0218 loss2:0.3552 loss3:0.0052 | AUC:0.8181 Anomaly AUC:0.6566
[2023-08-25 21:17:45,556][main.py][line:94][INFO] [Epoch:13/100]: lr:0.00044 | loss1:0.0243 loss2:0.3214 loss3:0.0053 | AUC:0.8028 Anomaly AUC:0.6589
[2023-08-25 21:19:11,883][main.py][line:94][INFO] [Epoch:14/100]: lr:0.00044 | loss1:0.0137 loss2:0.2623 loss3:0.0041 | AUC:0.8224 Anomaly AUC:0.6495
[2023-08-25 21:20:41,947][main.py][line:94][INFO] [Epoch:15/100]: lr:0.00043 | loss1:0.0256 loss2:0.2423 loss3:0.0059 | AUC:0.8316 Anomaly AUC:0.6506
[2023-08-25 21:21:58,973][main.py][line:94][INFO] [Epoch:16/100]: lr:0.00042 | loss1:0.0060 loss2:0.1709 loss3:0.0024 | AUC:0.8138 Anomaly AUC:0.6477
[2023-08-25 21:23:43,053][main.py][line:94][INFO] [Epoch:17/100]: lr:0.00041 | loss1:0.0141 loss2:0.1625 loss3:0.0038 | AUC:0.8284 Anomaly AUC:0.6506
[2023-08-25 21:25:07,972][main.py][line:94][INFO] [Epoch:18/100]: lr:0.00040 | loss1:0.0105 loss2:0.1351 loss3:0.0033 | AUC:0.8252 Anomaly AUC:0.6643
[2023-08-25 21:26:31,802][main.py][line:94][INFO] [Epoch:19/100]: lr:0.00039 | loss1:0.0135 loss2:0.1256 loss3:0.0035 | AUC:0.8314 Anomaly AUC:0.6670
[2023-08-25 21:27:21,179][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 21:27:21,301][main.py][line:145][INFO] total params:2.8436M
[2023-08-25 21:27:21,301][main.py][line:148][INFO] Training Mode
[2023-08-25 21:27:21,301][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 21:27:21,301][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 21:27:36,780][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 21:27:36,867][main.py][line:145][INFO] total params:3.3693M
[2023-08-25 21:27:36,867][main.py][line:148][INFO] Training Mode
[2023-08-25 21:27:36,867][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 21:27:36,867][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 21:27:43,013][main.py][line:71][INFO] Random initialize AUCAUC:0.4665 Anomaly AUC:0.48169
[2023-08-25 21:29:15,369][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0514 loss2:0.9740 loss3:0.3873 | AUC:0.6684 Anomaly AUC:0.5141
[2023-08-25 21:31:03,722][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0024 loss2:0.7021 loss3:0.3839 | AUC:0.7051 Anomaly AUC:0.5603
[2023-08-25 21:32:25,106][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0014 loss2:0.6016 loss3:0.3813 | AUC:0.6996 Anomaly AUC:0.5677
[2023-08-25 21:33:34,346][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0009 loss2:0.5230 loss3:0.3792 | AUC:0.7050 Anomaly AUC:0.5966
[2023-08-25 21:34:09,786][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 21:34:09,921][main.py][line:145][INFO] total params:3.3693M
[2023-08-25 21:34:09,921][main.py][line:148][INFO] Training Mode
[2023-08-25 21:34:09,921][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 21:34:09,921][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 21:34:20,067][main.py][line:71][INFO] Random initialize AUCAUC:0.4665 Anomaly AUC:0.48169
[2023-08-25 21:36:10,784][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0662 loss2:1.0190 loss3:0.3894 | AUC:0.7104 Anomaly AUC:0.5302
[2023-08-25 21:38:27,496][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0032 loss2:0.7444 loss3:0.3846 | AUC:0.6679 Anomaly AUC:0.5328
[2023-08-25 21:40:19,171][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0019 loss2:0.6611 loss3:0.3821 | AUC:0.6885 Anomaly AUC:0.5287
[2023-08-25 21:41:13,134][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-25 21:41:13,282][main.py][line:145][INFO] total params:7.5707M
[2023-08-25 21:41:13,282][main.py][line:148][INFO] Training Mode
[2023-08-25 21:41:13,283][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-25 21:41:13,283][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-25 21:41:24,935][main.py][line:71][INFO] Random initialize AUCAUC:0.5727 Anomaly AUC:0.55777
[2023-08-25 21:43:19,940][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5243 loss2:1.1448 loss3:0.2861 | AUC:0.8151 Anomaly AUC:0.6279
[2023-08-25 21:46:34,224][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.3069 loss2:0.9366 loss3:0.1481 | AUC:0.8114 Anomaly AUC:0.6646
[2023-08-25 21:48:08,948][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2187 loss2:0.8358 loss3:0.0879 | AUC:0.8488 Anomaly AUC:0.6926
[2023-08-25 21:49:34,942][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1631 loss2:0.7729 loss3:0.0569 | AUC:0.8612 Anomaly AUC:0.7024
[2023-08-25 21:51:07,231][main.py][line:94][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.1078 loss2:0.7077 loss3:0.0387 | AUC:0.8476 Anomaly AUC:0.6794
[2023-08-25 21:53:14,848][main.py][line:94][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0801 loss2:0.6469 loss3:0.0314 | AUC:0.8570 Anomaly AUC:0.7013
[2023-08-25 21:54:53,085][main.py][line:94][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0458 loss2:0.5701 loss3:0.0308 | AUC:0.8410 Anomaly AUC:0.6891
[2023-08-25 21:57:09,332][main.py][line:94][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0293 loss2:0.4895 loss3:0.0321 | AUC:0.8521 Anomaly AUC:0.6984
[2023-08-25 22:00:18,070][main.py][line:94][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0249 loss2:0.4169 loss3:0.0298 | AUC:0.8504 Anomaly AUC:0.6877
[2023-08-25 22:02:27,431][main.py][line:94][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0117 loss2:0.3176 loss3:0.0223 | AUC:0.8454 Anomaly AUC:0.6951
[2023-08-25 22:04:28,195][main.py][line:94][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0062 loss2:0.2242 loss3:0.0150 | AUC:0.8346 Anomaly AUC:0.6915
[2023-08-25 22:06:46,158][main.py][line:94][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0085 loss2:0.1583 loss3:0.0158 | AUC:0.8271 Anomaly AUC:0.7115
[2023-08-25 22:09:06,454][main.py][line:94][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0037 loss2:0.1038 loss3:0.0127 | AUC:0.8307 Anomaly AUC:0.6680
[2023-08-25 22:10:48,876][main.py][line:94][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0038 loss2:0.0659 loss3:0.0113 | AUC:0.8079 Anomaly AUC:0.6629
[2023-08-25 22:12:49,615][main.py][line:94][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0092 loss2:0.0890 loss3:0.0183 | AUC:0.8459 Anomaly AUC:0.6966
[2023-08-25 22:15:16,503][main.py][line:94][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0016 loss2:0.0373 loss3:0.0056 | AUC:0.8336 Anomaly AUC:0.6786
[2023-08-25 22:17:56,776][main.py][line:94][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0005 loss2:0.0215 loss3:0.0029 | AUC:0.8089 Anomaly AUC:0.6253
[2023-08-25 22:19:57,957][main.py][line:94][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0002 loss2:0.0129 loss3:0.0017 | AUC:0.8129 Anomaly AUC:0.6248
[2023-08-25 22:21:42,058][main.py][line:94][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0002 loss2:0.0098 loss3:0.0016 | AUC:0.8022 Anomaly AUC:0.6146
[2023-08-25 22:24:07,307][main.py][line:94][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0002 loss2:0.0083 loss3:0.0017 | AUC:0.7865 Anomaly AUC:0.5951
[2023-08-25 22:26:15,104][main.py][line:94][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0002 loss2:0.0076 loss3:0.0018 | AUC:0.7903 Anomaly AUC:0.5827
[2023-08-25 22:28:33,979][main.py][line:94][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0002 loss2:0.0069 loss3:0.0018 | AUC:0.8127 Anomaly AUC:0.6202
[2023-08-25 22:30:51,928][main.py][line:94][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0001 loss2:0.0061 loss3:0.0020 | AUC:0.7724 Anomaly AUC:0.5587
[2023-08-25 22:33:08,081][main.py][line:94][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.1723 loss2:0.3227 loss3:0.0628 | AUC:0.7875 Anomaly AUC:0.5940
[2023-08-25 22:35:07,751][main.py][line:94][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.2876 loss2:0.7955 loss3:0.0589 | AUC:0.8378 Anomaly AUC:0.6405
[2023-08-25 22:37:12,451][main.py][line:94][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0777 loss2:0.4013 loss3:0.0285 | AUC:0.8106 Anomaly AUC:0.6492
[2023-08-25 22:39:31,407][main.py][line:94][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0134 loss2:0.1524 loss3:0.0219 | AUC:0.8370 Anomaly AUC:0.6973
[2023-08-25 22:41:14,464][main.py][line:94][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0025 loss2:0.0484 loss3:0.0125 | AUC:0.8473 Anomaly AUC:0.6971
[2023-08-25 22:42:49,654][main.py][line:94][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0014 loss2:0.0221 loss3:0.0079 | AUC:0.8348 Anomaly AUC:0.6844
[2023-08-25 22:45:10,370][main.py][line:94][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0018 loss2:0.0172 loss3:0.0082 | AUC:0.7827 Anomaly AUC:0.6779
[2023-08-25 22:47:29,116][main.py][line:94][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0030 loss2:0.0213 loss3:0.0108 | AUC:0.8282 Anomaly AUC:0.6855
[2023-08-25 22:49:09,474][main.py][line:94][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0030 loss2:0.0254 loss3:0.0101 | AUC:0.8359 Anomaly AUC:0.7019
[2023-08-25 22:51:24,668][main.py][line:94][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0034 loss2:0.0154 loss3:0.0106 | AUC:0.7651 Anomaly AUC:0.7001
[2023-08-25 22:53:17,068][main.py][line:94][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0010 loss2:0.0102 loss3:0.0081 | AUC:0.8252 Anomaly AUC:0.6917
[2023-08-25 22:55:29,965][main.py][line:94][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0002 loss2:0.0046 loss3:0.0030 | AUC:0.8326 Anomaly AUC:0.6840
[2023-08-25 22:57:06,999][main.py][line:94][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0001 loss2:0.0026 loss3:0.0023 | AUC:0.8328 Anomaly AUC:0.6792
[2023-08-25 22:58:54,546][main.py][line:94][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0001 loss2:0.0025 loss3:0.0012 | AUC:0.8320 Anomaly AUC:0.6789
[2023-08-25 23:00:53,081][main.py][line:94][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0001 loss2:0.0031 loss3:0.0013 | AUC:0.8343 Anomaly AUC:0.6637
[2023-08-25 23:03:09,995][main.py][line:94][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0062 loss2:0.0393 loss3:0.0164 | AUC:0.8293 Anomaly AUC:0.7024
[2023-08-25 23:06:01,236][main.py][line:94][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0090 loss2:0.0593 loss3:0.0352 | AUC:0.8211 Anomaly AUC:0.7066
[2023-08-25 23:08:10,430][main.py][line:94][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0035 loss2:0.0218 loss3:0.0172 | AUC:0.8409 Anomaly AUC:0.6998
[2023-08-25 23:10:06,762][main.py][line:94][INFO] [Epoch:42/100]: lr:0.00050 | loss1:0.0004 loss2:0.0079 loss3:0.0069 | AUC:0.8395 Anomaly AUC:0.7039
[2023-08-25 23:11:56,178][main.py][line:94][INFO] [Epoch:43/100]: lr:0.00050 | loss1:0.0001 loss2:0.0046 loss3:0.0041 | AUC:0.8454 Anomaly AUC:0.7100
[2023-08-25 23:14:15,634][main.py][line:94][INFO] [Epoch:44/100]: lr:0.00050 | loss1:0.0001 loss2:0.0023 loss3:0.0024 | AUC:0.8485 Anomaly AUC:0.7096
[2023-08-25 23:15:50,967][main.py][line:94][INFO] [Epoch:45/100]: lr:0.00050 | loss1:0.0000 loss2:0.0017 loss3:0.0019 | AUC:0.8474 Anomaly AUC:0.7064
[2023-08-25 23:17:32,714][main.py][line:94][INFO] [Epoch:46/100]: lr:0.00050 | loss1:0.0000 loss2:0.0016 loss3:0.0017 | AUC:0.8466 Anomaly AUC:0.7053
[2023-08-25 23:19:20,287][main.py][line:94][INFO] [Epoch:47/100]: lr:0.00050 | loss1:0.0000 loss2:0.0014 loss3:0.0014 | AUC:0.8487 Anomaly AUC:0.7071
[2023-08-25 23:21:22,243][main.py][line:94][INFO] [Epoch:48/100]: lr:0.00050 | loss1:0.0000 loss2:0.0016 loss3:0.0015 | AUC:0.8476 Anomaly AUC:0.7061
[2023-08-25 23:23:01,412][main.py][line:94][INFO] [Epoch:49/100]: lr:0.00050 | loss1:0.0000 loss2:0.0014 loss3:0.0016 | AUC:0.8402 Anomaly AUC:0.7025
[2023-08-25 23:24:54,597][main.py][line:94][INFO] [Epoch:50/100]: lr:0.00050 | loss1:0.0000 loss2:0.0016 loss3:0.0022 | AUC:0.8416 Anomaly AUC:0.6967
[2023-08-25 23:27:02,555][main.py][line:94][INFO] [Epoch:51/100]: lr:0.00050 | loss1:0.0000 loss2:0.0015 loss3:0.0016 | AUC:0.8415 Anomaly AUC:0.6941
[2023-08-25 23:28:51,385][main.py][line:94][INFO] [Epoch:52/100]: lr:0.00050 | loss1:0.0000 loss2:0.0013 loss3:0.0017 | AUC:0.8418 Anomaly AUC:0.6950
[2023-08-25 23:30:31,948][main.py][line:94][INFO] [Epoch:53/100]: lr:0.00050 | loss1:0.0000 loss2:0.0013 loss3:0.0014 | AUC:0.8421 Anomaly AUC:0.6899
[2023-08-25 23:32:29,267][main.py][line:94][INFO] [Epoch:54/100]: lr:0.00050 | loss1:0.0000 loss2:0.0015 loss3:0.0019 | AUC:0.8456 Anomaly AUC:0.6948
[2023-08-25 23:34:14,949][main.py][line:94][INFO] [Epoch:55/100]: lr:0.00050 | loss1:0.0000 loss2:0.0012 loss3:0.0017 | AUC:0.8419 Anomaly AUC:0.6891
[2023-08-25 23:35:54,413][main.py][line:94][INFO] [Epoch:56/100]: lr:0.00050 | loss1:0.0918 loss2:0.1997 loss3:0.0931 | AUC:0.8031 Anomaly AUC:0.6779
[2023-08-25 23:38:34,635][main.py][line:94][INFO] [Epoch:57/100]: lr:0.00050 | loss1:0.0175 loss2:0.2444 loss3:0.0771 | AUC:0.7838 Anomaly AUC:0.6869
[2023-08-25 23:40:31,532][main.py][line:94][INFO] [Epoch:58/100]: lr:0.00050 | loss1:0.0050 loss2:0.0641 loss3:0.0297 | AUC:0.7646 Anomaly AUC:0.7091
[2023-08-25 23:42:45,586][main.py][line:94][INFO] [Epoch:59/100]: lr:0.00050 | loss1:0.0103 loss2:0.0580 loss3:0.0379 | AUC:0.7332 Anomaly AUC:0.6608
[2023-08-25 23:45:08,234][main.py][line:94][INFO] [Epoch:60/100]: lr:0.00050 | loss1:0.0015 loss2:0.0314 loss3:0.0181 | AUC:0.8378 Anomaly AUC:0.6975
[2023-08-25 23:46:43,605][main.py][line:94][INFO] [Epoch:61/100]: lr:0.00050 | loss1:0.0011 loss2:0.0082 loss3:0.0138 | AUC:0.8252 Anomaly AUC:0.6993
[2023-08-25 23:48:22,271][main.py][line:94][INFO] [Epoch:62/100]: lr:0.00050 | loss1:0.0003 loss2:0.0056 loss3:0.0095 | AUC:0.8441 Anomaly AUC:0.6997
[2023-08-25 23:50:33,390][main.py][line:94][INFO] [Epoch:63/100]: lr:0.00050 | loss1:0.0002 loss2:0.0030 loss3:0.0062 | AUC:0.8558 Anomaly AUC:0.7108
[2023-08-25 23:52:40,898][main.py][line:94][INFO] [Epoch:64/100]: lr:0.00050 | loss1:0.0006 loss2:0.0058 loss3:0.0076 | AUC:0.8532 Anomaly AUC:0.7133
[2023-08-25 23:54:20,735][main.py][line:94][INFO] [Epoch:65/100]: lr:0.00050 | loss1:0.0002 loss2:0.0022 loss3:0.0048 | AUC:0.8595 Anomaly AUC:0.7119
[2023-08-25 23:56:06,990][main.py][line:94][INFO] [Epoch:66/100]: lr:0.00050 | loss1:0.0001 loss2:0.0018 loss3:0.0039 | AUC:0.8558 Anomaly AUC:0.7077
[2023-08-25 23:57:53,073][main.py][line:94][INFO] [Epoch:67/100]: lr:0.00050 | loss1:0.0001 loss2:0.0019 loss3:0.0036 | AUC:0.8565 Anomaly AUC:0.7063
[2023-08-26 00:00:08,049][main.py][line:94][INFO] [Epoch:68/100]: lr:0.00050 | loss1:0.0064 loss2:0.0475 loss3:0.0470 | AUC:0.7942 Anomaly AUC:0.6997
[2023-08-26 00:02:30,329][main.py][line:94][INFO] [Epoch:69/100]: lr:0.00050 | loss1:0.0023 loss2:0.0152 loss3:0.0186 | AUC:0.8282 Anomaly AUC:0.7019
[2023-08-26 00:03:57,676][main.py][line:94][INFO] [Epoch:70/100]: lr:0.00050 | loss1:0.0038 loss2:0.0407 loss3:0.0367 | AUC:0.8152 Anomaly AUC:0.6818
[2023-08-26 00:05:22,722][main.py][line:94][INFO] [Epoch:71/100]: lr:0.00050 | loss1:0.0049 loss2:0.0347 loss3:0.0301 | AUC:0.7965 Anomaly AUC:0.6933
[2023-08-26 00:06:54,080][main.py][line:94][INFO] [Epoch:72/100]: lr:0.00050 | loss1:0.0013 loss2:0.0089 loss3:0.0131 | AUC:0.8340 Anomaly AUC:0.7038
[2023-08-26 00:08:40,435][main.py][line:94][INFO] [Epoch:73/100]: lr:0.00050 | loss1:0.0021 loss2:0.0103 loss3:0.0125 | AUC:0.8163 Anomaly AUC:0.6988
[2023-08-26 00:11:11,660][main.py][line:94][INFO] [Epoch:74/100]: lr:0.00050 | loss1:0.0021 loss2:0.0141 loss3:0.0144 | AUC:0.7974 Anomaly AUC:0.7032
[2023-08-26 00:12:56,693][main.py][line:94][INFO] [Epoch:75/100]: lr:0.00050 | loss1:0.0019 loss2:0.0063 loss3:0.0088 | AUC:0.8175 Anomaly AUC:0.7034
[2023-08-26 00:14:25,357][main.py][line:94][INFO] [Epoch:76/100]: lr:0.00050 | loss1:0.0015 loss2:0.0131 loss3:0.0153 | AUC:0.8214 Anomaly AUC:0.6850
[2023-08-26 00:16:15,255][main.py][line:94][INFO] [Epoch:77/100]: lr:0.00050 | loss1:0.0024 loss2:0.0289 loss3:0.0220 | AUC:0.8306 Anomaly AUC:0.6882
[2023-08-26 00:17:52,628][main.py][line:94][INFO] [Epoch:78/100]: lr:0.00050 | loss1:0.0002 loss2:0.0050 loss3:0.0087 | AUC:0.8465 Anomaly AUC:0.6915
[2023-08-26 00:19:42,573][main.py][line:94][INFO] [Epoch:79/100]: lr:0.00050 | loss1:0.0001 loss2:0.0020 loss3:0.0046 | AUC:0.8485 Anomaly AUC:0.6917
[2023-08-26 00:21:38,566][main.py][line:94][INFO] [Epoch:80/100]: lr:0.00050 | loss1:0.0010 loss2:0.0015 loss3:0.0036 | AUC:0.8424 Anomaly AUC:0.6776
[2023-08-26 00:22:44,923][main.py][line:109][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 00:22:45,087][main.py][line:145][INFO] total params:7.5707M
[2023-08-26 00:22:45,087][main.py][line:148][INFO] Training Mode
[2023-08-26 00:22:45,087][main.py][line:67][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 00:22:45,087][main.py][line:68][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0007
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 00:22:54,189][main.py][line:71][INFO] Random initialize AUCAUC:0.5727 Anomaly AUC:0.55777
[2023-08-26 00:24:06,941][main.py][line:94][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5243 loss2:1.1448 loss3:0.2861 | AUC:0.8151 Anomaly AUC:0.6279
[2023-08-26 00:25:21,995][main.py][line:94][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.3103 loss2:0.9382 loss3:0.1469 | AUC:0.8139 Anomaly AUC:0.6535
[2023-08-26 00:26:33,604][main.py][line:94][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2281 loss2:0.8414 loss3:0.0867 | AUC:0.8404 Anomaly AUC:0.6791
[2023-08-26 00:27:43,785][main.py][line:94][INFO] [Epoch:4/100]: lr:0.00049 | loss1:0.1658 loss2:0.7767 loss3:0.0594 | AUC:0.8265 Anomaly AUC:0.6667
[2023-08-26 00:29:09,134][main.py][line:94][INFO] [Epoch:5/100]: lr:0.00049 | loss1:0.1179 loss2:0.7103 loss3:0.0497 | AUC:0.8309 Anomaly AUC:0.6757
[2023-08-26 00:30:38,766][main.py][line:94][INFO] [Epoch:6/100]: lr:0.00049 | loss1:0.0654 loss2:0.6209 loss3:0.0352 | AUC:0.8358 Anomaly AUC:0.6790
[2023-08-26 00:31:52,410][main.py][line:94][INFO] [Epoch:7/100]: lr:0.00048 | loss1:0.0467 loss2:0.5515 loss3:0.0317 | AUC:0.8355 Anomaly AUC:0.6961
[2023-08-26 00:33:47,569][main.py][line:94][INFO] [Epoch:8/100]: lr:0.00048 | loss1:0.0244 loss2:0.4699 loss3:0.0265 | AUC:0.8445 Anomaly AUC:0.6958
[2023-08-26 00:35:41,435][main.py][line:94][INFO] [Epoch:9/100]: lr:0.00047 | loss1:0.0139 loss2:0.3871 loss3:0.0229 | AUC:0.8559 Anomaly AUC:0.6939
[2023-08-26 00:36:58,507][main.py][line:94][INFO] [Epoch:10/100]: lr:0.00047 | loss1:0.0052 loss2:0.2664 loss3:0.0165 | AUC:0.8156 Anomaly AUC:0.6893
[2023-08-26 00:38:35,219][main.py][line:94][INFO] [Epoch:11/100]: lr:0.00046 | loss1:0.0081 loss2:0.2264 loss3:0.0174 | AUC:0.8383 Anomaly AUC:0.6793
[2023-08-26 00:39:59,811][main.py][line:94][INFO] [Epoch:12/100]: lr:0.00045 | loss1:0.0054 loss2:0.1214 loss3:0.0142 | AUC:0.8299 Anomaly AUC:0.6846
[2023-08-26 00:41:36,552][main.py][line:94][INFO] [Epoch:13/100]: lr:0.00044 | loss1:0.0055 loss2:0.1133 loss3:0.0177 | AUC:0.8208 Anomaly AUC:0.6645
[2023-08-26 00:43:07,598][main.py][line:94][INFO] [Epoch:14/100]: lr:0.00044 | loss1:0.0015 loss2:0.0490 loss3:0.0044 | AUC:0.8266 Anomaly AUC:0.6504
[2023-08-26 00:44:38,874][main.py][line:94][INFO] [Epoch:15/100]: lr:0.00043 | loss1:0.0004 loss2:0.0284 loss3:0.0025 | AUC:0.8411 Anomaly AUC:0.6773
[2023-08-26 00:46:25,979][main.py][line:94][INFO] [Epoch:16/100]: lr:0.00042 | loss1:0.0003 loss2:0.0214 loss3:0.0018 | AUC:0.8417 Anomaly AUC:0.6719
[2023-08-26 00:48:15,288][main.py][line:94][INFO] [Epoch:17/100]: lr:0.00041 | loss1:0.0002 loss2:0.0169 loss3:0.0014 | AUC:0.8444 Anomaly AUC:0.6791
[2023-08-26 00:49:39,970][main.py][line:94][INFO] [Epoch:18/100]: lr:0.00040 | loss1:0.0002 loss2:0.0138 loss3:0.0013 | AUC:0.8411 Anomaly AUC:0.6653
[2023-08-26 00:50:58,969][main.py][line:94][INFO] [Epoch:19/100]: lr:0.00039 | loss1:0.0049 loss2:0.0324 loss3:0.0112 | AUC:0.8465 Anomaly AUC:0.6786
[2023-08-26 00:52:30,043][main.py][line:94][INFO] [Epoch:20/100]: lr:0.00038 | loss1:0.0043 loss2:0.0503 loss3:0.0156 | AUC:0.8439 Anomaly AUC:0.6678
[2023-08-26 00:53:56,966][main.py][line:94][INFO] [Epoch:21/100]: lr:0.00036 | loss1:0.0017 loss2:0.0311 loss3:0.0098 | AUC:0.8456 Anomaly AUC:0.6785
[2023-08-26 00:55:22,965][main.py][line:94][INFO] [Epoch:22/100]: lr:0.00035 | loss1:0.0003 loss2:0.0108 loss3:0.0047 | AUC:0.8466 Anomaly AUC:0.6786
[2023-08-26 00:56:42,454][main.py][line:94][INFO] [Epoch:23/100]: lr:0.00034 | loss1:0.0002 loss2:0.0079 loss3:0.0031 | AUC:0.8460 Anomaly AUC:0.6743
[2023-08-26 00:57:54,898][main.py][line:94][INFO] [Epoch:24/100]: lr:0.00033 | loss1:0.0001 loss2:0.0068 loss3:0.0021 | AUC:0.8485 Anomaly AUC:0.6746
[2023-08-26 00:59:30,503][main.py][line:94][INFO] [Epoch:25/100]: lr:0.00031 | loss1:0.0001 loss2:0.0060 loss3:0.0016 | AUC:0.8407 Anomaly AUC:0.6555
[2023-08-26 01:00:53,447][main.py][line:94][INFO] [Epoch:26/100]: lr:0.00030 | loss1:0.0001 loss2:0.0055 loss3:0.0015 | AUC:0.8377 Anomaly AUC:0.6471
[2023-08-26 01:02:18,699][main.py][line:94][INFO] [Epoch:27/100]: lr:0.00029 | loss1:0.0001 loss2:0.0052 loss3:0.0012 | AUC:0.8364 Anomaly AUC:0.6480
[2023-08-26 01:03:57,382][main.py][line:94][INFO] [Epoch:28/100]: lr:0.00028 | loss1:0.0001 loss2:0.0047 loss3:0.0012 | AUC:0.8314 Anomaly AUC:0.6358
[2023-08-26 01:05:43,744][main.py][line:94][INFO] [Epoch:29/100]: lr:0.00026 | loss1:0.0001 loss2:0.0046 loss3:0.0013 | AUC:0.8271 Anomaly AUC:0.6284
[2023-08-26 01:07:04,988][main.py][line:94][INFO] [Epoch:30/100]: lr:0.00025 | loss1:0.0032 loss2:0.0174 loss3:0.0152 | AUC:0.7995 Anomaly AUC:0.6625
[2023-08-26 01:08:25,675][main.py][line:94][INFO] [Epoch:31/100]: lr:0.00024 | loss1:0.0096 loss2:0.0590 loss3:0.0372 | AUC:0.8439 Anomaly AUC:0.6708
[2023-08-26 01:09:54,382][main.py][line:94][INFO] [Epoch:32/100]: lr:0.00022 | loss1:0.0029 loss2:0.0235 loss3:0.0138 | AUC:0.8490 Anomaly AUC:0.6838
[2023-08-26 01:11:30,103][main.py][line:94][INFO] [Epoch:33/100]: lr:0.00021 | loss1:0.0019 loss2:0.0170 loss3:0.0154 | AUC:0.8521 Anomaly AUC:0.6820
[2023-08-26 01:12:57,912][main.py][line:94][INFO] [Epoch:34/100]: lr:0.00020 | loss1:0.0003 loss2:0.0053 loss3:0.0037 | AUC:0.8496 Anomaly AUC:0.6802
[2023-08-26 01:14:27,871][main.py][line:94][INFO] [Epoch:35/100]: lr:0.00019 | loss1:0.0001 loss2:0.0040 loss3:0.0034 | AUC:0.8514 Anomaly AUC:0.6840
[2023-08-26 01:15:50,094][main.py][line:94][INFO] [Epoch:36/100]: lr:0.00017 | loss1:0.0001 loss2:0.0032 loss3:0.0022 | AUC:0.8526 Anomaly AUC:0.6855
[2023-08-26 01:17:27,461][main.py][line:94][INFO] [Epoch:37/100]: lr:0.00016 | loss1:0.0000 loss2:0.0030 loss3:0.0019 | AUC:0.8531 Anomaly AUC:0.6856
[2023-08-26 01:18:58,583][main.py][line:94][INFO] [Epoch:38/100]: lr:0.00015 | loss1:0.0000 loss2:0.0029 loss3:0.0018 | AUC:0.8534 Anomaly AUC:0.6866
[2023-08-26 01:20:22,586][main.py][line:94][INFO] [Epoch:39/100]: lr:0.00014 | loss1:0.0001 loss2:0.0026 loss3:0.0014 | AUC:0.8532 Anomaly AUC:0.6867
[2023-08-26 01:21:50,092][main.py][line:94][INFO] [Epoch:40/100]: lr:0.00013 | loss1:0.0000 loss2:0.0026 loss3:0.0015 | AUC:0.8541 Anomaly AUC:0.6881
[2023-08-26 01:23:10,722][main.py][line:94][INFO] [Epoch:41/100]: lr:0.00011 | loss1:0.0000 loss2:0.0024 loss3:0.0014 | AUC:0.8546 Anomaly AUC:0.6887
[2023-08-26 01:24:35,892][main.py][line:94][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0000 loss2:0.0025 loss3:0.0015 | AUC:0.8551 Anomaly AUC:0.6896
[2023-08-26 01:26:18,928][main.py][line:94][INFO] [Epoch:43/100]: lr:0.00009 | loss1:0.0000 loss2:0.0024 loss3:0.0013 | AUC:0.8558 Anomaly AUC:0.6911
[2023-08-26 01:27:40,705][main.py][line:94][INFO] [Epoch:44/100]: lr:0.00008 | loss1:0.0000 loss2:0.0023 loss3:0.0012 | AUC:0.8559 Anomaly AUC:0.6911
[2023-08-26 01:29:03,950][main.py][line:94][INFO] [Epoch:45/100]: lr:0.00007 | loss1:0.0000 loss2:0.0022 loss3:0.0012 | AUC:0.8562 Anomaly AUC:0.6923
[2023-08-26 01:30:37,788][main.py][line:94][INFO] [Epoch:46/100]: lr:0.00006 | loss1:0.0000 loss2:0.0022 loss3:0.0012 | AUC:0.8566 Anomaly AUC:0.6925
[2023-08-26 01:31:46,804][main.py][line:94][INFO] [Epoch:47/100]: lr:0.00006 | loss1:0.0000 loss2:0.0021 loss3:0.0013 | AUC:0.8572 Anomaly AUC:0.6939
[2023-08-26 01:33:11,339][main.py][line:94][INFO] [Epoch:48/100]: lr:0.00005 | loss1:0.0000 loss2:0.0022 loss3:0.0011 | AUC:0.8575 Anomaly AUC:0.6950
[2023-08-26 01:34:31,245][main.py][line:94][INFO] [Epoch:49/100]: lr:0.00004 | loss1:0.0000 loss2:0.0021 loss3:0.0012 | AUC:0.8588 Anomaly AUC:0.6962
[2023-08-26 01:35:44,860][main.py][line:94][INFO] [Epoch:50/100]: lr:0.00003 | loss1:0.0000 loss2:0.0022 loss3:0.0011 | AUC:0.8581 Anomaly AUC:0.6959
[2023-08-26 01:37:11,596][main.py][line:94][INFO] [Epoch:51/100]: lr:0.00003 | loss1:0.0000 loss2:0.0021 loss3:0.0010 | AUC:0.8583 Anomaly AUC:0.6966
[2023-08-26 01:38:30,011][main.py][line:94][INFO] [Epoch:52/100]: lr:0.00002 | loss1:0.0000 loss2:0.0021 loss3:0.0011 | AUC:0.8584 Anomaly AUC:0.6960
[2023-08-26 01:39:43,555][main.py][line:94][INFO] [Epoch:53/100]: lr:0.00002 | loss1:0.0000 loss2:0.0020 loss3:0.0011 | AUC:0.8581 Anomaly AUC:0.6957
[2023-08-26 01:40:54,801][main.py][line:94][INFO] [Epoch:54/100]: lr:0.00001 | loss1:0.0000 loss2:0.0021 loss3:0.0010 | AUC:0.8584 Anomaly AUC:0.6962
[2023-08-26 01:42:31,852][main.py][line:94][INFO] [Epoch:55/100]: lr:0.00001 | loss1:0.0000 loss2:0.0019 loss3:0.0010 | AUC:0.8582 Anomaly AUC:0.6967
[2023-08-26 01:43:57,174][main.py][line:94][INFO] [Epoch:56/100]: lr:0.00001 | loss1:0.0000 loss2:0.0019 loss3:0.0010 | AUC:0.8584 Anomaly AUC:0.6969
[2023-08-26 01:44:09,356][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 01:44:09,506][main.py][line:148][INFO] total params:7.5707M
[2023-08-26 01:44:09,506][main.py][line:151][INFO] Training Mode
[2023-08-26 01:44:09,507][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 01:44:09,507][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 5e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0007
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 01:44:17,171][main.py][line:74][INFO] Random initialize AUCAUC:0.5727 Anomaly AUC:0.55777
[2023-08-26 01:46:28,878][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 01:46:29,023][main.py][line:148][INFO] total params:7.5707M
[2023-08-26 01:46:29,023][main.py][line:151][INFO] Training Mode
[2023-08-26 01:46:29,024][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 01:46:29,024][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 5e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0007
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 01:46:37,015][main.py][line:74][INFO] Random initialize AUCAUC:0.5727 Anomaly AUC:0.55777
[2023-08-26 01:48:39,126][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00007 | loss1:0.5739 loss2:1.3020 loss3:0.3838 | AUC:0.8077 Anomaly AUC:0.6047
[2023-08-26 01:50:57,161][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.3043 loss2:1.0458 loss3:0.3120 | AUC:0.8131 Anomaly AUC:0.6487
[2023-08-26 01:52:47,642][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00012 | loss1:0.1931 loss2:0.9044 loss3:0.2347 | AUC:0.8234 Anomaly AUC:0.6725
[2023-08-26 01:54:47,748][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00014 | loss1:0.1347 loss2:0.8314 loss3:0.1582 | AUC:0.8178 Anomaly AUC:0.6710
[2023-08-26 01:56:53,190][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00016 | loss1:0.0864 loss2:0.7666 loss3:0.0831 | AUC:0.8230 Anomaly AUC:0.6809
[2023-08-26 01:58:56,784][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00018 | loss1:0.1227 loss2:0.7545 loss3:0.0535 | AUC:0.8294 Anomaly AUC:0.6856
[2023-08-26 02:01:04,164][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00021 | loss1:0.0438 loss2:0.6715 loss3:0.0265 | AUC:0.8211 Anomaly AUC:0.6789
[2023-08-26 02:03:52,779][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00023 | loss1:0.0715 loss2:0.6631 loss3:0.0254 | AUC:0.8253 Anomaly AUC:0.6931
[2023-08-26 02:06:26,793][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00025 | loss1:0.0445 loss2:0.6045 loss3:0.0176 | AUC:0.8061 Anomaly AUC:0.6810
[2023-08-26 02:08:29,337][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00028 | loss1:0.0310 loss2:0.5363 loss3:0.0123 | AUC:0.8497 Anomaly AUC:0.6876
[2023-08-26 02:11:01,712][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0647 loss2:0.5601 loss3:0.0160 | AUC:0.8569 Anomaly AUC:0.7029
[2023-08-26 02:13:51,903][main.py][line:97][INFO] [Epoch:12/100]: lr:0.00032 | loss1:0.0411 loss2:0.4852 loss3:0.0097 | AUC:0.8527 Anomaly AUC:0.6726
[2023-08-26 02:15:52,927][main.py][line:97][INFO] [Epoch:13/100]: lr:0.00034 | loss1:0.0151 loss2:0.3999 loss3:0.0055 | AUC:0.8422 Anomaly AUC:0.6830
[2023-08-26 02:17:57,977][main.py][line:97][INFO] [Epoch:14/100]: lr:0.00036 | loss1:0.0431 loss2:0.4097 loss3:0.0103 | AUC:0.8378 Anomaly AUC:0.7011
[2023-08-26 02:19:35,346][main.py][line:97][INFO] [Epoch:15/100]: lr:0.00039 | loss1:0.0205 loss2:0.3144 loss3:0.0057 | AUC:0.8487 Anomaly AUC:0.6856
[2023-08-26 02:21:24,564][main.py][line:97][INFO] [Epoch:16/100]: lr:0.00041 | loss1:0.0147 loss2:0.2482 loss3:0.0045 | AUC:0.8620 Anomaly AUC:0.7068
[2023-08-26 02:24:00,529][main.py][line:97][INFO] [Epoch:17/100]: lr:0.00043 | loss1:0.0094 loss2:0.1877 loss3:0.0032 | AUC:0.8569 Anomaly AUC:0.6895
[2023-08-26 02:26:03,772][main.py][line:97][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0179 loss2:0.1831 loss3:0.0048 | AUC:0.8283 Anomaly AUC:0.6393
[2023-08-26 02:28:08,897][main.py][line:97][INFO] [Epoch:19/100]: lr:0.00048 | loss1:0.0341 loss2:0.1918 loss3:0.0085 | AUC:0.8566 Anomaly AUC:0.6964
[2023-08-26 02:30:09,795][main.py][line:97][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0159 loss2:0.1133 loss3:0.0040 | AUC:0.8430 Anomaly AUC:0.6594
[2023-08-26 02:32:09,542][main.py][line:97][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0223 loss2:0.1217 loss3:0.0053 | AUC:0.8330 Anomaly AUC:0.6663
[2023-08-26 02:33:59,785][main.py][line:97][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0145 loss2:0.0887 loss3:0.0038 | AUC:0.8459 Anomaly AUC:0.6948
[2023-08-26 02:35:44,835][main.py][line:97][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0152 loss2:0.0774 loss3:0.0037 | AUC:0.8343 Anomaly AUC:0.6711
[2023-08-26 02:37:40,551][main.py][line:97][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0079 loss2:0.0573 loss3:0.0023 | AUC:0.8530 Anomaly AUC:0.6828
[2023-08-26 02:39:51,368][main.py][line:97][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0204 loss2:0.0746 loss3:0.0046 | AUC:0.8071 Anomaly AUC:0.6831
[2023-08-26 02:41:45,536][main.py][line:97][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0089 loss2:0.0482 loss3:0.0024 | AUC:0.8287 Anomaly AUC:0.6663
[2023-08-26 02:43:58,136][main.py][line:97][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0172 loss2:0.0552 loss3:0.0035 | AUC:0.8568 Anomaly AUC:0.6726
[2023-08-26 02:46:02,923][main.py][line:97][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0033 loss2:0.0237 loss3:0.0013 | AUC:0.8583 Anomaly AUC:0.6822
[2023-08-26 02:47:43,177][main.py][line:97][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0003 loss2:0.0144 loss3:0.0005 | AUC:0.8566 Anomaly AUC:0.6829
[2023-08-26 02:49:39,340][main.py][line:97][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0002 loss2:0.0106 loss3:0.0004 | AUC:0.8554 Anomaly AUC:0.6807
[2023-08-26 02:51:52,938][main.py][line:97][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0001 loss2:0.0088 loss3:0.0004 | AUC:0.8589 Anomaly AUC:0.6841
[2023-08-26 02:54:00,805][main.py][line:97][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0001 loss2:0.0082 loss3:0.0004 | AUC:0.8605 Anomaly AUC:0.6849
[2023-08-26 02:56:29,609][main.py][line:97][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0001 loss2:0.0075 loss3:0.0004 | AUC:0.8621 Anomaly AUC:0.6858
[2023-08-26 02:58:31,970][main.py][line:97][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0001 loss2:0.0062 loss3:0.0004 | AUC:0.8630 Anomaly AUC:0.6862
[2023-08-26 03:00:25,460][main.py][line:97][INFO] [Epoch:35/100]: lr:0.00049 | loss1:0.0001 loss2:0.0059 loss3:0.0004 | AUC:0.8626 Anomaly AUC:0.6834
[2023-08-26 03:02:38,018][main.py][line:97][INFO] [Epoch:36/100]: lr:0.00049 | loss1:0.0001 loss2:0.0050 loss3:0.0004 | AUC:0.8627 Anomaly AUC:0.6827
[2023-08-26 03:04:29,846][main.py][line:97][INFO] [Epoch:37/100]: lr:0.00049 | loss1:0.0001 loss2:0.0048 loss3:0.0005 | AUC:0.8625 Anomaly AUC:0.6818
[2023-08-26 03:06:54,768][main.py][line:97][INFO] [Epoch:38/100]: lr:0.00049 | loss1:0.0001 loss2:0.0045 loss3:0.0005 | AUC:0.8630 Anomaly AUC:0.6827
[2023-08-26 03:09:31,045][main.py][line:97][INFO] [Epoch:39/100]: lr:0.00049 | loss1:0.0001 loss2:0.0040 loss3:0.0005 | AUC:0.8627 Anomaly AUC:0.6806
[2023-08-26 03:11:48,700][main.py][line:97][INFO] [Epoch:40/100]: lr:0.00049 | loss1:0.0001 loss2:0.0039 loss3:0.0005 | AUC:0.8621 Anomaly AUC:0.6796
[2023-08-26 03:13:55,498][main.py][line:97][INFO] [Epoch:41/100]: lr:0.00049 | loss1:0.0000 loss2:0.0036 loss3:0.0005 | AUC:0.8613 Anomaly AUC:0.6768
[2023-08-26 03:16:28,167][main.py][line:97][INFO] [Epoch:42/100]: lr:0.00049 | loss1:0.0000 loss2:0.0035 loss3:0.0005 | AUC:0.8616 Anomaly AUC:0.6772
[2023-08-26 03:19:05,543][main.py][line:97][INFO] [Epoch:43/100]: lr:0.00049 | loss1:0.0000 loss2:0.0033 loss3:0.0005 | AUC:0.8618 Anomaly AUC:0.6793
[2023-08-26 03:21:41,836][main.py][line:97][INFO] [Epoch:44/100]: lr:0.00049 | loss1:0.0000 loss2:0.0030 loss3:0.0005 | AUC:0.8594 Anomaly AUC:0.6718
[2023-08-26 03:24:16,943][main.py][line:97][INFO] [Epoch:45/100]: lr:0.00048 | loss1:0.4847 loss2:0.8397 loss3:0.1089 | AUC:0.8055 Anomaly AUC:0.6112
[2023-08-26 03:26:35,663][main.py][line:97][INFO] [Epoch:46/100]: lr:0.00048 | loss1:0.1165 loss2:0.6666 loss3:0.0245 | AUC:0.8377 Anomaly AUC:0.6250
[2023-08-26 03:28:24,888][main.py][line:97][INFO] [Epoch:47/100]: lr:0.00048 | loss1:0.0421 loss2:0.3291 loss3:0.0079 | AUC:0.8088 Anomaly AUC:0.5830
[2023-08-26 03:31:20,095][main.py][line:97][INFO] [Epoch:48/100]: lr:0.00048 | loss1:0.0231 loss2:0.1333 loss3:0.0047 | AUC:0.8044 Anomaly AUC:0.5486
[2023-08-26 03:33:26,520][main.py][line:97][INFO] [Epoch:49/100]: lr:0.00048 | loss1:0.0154 loss2:0.0714 loss3:0.0036 | AUC:0.8155 Anomaly AUC:0.6072
[2023-08-26 03:36:05,094][main.py][line:97][INFO] [Epoch:50/100]: lr:0.00048 | loss1:0.0105 loss2:0.0397 loss3:0.0025 | AUC:0.8222 Anomaly AUC:0.6345
[2023-08-26 03:38:34,805][main.py][line:97][INFO] [Epoch:51/100]: lr:0.00048 | loss1:0.0164 loss2:0.0452 loss3:0.0034 | AUC:0.8351 Anomaly AUC:0.6251
[2023-08-26 03:40:18,611][main.py][line:97][INFO] [Epoch:52/100]: lr:0.00048 | loss1:0.0109 loss2:0.0301 loss3:0.0027 | AUC:0.8354 Anomaly AUC:0.6409
[2023-08-26 03:42:35,774][main.py][line:97][INFO] [Epoch:53/100]: lr:0.00047 | loss1:0.0069 loss2:0.0228 loss3:0.0021 | AUC:0.8412 Anomaly AUC:0.6509
[2023-08-26 03:45:03,573][main.py][line:97][INFO] [Epoch:54/100]: lr:0.00047 | loss1:0.0050 loss2:0.0149 loss3:0.0012 | AUC:0.8230 Anomaly AUC:0.6267
[2023-08-26 03:47:03,206][main.py][line:97][INFO] [Epoch:55/100]: lr:0.00047 | loss1:0.0096 loss2:0.0178 loss3:0.0022 | AUC:0.8351 Anomaly AUC:0.6403
[2023-08-26 03:49:32,401][main.py][line:97][INFO] [Epoch:56/100]: lr:0.00047 | loss1:0.0075 loss2:0.0165 loss3:0.0018 | AUC:0.8285 Anomaly AUC:0.6174
[2023-08-26 03:51:52,725][main.py][line:97][INFO] [Epoch:57/100]: lr:0.00047 | loss1:0.0064 loss2:0.0147 loss3:0.0016 | AUC:0.8170 Anomaly AUC:0.6167
[2023-08-26 03:54:01,321][main.py][line:97][INFO] [Epoch:58/100]: lr:0.00047 | loss1:0.0084 loss2:0.0217 loss3:0.0022 | AUC:0.8090 Anomaly AUC:0.6345
[2023-08-26 03:56:08,099][main.py][line:97][INFO] [Epoch:59/100]: lr:0.00046 | loss1:0.0050 loss2:0.0156 loss3:0.0018 | AUC:0.8307 Anomaly AUC:0.6550
[2023-08-26 03:59:55,334][main.py][line:97][INFO] [Epoch:60/100]: lr:0.00046 | loss1:0.0045 loss2:0.0094 loss3:0.0015 | AUC:0.8426 Anomaly AUC:0.6554
[2023-08-26 04:02:19,097][main.py][line:97][INFO] [Epoch:61/100]: lr:0.00046 | loss1:0.0056 loss2:0.0112 loss3:0.0012 | AUC:0.8452 Anomaly AUC:0.6318
[2023-08-26 04:04:33,302][main.py][line:97][INFO] [Epoch:62/100]: lr:0.00046 | loss1:0.0042 loss2:0.0135 loss3:0.0014 | AUC:0.8149 Anomaly AUC:0.6332
[2023-08-26 04:06:12,434][main.py][line:97][INFO] [Epoch:63/100]: lr:0.00046 | loss1:0.0077 loss2:0.0167 loss3:0.0024 | AUC:0.8283 Anomaly AUC:0.6170
[2023-08-26 04:08:04,115][main.py][line:97][INFO] [Epoch:64/100]: lr:0.00045 | loss1:0.0102 loss2:0.0125 loss3:0.0022 | AUC:0.8413 Anomaly AUC:0.6362
[2023-08-26 04:10:00,394][main.py][line:97][INFO] [Epoch:65/100]: lr:0.00045 | loss1:0.0064 loss2:0.0129 loss3:0.0020 | AUC:0.8139 Anomaly AUC:0.6394
[2023-08-26 04:11:36,859][main.py][line:97][INFO] [Epoch:66/100]: lr:0.00045 | loss1:0.0033 loss2:0.0086 loss3:0.0013 | AUC:0.8189 Anomaly AUC:0.6251
[2023-08-26 04:13:27,841][main.py][line:97][INFO] [Epoch:67/100]: lr:0.00045 | loss1:0.0055 loss2:0.0126 loss3:0.0016 | AUC:0.8249 Anomaly AUC:0.6538
[2023-08-26 04:15:20,545][main.py][line:97][INFO] [Epoch:68/100]: lr:0.00045 | loss1:0.0026 loss2:0.0093 loss3:0.0013 | AUC:0.8396 Anomaly AUC:0.6453
[2023-08-26 04:17:37,065][main.py][line:97][INFO] [Epoch:69/100]: lr:0.00044 | loss1:0.0000 loss2:0.0024 loss3:0.0004 | AUC:0.8367 Anomaly AUC:0.6471
[2023-08-26 04:19:21,470][main.py][line:97][INFO] [Epoch:70/100]: lr:0.00044 | loss1:0.0000 loss2:0.0014 loss3:0.0003 | AUC:0.8366 Anomaly AUC:0.6441
[2023-08-26 04:21:16,377][main.py][line:97][INFO] [Epoch:71/100]: lr:0.00044 | loss1:0.0000 loss2:0.0013 loss3:0.0003 | AUC:0.8354 Anomaly AUC:0.6398
[2023-08-26 04:22:59,127][main.py][line:97][INFO] [Epoch:72/100]: lr:0.00044 | loss1:0.0000 loss2:0.0012 loss3:0.0003 | AUC:0.8328 Anomaly AUC:0.6324
[2023-08-26 04:24:52,571][main.py][line:97][INFO] [Epoch:73/100]: lr:0.00043 | loss1:0.0000 loss2:0.0012 loss3:0.0003 | AUC:0.8304 Anomaly AUC:0.6270
[2023-08-26 04:26:45,890][main.py][line:97][INFO] [Epoch:74/100]: lr:0.00043 | loss1:0.0000 loss2:0.0012 loss3:0.0003 | AUC:0.8275 Anomaly AUC:0.6187
[2023-08-26 04:28:44,557][main.py][line:97][INFO] [Epoch:75/100]: lr:0.00043 | loss1:0.0000 loss2:0.0011 loss3:0.0003 | AUC:0.8256 Anomaly AUC:0.6135
[2023-08-26 04:30:53,900][main.py][line:97][INFO] [Epoch:76/100]: lr:0.00043 | loss1:0.0000 loss2:0.0012 loss3:0.0003 | AUC:0.8246 Anomaly AUC:0.6099
[2023-08-26 04:32:56,081][main.py][line:97][INFO] [Epoch:77/100]: lr:0.00043 | loss1:0.0000 loss2:0.0010 loss3:0.0003 | AUC:0.8234 Anomaly AUC:0.6065
[2023-08-26 04:35:29,631][main.py][line:97][INFO] [Epoch:78/100]: lr:0.00042 | loss1:0.0000 loss2:0.0010 loss3:0.0003 | AUC:0.8229 Anomaly AUC:0.6044
[2023-08-26 04:37:47,702][main.py][line:97][INFO] [Epoch:79/100]: lr:0.00042 | loss1:0.0000 loss2:0.0009 loss3:0.0003 | AUC:0.8213 Anomaly AUC:0.6028
[2023-08-26 04:39:28,326][main.py][line:97][INFO] [Epoch:80/100]: lr:0.00042 | loss1:0.0000 loss2:0.0004 loss3:0.0003 | AUC:0.8218 Anomaly AUC:0.6008
[2023-08-26 04:42:25,001][main.py][line:97][INFO] [Epoch:81/100]: lr:0.00042 | loss1:0.0000 loss2:0.0011 loss3:0.0003 | AUC:0.8214 Anomaly AUC:0.5971
[2023-08-26 04:44:14,034][main.py][line:97][INFO] [Epoch:82/100]: lr:0.00041 | loss1:0.0000 loss2:0.0010 loss3:0.0003 | AUC:0.8208 Anomaly AUC:0.5950
[2023-08-26 04:45:40,929][main.py][line:97][INFO] [Epoch:83/100]: lr:0.00041 | loss1:0.0000 loss2:0.0010 loss3:0.0003 | AUC:0.8207 Anomaly AUC:0.5946
[2023-08-26 04:47:16,712][main.py][line:97][INFO] [Epoch:84/100]: lr:0.00041 | loss1:0.0000 loss2:0.0012 loss3:0.0004 | AUC:0.8105 Anomaly AUC:0.6042
[2023-08-26 04:49:26,312][main.py][line:97][INFO] [Epoch:85/100]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7963 Anomaly AUC:0.5851
[2023-08-26 04:51:05,596][main.py][line:97][INFO] [Epoch:86/100]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7926 Anomaly AUC:0.5842
[2023-08-26 04:53:29,242][main.py][line:97][INFO] [Epoch:87/100]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7955 Anomaly AUC:0.5838
[2023-08-26 04:55:08,465][main.py][line:97][INFO] [Epoch:88/100]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7971 Anomaly AUC:0.5824
[2023-08-26 04:56:37,456][main.py][line:97][INFO] [Epoch:89/100]: lr:0.00039 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7988 Anomaly AUC:0.5840
[2023-08-26 04:58:14,790][main.py][line:97][INFO] [Epoch:90/100]: lr:0.00039 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7958 Anomaly AUC:0.5803
[2023-08-26 05:00:23,357][main.py][line:97][INFO] [Epoch:91/100]: lr:0.00039 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7957 Anomaly AUC:0.5796
[2023-08-26 05:02:28,735][main.py][line:97][INFO] [Epoch:92/100]: lr:0.00039 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7965 Anomaly AUC:0.5793
[2023-08-26 05:04:00,589][main.py][line:97][INFO] [Epoch:93/100]: lr:0.00038 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7961 Anomaly AUC:0.5798
[2023-08-26 05:05:25,035][main.py][line:97][INFO] [Epoch:94/100]: lr:0.00038 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7958 Anomaly AUC:0.5804
[2023-08-26 05:06:55,253][main.py][line:97][INFO] [Epoch:95/100]: lr:0.00038 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7954 Anomaly AUC:0.5812
[2023-08-26 05:08:27,834][main.py][line:97][INFO] [Epoch:96/100]: lr:0.00037 | loss1:0.1617 loss2:0.4751 loss3:0.0333 | AUC:0.8230 Anomaly AUC:0.6130
[2023-08-26 05:09:50,990][main.py][line:97][INFO] [Epoch:97/100]: lr:0.00037 | loss1:0.0687 loss2:0.4669 loss3:0.0165 | AUC:0.8325 Anomaly AUC:0.6353
[2023-08-26 05:11:27,447][main.py][line:97][INFO] [Epoch:98/100]: lr:0.00037 | loss1:0.0172 loss2:0.1442 loss3:0.0062 | AUC:0.8155 Anomaly AUC:0.6042
[2023-08-26 05:12:52,292][main.py][line:97][INFO] [Epoch:99/100]: lr:0.00036 | loss1:0.0105 loss2:0.0508 loss3:0.0039 | AUC:0.8294 Anomaly AUC:0.6419
[2023-08-26 05:14:21,537][main.py][line:97][INFO] [Epoch:100/100]: lr:0.00036 | loss1:0.0045 loss2:0.0182 loss3:0.0021 | AUC:0.8239 Anomaly AUC:0.6205
[2023-08-26 05:14:21,569][main.py][line:105][INFO] Training completes in 207m 45s | best AUCAUC:0.8630 Anomaly AUC:0.6827

[2023-08-26 11:16:20,943][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 11:16:21,078][main.py][line:148][INFO] total params:7.5707M
[2023-08-26 11:16:21,078][main.py][line:156][INFO] Test Mode
[2023-08-26 11:16:21,078][main.py][line:31][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-26 11:16:30,384][infer.py][line:47][INFO] offline AUC:0.8623 AP:0.3215 FAR:0.0076 | Complete in 0m 9s

[2023-08-26 11:18:16,576][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__863.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 11:18:16,688][main.py][line:148][INFO] total params:7.5707M
[2023-08-26 11:18:16,688][main.py][line:156][INFO] Test Mode
[2023-08-26 11:18:16,689][main.py][line:31][INFO] loading pretrained checkpoint from ./ckpt/ucf__863.pkl.
[2023-08-26 11:18:24,680][infer.py][line:47][INFO] offline AUC:0.8623 AP:0.3215 FAR:0.0076 | Complete in 0m 8s

[2023-08-26 11:21:53,609][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 11:21:53,742][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 11:21:53,743][main.py][line:156][INFO] Test Mode
[2023-08-26 11:21:53,743][main.py][line:31][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-26 11:22:02,704][infer.py][line:47][INFO] offline AUC:0.3875 AP:0.0627 FAR:0.0000 | Complete in 0m 9s

[2023-08-26 11:22:17,753][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 11:22:17,876][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 11:22:17,876][main.py][line:151][INFO] Training Mode
[2023-08-26 11:22:17,876][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 11:22:17,876][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 5e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0007
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 11:22:25,138][main.py][line:74][INFO] Random initialize AUCAUC:0.4114 Anomaly AUC:0.45879
[2023-08-26 11:23:59,485][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00007 | loss1:0.4877 loss2:1.2127 loss3:0.3855 | AUC:0.8065 Anomaly AUC:0.6061
[2023-08-26 11:25:33,249][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1285 loss2:0.9246 loss3:0.3939 | AUC:0.7598 Anomaly AUC:0.6221
[2023-08-26 11:26:54,764][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00012 | loss1:0.0142 loss2:0.7923 loss3:0.3730 | AUC:0.7388 Anomaly AUC:0.6530
[2023-08-26 11:28:10,961][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00014 | loss1:0.0086 loss2:0.7242 loss3:0.3464 | AUC:0.7176 Anomaly AUC:0.6664
[2023-08-26 11:29:51,008][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00016 | loss1:0.1285 loss2:0.8476 loss3:0.3691 | AUC:0.7495 Anomaly AUC:0.6504
[2023-08-26 11:31:24,923][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00018 | loss1:0.0097 loss2:0.6997 loss3:0.2958 | AUC:0.7248 Anomaly AUC:0.6579
[2023-08-26 11:33:24,855][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00021 | loss1:0.0101 loss2:0.6409 loss3:0.2257 | AUC:0.7492 Anomaly AUC:0.6584
[2023-08-26 11:34:51,654][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00023 | loss1:0.0088 loss2:0.5817 loss3:0.1553 | AUC:0.7323 Anomaly AUC:0.6479
[2023-08-26 11:36:42,446][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00025 | loss1:0.3243 loss2:0.9251 loss3:0.1996 | AUC:0.7840 Anomaly AUC:0.6549
[2023-08-26 11:38:45,038][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00028 | loss1:0.0602 loss2:0.7534 loss3:0.1811 | AUC:0.7848 Anomaly AUC:0.6503
[2023-08-26 11:40:25,143][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0187 loss2:0.7212 loss3:0.1253 | AUC:0.7362 Anomaly AUC:0.6398
[2023-08-26 11:42:26,393][main.py][line:97][INFO] [Epoch:12/100]: lr:0.00032 | loss1:0.0842 loss2:0.8319 loss3:0.1154 | AUC:0.7773 Anomaly AUC:0.6822
[2023-08-26 11:43:55,869][main.py][line:97][INFO] [Epoch:13/100]: lr:0.00034 | loss1:0.0094 loss2:0.6493 loss3:0.0800 | AUC:0.7788 Anomaly AUC:0.6740
[2023-08-26 11:45:23,000][main.py][line:97][INFO] [Epoch:14/100]: lr:0.00036 | loss1:0.0048 loss2:0.5082 loss3:0.0560 | AUC:0.7404 Anomaly AUC:0.6479
[2023-08-26 11:46:53,294][main.py][line:97][INFO] [Epoch:15/100]: lr:0.00039 | loss1:0.3668 loss2:0.8483 loss3:0.1212 | AUC:0.7474 Anomaly AUC:0.6447
[2023-08-26 11:48:19,471][main.py][line:97][INFO] [Epoch:16/100]: lr:0.00041 | loss1:0.3644 loss2:0.9240 loss3:0.0655 | AUC:0.8218 Anomaly AUC:0.6438
[2023-08-26 11:50:00,725][main.py][line:97][INFO] [Epoch:17/100]: lr:0.00043 | loss1:0.1490 loss2:0.7485 loss3:0.0751 | AUC:0.7760 Anomaly AUC:0.6568
[2023-08-26 11:51:41,201][main.py][line:97][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0131 loss2:0.5959 loss3:0.0549 | AUC:0.7772 Anomaly AUC:0.6538
[2023-08-26 11:53:10,657][main.py][line:97][INFO] [Epoch:19/100]: lr:0.00048 | loss1:0.0088 loss2:0.5466 loss3:0.0466 | AUC:0.7571 Anomaly AUC:0.6639
[2023-08-26 11:54:33,512][main.py][line:97][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0053 loss2:0.4885 loss3:0.0355 | AUC:0.6889 Anomaly AUC:0.6455
[2023-08-26 11:56:06,028][main.py][line:97][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0050 loss2:0.4487 loss3:0.0369 | AUC:0.7596 Anomaly AUC:0.6484
[2023-08-26 11:57:41,453][main.py][line:97][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0035 loss2:0.3837 loss3:0.0262 | AUC:0.6575 Anomaly AUC:0.6345
[2023-08-26 11:59:00,060][main.py][line:97][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0056 loss2:0.3814 loss3:0.0386 | AUC:0.7533 Anomaly AUC:0.6533
[2023-08-26 12:00:34,722][main.py][line:97][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0032 loss2:0.3237 loss3:0.0224 | AUC:0.5548 Anomaly AUC:0.6245
[2023-08-26 12:02:04,664][main.py][line:97][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0059 loss2:0.3695 loss3:0.0469 | AUC:0.8083 Anomaly AUC:0.6782
[2023-08-26 12:03:19,477][main.py][line:97][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0021 loss2:0.2379 loss3:0.0173 | AUC:0.7918 Anomaly AUC:0.6686
[2023-08-26 12:04:40,284][main.py][line:97][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0050 loss2:0.2646 loss3:0.0331 | AUC:0.7655 Anomaly AUC:0.6643
[2023-08-26 12:06:02,580][main.py][line:97][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0025 loss2:0.1819 loss3:0.0169 | AUC:0.7964 Anomaly AUC:0.6601
[2023-08-26 12:07:43,194][main.py][line:97][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0024 loss2:0.1716 loss3:0.0195 | AUC:0.7809 Anomaly AUC:0.6655
[2023-08-26 12:09:01,037][main.py][line:97][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0014 loss2:0.1281 loss3:0.0121 | AUC:0.7722 Anomaly AUC:0.6640
[2023-08-26 12:10:40,613][main.py][line:97][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0030 loss2:0.1205 loss3:0.0189 | AUC:0.7820 Anomaly AUC:0.6558
[2023-08-26 12:12:18,327][main.py][line:97][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0035 loss2:0.1386 loss3:0.0217 | AUC:0.7679 Anomaly AUC:0.6446
[2023-08-26 12:13:44,036][main.py][line:97][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0040 loss2:0.1118 loss3:0.0261 | AUC:0.7375 Anomaly AUC:0.6614
[2023-08-26 12:15:07,934][main.py][line:97][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0020 loss2:0.0753 loss3:0.0148 | AUC:0.7816 Anomaly AUC:0.6666
[2023-08-26 12:16:36,337][main.py][line:97][INFO] [Epoch:35/100]: lr:0.00049 | loss1:0.0013 loss2:0.0594 loss3:0.0109 | AUC:0.7399 Anomaly AUC:0.6472
[2023-08-26 12:17:57,775][main.py][line:97][INFO] [Epoch:36/100]: lr:0.00049 | loss1:0.0012 loss2:0.0557 loss3:0.0121 | AUC:0.7805 Anomaly AUC:0.6458
[2023-08-26 12:19:22,339][main.py][line:97][INFO] [Epoch:37/100]: lr:0.00049 | loss1:0.0035 loss2:0.1037 loss3:0.0265 | AUC:0.7904 Anomaly AUC:0.6884
[2023-08-26 12:20:11,704][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 12:20:11,861][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 12:20:11,861][main.py][line:151][INFO] Training Mode
[2023-08-26 12:20:11,861][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 12:20:11,861][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 5e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0007
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 12:20:22,837][main.py][line:74][INFO] Random initialize AUCAUC:0.4693 Anomaly AUC:0.51224
[2023-08-26 12:22:07,329][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00007 | loss1:0.4427 loss2:1.1923 loss3:0.3841 | AUC:0.7940 Anomaly AUC:0.6124
[2023-08-26 12:24:15,937][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1183 loss2:0.9240 loss3:0.3984 | AUC:0.7491 Anomaly AUC:0.6030
[2023-08-26 12:26:23,626][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00012 | loss1:0.0174 loss2:0.7987 loss3:0.3772 | AUC:0.6983 Anomaly AUC:0.6233
[2023-08-26 12:27:55,809][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00014 | loss1:0.0182 loss2:0.7462 loss3:0.3537 | AUC:0.5056 Anomaly AUC:0.6016
[2023-08-26 12:29:44,163][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00016 | loss1:0.0123 loss2:0.7130 loss3:0.3404 | AUC:0.5874 Anomaly AUC:0.6230
[2023-08-26 12:31:48,439][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00018 | loss1:0.0077 loss2:0.6532 loss3:0.2439 | AUC:0.6134 Anomaly AUC:0.6187
[2023-08-26 12:33:54,226][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00021 | loss1:0.0744 loss2:0.7365 loss3:0.2261 | AUC:0.6283 Anomaly AUC:0.6530
[2023-08-26 12:36:02,703][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00023 | loss1:0.0079 loss2:0.6189 loss3:0.1554 | AUC:0.7548 Anomaly AUC:0.6546
[2023-08-26 12:38:26,212][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00025 | loss1:0.0079 loss2:0.5694 loss3:0.1300 | AUC:0.7472 Anomaly AUC:0.6545
[2023-08-26 12:41:04,855][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00028 | loss1:0.0591 loss2:0.6150 loss3:0.1470 | AUC:0.7317 Anomaly AUC:0.6641
[2023-08-26 12:43:24,898][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0098 loss2:0.5611 loss3:0.1192 | AUC:0.7813 Anomaly AUC:0.6628
[2023-08-26 12:45:30,005][main.py][line:97][INFO] [Epoch:12/100]: lr:0.00032 | loss1:0.0783 loss2:0.5716 loss3:0.1248 | AUC:0.7618 Anomaly AUC:0.6148
[2023-08-26 12:47:16,414][main.py][line:97][INFO] [Epoch:13/100]: lr:0.00034 | loss1:0.0389 loss2:0.6712 loss3:0.1443 | AUC:0.7670 Anomaly AUC:0.6411
[2023-08-26 12:49:36,300][main.py][line:97][INFO] [Epoch:14/100]: lr:0.00036 | loss1:0.0081 loss2:0.5616 loss3:0.0544 | AUC:0.7541 Anomaly AUC:0.6544
[2023-08-26 12:51:17,978][main.py][line:97][INFO] [Epoch:15/100]: lr:0.00039 | loss1:0.0080 loss2:0.5276 loss3:0.0548 | AUC:0.7061 Anomaly AUC:0.6462
[2023-08-26 12:52:59,943][main.py][line:97][INFO] [Epoch:16/100]: lr:0.00041 | loss1:0.0055 loss2:0.4837 loss3:0.0413 | AUC:0.7485 Anomaly AUC:0.6563
[2023-08-26 12:54:36,927][main.py][line:97][INFO] [Epoch:17/100]: lr:0.00043 | loss1:0.0062 loss2:0.4497 loss3:0.0499 | AUC:0.6791 Anomaly AUC:0.6720
[2023-08-26 12:56:19,312][main.py][line:97][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.2347 loss2:0.5515 loss3:0.0800 | AUC:0.8064 Anomaly AUC:0.6152
[2023-08-26 12:58:26,738][main.py][line:97][INFO] [Epoch:19/100]: lr:0.00048 | loss1:0.2129 loss2:0.8174 loss3:0.0850 | AUC:0.7643 Anomaly AUC:0.6694
[2023-08-26 13:00:02,401][main.py][line:97][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0159 loss2:0.6297 loss3:0.0525 | AUC:0.7152 Anomaly AUC:0.6744
[2023-08-26 13:02:02,557][main.py][line:97][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0067 loss2:0.5671 loss3:0.0325 | AUC:0.7913 Anomaly AUC:0.6714
[2023-08-26 13:04:07,757][main.py][line:97][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.2040 loss2:0.7272 loss3:0.0571 | AUC:0.8283 Anomaly AUC:0.6581
[2023-08-26 13:06:37,164][main.py][line:97][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.1018 loss2:1.0328 loss3:0.0943 | AUC:0.7751 Anomaly AUC:0.6839
[2023-08-26 13:09:04,022][main.py][line:97][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0304 loss2:0.7195 loss3:0.0540 | AUC:0.7801 Anomaly AUC:0.6830
[2023-08-26 13:11:26,361][main.py][line:97][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0089 loss2:0.5190 loss3:0.0268 | AUC:0.7965 Anomaly AUC:0.6832
[2023-08-26 13:13:31,039][main.py][line:97][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0075 loss2:0.4620 loss3:0.0260 | AUC:0.7656 Anomaly AUC:0.6902
[2023-08-26 13:15:25,438][main.py][line:97][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.1030 loss2:0.5259 loss3:0.0560 | AUC:0.7813 Anomaly AUC:0.6788
[2023-08-26 13:17:28,285][main.py][line:97][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0228 loss2:0.5639 loss3:0.0482 | AUC:0.7709 Anomaly AUC:0.6777
[2023-08-26 13:19:18,075][main.py][line:97][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0069 loss2:0.4884 loss3:0.0228 | AUC:0.7496 Anomaly AUC:0.6941
[2023-08-26 13:21:25,931][main.py][line:97][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0051 loss2:0.4428 loss3:0.0240 | AUC:0.7709 Anomaly AUC:0.6740
[2023-08-26 13:23:31,054][main.py][line:97][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0051 loss2:0.4095 loss3:0.0248 | AUC:0.7948 Anomaly AUC:0.6810
[2023-08-26 13:25:32,057][main.py][line:97][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0045 loss2:0.3686 loss3:0.0201 | AUC:0.7979 Anomaly AUC:0.6678
[2023-08-26 13:27:19,449][main.py][line:97][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0026 loss2:0.3118 loss3:0.0135 | AUC:0.8200 Anomaly AUC:0.6776
[2023-08-26 13:29:17,939][main.py][line:97][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0062 loss2:0.3282 loss3:0.0308 | AUC:0.7901 Anomaly AUC:0.6834
[2023-08-26 13:31:25,227][main.py][line:97][INFO] [Epoch:35/100]: lr:0.00049 | loss1:0.0022 loss2:0.2585 loss3:0.0130 | AUC:0.8092 Anomaly AUC:0.6782
[2023-08-26 13:33:35,642][main.py][line:97][INFO] [Epoch:36/100]: lr:0.00049 | loss1:0.0044 loss2:0.2397 loss3:0.0182 | AUC:0.8104 Anomaly AUC:0.6816
[2023-08-26 13:35:38,613][main.py][line:97][INFO] [Epoch:37/100]: lr:0.00049 | loss1:0.0019 loss2:0.1838 loss3:0.0107 | AUC:0.8269 Anomaly AUC:0.6829
[2023-08-26 13:37:31,137][main.py][line:97][INFO] [Epoch:38/100]: lr:0.00049 | loss1:0.0020 loss2:0.1579 loss3:0.0091 | AUC:0.8125 Anomaly AUC:0.6758
[2023-08-26 13:39:45,740][main.py][line:97][INFO] [Epoch:39/100]: lr:0.00049 | loss1:0.0341 loss2:0.2847 loss3:0.0751 | AUC:0.8027 Anomaly AUC:0.6711
[2023-08-26 13:41:39,087][main.py][line:97][INFO] [Epoch:40/100]: lr:0.00049 | loss1:0.0100 loss2:0.2688 loss3:0.0442 | AUC:0.7929 Anomaly AUC:0.6849
[2023-08-26 13:43:57,431][main.py][line:97][INFO] [Epoch:41/100]: lr:0.00049 | loss1:0.0149 loss2:0.2561 loss3:0.0490 | AUC:0.8006 Anomaly AUC:0.6778
[2023-08-26 13:45:57,309][main.py][line:97][INFO] [Epoch:42/100]: lr:0.00049 | loss1:0.0507 loss2:0.3443 loss3:0.0745 | AUC:0.8289 Anomaly AUC:0.6873
[2023-08-26 13:47:55,082][main.py][line:97][INFO] [Epoch:43/100]: lr:0.00049 | loss1:0.0073 loss2:0.1908 loss3:0.0321 | AUC:0.7781 Anomaly AUC:0.6871
[2023-08-26 13:49:50,122][main.py][line:97][INFO] [Epoch:44/100]: lr:0.00049 | loss1:0.0084 loss2:0.1680 loss3:0.0331 | AUC:0.8075 Anomaly AUC:0.6828
[2023-08-26 13:51:42,373][main.py][line:97][INFO] [Epoch:45/100]: lr:0.00048 | loss1:0.0110 loss2:0.1607 loss3:0.0439 | AUC:0.8094 Anomaly AUC:0.6707
[2023-08-26 13:53:32,463][main.py][line:97][INFO] [Epoch:46/100]: lr:0.00048 | loss1:0.0040 loss2:0.1081 loss3:0.0224 | AUC:0.7982 Anomaly AUC:0.6693
[2023-08-26 13:55:14,686][main.py][line:97][INFO] [Epoch:47/100]: lr:0.00048 | loss1:0.0042 loss2:0.0877 loss3:0.0207 | AUC:0.8116 Anomaly AUC:0.6807
[2023-08-26 13:56:55,163][main.py][line:97][INFO] [Epoch:48/100]: lr:0.00048 | loss1:0.0037 loss2:0.0918 loss3:0.0194 | AUC:0.8201 Anomaly AUC:0.6886
[2023-08-26 13:59:05,038][main.py][line:97][INFO] [Epoch:49/100]: lr:0.00048 | loss1:0.0128 loss2:0.1043 loss3:0.0409 | AUC:0.8260 Anomaly AUC:0.6887
[2023-08-26 14:00:37,361][main.py][line:97][INFO] [Epoch:50/100]: lr:0.00048 | loss1:0.0085 loss2:0.0852 loss3:0.0340 | AUC:0.7969 Anomaly AUC:0.6629
[2023-08-26 14:02:19,304][main.py][line:97][INFO] [Epoch:51/100]: lr:0.00048 | loss1:0.0066 loss2:0.0643 loss3:0.0217 | AUC:0.8242 Anomaly AUC:0.6977
[2023-08-26 14:03:48,463][main.py][line:97][INFO] [Epoch:52/100]: lr:0.00048 | loss1:0.0042 loss2:0.0541 loss3:0.0243 | AUC:0.8243 Anomaly AUC:0.6713
[2023-08-26 14:05:30,745][main.py][line:97][INFO] [Epoch:53/100]: lr:0.00047 | loss1:0.0081 loss2:0.0636 loss3:0.0231 | AUC:0.8225 Anomaly AUC:0.6738
[2023-08-26 14:07:05,253][main.py][line:97][INFO] [Epoch:54/100]: lr:0.00047 | loss1:0.0034 loss2:0.0377 loss3:0.0143 | AUC:0.8343 Anomaly AUC:0.6867
[2023-08-26 14:08:45,194][main.py][line:97][INFO] [Epoch:55/100]: lr:0.00047 | loss1:0.0028 loss2:0.0380 loss3:0.0149 | AUC:0.8292 Anomaly AUC:0.6892
[2023-08-26 14:10:33,369][main.py][line:97][INFO] [Epoch:56/100]: lr:0.00047 | loss1:0.0015 loss2:0.0324 loss3:0.0101 | AUC:0.8158 Anomaly AUC:0.6917
[2023-08-26 14:12:19,408][main.py][line:97][INFO] [Epoch:57/100]: lr:0.00047 | loss1:0.0150 loss2:0.1023 loss3:0.0432 | AUC:0.8165 Anomaly AUC:0.6670
[2023-08-26 14:13:55,401][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 14:13:55,581][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 14:13:55,581][main.py][line:151][INFO] Training Mode
[2023-08-26 14:13:55,582][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 14:13:55,582][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 5e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0007
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 14:14:03,836][main.py][line:74][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 14:14:33,947][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 14:14:34,075][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 14:14:34,075][main.py][line:151][INFO] Training Mode
[2023-08-26 14:14:34,076][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 14:14:34,076][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 14:14:41,857][main.py][line:74][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 14:17:04,994][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00007 | loss1:0.4144 loss2:1.2064 loss3:0.3854 | AUC:0.8184 Anomaly AUC:0.6296
[2023-08-26 14:18:45,766][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0261 loss2:0.8633 loss3:0.3913 | AUC:0.7859 Anomaly AUC:0.6358
[2023-08-26 14:19:58,591][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00012 | loss1:0.0054 loss2:0.7539 loss3:0.3699 | AUC:0.7346 Anomaly AUC:0.6321
[2023-08-26 14:21:17,670][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00014 | loss1:0.3593 loss2:1.1717 loss3:0.3756 | AUC:0.6332 Anomaly AUC:0.4987
[2023-08-26 14:23:44,254][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00016 | loss1:0.0117 loss2:0.8091 loss3:0.3561 | AUC:0.6810 Anomaly AUC:0.5872
[2023-08-26 14:25:05,749][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00018 | loss1:0.0075 loss2:0.7158 loss3:0.3340 | AUC:0.6542 Anomaly AUC:0.6269
[2023-08-26 14:27:05,321][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00021 | loss1:0.2128 loss2:0.7719 loss3:0.3095 | AUC:0.5547 Anomaly AUC:0.5065
[2023-08-26 14:28:38,695][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00023 | loss1:0.3403 loss2:1.2716 loss3:0.2318 | AUC:0.8117 Anomaly AUC:0.6348
[2023-08-26 14:30:36,640][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00025 | loss1:0.0306 loss2:0.8898 loss3:0.1832 | AUC:0.7823 Anomaly AUC:0.6278
[2023-08-26 14:33:48,814][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00028 | loss1:0.0216 loss2:0.7630 loss3:0.1659 | AUC:0.6896 Anomaly AUC:0.6246
[2023-08-26 14:36:46,315][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0149 loss2:0.7210 loss3:0.1541 | AUC:0.6054 Anomaly AUC:0.5796
[2023-08-26 14:37:36,085][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 14:37:36,238][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 14:37:36,238][main.py][line:151][INFO] Training Mode
[2023-08-26 14:37:36,238][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 14:37:36,238][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 14:37:48,536][main.py][line:74][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 14:39:20,405][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4690 loss2:1.1404 loss3:0.3641 | AUC:0.7237 Anomaly AUC:0.5784
[2023-08-26 14:40:38,997][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.4138 loss2:1.1047 loss3:0.2704 | AUC:0.7761 Anomaly AUC:0.5981
[2023-08-26 14:42:03,217][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.3721 loss2:1.1659 loss3:0.1477 | AUC:0.8199 Anomaly AUC:0.6225
[2023-08-26 14:43:37,172][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.3130 loss2:1.0175 loss3:0.0663 | AUC:0.8240 Anomaly AUC:0.6277
[2023-08-26 14:45:05,776][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.2423 loss2:0.9382 loss3:0.0476 | AUC:0.8232 Anomaly AUC:0.6229
[2023-08-26 14:46:30,716][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.1846 loss2:0.8701 loss3:0.0340 | AUC:0.8174 Anomaly AUC:0.6195
[2023-08-26 14:48:07,913][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.1576 loss2:0.8261 loss3:0.0254 | AUC:0.8072 Anomaly AUC:0.6124
[2023-08-26 14:49:32,672][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.1371 loss2:0.7883 loss3:0.0219 | AUC:0.8234 Anomaly AUC:0.6120
[2023-08-26 14:51:19,788][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.1069 loss2:0.7371 loss3:0.0174 | AUC:0.8280 Anomaly AUC:0.6151
[2023-08-26 14:53:16,208][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0977 loss2:0.7056 loss3:0.0152 | AUC:0.8122 Anomaly AUC:0.6135
[2023-08-26 14:54:54,792][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0894 loss2:0.6844 loss3:0.0139 | AUC:0.8019 Anomaly AUC:0.6055
[2023-08-26 14:56:56,689][main.py][line:97][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0671 loss2:0.6262 loss3:0.0108 | AUC:0.8165 Anomaly AUC:0.6462
[2023-08-26 14:58:28,180][main.py][line:97][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0653 loss2:0.5893 loss3:0.0096 | AUC:0.8107 Anomaly AUC:0.6141
[2023-08-26 14:59:54,292][main.py][line:97][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0487 loss2:0.5380 loss3:0.0075 | AUC:0.7956 Anomaly AUC:0.6343
[2023-08-26 15:01:09,747][main.py][line:97][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0514 loss2:0.5274 loss3:0.0078 | AUC:0.8112 Anomaly AUC:0.6392
[2023-08-26 15:02:20,327][main.py][line:97][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0332 loss2:0.4651 loss3:0.0062 | AUC:0.7849 Anomaly AUC:0.6267
[2023-08-26 15:03:32,097][main.py][line:97][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0460 loss2:0.4489 loss3:0.0074 | AUC:0.7557 Anomaly AUC:0.6068
[2023-08-26 15:04:52,342][main.py][line:97][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0300 loss2:0.4072 loss3:0.0050 | AUC:0.7481 Anomaly AUC:0.5965
[2023-08-26 15:06:07,416][main.py][line:97][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0303 loss2:0.3702 loss3:0.0054 | AUC:0.7787 Anomaly AUC:0.5889
[2023-08-26 15:07:36,994][main.py][line:97][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0453 loss2:0.3645 loss3:0.0075 | AUC:0.8106 Anomaly AUC:0.6086
[2023-08-26 15:09:11,385][main.py][line:97][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0172 loss2:0.3107 loss3:0.0039 | AUC:0.8077 Anomaly AUC:0.6082
[2023-08-26 15:10:43,094][main.py][line:97][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0156 loss2:0.2590 loss3:0.0035 | AUC:0.8055 Anomaly AUC:0.6130
[2023-08-26 15:12:10,770][main.py][line:97][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0311 loss2:0.2834 loss3:0.0052 | AUC:0.7983 Anomaly AUC:0.5832
[2023-08-26 15:13:36,081][main.py][line:97][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0203 loss2:0.2391 loss3:0.0041 | AUC:0.8129 Anomaly AUC:0.6027
[2023-08-26 15:14:49,161][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 15:14:49,350][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 15:14:49,350][main.py][line:151][INFO] Training Mode
[2023-08-26 15:14:49,351][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 15:14:49,351][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 15:15:01,071][main.py][line:74][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 15:17:10,246][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5186 loss2:1.1583 loss3:0.3033 | AUC:0.8171 Anomaly AUC:0.6474
[2023-08-26 15:21:02,109][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.3236 loss2:0.9681 loss3:0.0634 | AUC:0.8297 Anomaly AUC:0.6540
[2023-08-26 15:23:29,911][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2406 loss2:0.8896 loss3:0.0379 | AUC:0.8233 Anomaly AUC:0.6522
[2023-08-26 15:25:34,424][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1919 loss2:0.8281 loss3:0.0300 | AUC:0.8234 Anomaly AUC:0.6524
[2023-08-26 15:27:53,462][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.1670 loss2:0.7901 loss3:0.0263 | AUC:0.8298 Anomaly AUC:0.6490
[2023-08-26 15:30:09,685][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.1314 loss2:0.7391 loss3:0.0213 | AUC:0.8247 Anomaly AUC:0.6779
[2023-08-26 15:31:48,930][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.1025 loss2:0.6939 loss3:0.0179 | AUC:0.8211 Anomaly AUC:0.6615
[2023-08-26 15:33:14,229][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0638 loss2:0.6301 loss3:0.0130 | AUC:0.7818 Anomaly AUC:0.6489
[2023-08-26 15:35:19,787][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0656 loss2:0.6180 loss3:0.0129 | AUC:0.7784 Anomaly AUC:0.6756
[2023-08-26 15:38:20,822][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0475 loss2:0.5668 loss3:0.0092 | AUC:0.7846 Anomaly AUC:0.6929
[2023-08-26 15:41:08,955][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0478 loss2:0.5337 loss3:0.0096 | AUC:0.7606 Anomaly AUC:0.6743
[2023-08-26 15:43:41,345][main.py][line:97][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0445 loss2:0.5096 loss3:0.0102 | AUC:0.7895 Anomaly AUC:0.6621
[2023-08-26 15:45:51,216][main.py][line:97][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0303 loss2:0.4447 loss3:0.0075 | AUC:0.8049 Anomaly AUC:0.6943
[2023-08-26 15:48:10,453][main.py][line:97][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0196 loss2:0.3974 loss3:0.0057 | AUC:0.7674 Anomaly AUC:0.6878
[2023-08-26 15:50:10,254][main.py][line:97][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0178 loss2:0.3554 loss3:0.0057 | AUC:0.8101 Anomaly AUC:0.6821
[2023-08-26 15:51:07,115][main.py][line:112][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 15:51:07,267][main.py][line:148][INFO] total params:9.6689M
[2023-08-26 15:51:07,267][main.py][line:151][INFO] Training Mode
[2023-08-26 15:51:07,267][main.py][line:70][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 15:51:07,267][main.py][line:71][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 15:51:17,623][main.py][line:74][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 15:53:22,429][main.py][line:97][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.3072 loss2:1.0684 loss3:0.4005 | AUC:0.4327 Anomaly AUC:0.4729
[2023-08-26 15:55:21,163][main.py][line:97][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2560 loss2:1.0467 loss3:0.3871 | AUC:0.6322 Anomaly AUC:0.5399
[2023-08-26 15:57:04,842][main.py][line:97][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1341 loss2:0.9493 loss3:0.3548 | AUC:0.4539 Anomaly AUC:0.5067
[2023-08-26 15:58:37,434][main.py][line:97][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0098 loss2:0.6785 loss3:0.2617 | AUC:0.6562 Anomaly AUC:0.5210
[2023-08-26 16:00:42,382][main.py][line:97][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0080 loss2:0.6642 loss3:0.2213 | AUC:0.6138 Anomaly AUC:0.5228
[2023-08-26 16:02:41,384][main.py][line:97][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.6395 loss2:1.1075 loss3:0.2719 | AUC:0.5377 Anomaly AUC:0.5206
[2023-08-26 16:04:32,326][main.py][line:97][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0267 loss2:0.9184 loss3:0.2233 | AUC:0.4585 Anomaly AUC:0.4808
[2023-08-26 16:06:16,662][main.py][line:97][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.2241 loss2:1.0289 loss3:0.1891 | AUC:0.7605 Anomaly AUC:0.5790
[2023-08-26 16:08:23,008][main.py][line:97][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0427 loss2:0.9336 loss3:0.2035 | AUC:0.6217 Anomaly AUC:0.5549
[2023-08-26 16:10:33,264][main.py][line:97][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0114 loss2:0.7888 loss3:0.1289 | AUC:0.7607 Anomaly AUC:0.6441
[2023-08-26 16:13:08,312][main.py][line:97][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0124 loss2:0.7478 loss3:0.0906 | AUC:0.7636 Anomaly AUC:0.6372
[2023-08-26 16:15:23,407][main.py][line:97][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0090 loss2:0.7120 loss3:0.0781 | AUC:0.7309 Anomaly AUC:0.6356
[2023-08-26 16:17:26,195][main.py][line:97][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0085 loss2:0.6769 loss3:0.0779 | AUC:0.6830 Anomaly AUC:0.6299
[2023-08-26 16:19:28,259][main.py][line:97][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0063 loss2:0.6405 loss3:0.0628 | AUC:0.7800 Anomaly AUC:0.6694
[2023-08-26 16:21:21,682][main.py][line:97][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0095 loss2:0.6129 loss3:0.0626 | AUC:0.7995 Anomaly AUC:0.6418
[2023-08-26 16:23:14,852][main.py][line:97][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0063 loss2:0.5733 loss3:0.0633 | AUC:0.7970 Anomaly AUC:0.6425
[2023-08-26 16:24:57,820][main.py][line:97][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.2960 loss2:0.8059 loss3:0.1087 | AUC:0.7908 Anomaly AUC:0.6176
[2023-08-26 16:26:44,988][main.py][line:97][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.3761 loss2:1.0857 loss3:0.0882 | AUC:0.8296 Anomaly AUC:0.6276
[2023-08-26 16:28:38,299][main.py][line:97][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.2610 loss2:0.9680 loss3:0.0608 | AUC:0.8221 Anomaly AUC:0.6327
[2023-08-26 16:30:46,900][main.py][line:97][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.1907 loss2:0.9245 loss3:0.0465 | AUC:0.8222 Anomaly AUC:0.6318
[2023-08-26 16:30:53,476][main.py][line:121][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:30:53,646][main.py][line:157][INFO] total params:9.6689M
[2023-08-26 16:30:53,646][main.py][line:160][INFO] Training Mode
[2023-08-26 16:30:53,647][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 16:30:53,647][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00019253422615602239
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0009458770702653651
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 16:32:03,561][main.py][line:105][INFO] [Epoch:1/30]: lr:0.00019 | loss1:0.4980 loss2:1.1649 loss3:0.2798 | AUC:0.8224 Anomaly AUC:0.6387
[2023-08-26 16:33:35,271][main.py][line:105][INFO] [Epoch:2/30]: lr:0.00019 | loss1:0.2956 loss2:0.9468 loss3:0.0732 | AUC:0.8191 Anomaly AUC:0.6916
[2023-08-26 16:34:56,693][main.py][line:105][INFO] [Epoch:3/30]: lr:0.00019 | loss1:0.2209 loss2:0.8710 loss3:0.0372 | AUC:0.8419 Anomaly AUC:0.6946
[2023-08-26 16:36:07,127][main.py][line:105][INFO] [Epoch:4/30]: lr:0.00019 | loss1:0.1834 loss2:0.8209 loss3:0.0298 | AUC:0.8312 Anomaly AUC:0.6770
[2023-08-26 16:37:19,709][main.py][line:105][INFO] [Epoch:5/30]: lr:0.00019 | loss1:0.1545 loss2:0.7839 loss3:0.0267 | AUC:0.8184 Anomaly AUC:0.6555
[2023-08-26 16:38:43,068][main.py][line:105][INFO] [Epoch:6/30]: lr:0.00019 | loss1:0.1175 loss2:0.7374 loss3:0.0215 | AUC:0.8305 Anomaly AUC:0.6414
[2023-08-26 16:40:23,661][main.py][line:121][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:40:23,821][main.py][line:165][INFO] total params:9.6689M
[2023-08-26 16:40:23,821][main.py][line:168][INFO] Training Mode
[2023-08-26 16:40:23,822][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 16:40:23,822][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003454957528378858
    lr: 0.0003454957528378858
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 1.715200534486453e-05
    lr: 1.715200534486453e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 16:41:01,318][main.py][line:105][INFO] [Epoch:1/30]: lr:0.00035 | loss1:0.6478 loss2:1.3595 loss3:0.3862 | AUC:0.8176 Anomaly AUC:0.6257
[2023-08-26 16:41:50,581][main.py][line:121][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:41:50,713][main.py][line:165][INFO] total params:9.6689M
[2023-08-26 16:41:50,713][main.py][line:168][INFO] Training Mode
[2023-08-26 16:41:50,714][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 16:41:50,714][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 1.446945948977353e-05
    lr: 1.446945948977353e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 9.808904550174232e-05
    lr: 9.808904550174232e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 16:42:24,221][main.py][line:121][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:42:24,342][main.py][line:165][INFO] total params:9.6689M
[2023-08-26 16:42:24,342][main.py][line:168][INFO] Training Mode
[2023-08-26 16:42:24,344][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 16:42:24,344][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 3.730090212424105e-05
    lr: 3.730090212424105e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0006249061683179006
    lr: 0.0006249061683179006
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 16:42:54,473][main.py][line:105][INFO] [Epoch:1/10]: lr:0.00004 | loss1:0.7195 loss2:1.3551 loss3:0.3766 | AUC:0.7993 Anomaly AUC:0.6159
[2023-08-26 16:43:21,786][main.py][line:105][INFO] [Epoch:2/10]: lr:0.00004 | loss1:0.5210 loss2:1.2126 loss3:0.3293 | AUC:0.8061 Anomaly AUC:0.5984
[2023-08-26 16:43:48,200][main.py][line:105][INFO] [Epoch:3/10]: lr:0.00004 | loss1:0.3809 loss2:1.0981 loss3:0.2069 | AUC:0.8110 Anomaly AUC:0.6111
[2023-08-26 16:44:09,772][main.py][line:105][INFO] [Epoch:4/10]: lr:0.00004 | loss1:0.3142 loss2:1.0148 loss3:0.1580 | AUC:0.8077 Anomaly AUC:0.6068
[2023-08-26 16:44:32,418][main.py][line:105][INFO] [Epoch:5/10]: lr:0.00004 | loss1:0.2625 loss2:0.9572 loss3:0.1410 | AUC:0.8290 Anomaly AUC:0.6454
[2023-08-26 16:44:57,593][main.py][line:105][INFO] [Epoch:6/10]: lr:0.00004 | loss1:0.2512 loss2:0.9489 loss3:0.1305 | AUC:0.8345 Anomaly AUC:0.6438
[2023-08-26 16:45:20,564][main.py][line:105][INFO] [Epoch:7/10]: lr:0.00004 | loss1:0.2172 loss2:0.9198 loss3:0.1183 | AUC:0.8241 Anomaly AUC:0.6522
[2023-08-26 16:45:52,138][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:45:52,277][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 16:45:52,278][main.py][line:169][INFO] Training Mode
[2023-08-26 16:45:52,279][main.py][line:79][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 16:45:52,279][main.py][line:80][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.00020800936756432736
    lr: 0.00020800936756432736
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 8.009905580349912e-05
    lr: 8.009905580349912e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 16:46:19,839][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00021 | loss1:0.6373 loss2:1.3160 loss3:0.3850 | AUC:0.8087 Anomaly AUC:0.6256
[2023-08-26 16:46:41,808][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00021 | loss1:0.3241 loss2:1.0929 loss3:0.3864 | AUC:0.8158 Anomaly AUC:0.6354
[2023-08-26 16:47:05,542][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00021 | loss1:0.1350 loss2:0.9555 loss3:0.3949 | AUC:0.8067 Anomaly AUC:0.6502
[2023-08-26 16:47:28,483][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00021 | loss1:0.0330 loss2:0.8618 loss3:0.4066 | AUC:0.7539 Anomaly AUC:0.6188
[2023-08-26 16:47:50,191][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00020 | loss1:0.0530 loss2:0.8496 loss3:0.4092 | AUC:0.5574 Anomaly AUC:0.5282
[2023-08-26 16:48:14,362][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00020 | loss1:0.0380 loss2:0.8202 loss3:0.4110 | AUC:0.5785 Anomaly AUC:0.5219
[2023-08-26 16:48:39,584][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00020 | loss1:0.0305 loss2:0.7980 loss3:0.4025 | AUC:0.5696 Anomaly AUC:0.5190
[2023-08-26 16:49:04,609][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00020 | loss1:0.0304 loss2:0.7800 loss3:0.3956 | AUC:0.5307 Anomaly AUC:0.5147
[2023-08-26 16:49:27,573][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00020 | loss1:0.0327 loss2:0.7585 loss3:0.3914 | AUC:0.5335 Anomaly AUC:0.5197
[2023-08-26 16:49:50,012][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00019 | loss1:0.0288 loss2:0.7383 loss3:0.3874 | AUC:0.5452 Anomaly AUC:0.5214
[2023-08-26 16:49:50,066][main.py][line:114][INFO] Training completes in 3m 58s | best AUCAUC:0.8158 Anomaly AUC:0.6354

[2023-08-26 16:49:50,117][main.py][line:79][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 16:49:50,117][main.py][line:80][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 1.0230245694566897e-05
    lr: 1.0230245694566897e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.00011246255879346856
    lr: 0.00011246255879346856
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 16:50:13,771][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00001 | loss1:0.2202 loss2:1.0177 loss3:0.3963 | AUC:0.8095 Anomaly AUC:0.6261
[2023-08-26 16:50:38,081][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00001 | loss1:0.0590 loss2:0.9746 loss3:0.4366 | AUC:0.8049 Anomaly AUC:0.6226
[2023-08-26 16:51:03,288][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00001 | loss1:0.0305 loss2:0.9407 loss3:0.4667 | AUC:0.7954 Anomaly AUC:0.6181
[2023-08-26 16:51:28,801][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00001 | loss1:0.0290 loss2:0.9190 loss3:0.4587 | AUC:0.7865 Anomaly AUC:0.6203
[2023-08-26 16:51:54,576][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00001 | loss1:0.0287 loss2:0.9043 loss3:0.4528 | AUC:0.7618 Anomaly AUC:0.6132
[2023-08-26 16:52:18,584][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00001 | loss1:0.0226 loss2:0.8914 loss3:0.4435 | AUC:0.7186 Anomaly AUC:0.6013
[2023-08-26 16:52:41,861][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00001 | loss1:0.0249 loss2:0.8889 loss3:0.4362 | AUC:0.7175 Anomaly AUC:0.6185
[2023-08-26 16:53:05,251][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00001 | loss1:0.0253 loss2:0.8879 loss3:0.4318 | AUC:0.7090 Anomaly AUC:0.6065
[2023-08-26 16:53:29,273][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00001 | loss1:0.0234 loss2:0.8826 loss3:0.4309 | AUC:0.7110 Anomaly AUC:0.6378
[2023-08-26 16:57:12,646][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:57:12,782][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 16:57:12,782][main.py][line:169][INFO] Training Mode
[2023-08-26 16:58:59,272][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 16:58:59,401][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 16:58:59,402][main.py][line:169][INFO] Training Mode
[2023-08-26 17:02:39,545][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:02:39,678][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:02:39,678][main.py][line:169][INFO] Training Mode
[2023-08-26 17:05:15,771][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:05:15,890][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:05:15,890][main.py][line:169][INFO] Training Mode
[2023-08-26 17:06:21,587][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:06:21,708][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:06:21,708][main.py][line:169][INFO] Training Mode
[2023-08-26 17:08:35,405][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:08:35,528][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:08:35,528][main.py][line:169][INFO] Training Mode
[2023-08-26 17:09:16,881][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:09:17,017][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:09:17,017][main.py][line:169][INFO] Training Mode
[2023-08-26 17:10:56,522][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:10:56,643][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:10:56,643][main.py][line:169][INFO] Training Mode
[2023-08-26 17:11:41,672][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:11:41,808][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:11:41,808][main.py][line:169][INFO] Training Mode
[2023-08-26 17:13:18,763][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:13:18,898][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:13:18,898][main.py][line:169][INFO] Training Mode
[2023-08-26 17:14:22,969][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:14:23,100][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:14:23,100][main.py][line:169][INFO] Training Mode
[2023-08-26 17:14:45,645][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:14:45,784][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:14:45,784][main.py][line:169][INFO] Training Mode
[2023-08-26 17:15:04,783][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:15:04,902][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:15:04,902][main.py][line:169][INFO] Training Mode
[2023-08-26 17:15:23,290][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00014 | loss1:0.6740 loss2:1.3455 loss3:0.3861 | AUC:0.8131 Anomaly AUC:0.6163
[2023-08-26 17:15:37,708][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00014 | loss1:0.3804 loss2:1.1418 loss3:0.3863 | AUC:0.8221 Anomaly AUC:0.6215
[2023-08-26 17:16:01,048][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00014 | loss1:0.2490 loss2:1.0120 loss3:0.3866 | AUC:0.8237 Anomaly AUC:0.6363
[2023-08-26 17:16:18,122][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:16:18,262][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:16:18,262][main.py][line:169][INFO] Training Mode
[2023-08-26 17:16:35,901][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00003 | loss1:0.7489 loss2:1.4048 loss3:0.3862 | AUC:0.8054 Anomaly AUC:0.6012
[2023-08-26 17:17:00,288][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00003 | loss1:0.5474 loss2:1.3782 loss3:0.3862 | AUC:0.8093 Anomaly AUC:0.5995
[2023-08-26 17:17:15,449][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00003 | loss1:0.3910 loss2:1.3436 loss3:0.3865 | AUC:0.8118 Anomaly AUC:0.6024
[2023-08-26 17:17:29,112][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00003 | loss1:0.2970 loss2:1.3122 loss3:0.3866 | AUC:0.8130 Anomaly AUC:0.6156
[2023-08-26 17:17:43,634][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00003 | loss1:0.2271 loss2:1.2862 loss3:0.3867 | AUC:0.8051 Anomaly AUC:0.6098
[2023-08-26 17:17:57,709][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00003 | loss1:0.1569 loss2:1.2674 loss3:0.3867 | AUC:0.7908 Anomaly AUC:0.6106
[2023-08-26 17:18:11,560][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00003 | loss1:0.1127 loss2:1.2481 loss3:0.3874 | AUC:0.7496 Anomaly AUC:0.5787
[2023-08-26 17:18:26,360][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00003 | loss1:0.0700 loss2:1.2263 loss3:0.3881 | AUC:0.6035 Anomaly AUC:0.5139
[2023-08-26 17:18:37,246][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00003 | loss1:0.0570 loss2:1.1981 loss3:0.3885 | AUC:0.5812 Anomaly AUC:0.5140
[2023-08-26 17:18:51,222][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00003 | loss1:0.0442 loss2:1.1738 loss3:0.3891 | AUC:0.5560 Anomaly AUC:0.5161
[2023-08-26 17:18:51,272][main.py][line:114][INFO] Training completes in 2m 33s | best AUCAUC:0.8130 Anomaly AUC:0.6156

[2023-08-26 17:19:04,886][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00023 | loss1:0.6452 loss2:1.3242 loss3:0.3859 | AUC:0.8051 Anomaly AUC:0.6275
[2023-08-26 17:19:19,921][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00023 | loss1:0.2176 loss2:1.2499 loss3:0.3921 | AUC:0.8092 Anomaly AUC:0.6386
[2023-08-26 17:19:30,908][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00023 | loss1:0.0445 loss2:1.1712 loss3:0.3891 | AUC:0.7094 Anomaly AUC:0.5519
[2023-08-26 17:19:44,844][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00023 | loss1:0.0655 loss2:1.1242 loss3:0.3735 | AUC:0.5109 Anomaly AUC:0.5144
[2023-08-26 17:19:56,779][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00023 | loss1:0.1653 loss2:1.0687 loss3:0.3867 | AUC:0.8149 Anomaly AUC:0.6327
[2023-08-26 17:20:10,140][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00022 | loss1:0.0252 loss2:0.9798 loss3:0.3451 | AUC:0.8331 Anomaly AUC:0.6633
[2023-08-26 17:20:23,247][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00022 | loss1:0.0304 loss2:0.9217 loss3:0.3076 | AUC:0.7918 Anomaly AUC:0.6157
[2023-08-26 17:20:42,362][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00022 | loss1:0.0267 loss2:0.8890 loss3:0.2822 | AUC:0.7552 Anomaly AUC:0.6015
[2023-08-26 17:20:54,186][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00022 | loss1:0.0288 loss2:0.8771 loss3:0.2676 | AUC:0.7413 Anomaly AUC:0.6476
[2023-08-26 17:21:12,325][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00021 | loss1:0.0248 loss2:0.8748 loss3:0.2570 | AUC:0.7575 Anomaly AUC:0.6627
[2023-08-26 17:21:12,378][main.py][line:114][INFO] Training completes in 2m 21s | best AUCAUC:0.8331 Anomaly AUC:0.6633

[2023-08-26 17:21:26,028][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00010 | loss1:0.3215 loss2:1.1578 loss3:0.9702 | AUC:0.7646 Anomaly AUC:0.6216
[2023-08-26 17:21:37,405][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00010 | loss1:0.0362 loss2:0.9196 loss3:0.6052 | AUC:0.7004 Anomaly AUC:0.5984
[2023-08-26 17:21:48,532][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00010 | loss1:0.0292 loss2:0.8757 loss3:0.5563 | AUC:0.6964 Anomaly AUC:0.6069
[2023-08-26 17:22:00,299][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00010 | loss1:0.0392 loss2:0.8660 loss3:0.6488 | AUC:0.7217 Anomaly AUC:0.6248
[2023-08-26 17:22:13,795][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00010 | loss1:0.0264 loss2:0.8417 loss3:0.5716 | AUC:0.6841 Anomaly AUC:0.6105
[2023-08-26 17:22:27,258][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00010 | loss1:0.0286 loss2:0.8363 loss3:0.5097 | AUC:0.6918 Anomaly AUC:0.6145
[2023-08-26 17:22:40,988][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00010 | loss1:0.0297 loss2:0.8256 loss3:0.4906 | AUC:0.5530 Anomaly AUC:0.5853
[2023-08-26 17:22:53,071][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00010 | loss1:0.0247 loss2:0.8097 loss3:0.4615 | AUC:0.6394 Anomaly AUC:0.5836
[2023-08-26 17:23:07,333][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00009 | loss1:0.0265 loss2:0.8042 loss3:0.4430 | AUC:0.6326 Anomaly AUC:0.6025
[2023-08-26 17:23:18,516][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00009 | loss1:0.0291 loss2:0.7843 loss3:0.4313 | AUC:0.6588 Anomaly AUC:0.6224
[2023-08-26 17:23:18,542][main.py][line:114][INFO] Training completes in 2m 6s | best AUCAUC:0.7646 Anomaly AUC:0.6216

[2023-08-26 17:24:33,476][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 17:24:33,619][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 17:24:33,619][main.py][line:169][INFO] Training Mode
[2023-08-26 17:24:53,160][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00063 | loss1:0.7342 loss2:1.4115 loss3:0.3857 | AUC:0.7959 Anomaly AUC:0.6217
[2023-08-26 17:25:03,789][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00063 | loss1:0.4650 loss2:1.4023 loss3:0.3891 | AUC:0.8016 Anomaly AUC:0.6174
[2023-08-26 17:25:25,186][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00063 | loss1:0.1135 loss2:1.3707 loss3:0.4296 | AUC:0.5438 Anomaly AUC:0.4937
[2023-08-26 17:25:39,241][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00062 | loss1:0.0475 loss2:1.2885 loss3:0.5351 | AUC:0.4536 Anomaly AUC:0.4806
[2023-08-26 17:25:50,320][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00062 | loss1:0.0356 loss2:1.1876 loss3:0.5868 | AUC:0.5602 Anomaly AUC:0.5313
[2023-08-26 17:26:01,183][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00062 | loss1:0.0341 loss2:1.1303 loss3:0.5983 | AUC:0.5044 Anomaly AUC:0.4966
[2023-08-26 17:26:12,170][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00061 | loss1:0.0353 loss2:1.0886 loss3:0.6036 | AUC:0.4974 Anomaly AUC:0.5082
[2023-08-26 17:26:25,018][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00060 | loss1:0.0345 loss2:1.0459 loss3:0.6026 | AUC:0.5150 Anomaly AUC:0.4843
[2023-08-26 17:26:37,982][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00060 | loss1:0.0346 loss2:1.0050 loss3:0.6003 | AUC:0.5544 Anomaly AUC:0.5127
[2023-08-26 17:26:51,105][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00059 | loss1:0.0316 loss2:0.9741 loss3:0.5984 | AUC:0.6002 Anomaly AUC:0.5260
[2023-08-26 17:26:51,158][main.py][line:114][INFO] Training completes in 2m 17s | best AUCAUC:0.8016 Anomaly AUC:0.6174

[2023-08-26 17:27:03,991][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00011 | loss1:0.2268 loss2:1.3601 loss3:0.3977 | AUC:0.8073 Anomaly AUC:0.6154
[2023-08-26 17:27:17,370][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00011 | loss1:0.0715 loss2:1.3148 loss3:0.3998 | AUC:0.7666 Anomaly AUC:0.5881
[2023-08-26 17:27:30,433][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00011 | loss1:0.0323 loss2:1.2537 loss3:0.3939 | AUC:0.4980 Anomaly AUC:0.4392
[2023-08-26 17:27:41,561][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00011 | loss1:0.0305 loss2:1.1902 loss3:0.3863 | AUC:0.3704 Anomaly AUC:0.4243
[2023-08-26 17:27:52,418][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00011 | loss1:0.0408 loss2:1.1298 loss3:0.3841 | AUC:0.3324 Anomaly AUC:0.4238
[2023-08-26 17:28:03,425][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00011 | loss1:0.0245 loss2:1.0721 loss3:0.3814 | AUC:0.3223 Anomaly AUC:0.4205
[2023-08-26 17:28:16,419][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00010 | loss1:0.0287 loss2:1.0426 loss3:0.3759 | AUC:0.2907 Anomaly AUC:0.4286
[2023-08-26 17:28:32,765][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00010 | loss1:0.0285 loss2:1.0300 loss3:0.3734 | AUC:0.2823 Anomaly AUC:0.4348
[2023-08-26 17:28:46,759][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00010 | loss1:0.0319 loss2:1.0095 loss3:0.3700 | AUC:0.2898 Anomaly AUC:0.4338
[2023-08-26 17:29:02,351][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00010 | loss1:0.0281 loss2:0.9802 loss3:0.3653 | AUC:0.3265 Anomaly AUC:0.4423
[2023-08-26 17:29:02,378][main.py][line:114][INFO] Training completes in 2m 11s | best AUCAUC:0.8073 Anomaly AUC:0.6154

[2023-08-26 17:29:13,278][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00003 | loss1:0.0716 loss2:1.3438 loss3:0.4020 | AUC:0.8010 Anomaly AUC:0.6165
[2023-08-26 17:29:27,800][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00003 | loss1:0.0357 loss2:1.3496 loss3:0.4013 | AUC:0.7949 Anomaly AUC:0.6130
[2023-08-26 17:29:41,049][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00003 | loss1:0.0283 loss2:1.3513 loss3:0.3967 | AUC:0.7865 Anomaly AUC:0.6178
[2023-08-26 17:29:54,031][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00003 | loss1:0.0297 loss2:1.3393 loss3:0.3945 | AUC:0.7900 Anomaly AUC:0.6156
[2023-08-26 17:30:07,115][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00003 | loss1:0.0239 loss2:1.3389 loss3:0.3928 | AUC:0.7782 Anomaly AUC:0.6093
[2023-08-26 17:30:20,021][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00003 | loss1:0.0271 loss2:1.3444 loss3:0.3905 | AUC:0.7788 Anomaly AUC:0.5994
[2023-08-26 17:30:32,949][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00003 | loss1:0.0268 loss2:1.3434 loss3:0.3885 | AUC:0.7184 Anomaly AUC:0.5796
[2023-08-26 17:30:45,880][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00003 | loss1:0.0249 loss2:1.3358 loss3:0.3870 | AUC:0.7007 Anomaly AUC:0.5871
[2023-08-26 17:30:58,408][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00003 | loss1:0.0192 loss2:1.3407 loss3:0.3851 | AUC:0.7539 Anomaly AUC:0.5989
[2023-08-26 17:31:09,793][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00003 | loss1:0.0265 loss2:1.3363 loss3:0.3829 | AUC:0.7233 Anomaly AUC:0.5741
[2023-08-26 17:31:09,846][main.py][line:114][INFO] Training completes in 2m 7s | best AUCAUC:0.8010 Anomaly AUC:0.6165

[2023-08-26 17:31:22,868][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00001 | loss1:0.3515 loss2:1.3340 loss3:0.5067 | AUC:0.6510 Anomaly AUC:0.5902
[2023-08-26 17:31:38,462][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00001 | loss1:0.0377 loss2:1.2542 loss3:0.4771 | AUC:0.3969 Anomaly AUC:0.4825
[2023-08-26 17:31:50,207][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00001 | loss1:0.0394 loss2:1.1370 loss3:0.4417 | AUC:0.3857 Anomaly AUC:0.4818
[2023-08-26 17:32:03,358][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00001 | loss1:0.0390 loss2:1.0468 loss3:0.4243 | AUC:0.5363 Anomaly AUC:0.4990
[2023-08-26 17:32:20,431][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00001 | loss1:0.0464 loss2:1.0139 loss3:0.4090 | AUC:0.6048 Anomaly AUC:0.5480
[2023-08-26 17:32:31,348][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00001 | loss1:0.0370 loss2:0.9741 loss3:0.3836 | AUC:0.7189 Anomaly AUC:0.5922
[2023-08-26 17:32:43,458][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00001 | loss1:0.0414 loss2:0.9693 loss3:0.3711 | AUC:0.6152 Anomaly AUC:0.5493
[2023-08-26 17:32:54,527][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00001 | loss1:0.0421 loss2:0.9547 loss3:0.3657 | AUC:0.6940 Anomaly AUC:0.6057
[2023-08-26 17:33:05,448][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00001 | loss1:0.0403 loss2:0.9299 loss3:0.3570 | AUC:0.7002 Anomaly AUC:0.6039
[2023-08-26 17:33:16,509][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00001 | loss1:0.0428 loss2:0.9077 loss3:0.3478 | AUC:0.6947 Anomaly AUC:0.6124
[2023-08-26 17:33:16,535][main.py][line:114][INFO] Training completes in 2m 7s | best AUCAUC:0.7189 Anomaly AUC:0.5922

[2023-08-26 17:33:29,801][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00003 | loss1:0.0331 loss2:0.9538 loss3:0.3553 | AUC:0.7639 Anomaly AUC:0.6149
[2023-08-26 17:33:42,727][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00003 | loss1:0.0356 loss2:0.9283 loss3:0.3404 | AUC:0.7621 Anomaly AUC:0.6208
[2023-08-26 17:33:56,083][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00003 | loss1:0.0371 loss2:0.9092 loss3:0.3355 | AUC:0.7766 Anomaly AUC:0.6206
[2023-08-26 17:34:09,190][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00003 | loss1:0.0355 loss2:0.8671 loss3:0.3267 | AUC:0.7845 Anomaly AUC:0.6247
[2023-08-26 17:34:22,070][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00003 | loss1:0.0297 loss2:0.8516 loss3:0.3210 | AUC:0.5062 Anomaly AUC:0.5632
[2023-08-26 17:34:38,392][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00003 | loss1:0.0384 loss2:0.8372 loss3:0.3332 | AUC:0.7641 Anomaly AUC:0.6208
[2023-08-26 17:34:49,303][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00003 | loss1:0.0312 loss2:0.8133 loss3:0.3065 | AUC:0.7499 Anomaly AUC:0.6189
[2023-08-26 17:35:01,523][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00003 | loss1:0.0303 loss2:0.7941 loss3:0.2886 | AUC:0.7492 Anomaly AUC:0.6243
[2023-08-26 17:35:14,783][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00003 | loss1:0.0310 loss2:0.7831 loss3:0.2781 | AUC:0.7334 Anomaly AUC:0.6175
[2023-08-26 17:35:28,018][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00003 | loss1:0.0322 loss2:0.7746 loss3:0.2679 | AUC:0.7197 Anomaly AUC:0.6247
[2023-08-26 17:35:28,071][main.py][line:114][INFO] Training completes in 2m 11s | best AUCAUC:0.7845 Anomaly AUC:0.6247

[2023-08-26 17:35:45,518][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00045 | loss1:0.1920 loss2:0.9936 loss3:0.3338 | AUC:0.8011 Anomaly AUC:0.6349
[2023-08-26 17:35:58,640][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00045 | loss1:0.0290 loss2:0.8549 loss3:0.3306 | AUC:0.7230 Anomaly AUC:0.6057
[2023-08-26 17:36:12,483][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00045 | loss1:0.0322 loss2:0.8179 loss3:0.3376 | AUC:0.7928 Anomaly AUC:0.6189
[2023-08-26 17:36:26,019][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00045 | loss1:0.0305 loss2:0.7920 loss3:0.3289 | AUC:0.7929 Anomaly AUC:0.6183
[2023-08-26 17:36:37,000][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00044 | loss1:0.0284 loss2:0.7650 loss3:0.3257 | AUC:0.7834 Anomaly AUC:0.6132
[2023-08-26 17:36:48,512][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00044 | loss1:0.0219 loss2:0.7366 loss3:0.3226 | AUC:0.6362 Anomaly AUC:0.5687
[2023-08-26 17:37:02,484][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00044 | loss1:0.0792 loss2:0.8722 loss3:0.3488 | AUC:0.6925 Anomaly AUC:0.6049
[2023-08-26 17:37:15,695][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00043 | loss1:0.0274 loss2:0.7612 loss3:0.3439 | AUC:0.7707 Anomaly AUC:0.6172
[2023-08-26 17:37:32,182][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00043 | loss1:0.0266 loss2:0.7305 loss3:0.3338 | AUC:0.7661 Anomaly AUC:0.6074
[2023-08-26 17:37:44,682][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00042 | loss1:0.0293 loss2:0.6990 loss3:0.3273 | AUC:0.7722 Anomaly AUC:0.6143
[2023-08-26 17:37:44,708][main.py][line:114][INFO] Training completes in 2m 17s | best AUCAUC:0.8011 Anomaly AUC:0.6349

[2023-08-26 17:37:56,294][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00003 | loss1:0.0334 loss2:0.8846 loss3:0.3356 | AUC:0.7977 Anomaly AUC:0.6341
[2023-08-26 17:38:10,992][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00003 | loss1:0.0276 loss2:0.8539 loss3:0.3137 | AUC:0.7866 Anomaly AUC:0.6439
[2023-08-26 17:38:25,070][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00003 | loss1:0.0275 loss2:0.8392 loss3:0.3026 | AUC:0.7920 Anomaly AUC:0.6257
[2023-08-26 17:38:38,624][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00003 | loss1:0.0270 loss2:0.8299 loss3:0.2903 | AUC:0.7675 Anomaly AUC:0.6322
[2023-08-26 17:38:49,597][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00003 | loss1:0.0265 loss2:0.8216 loss3:0.2831 | AUC:0.7751 Anomaly AUC:0.6273
[2023-08-26 17:39:00,554][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00003 | loss1:0.0297 loss2:0.8221 loss3:0.2659 | AUC:0.7800 Anomaly AUC:0.6299
[2023-08-26 17:39:16,162][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00003 | loss1:0.0248 loss2:0.8052 loss3:0.2455 | AUC:0.7882 Anomaly AUC:0.6305
[2023-08-26 17:39:29,180][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00003 | loss1:0.0248 loss2:0.8159 loss3:0.2609 | AUC:0.7495 Anomaly AUC:0.6364
[2023-08-26 17:39:44,753][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00003 | loss1:0.0242 loss2:0.8078 loss3:0.2191 | AUC:0.7797 Anomaly AUC:0.6370
[2023-08-26 17:39:58,237][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00003 | loss1:0.0232 loss2:0.7934 loss3:0.1773 | AUC:0.7806 Anomaly AUC:0.6338
[2023-08-26 17:39:58,289][main.py][line:114][INFO] Training completes in 2m 14s | best AUCAUC:0.7977 Anomaly AUC:0.6341

[2023-08-26 17:40:09,177][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00012 | loss1:0.1180 loss2:0.9809 loss3:0.3553 | AUC:0.7797 Anomaly AUC:0.6443
[2023-08-26 17:40:19,973][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00012 | loss1:0.0329 loss2:0.9701 loss3:0.3626 | AUC:0.6258 Anomaly AUC:0.5915
[2023-08-26 17:40:30,977][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00012 | loss1:0.0259 loss2:0.9426 loss3:0.3520 | AUC:0.6947 Anomaly AUC:0.5903
[2023-08-26 17:40:44,442][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00012 | loss1:0.0265 loss2:0.9216 loss3:0.3393 | AUC:0.5800 Anomaly AUC:0.5657
[2023-08-26 17:41:10,422][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00012 | loss1:0.0285 loss2:0.9228 loss3:0.3314 | AUC:0.3710 Anomaly AUC:0.5248
[2023-08-26 17:41:21,520][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00012 | loss1:0.0326 loss2:0.9519 loss3:0.3314 | AUC:0.5262 Anomaly AUC:0.5611
[2023-08-26 17:41:35,320][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00012 | loss1:0.0277 loss2:0.9217 loss3:0.3171 | AUC:0.7054 Anomaly AUC:0.6073
[2023-08-26 17:41:48,163][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00012 | loss1:0.0226 loss2:0.9075 loss3:0.3000 | AUC:0.4784 Anomaly AUC:0.5884
[2023-08-26 17:42:02,727][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00011 | loss1:0.0228 loss2:0.9208 loss3:0.3091 | AUC:0.6578 Anomaly AUC:0.6288
[2023-08-26 17:42:16,204][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00011 | loss1:0.0226 loss2:0.8974 loss3:0.2974 | AUC:0.4306 Anomaly AUC:0.5920
[2023-08-26 17:42:16,231][main.py][line:114][INFO] Training completes in 2m 18s | best AUCAUC:0.7797 Anomaly AUC:0.6443

[2023-08-26 17:42:29,342][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00005 | loss1:0.2139 loss2:1.0503 loss3:0.4227 | AUC:0.5340 Anomaly AUC:0.5579
[2023-08-26 17:42:42,801][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00005 | loss1:0.0408 loss2:0.9004 loss3:0.3638 | AUC:0.4374 Anomaly AUC:0.5470
[2023-08-26 17:42:56,274][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00005 | loss1:0.0414 loss2:0.8706 loss3:0.3397 | AUC:0.4318 Anomaly AUC:0.5364
[2023-08-26 17:43:09,989][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00005 | loss1:0.0385 loss2:0.8505 loss3:0.3173 | AUC:0.5440 Anomaly AUC:0.5659
[2023-08-26 17:43:24,626][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00005 | loss1:0.0357 loss2:0.8423 loss3:0.2986 | AUC:0.3414 Anomaly AUC:0.5225
[2023-08-26 17:43:37,977][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00005 | loss1:0.0439 loss2:0.8427 loss3:0.2806 | AUC:0.5210 Anomaly AUC:0.5595
[2023-08-26 17:43:51,809][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00005 | loss1:0.0390 loss2:0.8410 loss3:0.2923 | AUC:0.2979 Anomaly AUC:0.5068
[2023-08-26 17:44:05,631][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00005 | loss1:0.0557 loss2:0.8592 loss3:0.2758 | AUC:0.3697 Anomaly AUC:0.5244
[2023-08-26 17:44:19,032][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00005 | loss1:0.0330 loss2:0.8147 loss3:0.2213 | AUC:0.7094 Anomaly AUC:0.5955
[2023-08-26 17:44:32,654][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00005 | loss1:0.0289 loss2:0.7911 loss3:0.1972 | AUC:0.4148 Anomaly AUC:0.5674
[2023-08-26 17:44:32,706][main.py][line:114][INFO] Training completes in 2m 16s | best AUCAUC:0.7094 Anomaly AUC:0.5955

[2023-08-26 17:44:43,751][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00001 | loss1:0.0302 loss2:0.7869 loss3:0.1942 | AUC:0.6746 Anomaly AUC:0.6335
[2023-08-26 17:44:54,622][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00001 | loss1:0.0282 loss2:0.7683 loss3:0.1830 | AUC:0.7125 Anomaly AUC:0.6248
[2023-08-26 17:45:05,995][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00001 | loss1:0.0278 loss2:0.7618 loss3:0.1739 | AUC:0.7263 Anomaly AUC:0.6193
[2023-08-26 17:45:19,138][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00001 | loss1:0.0270 loss2:0.7573 loss3:0.1680 | AUC:0.6929 Anomaly AUC:0.6216
[2023-08-26 17:45:32,934][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00001 | loss1:0.0251 loss2:0.7478 loss3:0.1650 | AUC:0.7206 Anomaly AUC:0.6145
[2023-08-26 17:45:44,867][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00001 | loss1:0.0227 loss2:0.7445 loss3:0.1534 | AUC:0.6946 Anomaly AUC:0.6160
[2023-08-26 17:45:56,096][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00001 | loss1:0.0254 loss2:0.7381 loss3:0.1570 | AUC:0.6710 Anomaly AUC:0.6091
[2023-08-26 17:46:07,586][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00001 | loss1:0.0295 loss2:0.7321 loss3:0.1607 | AUC:0.6717 Anomaly AUC:0.6122
[2023-08-26 17:46:22,035][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00001 | loss1:0.0255 loss2:0.7204 loss3:0.1474 | AUC:0.6404 Anomaly AUC:0.6097
[2023-08-26 17:46:35,735][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00001 | loss1:0.0248 loss2:0.7121 loss3:0.1357 | AUC:0.6381 Anomaly AUC:0.6090
[2023-08-26 17:46:35,788][main.py][line:114][INFO] Training completes in 2m 3s | best AUCAUC:0.7263 Anomaly AUC:0.6193

[2023-08-26 17:46:48,962][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00016 | loss1:0.0237 loss2:0.7733 loss3:0.1666 | AUC:0.6756 Anomaly AUC:0.6179
[2023-08-26 17:47:09,789][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00016 | loss1:0.0290 loss2:0.7757 loss3:0.1706 | AUC:0.7538 Anomaly AUC:0.6209
[2023-08-26 17:47:20,688][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00016 | loss1:0.0236 loss2:0.7557 loss3:0.1615 | AUC:0.7008 Anomaly AUC:0.6201
[2023-08-26 17:47:32,664][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00016 | loss1:0.0258 loss2:0.7509 loss3:0.1593 | AUC:0.7094 Anomaly AUC:0.6235
[2023-08-26 17:47:46,349][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00016 | loss1:0.0285 loss2:0.7439 loss3:0.1535 | AUC:0.6953 Anomaly AUC:0.6219
[2023-08-26 17:48:01,506][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00015 | loss1:0.0256 loss2:0.7381 loss3:0.1530 | AUC:0.7319 Anomaly AUC:0.6266
[2023-08-26 17:48:13,510][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00015 | loss1:0.0225 loss2:0.7171 loss3:0.1537 | AUC:0.7285 Anomaly AUC:0.6262
[2023-08-26 17:48:27,388][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00015 | loss1:0.0256 loss2:0.7178 loss3:0.1506 | AUC:0.6882 Anomaly AUC:0.6241
[2023-08-26 17:48:41,162][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00015 | loss1:0.0264 loss2:0.7174 loss3:0.1496 | AUC:0.7374 Anomaly AUC:0.6247
[2023-08-26 17:48:52,097][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00015 | loss1:0.0277 loss2:0.7112 loss3:0.1447 | AUC:0.7186 Anomaly AUC:0.6249
[2023-08-26 17:48:52,124][main.py][line:114][INFO] Training completes in 2m 16s | best AUCAUC:0.7538 Anomaly AUC:0.6209

[2023-08-26 17:49:03,091][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00089 | loss1:0.3266 loss2:1.1936 loss3:0.1719 | AUC:0.7813 Anomaly AUC:0.6011
[2023-08-26 17:49:16,773][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00089 | loss1:0.0254 loss2:1.0680 loss3:0.1908 | AUC:0.6557 Anomaly AUC:0.5416
[2023-08-26 17:49:30,401][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00089 | loss1:0.0328 loss2:0.8833 loss3:0.1846 | AUC:0.7481 Anomaly AUC:0.5979
[2023-08-26 17:49:44,023][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00088 | loss1:0.0298 loss2:0.8975 loss3:0.1852 | AUC:0.7833 Anomaly AUC:0.6166
[2023-08-26 17:49:57,820][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00088 | loss1:0.0282 loss2:0.8562 loss3:0.1850 | AUC:0.7863 Anomaly AUC:0.6198
[2023-08-26 17:50:11,300][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00087 | loss1:0.0235 loss2:0.8262 loss3:0.1865 | AUC:0.7707 Anomaly AUC:0.6014
[2023-08-26 17:50:27,265][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00086 | loss1:0.0251 loss2:0.7968 loss3:0.1839 | AUC:0.7849 Anomaly AUC:0.6146
[2023-08-26 17:50:38,187][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00085 | loss1:0.0292 loss2:0.7812 loss3:0.1851 | AUC:0.7814 Anomaly AUC:0.5994
[2023-08-26 17:50:49,340][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00084 | loss1:0.0256 loss2:0.7481 loss3:0.1836 | AUC:0.7623 Anomaly AUC:0.5925
[2023-08-26 17:51:03,548][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00083 | loss1:0.0258 loss2:0.7472 loss3:0.1843 | AUC:0.7545 Anomaly AUC:0.5658
[2023-08-26 17:51:03,600][main.py][line:114][INFO] Training completes in 2m 11s | best AUCAUC:0.7863 Anomaly AUC:0.6198

[2023-08-26 17:51:17,032][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00031 | loss1:0.0326 loss2:0.7705 loss3:0.1949 | AUC:0.7833 Anomaly AUC:0.6206
[2023-08-26 17:51:30,379][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00031 | loss1:0.0279 loss2:0.7726 loss3:0.1954 | AUC:0.7606 Anomaly AUC:0.6031
[2023-08-26 17:51:44,210][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00031 | loss1:0.0323 loss2:0.7623 loss3:0.2011 | AUC:0.7737 Anomaly AUC:0.6115
[2023-08-26 17:51:57,766][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00031 | loss1:0.0273 loss2:0.7310 loss3:0.2020 | AUC:0.7771 Anomaly AUC:0.6021
[2023-08-26 17:52:11,687][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00031 | loss1:0.0250 loss2:0.7139 loss3:0.2034 | AUC:0.7729 Anomaly AUC:0.5990
[2023-08-26 17:52:22,821][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00031 | loss1:0.0264 loss2:0.6968 loss3:0.2007 | AUC:0.7753 Anomaly AUC:0.6079
[2023-08-26 17:52:41,462][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00030 | loss1:0.0244 loss2:0.7001 loss3:0.2052 | AUC:0.7678 Anomaly AUC:0.5975
[2023-08-26 17:52:57,824][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00030 | loss1:0.0262 loss2:0.6815 loss3:0.2121 | AUC:0.7306 Anomaly AUC:0.6042
[2023-08-26 17:53:18,123][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00030 | loss1:0.0247 loss2:0.6814 loss3:0.2135 | AUC:0.7634 Anomaly AUC:0.6038
[2023-08-26 17:53:31,135][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00029 | loss1:0.0221 loss2:0.6699 loss3:0.2066 | AUC:0.7573 Anomaly AUC:0.6029
[2023-08-26 17:53:31,161][main.py][line:114][INFO] Training completes in 2m 27s | best AUCAUC:0.7833 Anomaly AUC:0.6206

[2023-08-26 17:53:43,085][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00008 | loss1:0.0270 loss2:0.7242 loss3:0.1656 | AUC:0.7249 Anomaly AUC:0.6169
[2023-08-26 17:53:56,317][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00008 | loss1:0.0266 loss2:0.7139 loss3:0.1559 | AUC:0.7566 Anomaly AUC:0.6211
[2023-08-26 17:54:07,355][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00008 | loss1:0.0212 loss2:0.7076 loss3:0.1519 | AUC:0.7521 Anomaly AUC:0.6215
[2023-08-26 17:54:19,114][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00008 | loss1:0.0274 loss2:0.7051 loss3:0.1491 | AUC:0.7423 Anomaly AUC:0.6227
[2023-08-26 17:54:33,100][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00007 | loss1:0.0266 loss2:0.6947 loss3:0.1450 | AUC:0.7341 Anomaly AUC:0.6222
[2023-08-26 17:54:44,172][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00007 | loss1:0.0224 loss2:0.6912 loss3:0.1453 | AUC:0.7319 Anomaly AUC:0.6230
[2023-08-26 17:54:59,320][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00007 | loss1:0.0222 loss2:0.6850 loss3:0.1432 | AUC:0.7265 Anomaly AUC:0.6241
[2023-08-26 17:55:15,868][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00007 | loss1:0.0186 loss2:0.6862 loss3:0.1420 | AUC:0.7280 Anomaly AUC:0.6263
[2023-08-26 17:55:30,369][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00007 | loss1:0.0217 loss2:0.6779 loss3:0.1391 | AUC:0.7116 Anomaly AUC:0.6238
[2023-08-26 17:55:44,693][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00007 | loss1:0.0215 loss2:0.6746 loss3:0.1371 | AUC:0.7153 Anomaly AUC:0.6252
[2023-08-26 17:55:44,746][main.py][line:114][INFO] Training completes in 2m 14s | best AUCAUC:0.7566 Anomaly AUC:0.6211

[2023-08-26 17:55:59,498][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00022 | loss1:0.0272 loss2:0.7492 loss3:0.1750 | AUC:0.7522 Anomaly AUC:0.6108
[2023-08-26 17:56:14,070][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00022 | loss1:0.0438 loss2:0.7530 loss3:0.1575 | AUC:0.7448 Anomaly AUC:0.6082
[2023-08-26 17:56:28,722][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00022 | loss1:0.0301 loss2:0.7385 loss3:0.1393 | AUC:0.7542 Anomaly AUC:0.6287
[2023-08-26 17:56:43,729][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00022 | loss1:0.0329 loss2:0.7396 loss3:0.1383 | AUC:0.7465 Anomaly AUC:0.6440
[2023-08-26 17:56:58,183][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00022 | loss1:0.0267 loss2:0.7367 loss3:0.1279 | AUC:0.7326 Anomaly AUC:0.6403
[2023-08-26 17:57:12,595][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00022 | loss1:0.0243 loss2:0.7229 loss3:0.1302 | AUC:0.7071 Anomaly AUC:0.6486
[2023-08-26 17:57:27,310][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00022 | loss1:0.0244 loss2:0.7110 loss3:0.1300 | AUC:0.6759 Anomaly AUC:0.6347
[2023-08-26 17:57:38,472][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00021 | loss1:0.0212 loss2:0.6959 loss3:0.1239 | AUC:0.6811 Anomaly AUC:0.6403
[2023-08-26 17:57:56,153][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00021 | loss1:0.0232 loss2:0.7017 loss3:0.1260 | AUC:0.6402 Anomaly AUC:0.6362
[2023-08-26 17:58:08,074][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00021 | loss1:0.0235 loss2:0.7040 loss3:0.1282 | AUC:0.7061 Anomaly AUC:0.6385
[2023-08-26 17:58:08,126][main.py][line:114][INFO] Training completes in 2m 23s | best AUCAUC:0.7542 Anomaly AUC:0.6287

[2023-08-26 17:58:24,661][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00095 | loss1:0.2011 loss2:1.1404 loss3:0.1294 | AUC:0.6556 Anomaly AUC:0.4913
[2023-08-26 17:58:35,705][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00095 | loss1:0.0326 loss2:1.1274 loss3:0.1301 | AUC:0.6850 Anomaly AUC:0.5182
[2023-08-26 17:58:47,766][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00094 | loss1:0.0401 loss2:1.0992 loss3:0.1257 | AUC:0.6458 Anomaly AUC:0.4845
[2023-08-26 17:59:02,666][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00094 | loss1:0.0448 loss2:1.1002 loss3:0.1275 | AUC:0.7489 Anomaly AUC:0.6026
[2023-08-26 17:59:13,591][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00093 | loss1:0.0325 loss2:1.0966 loss3:0.1258 | AUC:0.6901 Anomaly AUC:0.5381
[2023-08-26 17:59:25,718][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00093 | loss1:0.0273 loss2:1.0708 loss3:0.1232 | AUC:0.7310 Anomaly AUC:0.5862
[2023-08-26 17:59:36,925][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00092 | loss1:0.0440 loss2:1.0401 loss3:0.1296 | AUC:0.7571 Anomaly AUC:0.6145
[2023-08-26 17:59:48,023][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00091 | loss1:0.0267 loss2:0.9180 loss3:0.1234 | AUC:0.7562 Anomaly AUC:0.6302
[2023-08-26 18:00:06,004][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00090 | loss1:0.0261 loss2:0.8489 loss3:0.1222 | AUC:0.7272 Anomaly AUC:0.5732
[2023-08-26 18:00:20,592][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00089 | loss1:0.0298 loss2:0.7905 loss3:0.1263 | AUC:0.7482 Anomaly AUC:0.6473
[2023-08-26 18:00:20,645][main.py][line:114][INFO] Training completes in 2m 12s | best AUCAUC:0.7571 Anomaly AUC:0.6145

[2023-08-26 18:00:39,479][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00009 | loss1:0.0266 loss2:0.7435 loss3:0.1533 | AUC:0.7733 Anomaly AUC:0.6421
[2023-08-26 18:00:50,289][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00009 | loss1:0.0247 loss2:0.6621 loss3:0.1371 | AUC:0.7475 Anomaly AUC:0.6503
[2023-08-26 18:01:01,322][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00009 | loss1:0.0238 loss2:0.6380 loss3:0.1328 | AUC:0.7234 Anomaly AUC:0.6288
[2023-08-26 18:01:13,003][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00009 | loss1:0.0222 loss2:0.6073 loss3:0.1255 | AUC:0.7436 Anomaly AUC:0.6260
[2023-08-26 18:01:26,310][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00009 | loss1:0.0254 loss2:0.5997 loss3:0.1447 | AUC:0.7256 Anomaly AUC:0.6372
[2023-08-26 18:01:42,696][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00009 | loss1:0.0188 loss2:0.5775 loss3:0.1377 | AUC:0.7275 Anomaly AUC:0.6282
[2023-08-26 18:01:58,134][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00009 | loss1:0.0226 loss2:0.5809 loss3:0.1315 | AUC:0.7346 Anomaly AUC:0.6153
[2023-08-26 18:02:13,367][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00009 | loss1:0.0244 loss2:0.5680 loss3:0.1313 | AUC:0.7395 Anomaly AUC:0.6147
[2023-08-26 18:02:37,664][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00009 | loss1:0.0229 loss2:0.5489 loss3:0.1306 | AUC:0.7645 Anomaly AUC:0.6266
[2023-08-26 18:02:49,252][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00009 | loss1:0.0219 loss2:0.5355 loss3:0.1276 | AUC:0.7443 Anomaly AUC:0.6244
[2023-08-26 18:02:49,307][main.py][line:114][INFO] Training completes in 2m 29s | best AUCAUC:0.7733 Anomaly AUC:0.6421

[2023-08-26 18:03:03,689][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00050 | loss1:0.0458 loss2:0.7146 loss3:0.1462 | AUC:0.7796 Anomaly AUC:0.6431
[2023-08-26 18:03:14,649][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00050 | loss1:0.0241 loss2:0.6478 loss3:0.1292 | AUC:0.7513 Anomaly AUC:0.6412
[2023-08-26 18:03:42,037][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00050 | loss1:0.0288 loss2:0.6322 loss3:0.1237 | AUC:0.7581 Anomaly AUC:0.6420
[2023-08-26 18:03:56,202][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00050 | loss1:0.0266 loss2:0.6074 loss3:0.1202 | AUC:0.7544 Anomaly AUC:0.6411
[2023-08-26 18:04:09,044][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00049 | loss1:0.0263 loss2:0.5953 loss3:0.1236 | AUC:0.7530 Anomaly AUC:0.6428
[2023-08-26 18:04:20,146][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00049 | loss1:0.0265 loss2:0.5828 loss3:0.1170 | AUC:0.7491 Anomaly AUC:0.6488
[2023-08-26 18:04:32,989][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00048 | loss1:0.0281 loss2:0.5716 loss3:0.1173 | AUC:0.7507 Anomaly AUC:0.6391
[2023-08-26 18:04:50,542][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00048 | loss1:0.0274 loss2:0.5566 loss3:0.1168 | AUC:0.7465 Anomaly AUC:0.6431
[2023-08-26 18:05:03,718][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00047 | loss1:0.0239 loss2:0.5281 loss3:0.1139 | AUC:0.7516 Anomaly AUC:0.6435
[2023-08-26 18:05:18,458][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00047 | loss1:0.0174 loss2:0.5205 loss3:0.1157 | AUC:0.7540 Anomaly AUC:0.6438
[2023-08-26 18:05:18,512][main.py][line:114][INFO] Training completes in 2m 29s | best AUCAUC:0.7796 Anomaly AUC:0.6431

[2023-08-26 18:05:33,035][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00021 | loss1:0.0267 loss2:0.6458 loss3:0.1205 | AUC:0.7412 Anomaly AUC:0.6420
[2023-08-26 18:05:51,060][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00021 | loss1:0.0316 loss2:0.6357 loss3:0.1150 | AUC:0.7406 Anomaly AUC:0.6464
[2023-08-26 18:06:01,956][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00021 | loss1:0.0266 loss2:0.6208 loss3:0.1142 | AUC:0.7476 Anomaly AUC:0.6448
[2023-08-26 18:06:12,848][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00021 | loss1:0.0260 loss2:0.6109 loss3:0.1137 | AUC:0.7306 Anomaly AUC:0.6432
[2023-08-26 18:06:24,612][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00020 | loss1:0.0234 loss2:0.6030 loss3:0.1137 | AUC:0.7266 Anomaly AUC:0.6506
[2023-08-26 18:06:37,770][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00020 | loss1:0.0267 loss2:0.5993 loss3:0.1156 | AUC:0.7279 Anomaly AUC:0.6434
[2023-08-26 18:06:55,009][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00020 | loss1:0.0234 loss2:0.5882 loss3:0.1122 | AUC:0.7204 Anomaly AUC:0.6426
[2023-08-26 18:07:05,974][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00020 | loss1:0.0234 loss2:0.5823 loss3:0.1109 | AUC:0.7335 Anomaly AUC:0.6401
[2023-08-26 18:07:18,086][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00020 | loss1:0.0242 loss2:0.5918 loss3:0.1089 | AUC:0.7354 Anomaly AUC:0.6402
[2023-08-26 18:07:32,349][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00019 | loss1:0.0208 loss2:0.5626 loss3:0.1080 | AUC:0.7339 Anomaly AUC:0.6365
[2023-08-26 18:07:32,376][main.py][line:114][INFO] Training completes in 2m 14s | best AUCAUC:0.7476 Anomaly AUC:0.6448

[2023-08-26 18:07:46,277][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00007 | loss1:0.0267 loss2:0.5975 loss3:0.1191 | AUC:0.7338 Anomaly AUC:0.6485
[2023-08-26 18:07:57,361][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00007 | loss1:0.0241 loss2:0.5945 loss3:0.1184 | AUC:0.7418 Anomaly AUC:0.6424
[2023-08-26 18:08:08,377][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00007 | loss1:0.0186 loss2:0.5862 loss3:0.1177 | AUC:0.7482 Anomaly AUC:0.6405
[2023-08-26 18:08:20,444][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00007 | loss1:0.0180 loss2:0.5833 loss3:0.1170 | AUC:0.7424 Anomaly AUC:0.6389
[2023-08-26 18:08:51,276][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00007 | loss1:0.0203 loss2:0.5748 loss3:0.1155 | AUC:0.7489 Anomaly AUC:0.6407
[2023-08-26 18:09:03,444][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00007 | loss1:0.0165 loss2:0.5666 loss3:0.1156 | AUC:0.7476 Anomaly AUC:0.6429
[2023-08-26 18:09:26,145][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00007 | loss1:0.0222 loss2:0.5674 loss3:0.1180 | AUC:0.7431 Anomaly AUC:0.6404
[2023-08-26 18:09:37,091][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00007 | loss1:0.0160 loss2:0.5560 loss3:0.1174 | AUC:0.7390 Anomaly AUC:0.6399
[2023-08-26 18:09:51,559][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00007 | loss1:0.0151 loss2:0.5537 loss3:0.1173 | AUC:0.7361 Anomaly AUC:0.6404
[2023-08-26 18:10:05,090][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00007 | loss1:0.0158 loss2:0.5497 loss3:0.1183 | AUC:0.7360 Anomaly AUC:0.6412
[2023-08-26 18:10:05,140][main.py][line:114][INFO] Training completes in 2m 33s | best AUCAUC:0.7489 Anomaly AUC:0.6407

[2023-08-26 18:10:20,090][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00014 | loss1:0.0213 loss2:0.5724 loss3:0.1150 | AUC:0.6653 Anomaly AUC:0.6330
[2023-08-26 18:10:31,014][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00014 | loss1:0.0249 loss2:0.5786 loss3:0.1217 | AUC:0.7060 Anomaly AUC:0.6410
[2023-08-26 18:10:42,963][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00014 | loss1:0.0239 loss2:0.5673 loss3:0.1137 | AUC:0.7095 Anomaly AUC:0.6404
[2023-08-26 18:11:00,939][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00014 | loss1:0.0165 loss2:0.5636 loss3:0.1136 | AUC:0.7098 Anomaly AUC:0.6366
[2023-08-26 18:11:14,720][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00014 | loss1:0.0163 loss2:0.5498 loss3:0.1125 | AUC:0.6993 Anomaly AUC:0.6298
[2023-08-26 18:11:25,713][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00014 | loss1:0.0185 loss2:0.5473 loss3:0.1139 | AUC:0.7214 Anomaly AUC:0.6336
[2023-08-26 18:13:43,110][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 18:13:43,232][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 18:13:43,232][main.py][line:169][INFO] Training Mode
[2023-08-26 18:18:40,299][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 18:18:40,420][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 18:18:40,420][main.py][line:169][INFO] Training Mode
[2023-08-26 18:19:51,356][main.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.8, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 18:19:51,477][main.py][line:166][INFO] total params:9.6689M
[2023-08-26 18:19:51,477][main.py][line:169][INFO] Training Mode
[2023-08-26 18:20:11,498][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00020 | loss1:0.6685 loss2:1.2951 loss3:0.3817 | AUC:0.7970 Anomaly AUC:0.6247
[2023-08-26 18:20:22,549][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00020 | loss1:0.4257 loss2:1.1278 loss3:0.3809 | AUC:0.8126 Anomaly AUC:0.6408
[2023-08-26 18:20:33,074][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00020 | loss1:0.1385 loss2:0.9629 loss3:0.4401 | AUC:0.8020 Anomaly AUC:0.6661
[2023-08-26 18:20:43,686][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00020 | loss1:0.0471 loss2:0.8708 loss3:0.4074 | AUC:0.7698 Anomaly AUC:0.6162
[2023-08-26 18:20:55,424][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00020 | loss1:0.0825 loss2:0.8678 loss3:0.4160 | AUC:0.8022 Anomaly AUC:0.6426
[2023-08-26 18:21:07,497][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00020 | loss1:0.0398 loss2:0.8272 loss3:0.3626 | AUC:0.7921 Anomaly AUC:0.6472
[2023-08-26 18:21:20,515][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00020 | loss1:0.0327 loss2:0.8036 loss3:0.3292 | AUC:0.7661 Anomaly AUC:0.6327
[2023-08-26 18:21:35,229][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00020 | loss1:0.0374 loss2:0.7874 loss3:0.3186 | AUC:0.7484 Anomaly AUC:0.6434
[2023-08-26 18:21:47,982][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00020 | loss1:0.0359 loss2:0.7712 loss3:0.2327 | AUC:0.7463 Anomaly AUC:0.6269
[2023-08-26 18:22:02,295][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00020 | loss1:0.0636 loss2:0.8017 loss3:0.3102 | AUC:0.7100 Anomaly AUC:0.6058
[2023-08-26 18:22:02,351][main.py][line:114][INFO] Training completes in 2m 11s | best AUCAUC:0.8126 Anomaly AUC:0.6408

[2023-08-26 18:22:15,279][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00040 | loss1:0.5269 loss2:1.2048 loss3:0.3693 | AUC:0.8034 Anomaly AUC:0.6037
[2023-08-26 18:22:29,502][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00040 | loss1:0.2940 loss2:1.0289 loss3:0.3079 | AUC:0.7998 Anomaly AUC:0.6171
[2023-08-26 18:22:42,281][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00040 | loss1:0.0823 loss2:0.8962 loss3:0.3280 | AUC:0.7984 Anomaly AUC:0.6397
[2023-08-26 18:22:54,765][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00040 | loss1:0.0886 loss2:0.8833 loss3:0.3463 | AUC:0.7702 Anomaly AUC:0.6387
[2023-08-26 18:23:06,235][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00040 | loss1:0.1300 loss2:0.9309 loss3:0.2549 | AUC:0.7667 Anomaly AUC:0.6440
[2023-08-26 18:23:17,155][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00040 | loss1:0.0617 loss2:0.8594 loss3:0.2295 | AUC:0.7979 Anomaly AUC:0.6545
[2023-08-26 18:23:28,040][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00040 | loss1:0.0513 loss2:0.8376 loss3:0.1748 | AUC:0.7058 Anomaly AUC:0.6455
[2023-08-26 18:23:39,989][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00040 | loss1:0.0492 loss2:0.8244 loss3:0.1405 | AUC:0.7633 Anomaly AUC:0.6511
[2023-08-26 18:23:52,353][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00040 | loss1:0.0367 loss2:0.7877 loss3:0.1186 | AUC:0.7304 Anomaly AUC:0.6472
[2023-08-26 18:24:04,849][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00040 | loss1:0.0345 loss2:0.7573 loss3:0.1067 | AUC:0.7516 Anomaly AUC:0.6500
[2023-08-26 18:24:04,899][main.py][line:114][INFO] Training completes in 2m 2s | best AUCAUC:0.8034 Anomaly AUC:0.6037

[2023-08-26 18:24:17,285][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00100 | loss1:0.5666 loss2:1.2206 loss3:0.3542 | AUC:0.8087 Anomaly AUC:0.6136
[2023-08-26 18:24:29,850][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00100 | loss1:0.3381 loss2:1.0695 loss3:0.2393 | AUC:0.7937 Anomaly AUC:0.6171
[2023-08-26 18:24:42,219][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00100 | loss1:0.2897 loss2:1.0209 loss3:0.1789 | AUC:0.8037 Anomaly AUC:0.6161
[2023-08-26 18:24:53,768][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00100 | loss1:0.2474 loss2:0.9685 loss3:0.1542 | AUC:0.8116 Anomaly AUC:0.6282
[2023-08-26 18:25:07,808][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00100 | loss1:0.2527 loss2:0.9699 loss3:0.1509 | AUC:0.8067 Anomaly AUC:0.6227
[2023-08-26 18:25:20,227][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00100 | loss1:0.2133 loss2:0.9488 loss3:0.1342 | AUC:0.8058 Anomaly AUC:0.6365
[2023-08-26 18:25:32,679][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00100 | loss1:0.1765 loss2:0.9247 loss3:0.1210 | AUC:0.7958 Anomaly AUC:0.6417
[2023-08-26 18:25:45,121][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00100 | loss1:0.1643 loss2:0.9022 loss3:0.1112 | AUC:0.8048 Anomaly AUC:0.6417
[2023-08-26 18:25:57,567][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00100 | loss1:0.1646 loss2:0.9058 loss3:0.1019 | AUC:0.8042 Anomaly AUC:0.6188
[2023-08-26 18:26:10,194][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00100 | loss1:0.1287 loss2:0.8748 loss3:0.0913 | AUC:0.8016 Anomaly AUC:0.6242
[2023-08-26 18:26:10,245][main.py][line:114][INFO] Training completes in 2m 5s | best AUCAUC:0.8116 Anomaly AUC:0.6282

[2023-08-26 18:26:24,155][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00020 | loss1:0.2925 loss2:0.9869 loss3:0.1701 | AUC:0.8142 Anomaly AUC:0.6348
[2023-08-26 18:26:35,140][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00020 | loss1:0.1620 loss2:0.9160 loss3:0.1302 | AUC:0.8088 Anomaly AUC:0.6319
[2023-08-26 18:26:45,979][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00020 | loss1:0.1411 loss2:0.8731 loss3:0.1075 | AUC:0.8161 Anomaly AUC:0.6301
[2023-08-26 18:26:57,640][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00020 | loss1:0.1220 loss2:0.8417 loss3:0.0922 | AUC:0.8080 Anomaly AUC:0.6440
[2023-08-26 18:27:10,466][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00020 | loss1:0.1527 loss2:0.8434 loss3:0.0886 | AUC:0.8224 Anomaly AUC:0.6466
[2023-08-26 18:27:21,985][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00020 | loss1:0.1217 loss2:0.8053 loss3:0.0811 | AUC:0.8116 Anomaly AUC:0.6678
[2023-08-26 18:27:32,837][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00020 | loss1:0.0904 loss2:0.7817 loss3:0.0691 | AUC:0.8020 Anomaly AUC:0.6515
[2023-08-26 18:27:43,814][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00020 | loss1:0.0861 loss2:0.7583 loss3:0.0667 | AUC:0.8067 Anomaly AUC:0.6743
[2023-08-26 18:27:56,917][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00020 | loss1:0.0823 loss2:0.7463 loss3:0.0573 | AUC:0.8090 Anomaly AUC:0.6508
[2023-08-26 18:28:07,803][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00020 | loss1:0.0494 loss2:0.7111 loss3:0.0523 | AUC:0.8025 Anomaly AUC:0.6612
[2023-08-26 18:28:07,829][main.py][line:114][INFO] Training completes in 1m 58s | best AUCAUC:0.8224 Anomaly AUC:0.6466

[2023-08-26 18:28:18,671][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.4159 loss2:1.1583 loss3:0.1538 | AUC:0.8127 Anomaly AUC:0.6169
[2023-08-26 18:28:30,592][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.2072 loss2:0.9921 loss3:0.1431 | AUC:0.8010 Anomaly AUC:0.6194
[2023-08-26 18:28:41,980][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.1629 loss2:0.9631 loss3:0.1226 | AUC:0.8083 Anomaly AUC:0.6243
[2023-08-26 18:28:52,859][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.1443 loss2:0.9335 loss3:0.1310 | AUC:0.8207 Anomaly AUC:0.6365
[2023-08-26 18:29:03,785][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.1429 loss2:0.9288 loss3:0.1305 | AUC:0.8147 Anomaly AUC:0.6456
[2023-08-26 18:29:19,100][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.1755 loss2:0.9460 loss3:0.1320 | AUC:0.8114 Anomaly AUC:0.6469
[2023-08-26 18:29:30,859][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.1188 loss2:0.9024 loss3:0.1184 | AUC:0.8207 Anomaly AUC:0.6490
[2023-08-26 18:29:44,986][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.1095 loss2:0.8947 loss3:0.1129 | AUC:0.8082 Anomaly AUC:0.6391
[2023-08-26 18:29:57,442][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.1008 loss2:0.8795 loss3:0.1086 | AUC:0.8078 Anomaly AUC:0.6578
[2023-08-26 18:30:09,514][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.1565 loss2:0.9261 loss3:0.1180 | AUC:0.8183 Anomaly AUC:0.6442
[2023-08-26 18:30:09,567][main.py][line:114][INFO] Training completes in 2m 2s | best AUCAUC:0.8207 Anomaly AUC:0.6365

[2023-08-26 18:30:21,915][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00010 | loss1:0.1228 loss2:0.9144 loss3:0.1297 | AUC:0.8185 Anomaly AUC:0.6375
[2023-08-26 18:30:34,189][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00010 | loss1:0.0624 loss2:0.8713 loss3:0.1047 | AUC:0.8111 Anomaly AUC:0.6398
[2023-08-26 18:30:46,046][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00010 | loss1:0.0491 loss2:0.8429 loss3:0.0881 | AUC:0.8097 Anomaly AUC:0.6437
[2023-08-26 18:31:00,213][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00010 | loss1:0.0612 loss2:0.8318 loss3:0.0812 | AUC:0.8114 Anomaly AUC:0.6569
[2023-08-26 18:31:12,360][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00010 | loss1:0.0443 loss2:0.8092 loss3:0.0764 | AUC:0.8020 Anomaly AUC:0.6544
[2023-08-26 18:31:25,282][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00010 | loss1:0.0366 loss2:0.7925 loss3:0.0700 | AUC:0.8094 Anomaly AUC:0.6512
[2023-08-26 18:31:39,491][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00010 | loss1:0.0223 loss2:0.7641 loss3:0.0637 | AUC:0.8167 Anomaly AUC:0.6699
[2023-08-26 18:31:51,912][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00010 | loss1:0.0346 loss2:0.7652 loss3:0.0594 | AUC:0.8141 Anomaly AUC:0.6577
[2023-08-26 18:32:04,632][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00010 | loss1:0.0673 loss2:0.7840 loss3:0.0810 | AUC:0.8115 Anomaly AUC:0.6639
[2023-08-26 18:32:17,282][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00010 | loss1:0.0239 loss2:0.7446 loss3:0.0590 | AUC:0.8030 Anomaly AUC:0.6488
[2023-08-26 18:32:17,333][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8185 Anomaly AUC:0.6375

[2023-08-26 18:32:31,896][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00010 | loss1:0.0711 loss2:0.8654 loss3:0.1151 | AUC:0.8116 Anomaly AUC:0.6333
[2023-08-26 18:32:43,275][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00010 | loss1:0.0602 loss2:0.8242 loss3:0.1052 | AUC:0.8097 Anomaly AUC:0.6292
[2023-08-26 18:32:54,102][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00010 | loss1:0.0432 loss2:0.7858 loss3:0.0932 | AUC:0.8110 Anomaly AUC:0.6268
[2023-08-26 18:33:06,434][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00010 | loss1:0.0377 loss2:0.7677 loss3:0.0861 | AUC:0.8132 Anomaly AUC:0.6245
[2023-08-26 18:33:20,411][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00010 | loss1:0.0346 loss2:0.7502 loss3:0.0897 | AUC:0.8113 Anomaly AUC:0.6325
[2023-08-26 18:33:34,922][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00010 | loss1:0.0267 loss2:0.7336 loss3:0.0786 | AUC:0.8164 Anomaly AUC:0.6412
[2023-08-26 18:33:47,281][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00010 | loss1:0.0205 loss2:0.7155 loss3:0.0743 | AUC:0.8170 Anomaly AUC:0.6590
[2023-08-26 18:34:00,066][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00010 | loss1:0.0254 loss2:0.7096 loss3:0.0841 | AUC:0.8195 Anomaly AUC:0.6492
[2023-08-26 18:34:14,761][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00010 | loss1:0.0166 loss2:0.6919 loss3:0.0702 | AUC:0.8117 Anomaly AUC:0.6570
[2023-08-26 18:34:29,144][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00010 | loss1:0.0140 loss2:0.6710 loss3:0.0646 | AUC:0.8070 Anomaly AUC:0.6514
[2023-08-26 18:34:29,197][main.py][line:114][INFO] Training completes in 2m 12s | best AUCAUC:0.8195 Anomaly AUC:0.6492

[2023-08-26 18:34:41,620][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00020 | loss1:0.2567 loss2:0.8972 loss3:0.2385 | AUC:0.8075 Anomaly AUC:0.6448
[2023-08-26 18:34:54,322][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00020 | loss1:0.0817 loss2:0.7516 loss3:0.1320 | AUC:0.8135 Anomaly AUC:0.6417
[2023-08-26 18:35:06,638][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00020 | loss1:0.0657 loss2:0.7176 loss3:0.1083 | AUC:0.8186 Anomaly AUC:0.6621
[2023-08-26 18:35:21,066][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00020 | loss1:0.0626 loss2:0.7106 loss3:0.0871 | AUC:0.8082 Anomaly AUC:0.6524
[2023-08-26 18:35:33,389][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00020 | loss1:0.0418 loss2:0.6851 loss3:0.0739 | AUC:0.7996 Anomaly AUC:0.6660
[2023-08-26 18:35:46,189][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00020 | loss1:0.0623 loss2:0.6913 loss3:0.0766 | AUC:0.8184 Anomaly AUC:0.6619
[2023-08-26 18:35:58,780][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00020 | loss1:0.0477 loss2:0.6776 loss3:0.0747 | AUC:0.8186 Anomaly AUC:0.6692
[2023-08-26 18:36:13,286][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00020 | loss1:0.0336 loss2:0.6622 loss3:0.0680 | AUC:0.7963 Anomaly AUC:0.6487
[2023-08-26 18:36:25,897][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00020 | loss1:0.0523 loss2:0.6577 loss3:0.0662 | AUC:0.8045 Anomaly AUC:0.6423
[2023-08-26 18:36:38,191][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00020 | loss1:0.0363 loss2:0.6441 loss3:0.0640 | AUC:0.8103 Anomaly AUC:0.6567
[2023-08-26 18:36:38,242][main.py][line:114][INFO] Training completes in 2m 9s | best AUCAUC:0.8186 Anomaly AUC:0.6692

[2023-08-26 18:36:50,644][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00010 | loss1:0.1673 loss2:0.7618 loss3:0.1539 | AUC:0.8022 Anomaly AUC:0.6178
[2023-08-26 18:37:03,283][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00010 | loss1:0.0417 loss2:0.6710 loss3:0.0814 | AUC:0.8061 Anomaly AUC:0.6278
[2023-08-26 18:37:17,605][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00010 | loss1:0.0233 loss2:0.6490 loss3:0.0650 | AUC:0.8181 Anomaly AUC:0.6495
[2023-08-26 18:37:30,125][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00010 | loss1:0.0168 loss2:0.6370 loss3:0.0564 | AUC:0.8190 Anomaly AUC:0.6422
[2023-08-26 18:37:42,196][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00010 | loss1:0.0157 loss2:0.6370 loss3:0.0559 | AUC:0.8099 Anomaly AUC:0.6303
[2023-08-26 18:37:53,885][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00010 | loss1:0.0071 loss2:0.6186 loss3:0.0494 | AUC:0.8095 Anomaly AUC:0.6402
[2023-08-26 18:38:07,069][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00010 | loss1:0.0082 loss2:0.6180 loss3:0.0501 | AUC:0.8217 Anomaly AUC:0.6645
[2023-08-26 18:38:19,789][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00010 | loss1:0.0133 loss2:0.6156 loss3:0.0511 | AUC:0.8201 Anomaly AUC:0.6582
[2023-08-26 18:38:33,504][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00010 | loss1:0.0189 loss2:0.6161 loss3:0.0567 | AUC:0.8118 Anomaly AUC:0.6620
[2023-08-26 18:38:44,981][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00010 | loss1:0.0294 loss2:0.6162 loss3:0.0529 | AUC:0.8122 Anomaly AUC:0.6611
[2023-08-26 18:38:45,008][main.py][line:114][INFO] Training completes in 2m 7s | best AUCAUC:0.8217 Anomaly AUC:0.6645

[2023-08-26 18:38:58,647][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.3267 loss2:1.0560 loss3:0.0844 | AUC:0.8070 Anomaly AUC:0.6197
[2023-08-26 18:39:13,223][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0733 loss2:0.7965 loss3:0.0438 | AUC:0.8108 Anomaly AUC:0.6497
[2023-08-26 18:39:25,449][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0456 loss2:0.7421 loss3:0.0379 | AUC:0.7884 Anomaly AUC:0.6538
[2023-08-26 18:39:38,364][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.1039 loss2:0.7754 loss3:0.0453 | AUC:0.8215 Anomaly AUC:0.6423
[2023-08-26 18:39:50,152][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0453 loss2:0.7231 loss3:0.0384 | AUC:0.7908 Anomaly AUC:0.6468
[2023-08-26 18:40:03,641][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0633 loss2:0.7291 loss3:0.0407 | AUC:0.8211 Anomaly AUC:0.6461
[2023-08-26 18:40:15,673][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0404 loss2:0.6929 loss3:0.0316 | AUC:0.7918 Anomaly AUC:0.6669
[2023-08-26 18:40:28,067][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.1199 loss2:0.7754 loss3:0.0458 | AUC:0.8103 Anomaly AUC:0.6782
[2023-08-26 18:40:39,901][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0384 loss2:0.6857 loss3:0.0250 | AUC:0.8104 Anomaly AUC:0.6603
[2023-08-26 18:40:53,311][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0266 loss2:0.6439 loss3:0.0206 | AUC:0.8159 Anomaly AUC:0.6665
[2023-08-26 18:40:53,361][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8215 Anomaly AUC:0.6423

[2023-08-26 18:41:05,766][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00050 | loss1:0.0744 loss2:0.7386 loss3:0.0567 | AUC:0.8005 Anomaly AUC:0.6422
[2023-08-26 18:41:17,544][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00050 | loss1:0.0350 loss2:0.6658 loss3:0.0483 | AUC:0.8016 Anomaly AUC:0.6447
[2023-08-26 18:41:29,497][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00050 | loss1:0.0399 loss2:0.6464 loss3:0.0508 | AUC:0.7903 Anomaly AUC:0.6415
[2023-08-26 18:41:42,992][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00050 | loss1:0.0367 loss2:0.6379 loss3:0.0553 | AUC:0.7946 Anomaly AUC:0.6241
[2023-08-26 18:41:53,871][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00050 | loss1:0.0266 loss2:0.6106 loss3:0.0541 | AUC:0.7994 Anomaly AUC:0.6550
[2023-08-26 18:42:04,765][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00050 | loss1:0.0393 loss2:0.5716 loss3:0.0594 | AUC:0.7932 Anomaly AUC:0.6396
[2023-08-26 18:42:15,760][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00050 | loss1:0.0478 loss2:0.5943 loss3:0.0609 | AUC:0.8142 Anomaly AUC:0.6518
[2023-08-26 18:42:27,341][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00050 | loss1:0.0452 loss2:0.5733 loss3:0.0584 | AUC:0.8052 Anomaly AUC:0.6351
[2023-08-26 18:42:40,049][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00050 | loss1:0.0260 loss2:0.5663 loss3:0.0727 | AUC:0.8126 Anomaly AUC:0.6607
[2023-08-26 18:42:54,426][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00050 | loss1:0.0160 loss2:0.5250 loss3:0.0498 | AUC:0.8176 Anomaly AUC:0.6566
[2023-08-26 18:42:54,477][main.py][line:114][INFO] Training completes in 2m 1s | best AUCAUC:0.8176 Anomaly AUC:0.6566

[2023-08-26 18:43:07,072][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00030 | loss1:0.0808 loss2:0.5531 loss3:0.0585 | AUC:0.7910 Anomaly AUC:0.6626
[2023-08-26 18:43:20,606][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00030 | loss1:0.0100 loss2:0.4790 loss3:0.0417 | AUC:0.8060 Anomaly AUC:0.6645
[2023-08-26 18:43:31,447][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00030 | loss1:0.0051 loss2:0.4484 loss3:0.0348 | AUC:0.8007 Anomaly AUC:0.6554
[2023-08-26 18:43:42,444][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00030 | loss1:0.0170 loss2:0.4454 loss3:0.0375 | AUC:0.7920 Anomaly AUC:0.6767
[2023-08-26 18:43:54,242][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00030 | loss1:0.0255 loss2:0.4535 loss3:0.0340 | AUC:0.8205 Anomaly AUC:0.6633
[2023-08-26 18:44:06,274][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00030 | loss1:0.0075 loss2:0.4269 loss3:0.0355 | AUC:0.8118 Anomaly AUC:0.6645
[2023-08-26 18:44:18,643][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00030 | loss1:0.0270 loss2:0.4093 loss3:0.0376 | AUC:0.8152 Anomaly AUC:0.6596
[2023-08-26 18:44:31,420][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00030 | loss1:0.0320 loss2:0.4448 loss3:0.0438 | AUC:0.8099 Anomaly AUC:0.6448
[2023-08-26 18:44:45,846][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00030 | loss1:0.0147 loss2:0.4298 loss3:0.0349 | AUC:0.8108 Anomaly AUC:0.6548
[2023-08-26 18:44:57,436][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00030 | loss1:0.0129 loss2:0.3907 loss3:0.0283 | AUC:0.8168 Anomaly AUC:0.6640
[2023-08-26 18:44:57,468][main.py][line:114][INFO] Training completes in 2m 3s | best AUCAUC:0.8205 Anomaly AUC:0.6633

[2023-08-26 18:45:11,321][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00040 | loss1:0.0976 loss2:0.6442 loss3:0.0638 | AUC:0.8186 Anomaly AUC:0.6772
[2023-08-26 18:45:23,757][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00040 | loss1:0.0144 loss2:0.4750 loss3:0.0477 | AUC:0.8168 Anomaly AUC:0.6504
[2023-08-26 18:45:35,082][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00040 | loss1:0.0058 loss2:0.4012 loss3:0.0376 | AUC:0.8044 Anomaly AUC:0.6824
[2023-08-26 18:45:46,061][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00040 | loss1:0.0030 loss2:0.3829 loss3:0.0439 | AUC:0.8158 Anomaly AUC:0.6601
[2023-08-26 18:45:57,008][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00040 | loss1:0.0024 loss2:0.3156 loss3:0.0403 | AUC:0.8115 Anomaly AUC:0.6500
[2023-08-26 18:46:10,537][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00040 | loss1:0.0040 loss2:0.3806 loss3:0.0491 | AUC:0.8126 Anomaly AUC:0.6494
[2023-08-26 18:46:23,394][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00040 | loss1:0.0020 loss2:0.3557 loss3:0.0427 | AUC:0.8102 Anomaly AUC:0.6604
[2023-08-26 18:46:35,703][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00040 | loss1:0.0010 loss2:0.3274 loss3:0.0532 | AUC:0.8166 Anomaly AUC:0.6664
[2023-08-26 18:46:52,815][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00040 | loss1:0.0186 loss2:0.3528 loss3:0.0629 | AUC:0.8152 Anomaly AUC:0.6657
[2023-08-26 18:47:05,416][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00040 | loss1:0.0532 loss2:0.4436 loss3:0.0780 | AUC:0.8211 Anomaly AUC:0.6498
[2023-08-26 18:47:05,468][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8211 Anomaly AUC:0.6498

[2023-08-26 18:47:19,747][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00060 | loss1:0.0769 loss2:0.5891 loss3:0.0761 | AUC:0.8097 Anomaly AUC:0.6576
[2023-08-26 18:47:31,953][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00060 | loss1:0.0109 loss2:0.4146 loss3:0.0489 | AUC:0.8088 Anomaly AUC:0.6661
[2023-08-26 18:47:44,285][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00060 | loss1:0.0038 loss2:0.3593 loss3:0.0303 | AUC:0.8103 Anomaly AUC:0.6659
[2023-08-26 18:47:56,039][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00060 | loss1:0.0030 loss2:0.3277 loss3:0.0249 | AUC:0.8167 Anomaly AUC:0.6672
[2023-08-26 18:48:10,104][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00060 | loss1:0.0897 loss2:0.4042 loss3:0.0390 | AUC:0.7826 Anomaly AUC:0.6305
[2023-08-26 18:48:23,992][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00060 | loss1:0.0410 loss2:0.5574 loss3:0.0547 | AUC:0.8020 Anomaly AUC:0.6539
[2023-08-26 18:48:36,682][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00060 | loss1:0.0235 loss2:0.4265 loss3:0.0283 | AUC:0.8053 Anomaly AUC:0.6557
[2023-08-26 18:48:50,223][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00060 | loss1:0.0244 loss2:0.2652 loss3:0.0281 | AUC:0.8085 Anomaly AUC:0.6414
[2023-08-26 18:49:02,583][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00060 | loss1:0.0240 loss2:0.4169 loss3:0.0228 | AUC:0.8159 Anomaly AUC:0.6497
[2023-08-26 18:49:14,348][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00060 | loss1:0.0361 loss2:0.3897 loss3:0.0242 | AUC:0.7964 Anomaly AUC:0.6482
[2023-08-26 18:49:14,376][main.py][line:114][INFO] Training completes in 2m 9s | best AUCAUC:0.8167 Anomaly AUC:0.6672

[2023-08-26 18:49:27,892][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00010 | loss1:0.0034 loss2:0.2881 loss3:0.0273 | AUC:0.8111 Anomaly AUC:0.6648
[2023-08-26 18:49:40,036][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00010 | loss1:0.0009 loss2:0.2602 loss3:0.0248 | AUC:0.8138 Anomaly AUC:0.6634
[2023-08-26 18:49:52,273][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00010 | loss1:0.0007 loss2:0.2438 loss3:0.0242 | AUC:0.8078 Anomaly AUC:0.6615
[2023-08-26 18:50:04,579][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00010 | loss1:0.0007 loss2:0.2204 loss3:0.0244 | AUC:0.8108 Anomaly AUC:0.6640
[2023-08-26 18:50:16,354][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00010 | loss1:0.0005 loss2:0.2149 loss3:0.0261 | AUC:0.8156 Anomaly AUC:0.6661
[2023-08-26 18:50:29,206][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00010 | loss1:0.0005 loss2:0.2066 loss3:0.0252 | AUC:0.8093 Anomaly AUC:0.6641
[2023-08-26 18:50:43,001][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00010 | loss1:0.0006 loss2:0.2001 loss3:0.0284 | AUC:0.8053 Anomaly AUC:0.6647
[2023-08-26 18:50:55,403][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00010 | loss1:0.0022 loss2:0.2076 loss3:0.0315 | AUC:0.8135 Anomaly AUC:0.6724
[2023-08-26 18:51:08,327][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00010 | loss1:0.0045 loss2:0.2098 loss3:0.0341 | AUC:0.8103 Anomaly AUC:0.6734
[2023-08-26 18:51:22,291][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00010 | loss1:0.0007 loss2:0.1930 loss3:0.0304 | AUC:0.8069 Anomaly AUC:0.6686
[2023-08-26 18:51:22,341][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8156 Anomaly AUC:0.6661

[2023-08-26 18:51:34,124][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00030 | loss1:0.0230 loss2:0.4468 loss3:0.0493 | AUC:0.8116 Anomaly AUC:0.6760
[2023-08-26 18:51:48,125][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00030 | loss1:0.0012 loss2:0.3282 loss3:0.0297 | AUC:0.8118 Anomaly AUC:0.6690
[2023-08-26 18:52:02,553][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00030 | loss1:0.0003 loss2:0.2542 loss3:0.0174 | AUC:0.8086 Anomaly AUC:0.6627
[2023-08-26 18:52:17,947][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00030 | loss1:0.0061 loss2:0.2116 loss3:0.0222 | AUC:0.8062 Anomaly AUC:0.6606
[2023-08-26 18:52:28,892][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00030 | loss1:0.0049 loss2:0.3031 loss3:0.0254 | AUC:0.7749 Anomaly AUC:0.6653
[2023-08-26 18:52:39,780][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00030 | loss1:0.0261 loss2:0.3624 loss3:0.0278 | AUC:0.8073 Anomaly AUC:0.6625
[2023-08-26 18:52:51,849][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00030 | loss1:0.0203 loss2:0.5760 loss3:0.0225 | AUC:0.8147 Anomaly AUC:0.6446
[2023-08-26 18:53:05,390][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00030 | loss1:0.0137 loss2:0.4275 loss3:0.0256 | AUC:0.8083 Anomaly AUC:0.6376
[2023-08-26 18:53:17,032][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00030 | loss1:0.0199 loss2:0.2328 loss3:0.0316 | AUC:0.8098 Anomaly AUC:0.6450
[2023-08-26 18:53:29,470][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00030 | loss1:0.0132 loss2:0.1689 loss3:0.0198 | AUC:0.7985 Anomaly AUC:0.6337
[2023-08-26 18:53:29,526][main.py][line:114][INFO] Training completes in 2m 7s | best AUCAUC:0.8147 Anomaly AUC:0.6446

[2023-08-26 18:53:41,853][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00030 | loss1:0.0720 loss2:0.4036 loss3:0.0435 | AUC:0.8118 Anomaly AUC:0.6569
[2023-08-26 18:53:55,488][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00030 | loss1:0.0022 loss2:0.2962 loss3:0.0242 | AUC:0.8042 Anomaly AUC:0.6652
[2023-08-26 18:54:09,128][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00030 | loss1:0.0007 loss2:0.1888 loss3:0.0173 | AUC:0.8096 Anomaly AUC:0.6636
[2023-08-26 18:54:21,344][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00030 | loss1:0.0029 loss2:0.2195 loss3:0.0149 | AUC:0.7962 Anomaly AUC:0.6707
[2023-08-26 18:54:34,214][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00030 | loss1:0.0033 loss2:0.2425 loss3:0.0152 | AUC:0.7898 Anomaly AUC:0.6624
[2023-08-26 18:54:48,351][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00030 | loss1:0.0206 loss2:0.2739 loss3:0.0214 | AUC:0.8034 Anomaly AUC:0.6408
[2023-08-26 18:55:00,728][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00030 | loss1:0.0121 loss2:0.2610 loss3:0.0167 | AUC:0.7819 Anomaly AUC:0.6535
[2023-08-26 18:55:13,446][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00030 | loss1:0.0809 loss2:0.3916 loss3:0.0361 | AUC:0.8090 Anomaly AUC:0.6599
[2023-08-26 18:55:25,854][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00030 | loss1:0.0165 loss2:0.3262 loss3:0.0308 | AUC:0.8042 Anomaly AUC:0.6762
[2023-08-26 18:55:39,692][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00030 | loss1:0.0104 loss2:0.2423 loss3:0.0150 | AUC:0.7811 Anomaly AUC:0.6733
[2023-08-26 18:55:39,719][main.py][line:114][INFO] Training completes in 2m 10s | best AUCAUC:0.8118 Anomaly AUC:0.6569

[2023-08-26 18:55:53,114][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00060 | loss1:0.0304 loss2:0.4964 loss3:0.0382 | AUC:0.7965 Anomaly AUC:0.6397
[2023-08-26 18:56:05,906][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00060 | loss1:0.0142 loss2:0.3023 loss3:0.0374 | AUC:0.8092 Anomaly AUC:0.6619
[2023-08-26 18:56:17,842][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00060 | loss1:0.0039 loss2:0.3096 loss3:0.0301 | AUC:0.8117 Anomaly AUC:0.6578
[2023-08-26 18:56:29,980][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00060 | loss1:0.0031 loss2:0.2550 loss3:0.0318 | AUC:0.8009 Anomaly AUC:0.6633
[2023-08-26 18:56:42,702][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00060 | loss1:0.0033 loss2:0.2319 loss3:0.0365 | AUC:0.8048 Anomaly AUC:0.6467
[2023-08-26 18:56:54,163][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00060 | loss1:0.0162 loss2:0.2436 loss3:0.0345 | AUC:0.8123 Anomaly AUC:0.6618
[2023-08-26 18:57:05,071][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00060 | loss1:0.0214 loss2:0.2275 loss3:0.0497 | AUC:0.8095 Anomaly AUC:0.6571
[2023-08-26 18:57:16,042][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00060 | loss1:0.0446 loss2:0.2806 loss3:0.0623 | AUC:0.8167 Anomaly AUC:0.6731
[2023-08-26 18:57:29,538][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00060 | loss1:0.0502 loss2:0.2871 loss3:0.1918 | AUC:0.8086 Anomaly AUC:0.6849
[2023-08-26 18:57:41,737][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00060 | loss1:0.0135 loss2:0.1662 loss3:0.0593 | AUC:0.8115 Anomaly AUC:0.6743
[2023-08-26 18:57:41,811][main.py][line:114][INFO] Training completes in 2m 2s | best AUCAUC:0.8167 Anomaly AUC:0.6731

[2023-08-26 18:57:53,527][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00020 | loss1:0.0136 loss2:0.2037 loss3:0.0474 | AUC:0.8082 Anomaly AUC:0.6669
[2023-08-26 18:58:06,773][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00020 | loss1:0.0016 loss2:0.1549 loss3:0.0349 | AUC:0.8088 Anomaly AUC:0.6670
[2023-08-26 18:58:19,154][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00020 | loss1:0.0012 loss2:0.1181 loss3:0.0355 | AUC:0.8104 Anomaly AUC:0.6657
[2023-08-26 18:58:32,056][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00020 | loss1:0.0012 loss2:0.1141 loss3:0.0317 | AUC:0.8073 Anomaly AUC:0.6688
[2023-08-26 18:58:46,207][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00020 | loss1:0.0036 loss2:0.1267 loss3:0.0353 | AUC:0.8060 Anomaly AUC:0.6640
[2023-08-26 18:58:58,026][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00020 | loss1:0.0010 loss2:0.1188 loss3:0.0392 | AUC:0.8035 Anomaly AUC:0.6628
[2023-08-26 18:59:10,717][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00020 | loss1:0.0006 loss2:0.1037 loss3:0.0324 | AUC:0.8016 Anomaly AUC:0.6632
[2023-08-26 18:59:24,082][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00020 | loss1:0.0006 loss2:0.0921 loss3:0.0294 | AUC:0.8005 Anomaly AUC:0.6656
[2023-08-26 18:59:35,783][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00020 | loss1:0.0003 loss2:0.0853 loss3:0.0245 | AUC:0.8021 Anomaly AUC:0.6652
[2023-08-26 18:59:49,540][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00020 | loss1:0.0003 loss2:0.0764 loss3:0.0242 | AUC:0.8032 Anomaly AUC:0.6670
[2023-08-26 18:59:49,592][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8104 Anomaly AUC:0.6657

[2023-08-26 19:00:04,369][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00050 | loss1:0.0012 loss2:0.1812 loss3:0.0308 | AUC:0.8013 Anomaly AUC:0.6590
[2023-08-26 19:00:18,610][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00050 | loss1:0.0005 loss2:0.1226 loss3:0.0273 | AUC:0.7998 Anomaly AUC:0.6578
[2023-08-26 19:00:30,627][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00050 | loss1:0.0008 loss2:0.1019 loss3:0.0264 | AUC:0.7977 Anomaly AUC:0.6578
[2023-08-26 19:00:42,826][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00050 | loss1:0.0004 loss2:0.1051 loss3:0.0252 | AUC:0.8018 Anomaly AUC:0.6631
[2023-08-26 19:00:55,633][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00050 | loss1:0.0005 loss2:0.0933 loss3:0.0251 | AUC:0.8008 Anomaly AUC:0.6637
[2023-08-26 19:01:10,201][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00050 | loss1:0.0009 loss2:0.0906 loss3:0.0231 | AUC:0.7933 Anomaly AUC:0.6652
[2023-08-26 19:01:27,306][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00050 | loss1:0.0146 loss2:0.1875 loss3:0.0339 | AUC:0.8002 Anomaly AUC:0.6655
[2023-08-26 19:01:38,255][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00050 | loss1:0.0023 loss2:0.1392 loss3:0.0299 | AUC:0.7970 Anomaly AUC:0.6645
[2023-08-26 19:01:50,265][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00050 | loss1:0.0013 loss2:0.1171 loss3:0.0296 | AUC:0.7960 Anomaly AUC:0.6634
[2023-08-26 19:02:01,669][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00050 | loss1:0.0006 loss2:0.0597 loss3:0.0250 | AUC:0.7876 Anomaly AUC:0.6624
[2023-08-26 19:02:01,696][main.py][line:114][INFO] Training completes in 2m 12s | best AUCAUC:0.8018 Anomaly AUC:0.6631

[2023-08-26 19:02:12,622][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0849 loss2:0.4089 loss3:0.0493 | AUC:0.7987 Anomaly AUC:0.6580
[2023-08-26 19:02:23,575][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0196 loss2:0.1823 loss3:0.0342 | AUC:0.8004 Anomaly AUC:0.6637
[2023-08-26 19:02:36,883][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0342 loss2:0.1956 loss3:0.0312 | AUC:0.8043 Anomaly AUC:0.6642
[2023-08-26 19:02:47,658][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0147 loss2:0.1889 loss3:0.0228 | AUC:0.8009 Anomaly AUC:0.6641
[2023-08-26 19:02:58,614][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0217 loss2:0.1462 loss3:0.0242 | AUC:0.8125 Anomaly AUC:0.6733
[2023-08-26 19:03:10,232][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0451 loss2:0.1961 loss3:0.0338 | AUC:0.8045 Anomaly AUC:0.6650
[2023-08-26 19:03:22,894][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0149 loss2:0.1320 loss3:0.0206 | AUC:0.8070 Anomaly AUC:0.6719
[2023-08-26 19:03:37,354][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0235 loss2:0.1722 loss3:0.0316 | AUC:0.7990 Anomaly AUC:0.6536
[2023-08-26 19:03:49,957][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0081 loss2:0.1127 loss3:0.0236 | AUC:0.8078 Anomaly AUC:0.6852
[2023-08-26 19:04:04,506][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0027 loss2:0.0879 loss3:0.0162 | AUC:0.7983 Anomaly AUC:0.6750
[2023-08-26 19:04:04,556][main.py][line:114][INFO] Training completes in 2m 3s | best AUCAUC:0.8125 Anomaly AUC:0.6733

[2023-08-26 19:04:18,984][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00090 | loss1:0.0692 loss2:0.3797 loss3:0.0405 | AUC:0.7965 Anomaly AUC:0.6726
[2023-08-26 19:04:33,754][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00090 | loss1:0.0028 loss2:0.1999 loss3:0.0217 | AUC:0.8002 Anomaly AUC:0.6734
[2023-08-26 19:04:48,141][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00090 | loss1:0.0236 loss2:0.2287 loss3:0.0260 | AUC:0.8274 Anomaly AUC:0.6741
[2023-08-26 19:04:59,860][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00090 | loss1:0.0236 loss2:0.2426 loss3:0.0234 | AUC:0.8229 Anomaly AUC:0.6627
[2023-08-26 19:05:13,825][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00090 | loss1:0.0111 loss2:0.1618 loss3:0.0197 | AUC:0.8126 Anomaly AUC:0.6780
[2023-08-26 19:05:28,280][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00090 | loss1:0.0058 loss2:0.1351 loss3:0.0135 | AUC:0.8141 Anomaly AUC:0.6730
[2023-08-26 19:05:39,599][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00090 | loss1:0.0239 loss2:0.1668 loss3:0.0171 | AUC:0.8151 Anomaly AUC:0.6809
[2023-08-26 19:05:50,526][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00090 | loss1:0.0187 loss2:0.1888 loss3:0.0167 | AUC:0.8184 Anomaly AUC:0.6735
[2023-08-26 19:06:01,403][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00090 | loss1:0.0052 loss2:0.1214 loss3:0.0133 | AUC:0.8085 Anomaly AUC:0.6805
[2023-08-26 19:06:34,310][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00090 | loss1:0.0151 loss2:0.1364 loss3:0.0094 | AUC:0.8015 Anomaly AUC:0.6674
[2023-08-26 19:06:34,337][main.py][line:114][INFO] Training completes in 2m 30s | best AUCAUC:0.8274 Anomaly AUC:0.6741

[2023-08-26 19:06:45,259][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00100 | loss1:0.0963 loss2:0.5074 loss3:0.0364 | AUC:0.8215 Anomaly AUC:0.6507
[2023-08-26 19:06:59,222][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00100 | loss1:0.0109 loss2:0.2309 loss3:0.0213 | AUC:0.8119 Anomaly AUC:0.6684
[2023-08-26 19:07:11,670][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00100 | loss1:0.0020 loss2:0.1487 loss3:0.0178 | AUC:0.8139 Anomaly AUC:0.6709
[2023-08-26 19:07:25,325][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00100 | loss1:0.0029 loss2:0.1370 loss3:0.0136 | AUC:0.7900 Anomaly AUC:0.6768
[2023-08-26 19:07:36,304][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00100 | loss1:0.0343 loss2:0.2209 loss3:0.0207 | AUC:0.8225 Anomaly AUC:0.6680
[2023-08-26 19:07:47,206][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00100 | loss1:0.0506 loss2:0.3322 loss3:0.0248 | AUC:0.7745 Anomaly AUC:0.6698
[2023-08-26 19:07:58,085][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00100 | loss1:0.0515 loss2:0.3297 loss3:0.0338 | AUC:0.8135 Anomaly AUC:0.6514
[2023-08-26 19:08:12,125][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00100 | loss1:0.0439 loss2:0.2726 loss3:0.0367 | AUC:0.8226 Anomaly AUC:0.6862
[2023-08-26 19:08:23,574][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00100 | loss1:0.0201 loss2:0.2217 loss3:0.0203 | AUC:0.8171 Anomaly AUC:0.6860
[2023-08-26 19:08:34,437][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00100 | loss1:0.0878 loss2:0.4555 loss3:0.0358 | AUC:0.8198 Anomaly AUC:0.6691
[2023-08-26 19:08:34,464][main.py][line:114][INFO] Training completes in 2m 0s | best AUCAUC:0.8226 Anomaly AUC:0.6862

[2023-08-26 19:08:45,235][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00100 | loss1:0.1777 loss2:0.9094 loss3:0.0502 | AUC:0.8222 Anomaly AUC:0.6424
[2023-08-26 19:09:04,891][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00100 | loss1:0.0169 loss2:0.4395 loss3:0.0304 | AUC:0.8201 Anomaly AUC:0.6600
[2023-08-26 19:09:19,502][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00100 | loss1:0.0109 loss2:0.3053 loss3:0.0195 | AUC:0.8326 Anomaly AUC:0.6639
[2023-08-26 19:09:35,608][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00100 | loss1:0.0068 loss2:0.2391 loss3:0.0165 | AUC:0.8105 Anomaly AUC:0.6748
[2023-08-26 19:09:49,694][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00100 | loss1:0.0015 loss2:0.1499 loss3:0.0126 | AUC:0.8241 Anomaly AUC:0.6851
[2023-08-26 19:10:02,536][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00100 | loss1:0.0076 loss2:0.1269 loss3:0.0108 | AUC:0.8157 Anomaly AUC:0.6809
[2023-08-26 19:10:17,274][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00100 | loss1:0.0019 loss2:0.1642 loss3:0.0088 | AUC:0.8170 Anomaly AUC:0.6818
[2023-08-26 19:10:31,119][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00100 | loss1:0.0015 loss2:0.1245 loss3:0.0079 | AUC:0.8222 Anomaly AUC:0.6855
[2023-08-26 19:10:42,054][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00100 | loss1:0.0528 loss2:0.2842 loss3:0.0227 | AUC:0.8231 Anomaly AUC:0.6729
[2023-08-26 19:10:52,939][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00100 | loss1:0.0163 loss2:0.2732 loss3:0.0220 | AUC:0.8282 Anomaly AUC:0.6758
[2023-08-26 19:10:52,965][main.py][line:114][INFO] Training completes in 2m 18s | best AUCAUC:0.8326 Anomaly AUC:0.6639

[2023-08-26 19:11:03,826][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00100 | loss1:0.1833 loss2:0.7914 loss3:0.0414 | AUC:0.8184 Anomaly AUC:0.6559
[2023-08-26 19:11:17,606][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00100 | loss1:0.0088 loss2:0.5408 loss3:0.0245 | AUC:0.8180 Anomaly AUC:0.6751
[2023-08-26 19:11:32,300][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00100 | loss1:0.0034 loss2:0.4122 loss3:0.0203 | AUC:0.8209 Anomaly AUC:0.6790
[2023-08-26 19:11:45,951][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00100 | loss1:0.0019 loss2:0.3017 loss3:0.0164 | AUC:0.8186 Anomaly AUC:0.6772
[2023-08-26 19:11:56,970][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00100 | loss1:0.0055 loss2:0.2747 loss3:0.0161 | AUC:0.8140 Anomaly AUC:0.6689
[2023-08-26 19:12:07,860][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00100 | loss1:0.0233 loss2:0.3249 loss3:0.0197 | AUC:0.8168 Anomaly AUC:0.6761
[2023-08-26 19:12:21,708][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00100 | loss1:0.0104 loss2:0.3354 loss3:0.0144 | AUC:0.8051 Anomaly AUC:0.6741
[2023-08-26 19:12:34,484][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00100 | loss1:0.0119 loss2:0.2699 loss3:0.0123 | AUC:0.8128 Anomaly AUC:0.6724
[2023-08-26 19:12:45,462][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00100 | loss1:0.0066 loss2:0.2198 loss3:0.0104 | AUC:0.8111 Anomaly AUC:0.6624
[2023-08-26 19:12:56,488][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00100 | loss1:0.0083 loss2:0.2295 loss3:0.0093 | AUC:0.8128 Anomaly AUC:0.6706
[2023-08-26 19:12:56,514][main.py][line:114][INFO] Training completes in 2m 3s | best AUCAUC:0.8209 Anomaly AUC:0.6790

[2023-08-26 19:13:09,786][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00090 | loss1:0.0587 loss2:0.6436 loss3:0.0417 | AUC:0.7983 Anomaly AUC:0.6511
[2023-08-26 19:13:22,611][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00090 | loss1:0.0130 loss2:0.3299 loss3:0.0182 | AUC:0.8209 Anomaly AUC:0.6660
[2023-08-26 19:13:36,739][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00090 | loss1:0.0127 loss2:0.2669 loss3:0.0194 | AUC:0.7956 Anomaly AUC:0.6688
[2023-08-26 19:13:49,554][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00090 | loss1:0.0196 loss2:0.2276 loss3:0.0183 | AUC:0.8202 Anomaly AUC:0.6988
[2023-08-26 19:14:00,977][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00090 | loss1:0.0203 loss2:0.2377 loss3:0.0133 | AUC:0.8129 Anomaly AUC:0.6673
[2023-08-26 19:14:11,877][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00090 | loss1:0.0145 loss2:0.1945 loss3:0.0101 | AUC:0.7922 Anomaly AUC:0.6596
[2023-08-26 19:14:22,919][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00090 | loss1:0.0116 loss2:0.1801 loss3:0.0090 | AUC:0.8043 Anomaly AUC:0.6736
[2023-08-26 19:14:36,267][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00090 | loss1:0.0175 loss2:0.2004 loss3:0.0150 | AUC:0.8209 Anomaly AUC:0.6748
[2023-08-26 19:14:50,181][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00090 | loss1:0.0044 loss2:0.1848 loss3:0.0100 | AUC:0.8217 Anomaly AUC:0.6661
[2023-08-26 19:15:01,562][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00090 | loss1:0.0366 loss2:0.1828 loss3:0.0130 | AUC:0.8009 Anomaly AUC:0.6769
[2023-08-26 19:15:01,605][main.py][line:114][INFO] Training completes in 2m 5s | best AUCAUC:0.8217 Anomaly AUC:0.6661

[2023-08-26 19:15:12,475][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00090 | loss1:0.0984 loss2:0.4368 loss3:0.0220 | AUC:0.8164 Anomaly AUC:0.6672
[2023-08-26 19:15:23,288][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00090 | loss1:0.0022 loss2:0.1450 loss3:0.0092 | AUC:0.8073 Anomaly AUC:0.6741
[2023-08-26 19:15:37,370][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00090 | loss1:0.0007 loss2:0.0819 loss3:0.0078 | AUC:0.8115 Anomaly AUC:0.6761
[2023-08-26 19:15:51,842][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00090 | loss1:0.0006 loss2:0.0653 loss3:0.0069 | AUC:0.8071 Anomaly AUC:0.6697
[2023-08-26 19:16:06,301][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00090 | loss1:0.0003 loss2:0.0566 loss3:0.0073 | AUC:0.8050 Anomaly AUC:0.6658
[2023-08-26 19:16:26,618][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00090 | loss1:0.0005 loss2:0.0599 loss3:0.0063 | AUC:0.8017 Anomaly AUC:0.6696
[2023-08-26 19:16:37,575][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00090 | loss1:0.0003 loss2:0.0511 loss3:0.0069 | AUC:0.8065 Anomaly AUC:0.6661
[2023-08-26 19:16:49,752][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00090 | loss1:0.0007 loss2:0.0546 loss3:0.0059 | AUC:0.8019 Anomaly AUC:0.6649
[2023-08-26 19:17:04,154][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00090 | loss1:0.0225 loss2:0.2120 loss3:0.0144 | AUC:0.8108 Anomaly AUC:0.6773
[2023-08-26 19:17:18,056][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00090 | loss1:0.0156 loss2:0.1792 loss3:0.0150 | AUC:0.8155 Anomaly AUC:0.6635
[2023-08-26 19:17:18,084][main.py][line:114][INFO] Training completes in 2m 16s | best AUCAUC:0.8164 Anomaly AUC:0.6672

[2023-08-26 19:17:28,877][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00090 | loss1:0.0855 loss2:0.3928 loss3:0.0207 | AUC:0.8047 Anomaly AUC:0.6565
[2023-08-26 19:17:39,722][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00090 | loss1:0.0161 loss2:0.1572 loss3:0.0137 | AUC:0.8041 Anomaly AUC:0.6640
[2023-08-26 19:17:51,520][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00090 | loss1:0.0054 loss2:0.1154 loss3:0.0100 | AUC:0.7933 Anomaly AUC:0.6710
[2023-08-26 19:18:05,368][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00090 | loss1:0.0088 loss2:0.0930 loss3:0.0091 | AUC:0.8061 Anomaly AUC:0.6585
[2023-08-26 19:18:16,326][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00090 | loss1:0.0039 loss2:0.0886 loss3:0.0084 | AUC:0.8033 Anomaly AUC:0.6703
[2023-08-26 19:18:27,123][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00090 | loss1:0.0156 loss2:0.1011 loss3:0.0106 | AUC:0.7944 Anomaly AUC:0.6677
[2023-08-26 19:18:39,277][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00090 | loss1:0.0331 loss2:0.1719 loss3:0.0193 | AUC:0.8139 Anomaly AUC:0.6712
[2023-08-26 19:18:50,675][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00090 | loss1:0.0249 loss2:0.1455 loss3:0.0215 | AUC:0.8141 Anomaly AUC:0.6553
[2023-08-26 19:19:01,593][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00090 | loss1:0.0066 loss2:0.0855 loss3:0.0133 | AUC:0.8184 Anomaly AUC:0.6601
[2023-08-26 19:19:17,830][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00090 | loss1:0.0023 loss2:0.0490 loss3:0.0090 | AUC:0.8111 Anomaly AUC:0.6608
[2023-08-26 19:19:17,882][main.py][line:114][INFO] Training completes in 1m 60s | best AUCAUC:0.8184 Anomaly AUC:0.6601

[2023-08-26 19:19:30,705][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00100 | loss1:0.0508 loss2:0.8883 loss3:0.0208 | AUC:0.8187 Anomaly AUC:0.6645
[2023-08-26 19:19:44,247][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00100 | loss1:0.0078 loss2:0.7666 loss3:0.0144 | AUC:0.8194 Anomaly AUC:0.6413
[2023-08-26 19:19:55,189][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00100 | loss1:0.0159 loss2:0.6474 loss3:0.0083 | AUC:0.8105 Anomaly AUC:0.6433
[2023-08-26 19:20:08,694][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00100 | loss1:0.0055 loss2:0.5900 loss3:0.0095 | AUC:0.8181 Anomaly AUC:0.6556
[2023-08-26 19:20:20,526][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00100 | loss1:0.0011 loss2:0.4172 loss3:0.0071 | AUC:0.8159 Anomaly AUC:0.6548
[2023-08-26 19:20:34,839][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00100 | loss1:0.0020 loss2:0.2021 loss3:0.0072 | AUC:0.8088 Anomaly AUC:0.6557
[2023-08-26 19:20:47,113][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00100 | loss1:0.0511 loss2:0.8096 loss3:0.0179 | AUC:0.8129 Anomaly AUC:0.6643
[2023-08-26 19:20:58,942][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00100 | loss1:0.0138 loss2:0.9834 loss3:0.0166 | AUC:0.8001 Anomaly AUC:0.5994
[2023-08-26 19:21:13,053][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00100 | loss1:0.0342 loss2:1.0104 loss3:0.0249 | AUC:0.8036 Anomaly AUC:0.6728
[2023-08-26 19:21:28,100][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00100 | loss1:0.0162 loss2:0.8862 loss3:0.0152 | AUC:0.8250 Anomaly AUC:0.6623
[2023-08-26 19:21:28,149][main.py][line:114][INFO] Training completes in 2m 10s | best AUCAUC:0.8250 Anomaly AUC:0.6623

[2023-08-26 19:21:39,578][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.0185 loss2:0.6837 loss3:0.0159 | AUC:0.8098 Anomaly AUC:0.6250
[2023-08-26 19:21:50,477][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0056 loss2:0.6233 loss3:0.0101 | AUC:0.8288 Anomaly AUC:0.6807
[2023-08-26 19:22:01,278][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0147 loss2:0.8409 loss3:0.0112 | AUC:0.8184 Anomaly AUC:0.6484
[2023-08-26 19:22:15,082][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.0057 loss2:0.8237 loss3:0.0121 | AUC:0.8195 Anomaly AUC:0.6650
[2023-08-26 19:22:29,910][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0126 loss2:0.7686 loss3:0.0093 | AUC:0.8189 Anomaly AUC:0.6525
[2023-08-26 19:22:44,412][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0014 loss2:0.4474 loss3:0.0068 | AUC:0.7825 Anomaly AUC:0.5774
[2023-08-26 19:22:57,026][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0116 loss2:0.6334 loss3:0.0117 | AUC:0.8214 Anomaly AUC:0.6622
[2023-08-26 19:23:11,786][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0038 loss2:0.5136 loss3:0.0084 | AUC:0.8122 Anomaly AUC:0.6418
[2023-08-26 19:23:23,068][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0301 loss2:0.6423 loss3:0.0111 | AUC:0.7956 Anomaly AUC:0.6054
[2023-08-26 19:23:41,239][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0097 loss2:0.9072 loss3:0.0136 | AUC:0.8228 Anomaly AUC:0.6334
[2023-08-26 19:23:41,266][main.py][line:114][INFO] Training completes in 2m 13s | best AUCAUC:0.8288 Anomaly AUC:0.6807

[2023-08-26 19:23:53,105][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.0220 loss2:0.3091 loss3:0.0100 | AUC:0.8270 Anomaly AUC:0.6580
[2023-08-26 19:24:04,562][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0046 loss2:0.4966 loss3:0.0088 | AUC:0.8217 Anomaly AUC:0.6818
[2023-08-26 19:24:15,571][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0014 loss2:0.2464 loss3:0.0081 | AUC:0.8248 Anomaly AUC:0.6734
[2023-08-26 19:24:26,587][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.0005 loss2:0.1605 loss3:0.0070 | AUC:0.8257 Anomaly AUC:0.6724
[2023-08-26 19:24:38,694][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0002 loss2:0.1846 loss3:0.0062 | AUC:0.8202 Anomaly AUC:0.6739
[2023-08-26 19:24:53,215][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0012 loss2:0.0971 loss3:0.0067 | AUC:0.8120 Anomaly AUC:0.6665
[2023-08-26 19:25:06,852][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0247 loss2:0.2353 loss3:0.0104 | AUC:0.8186 Anomaly AUC:0.6671
[2023-08-26 19:25:17,733][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0291 loss2:0.3737 loss3:0.0169 | AUC:0.8006 Anomaly AUC:0.6764
[2023-08-26 19:25:28,661][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0082 loss2:0.2616 loss3:0.0099 | AUC:0.8226 Anomaly AUC:0.6701
[2023-08-26 19:25:40,550][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0005 loss2:0.1186 loss3:0.0073 | AUC:0.8235 Anomaly AUC:0.6788
[2023-08-26 19:25:40,603][main.py][line:114][INFO] Training completes in 1m 59s | best AUCAUC:0.8270 Anomaly AUC:0.6580

[2023-08-26 19:25:55,116][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.0185 loss2:0.4587 loss3:0.0123 | AUC:0.8308 Anomaly AUC:0.6718
[2023-08-26 19:26:08,015][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0036 loss2:0.1566 loss3:0.0091 | AUC:0.8287 Anomaly AUC:0.6592
[2023-08-26 19:26:22,035][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0107 loss2:0.2013 loss3:0.0144 | AUC:0.7837 Anomaly AUC:0.6662
[2023-08-26 19:26:33,156][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.0089 loss2:0.2117 loss3:0.0086 | AUC:0.8181 Anomaly AUC:0.6731
[2023-08-26 19:26:43,826][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0081 loss2:0.1603 loss3:0.0083 | AUC:0.8253 Anomaly AUC:0.6633
[2023-08-26 19:26:54,723][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0204 loss2:0.4142 loss3:0.0140 | AUC:0.8284 Anomaly AUC:0.6662
[2023-08-26 19:27:07,990][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0087 loss2:0.2362 loss3:0.0109 | AUC:0.8323 Anomaly AUC:0.6780
[2023-08-26 19:27:23,321][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0242 loss2:0.3062 loss3:0.0156 | AUC:0.8264 Anomaly AUC:0.6691
[2023-08-26 19:27:34,216][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0015 loss2:0.1521 loss3:0.0103 | AUC:0.8249 Anomaly AUC:0.6736
[2023-08-26 19:27:45,063][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0004 loss2:0.0672 loss3:0.0069 | AUC:0.8239 Anomaly AUC:0.6743
[2023-08-26 19:27:45,091][main.py][line:114][INFO] Training completes in 2m 4s | best AUCAUC:0.8323 Anomaly AUC:0.6780

[2023-08-26 19:27:59,060][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0108 loss2:0.2365 loss3:0.0114 | AUC:0.8367 Anomaly AUC:0.6763
[2023-08-26 19:28:11,925][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0023 loss2:0.1160 loss3:0.0066 | AUC:0.8239 Anomaly AUC:0.6694
[2023-08-26 19:28:23,290][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0007 loss2:0.1067 loss3:0.0062 | AUC:0.8277 Anomaly AUC:0.6711
[2023-08-26 19:28:33,993][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0003 loss2:0.1168 loss3:0.0057 | AUC:0.8317 Anomaly AUC:0.6740
[2023-08-26 19:28:44,964][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0040 loss2:0.0897 loss3:0.0059 | AUC:0.8121 Anomaly AUC:0.6766
[2023-08-26 19:28:59,037][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0140 loss2:0.1325 loss3:0.0084 | AUC:0.8275 Anomaly AUC:0.6570
[2023-08-26 19:29:12,878][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0280 loss2:0.1592 loss3:0.0120 | AUC:0.8254 Anomaly AUC:0.6522
[2023-08-26 19:29:23,936][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0107 loss2:0.1041 loss3:0.0079 | AUC:0.8279 Anomaly AUC:0.6697
[2023-08-26 19:29:34,956][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0036 loss2:0.0666 loss3:0.0076 | AUC:0.8179 Anomaly AUC:0.6599
[2023-08-26 19:29:46,703][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0054 loss2:0.0522 loss3:0.0075 | AUC:0.8220 Anomaly AUC:0.6534
[2023-08-26 19:29:46,753][main.py][line:114][INFO] Training completes in 2m 2s | best AUCAUC:0.8367 Anomaly AUC:0.6763

[2023-08-26 19:29:58,708][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0054 loss2:0.1216 loss3:0.0099 | AUC:0.8309 Anomaly AUC:0.6654
[2023-08-26 19:30:11,398][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0034 loss2:0.1517 loss3:0.0081 | AUC:0.8247 Anomaly AUC:0.6656
[2023-08-26 19:30:27,198][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0034 loss2:0.1042 loss3:0.0069 | AUC:0.8229 Anomaly AUC:0.6636
[2023-08-26 19:30:38,559][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0006 loss2:0.0820 loss3:0.0076 | AUC:0.8184 Anomaly AUC:0.6613
[2023-08-26 19:30:53,506][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0002 loss2:0.0349 loss3:0.0066 | AUC:0.8228 Anomaly AUC:0.6713
[2023-08-26 19:31:04,790][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0003 loss2:0.1161 loss3:0.0051 | AUC:0.8162 Anomaly AUC:0.6659
[2023-08-26 19:31:17,737][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0004 loss2:0.2359 loss3:0.0059 | AUC:0.8159 Anomaly AUC:0.6733
[2023-08-26 19:31:32,343][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0003 loss2:0.0821 loss3:0.0060 | AUC:0.8191 Anomaly AUC:0.6677
[2023-08-26 19:31:43,507][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0005 loss2:0.1369 loss3:0.0051 | AUC:0.8138 Anomaly AUC:0.6581
[2023-08-26 19:31:54,367][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0049 loss2:0.2416 loss3:0.0065 | AUC:0.7990 Anomaly AUC:0.6782
[2023-08-26 19:31:54,394][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8309 Anomaly AUC:0.6654

[2023-08-26 19:32:05,275][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0103 loss2:0.2313 loss3:0.0112 | AUC:0.8279 Anomaly AUC:0.6754
[2023-08-26 19:32:18,954][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0038 loss2:0.1349 loss3:0.0078 | AUC:0.8287 Anomaly AUC:0.6803
[2023-08-26 19:32:31,450][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0031 loss2:0.1038 loss3:0.0072 | AUC:0.8193 Anomaly AUC:0.6639
[2023-08-26 19:32:43,476][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0146 loss2:0.3291 loss3:0.0131 | AUC:0.8052 Anomaly AUC:0.6150
[2023-08-26 19:32:55,932][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0125 loss2:0.2653 loss3:0.0201 | AUC:0.8178 Anomaly AUC:0.6379
[2023-08-26 19:33:07,698][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0028 loss2:0.1494 loss3:0.0116 | AUC:0.8322 Anomaly AUC:0.6695
[2023-08-26 19:33:18,729][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0016 loss2:0.0760 loss3:0.0062 | AUC:0.8319 Anomaly AUC:0.6706
[2023-08-26 19:33:29,735][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0003 loss2:0.0509 loss3:0.0057 | AUC:0.8329 Anomaly AUC:0.6714
[2023-08-26 19:33:44,139][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0002 loss2:0.0339 loss3:0.0055 | AUC:0.8307 Anomaly AUC:0.6737
[2023-08-26 19:33:56,421][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0002 loss2:0.0312 loss3:0.0051 | AUC:0.8322 Anomaly AUC:0.6740
[2023-08-26 19:33:56,474][main.py][line:114][INFO] Training completes in 2m 2s | best AUCAUC:0.8329 Anomaly AUC:0.6714

[2023-08-26 19:34:10,974][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0058 loss2:0.1151 loss3:0.0088 | AUC:0.8199 Anomaly AUC:0.6519
[2023-08-26 19:34:25,235][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0092 loss2:0.1170 loss3:0.0097 | AUC:0.8326 Anomaly AUC:0.6574
[2023-08-26 19:34:37,662][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0102 loss2:0.1779 loss3:0.0152 | AUC:0.8257 Anomaly AUC:0.6628
[2023-08-26 19:34:51,424][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0101 loss2:0.1629 loss3:0.0072 | AUC:0.8311 Anomaly AUC:0.6715
[2023-08-26 19:35:02,265][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0035 loss2:0.0713 loss3:0.0077 | AUC:0.8225 Anomaly AUC:0.6616
[2023-08-26 19:35:13,118][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0007 loss2:0.0958 loss3:0.0105 | AUC:0.8233 Anomaly AUC:0.6600
[2023-08-26 19:35:23,904][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0002 loss2:0.0666 loss3:0.0070 | AUC:0.8238 Anomaly AUC:0.6666
[2023-08-26 19:35:47,262][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0002 loss2:0.1460 loss3:0.0061 | AUC:0.8207 Anomaly AUC:0.6715
[2023-08-26 19:35:58,224][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0002 loss2:0.1112 loss3:0.0053 | AUC:0.8250 Anomaly AUC:0.6704
[2023-08-26 19:36:10,181][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0002 loss2:0.0465 loss3:0.0054 | AUC:0.8255 Anomaly AUC:0.6650
[2023-08-26 19:36:10,257][main.py][line:114][INFO] Training completes in 2m 14s | best AUCAUC:0.8326 Anomaly AUC:0.6574

[2023-08-26 19:36:21,448][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0093 loss2:0.2277 loss3:0.0102 | AUC:0.8326 Anomaly AUC:0.6634
[2023-08-26 19:36:32,226][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0057 loss2:0.3301 loss3:0.0104 | AUC:0.8249 Anomaly AUC:0.6684
[2023-08-26 19:36:42,947][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0038 loss2:0.0899 loss3:0.0067 | AUC:0.8035 Anomaly AUC:0.6543
[2023-08-26 19:36:57,002][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0050 loss2:0.3163 loss3:0.0111 | AUC:0.8206 Anomaly AUC:0.6774
[2023-08-26 19:37:08,406][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0115 loss2:0.1198 loss3:0.0103 | AUC:0.8288 Anomaly AUC:0.6605
[2023-08-26 19:37:19,342][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0098 loss2:0.1031 loss3:0.0108 | AUC:0.7932 Anomaly AUC:0.6658
[2023-08-26 19:37:30,254][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0099 loss2:0.1194 loss3:0.0118 | AUC:0.8229 Anomaly AUC:0.6469
[2023-08-26 19:37:42,045][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0102 loss2:0.0777 loss3:0.0125 | AUC:0.8246 Anomaly AUC:0.6711
[2023-08-26 19:37:56,636][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0008 loss2:0.0644 loss3:0.0070 | AUC:0.8234 Anomaly AUC:0.6656
[2023-08-26 19:38:10,404][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0002 loss2:0.0222 loss3:0.0066 | AUC:0.8247 Anomaly AUC:0.6626
[2023-08-26 19:38:10,448][main.py][line:114][INFO] Training completes in 2m 0s | best AUCAUC:0.8326 Anomaly AUC:0.6634

[2023-08-26 19:38:21,429][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00060 | loss1:0.0417 loss2:0.3617 loss3:0.0133 | AUC:0.8214 Anomaly AUC:0.6586
[2023-08-26 19:38:35,177][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00060 | loss1:0.0183 loss2:0.2955 loss3:0.0130 | AUC:0.8255 Anomaly AUC:0.6624
[2023-08-26 19:38:47,143][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00060 | loss1:0.0032 loss2:0.1193 loss3:0.0081 | AUC:0.8237 Anomaly AUC:0.6709
[2023-08-26 19:38:58,618][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00060 | loss1:0.0005 loss2:0.0605 loss3:0.0062 | AUC:0.8210 Anomaly AUC:0.6667
[2023-08-26 19:39:09,405][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00060 | loss1:0.0003 loss2:0.0400 loss3:0.0060 | AUC:0.8189 Anomaly AUC:0.6653
[2023-08-26 19:39:20,297][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00060 | loss1:0.0002 loss2:0.0177 loss3:0.0061 | AUC:0.8166 Anomaly AUC:0.6640
[2023-08-26 19:39:34,343][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00060 | loss1:0.0002 loss2:0.0270 loss3:0.0063 | AUC:0.8169 Anomaly AUC:0.6660
[2023-08-26 19:39:48,062][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00060 | loss1:0.0002 loss2:0.0283 loss3:0.0060 | AUC:0.8158 Anomaly AUC:0.6664
[2023-08-26 19:39:58,894][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00060 | loss1:0.0002 loss2:0.0433 loss3:0.0059 | AUC:0.8171 Anomaly AUC:0.6685
[2023-08-26 19:40:09,792][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00060 | loss1:0.0004 loss2:0.1082 loss3:0.0057 | AUC:0.8198 Anomaly AUC:0.6671
[2023-08-26 19:40:09,819][main.py][line:114][INFO] Training completes in 1m 59s | best AUCAUC:0.8255 Anomaly AUC:0.6624

[2023-08-26 19:40:21,811][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0050 loss2:0.2312 loss3:0.0076 | AUC:0.8183 Anomaly AUC:0.6669
[2023-08-26 19:40:34,087][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0004 loss2:0.0593 loss3:0.0076 | AUC:0.8137 Anomaly AUC:0.6684
[2023-08-26 19:40:46,425][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0010 loss2:0.0852 loss3:0.0056 | AUC:0.8194 Anomaly AUC:0.6679
[2023-08-26 19:41:00,899][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0006 loss2:0.1589 loss3:0.0050 | AUC:0.8174 Anomaly AUC:0.6683
[2023-08-26 19:41:14,596][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0005 loss2:0.1312 loss3:0.0048 | AUC:0.8172 Anomaly AUC:0.6654
[2023-08-26 19:41:25,607][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0004 loss2:0.0571 loss3:0.0056 | AUC:0.8124 Anomaly AUC:0.6609
[2023-08-26 19:41:36,354][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0001 loss2:0.0000 loss3:0.0047 | AUC:0.8124 Anomaly AUC:0.6595
[2023-08-26 19:41:47,086][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0045 | AUC:0.8118 Anomaly AUC:0.6591
[2023-08-26 19:42:00,822][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0044 | AUC:0.8127 Anomaly AUC:0.6614
[2023-08-26 19:42:15,169][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0041 | AUC:0.8135 Anomaly AUC:0.6631
[2023-08-26 19:42:15,220][main.py][line:114][INFO] Training completes in 2m 5s | best AUCAUC:0.8194 Anomaly AUC:0.6679

[2023-08-26 19:42:26,411][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00050 | loss1:0.0144 loss2:0.0000 loss3:0.0085 | AUC:0.8134 Anomaly AUC:0.6225
[2023-08-26 19:42:37,284][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00050 | loss1:0.0299 loss2:0.5735 loss3:0.0273 | AUC:0.8238 Anomaly AUC:0.6629
[2023-08-26 19:42:48,124][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00050 | loss1:0.0097 loss2:0.2975 loss3:0.0124 | AUC:0.8213 Anomaly AUC:0.6649
[2023-08-26 19:43:00,120][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00050 | loss1:0.0003 loss2:0.0851 loss3:0.0067 | AUC:0.8192 Anomaly AUC:0.6565
[2023-08-26 19:43:11,489][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00050 | loss1:0.0002 loss2:0.0635 loss3:0.0050 | AUC:0.8187 Anomaly AUC:0.6576
[2023-08-26 19:43:22,271][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00050 | loss1:0.0001 loss2:0.0367 loss3:0.0059 | AUC:0.8181 Anomaly AUC:0.6562
[2023-08-26 19:43:33,249][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00050 | loss1:0.0002 loss2:0.0506 loss3:0.0053 | AUC:0.8185 Anomaly AUC:0.6608
[2023-08-26 19:43:46,858][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00050 | loss1:0.0001 loss2:0.0221 loss3:0.0054 | AUC:0.8177 Anomaly AUC:0.6617
[2023-08-26 19:43:59,049][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00050 | loss1:0.0003 loss2:0.0886 loss3:0.0050 | AUC:0.8163 Anomaly AUC:0.6568
[2023-08-26 19:44:13,833][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00050 | loss1:0.0007 loss2:0.0812 loss3:0.0053 | AUC:0.8175 Anomaly AUC:0.6538
[2023-08-26 19:44:13,860][main.py][line:114][INFO] Training completes in 1m 59s | best AUCAUC:0.8238 Anomaly AUC:0.6629

[2023-08-26 19:44:24,713][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00060 | loss1:0.0117 loss2:0.0994 loss3:0.0152 | AUC:0.8218 Anomaly AUC:0.6478
[2023-08-26 19:44:35,490][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00060 | loss1:0.0015 loss2:0.0832 loss3:0.0136 | AUC:0.8193 Anomaly AUC:0.6596
[2023-08-26 19:44:47,028][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00060 | loss1:0.0001 loss2:0.0204 loss3:0.0093 | AUC:0.8217 Anomaly AUC:0.6635
[2023-08-26 19:44:58,489][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0058 | AUC:0.8229 Anomaly AUC:0.6663
[2023-08-26 19:45:11,010][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0051 | AUC:0.8238 Anomaly AUC:0.6683
[2023-08-26 19:45:21,781][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0046 | AUC:0.8244 Anomaly AUC:0.6692
[2023-08-26 19:45:35,785][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0047 | AUC:0.8238 Anomaly AUC:0.6684
[2023-08-26 19:45:47,928][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0047 | AUC:0.8236 Anomaly AUC:0.6693
[2023-08-26 19:45:59,760][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0043 | AUC:0.8234 Anomaly AUC:0.6692
[2023-08-26 19:46:12,445][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0048 | AUC:0.8234 Anomaly AUC:0.6694
[2023-08-26 19:46:12,495][main.py][line:114][INFO] Training completes in 1m 59s | best AUCAUC:0.8244 Anomaly AUC:0.6692

[2023-08-26 19:46:23,579][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0618 loss2:0.0752 loss3:0.0096 | AUC:0.8250 Anomaly AUC:0.6731
[2023-08-26 19:46:34,418][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0099 loss2:0.6545 loss3:0.0063 | AUC:0.8288 Anomaly AUC:0.6651
[2023-08-26 19:46:45,219][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0007 loss2:0.5940 loss3:0.0049 | AUC:0.8275 Anomaly AUC:0.6711
[2023-08-26 19:46:59,150][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0003 loss2:0.1733 loss3:0.0049 | AUC:0.8242 Anomaly AUC:0.6795
[2023-08-26 19:47:10,469][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0016 loss2:0.4500 loss3:0.0046 | AUC:0.8258 Anomaly AUC:0.6798
[2023-08-26 19:47:21,289][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0003 loss2:0.1786 loss3:0.0047 | AUC:0.8261 Anomaly AUC:0.6770
[2023-08-26 19:47:32,228][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0002 loss2:0.1054 loss3:0.0054 | AUC:0.8237 Anomaly AUC:0.6753
[2023-08-26 19:47:46,095][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0003 loss2:0.1040 loss3:0.0047 | AUC:0.8220 Anomaly AUC:0.6719
[2023-08-26 19:47:59,846][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0002 loss2:0.0636 loss3:0.0055 | AUC:0.8241 Anomaly AUC:0.6722
[2023-08-26 19:48:13,382][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0002 loss2:0.0513 loss3:0.0046 | AUC:0.8209 Anomaly AUC:0.6752
[2023-08-26 19:48:13,452][main.py][line:114][INFO] Training completes in 2m 1s | best AUCAUC:0.8288 Anomaly AUC:0.6651

[2023-08-26 19:48:27,883][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0074 loss2:0.5029 loss3:0.0107 | AUC:0.8194 Anomaly AUC:0.6543
[2023-08-26 19:48:39,911][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0003 loss2:0.3050 loss3:0.0056 | AUC:0.8283 Anomaly AUC:0.6680
[2023-08-26 19:48:57,215][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0042 loss2:0.2282 loss3:0.0061 | AUC:0.8160 Anomaly AUC:0.6689
[2023-08-26 19:49:11,781][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0132 loss2:0.6058 loss3:0.0099 | AUC:0.8235 Anomaly AUC:0.6615
[2023-08-26 19:49:25,480][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0030 loss2:0.4784 loss3:0.0068 | AUC:0.8151 Anomaly AUC:0.6624
[2023-08-26 19:49:42,217][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0008 loss2:0.2522 loss3:0.0046 | AUC:0.8100 Anomaly AUC:0.6673
[2023-08-26 19:49:53,113][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0004 loss2:0.4678 loss3:0.0045 | AUC:0.8115 Anomaly AUC:0.6694
[2023-08-26 19:50:10,766][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0002 loss2:0.1817 loss3:0.0047 | AUC:0.8141 Anomaly AUC:0.6698
[2023-08-26 19:50:22,172][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0002 loss2:0.1516 loss3:0.0052 | AUC:0.8112 Anomaly AUC:0.6693
[2023-08-26 19:50:33,046][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0002 loss2:0.1020 loss3:0.0044 | AUC:0.8083 Anomaly AUC:0.6665
[2023-08-26 19:50:33,072][main.py][line:114][INFO] Training completes in 2m 20s | best AUCAUC:0.8283 Anomaly AUC:0.6680

[2023-08-26 19:50:43,833][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00070 | loss1:0.0208 loss2:0.0444 loss3:0.0122 | AUC:0.8068 Anomaly AUC:0.6634
[2023-08-26 19:50:57,493][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00070 | loss1:0.0080 loss2:0.0320 loss3:0.0061 | AUC:0.8186 Anomaly AUC:0.6674
[2023-08-26 19:51:09,842][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00070 | loss1:0.0062 loss2:0.2328 loss3:0.0055 | AUC:0.8258 Anomaly AUC:0.6654
[2023-08-26 19:51:20,765][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00070 | loss1:0.0054 loss2:0.7498 loss3:0.0063 | AUC:0.8321 Anomaly AUC:0.6837
[2023-08-26 19:51:31,535][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00070 | loss1:0.0002 loss2:0.5550 loss3:0.0041 | AUC:0.8181 Anomaly AUC:0.6755
[2023-08-26 19:51:43,396][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00070 | loss1:0.0009 loss2:0.2750 loss3:0.0055 | AUC:0.8224 Anomaly AUC:0.6689
[2023-08-26 19:51:57,789][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00070 | loss1:0.0004 loss2:0.2759 loss3:0.0047 | AUC:0.8180 Anomaly AUC:0.6713
[2023-08-26 19:52:21,409][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00070 | loss1:0.0005 loss2:0.1439 loss3:0.0044 | AUC:0.8173 Anomaly AUC:0.6596
[2023-08-26 19:52:32,456][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00070 | loss1:0.0002 loss2:0.1153 loss3:0.0051 | AUC:0.8132 Anomaly AUC:0.6736
[2023-08-26 19:52:46,626][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00070 | loss1:0.0002 loss2:0.0851 loss3:0.0041 | AUC:0.8080 Anomaly AUC:0.6697
[2023-08-26 19:52:46,677][main.py][line:114][INFO] Training completes in 2m 14s | best AUCAUC:0.8321 Anomaly AUC:0.6837

[2023-08-26 19:53:01,191][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.0010 loss2:0.5101 loss3:0.0049 | AUC:0.8126 Anomaly AUC:0.6505
[2023-08-26 19:53:13,684][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0073 loss2:0.1722 loss3:0.0067 | AUC:0.8264 Anomaly AUC:0.6709
[2023-08-26 19:53:28,129][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0063 loss2:0.3747 loss3:0.0052 | AUC:0.8245 Anomaly AUC:0.6797
[2023-08-26 19:53:40,937][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.0121 loss2:0.2246 loss3:0.0067 | AUC:0.8223 Anomaly AUC:0.6875
[2023-08-26 19:53:52,397][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0007 loss2:0.1761 loss3:0.0044 | AUC:0.8180 Anomaly AUC:0.6765
[2023-08-26 19:54:03,206][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0003 loss2:0.1344 loss3:0.0041 | AUC:0.8169 Anomaly AUC:0.6808
[2023-08-26 19:54:14,209][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0002 loss2:0.1020 loss3:0.0045 | AUC:0.8207 Anomaly AUC:0.6802
[2023-08-26 19:54:26,119][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0001 loss2:0.1002 loss3:0.0047 | AUC:0.8203 Anomaly AUC:0.6793
[2023-08-26 19:54:40,705][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0002 loss2:0.0843 loss3:0.0043 | AUC:0.8153 Anomaly AUC:0.6771
[2023-08-26 19:54:54,473][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0002 loss2:0.0641 loss3:0.0043 | AUC:0.8174 Anomaly AUC:0.6834
[2023-08-26 19:54:54,500][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8264 Anomaly AUC:0.6709

[2023-08-26 19:55:05,379][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00040 | loss1:0.0389 loss2:0.3832 loss3:0.0167 | AUC:0.8076 Anomaly AUC:0.6852
[2023-08-26 19:55:16,303][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00040 | loss1:0.0011 loss2:0.1702 loss3:0.0084 | AUC:0.8161 Anomaly AUC:0.6822
[2023-08-26 19:55:27,880][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00040 | loss1:0.0003 loss2:0.0976 loss3:0.0061 | AUC:0.8200 Anomaly AUC:0.6776
[2023-08-26 19:55:40,740][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00040 | loss1:0.0004 loss2:0.0654 loss3:0.0073 | AUC:0.8173 Anomaly AUC:0.6729
[2023-08-26 19:55:55,046][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00040 | loss1:0.0004 loss2:0.0514 loss3:0.0056 | AUC:0.8177 Anomaly AUC:0.6821
[2023-08-26 19:56:07,845][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00040 | loss1:0.0003 loss2:0.0380 loss3:0.0055 | AUC:0.8201 Anomaly AUC:0.6766
[2023-08-26 19:56:19,324][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00040 | loss1:0.0003 loss2:0.0340 loss3:0.0056 | AUC:0.8217 Anomaly AUC:0.6844
[2023-08-26 19:56:30,269][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00040 | loss1:0.0015 loss2:0.0236 loss3:0.0061 | AUC:0.8251 Anomaly AUC:0.6870
[2023-08-26 19:56:41,110][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00040 | loss1:0.0002 loss2:0.0156 loss3:0.0056 | AUC:0.8193 Anomaly AUC:0.6827
[2023-08-26 19:56:54,858][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00040 | loss1:0.0003 loss2:0.0145 loss3:0.0059 | AUC:0.8165 Anomaly AUC:0.6695
[2023-08-26 19:56:54,914][main.py][line:114][INFO] Training completes in 2m 0s | best AUCAUC:0.8251 Anomaly AUC:0.6870

[2023-08-26 19:57:06,619][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00060 | loss1:0.0082 loss2:0.0869 loss3:0.0073 | AUC:0.8227 Anomaly AUC:0.6892
[2023-08-26 19:57:17,579][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00060 | loss1:0.0004 loss2:0.0338 loss3:0.0069 | AUC:0.8246 Anomaly AUC:0.6851
[2023-08-26 19:57:28,528][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00060 | loss1:0.0016 loss2:0.3048 loss3:0.0060 | AUC:0.8285 Anomaly AUC:0.6772
[2023-08-26 19:57:41,838][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00060 | loss1:0.0063 loss2:0.1294 loss3:0.0061 | AUC:0.8086 Anomaly AUC:0.6784
[2023-08-26 19:57:52,700][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00060 | loss1:0.0009 loss2:0.0588 loss3:0.0061 | AUC:0.8133 Anomaly AUC:0.6782
[2023-08-26 19:58:03,663][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00060 | loss1:0.0022 loss2:0.0413 loss3:0.0053 | AUC:0.8282 Anomaly AUC:0.6845
[2023-08-26 19:58:15,188][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00060 | loss1:0.0219 loss2:0.0571 loss3:0.0074 | AUC:0.8312 Anomaly AUC:0.6697
[2023-08-26 19:58:28,114][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00060 | loss1:0.0099 loss2:0.0817 loss3:0.0082 | AUC:0.8169 Anomaly AUC:0.6770
[2023-08-26 19:58:39,495][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00060 | loss1:0.0079 loss2:0.0578 loss3:0.0069 | AUC:0.8131 Anomaly AUC:0.6760
[2023-08-26 19:58:52,356][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00060 | loss1:0.0034 loss2:0.0778 loss3:0.0063 | AUC:0.8024 Anomaly AUC:0.6706
[2023-08-26 19:58:52,383][main.py][line:114][INFO] Training completes in 1m 57s | best AUCAUC:0.8312 Anomaly AUC:0.6697

[2023-08-26 19:59:03,241][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00050 | loss1:0.0159 loss2:0.1099 loss3:0.0105 | AUC:0.8065 Anomaly AUC:0.6777
[2023-08-26 19:59:17,224][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00050 | loss1:0.0004 loss2:0.0333 loss3:0.0058 | AUC:0.8255 Anomaly AUC:0.6794
[2023-08-26 19:59:35,139][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00050 | loss1:0.0001 loss2:0.0111 loss3:0.0053 | AUC:0.8271 Anomaly AUC:0.6803
[2023-08-26 19:59:45,867][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00050 | loss1:0.0001 loss2:0.0082 loss3:0.0041 | AUC:0.8245 Anomaly AUC:0.6808
[2023-08-26 19:59:57,884][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00050 | loss1:0.0000 loss2:0.0086 loss3:0.0042 | AUC:0.8261 Anomaly AUC:0.6828
[2023-08-26 20:00:10,382][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00050 | loss1:0.0001 loss2:0.0065 loss3:0.0037 | AUC:0.8265 Anomaly AUC:0.6822
[2023-08-26 20:00:24,841][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00050 | loss1:0.0001 loss2:0.0199 loss3:0.0043 | AUC:0.8242 Anomaly AUC:0.6831
[2023-08-26 20:00:38,598][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00050 | loss1:0.0001 loss2:0.0193 loss3:0.0039 | AUC:0.8233 Anomaly AUC:0.6817
[2023-08-26 20:00:49,350][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00050 | loss1:0.0002 loss2:0.0285 loss3:0.0042 | AUC:0.8204 Anomaly AUC:0.6741
[2023-08-26 20:01:00,151][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00050 | loss1:0.0001 loss2:0.0983 loss3:0.0040 | AUC:0.8202 Anomaly AUC:0.6724
[2023-08-26 20:01:00,178][main.py][line:114][INFO] Training completes in 2m 8s | best AUCAUC:0.8271 Anomaly AUC:0.6803

[2023-08-26 20:01:11,759][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.0144 loss2:0.2697 loss3:0.0099 | AUC:0.8369 Anomaly AUC:0.6678
[2023-08-26 20:01:24,443][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0180 loss2:0.1369 loss3:0.0104 | AUC:0.7977 Anomaly AUC:0.6790
[2023-08-26 20:01:38,860][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0203 loss2:0.1430 loss3:0.0111 | AUC:0.8290 Anomaly AUC:0.6823
[2023-08-26 20:01:51,596][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.0037 loss2:0.0639 loss3:0.0066 | AUC:0.8240 Anomaly AUC:0.6727
[2023-08-26 20:02:06,318][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0027 loss2:0.0399 loss3:0.0055 | AUC:0.8243 Anomaly AUC:0.6742
[2023-08-26 20:02:20,664][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0025 loss2:0.0305 loss3:0.0051 | AUC:0.8141 Anomaly AUC:0.6766
[2023-08-26 20:02:33,383][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0024 loss2:0.0184 loss3:0.0050 | AUC:0.8206 Anomaly AUC:0.6741
[2023-08-26 20:02:45,737][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0022 loss2:0.0298 loss3:0.0057 | AUC:0.8202 Anomaly AUC:0.6782
[2023-08-26 20:02:56,737][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0022 loss2:0.0338 loss3:0.0047 | AUC:0.8145 Anomaly AUC:0.6808
[2023-08-26 20:03:07,674][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0020 loss2:0.0318 loss3:0.0053 | AUC:0.8158 Anomaly AUC:0.6776
[2023-08-26 20:03:07,700][main.py][line:114][INFO] Training completes in 2m 7s | best AUCAUC:0.8369 Anomaly AUC:0.6678

[2023-08-26 20:03:21,459][main.py][line:106][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.0171 loss2:0.2741 loss3:0.0112 | AUC:0.7851 Anomaly AUC:0.6736
[2023-08-26 20:03:35,859][main.py][line:106][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.0178 loss2:0.1008 loss3:0.0123 | AUC:0.8164 Anomaly AUC:0.6634
[2023-08-26 20:03:48,800][main.py][line:106][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.0142 loss2:0.1148 loss3:0.0089 | AUC:0.8193 Anomaly AUC:0.6763
[2023-08-26 20:04:00,251][main.py][line:106][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.0044 loss2:0.0639 loss3:0.0081 | AUC:0.8209 Anomaly AUC:0.6693
[2023-08-26 20:04:11,133][main.py][line:106][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.0046 loss2:0.0468 loss3:0.0069 | AUC:0.8101 Anomaly AUC:0.6907
[2023-08-26 20:04:22,168][main.py][line:106][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.0030 loss2:0.0372 loss3:0.0058 | AUC:0.8191 Anomaly AUC:0.6741
[2023-08-26 20:04:36,247][main.py][line:106][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.0004 loss2:0.0195 loss3:0.0057 | AUC:0.8169 Anomaly AUC:0.6827
[2023-08-26 20:04:51,073][main.py][line:106][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0002 loss2:0.0229 loss3:0.0049 | AUC:0.8220 Anomaly AUC:0.6839
[2023-08-26 20:05:02,437][main.py][line:106][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0002 loss2:0.0364 loss3:0.0049 | AUC:0.8215 Anomaly AUC:0.6757
[2023-08-26 20:05:13,343][main.py][line:106][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0003 loss2:0.1077 loss3:0.0048 | AUC:0.8243 Anomaly AUC:0.6738
[2023-08-26 20:05:13,368][main.py][line:114][INFO] Training completes in 2m 6s | best AUCAUC:0.8243 Anomaly AUC:0.6738

[2023-08-26 20:08:26,641][main.py][line:115][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 10, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 20:08:26,776][main.py][line:151][INFO] total params:9.6689M
[2023-08-26 20:08:26,776][main.py][line:154][INFO] Training Mode
[2023-08-26 20:08:26,777][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 20:08:26,777][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 20:08:34,796][main.py][line:77][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 20:09:01,928][main.py][line:100][INFO] [Epoch:1/10]: lr:0.00080 | loss1:0.5661 loss2:1.2751 loss3:0.3325 | AUC:0.8016 Anomaly AUC:0.6263
[2023-08-26 20:09:37,489][main.py][line:100][INFO] [Epoch:2/10]: lr:0.00080 | loss1:0.3508 loss2:1.1085 loss3:0.1060 | AUC:0.8178 Anomaly AUC:0.6267
[2023-08-26 20:10:19,889][main.py][line:100][INFO] [Epoch:3/10]: lr:0.00080 | loss1:0.2772 loss2:1.0430 loss3:0.0545 | AUC:0.8319 Anomaly AUC:0.6498
[2023-08-26 20:10:54,572][main.py][line:100][INFO] [Epoch:4/10]: lr:0.00080 | loss1:0.2110 loss2:0.9668 loss3:0.0337 | AUC:0.8390 Anomaly AUC:0.6631
[2023-08-26 20:11:47,849][main.py][line:100][INFO] [Epoch:5/10]: lr:0.00080 | loss1:0.1592 loss2:0.9053 loss3:0.0254 | AUC:0.8181 Anomaly AUC:0.6701
[2023-08-26 20:12:31,743][main.py][line:100][INFO] [Epoch:6/10]: lr:0.00080 | loss1:0.1463 loss2:0.8999 loss3:0.0240 | AUC:0.8334 Anomaly AUC:0.6734
[2023-08-26 20:13:24,303][main.py][line:100][INFO] [Epoch:7/10]: lr:0.00080 | loss1:0.1112 loss2:0.8273 loss3:0.0188 | AUC:0.8025 Anomaly AUC:0.6371
[2023-08-26 20:14:04,447][main.py][line:100][INFO] [Epoch:8/10]: lr:0.00080 | loss1:0.0861 loss2:0.7794 loss3:0.0161 | AUC:0.8173 Anomaly AUC:0.6642
[2023-08-26 20:14:53,549][main.py][line:100][INFO] [Epoch:9/10]: lr:0.00080 | loss1:0.0717 loss2:0.7491 loss3:0.0142 | AUC:0.8294 Anomaly AUC:0.6541
[2023-08-26 20:16:00,633][main.py][line:100][INFO] [Epoch:10/10]: lr:0.00080 | loss1:0.0616 loss2:0.7137 loss3:0.0123 | AUC:0.8354 Anomaly AUC:0.6619
[2023-08-26 20:16:00,668][main.py][line:108][INFO] Training completes in 7m 26s | best AUCAUC:0.8390 Anomaly AUC:0.6631

[2023-08-26 20:21:09,653][main.py][line:115][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 20:21:09,822][main.py][line:151][INFO] total params:9.6689M
[2023-08-26 20:21:09,822][main.py][line:154][INFO] Training Mode
[2023-08-26 20:21:09,822][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 20:21:09,822][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 20:21:17,898][main.py][line:77][INFO] Random initialize AUCAUC:0.5276 Anomaly AUC:0.48186
[2023-08-26 20:22:05,244][main.py][line:100][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.5661 loss2:1.2751 loss3:0.3325 | AUC:0.8016 Anomaly AUC:0.6263
[2023-08-26 20:23:16,482][main.py][line:100][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.3508 loss2:1.1085 loss3:0.1060 | AUC:0.8178 Anomaly AUC:0.6267
[2023-08-26 20:24:06,649][main.py][line:100][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.2772 loss2:1.0430 loss3:0.0545 | AUC:0.8319 Anomaly AUC:0.6498
[2023-08-26 20:24:51,894][main.py][line:100][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.2110 loss2:0.9668 loss3:0.0337 | AUC:0.8390 Anomaly AUC:0.6631
[2023-08-26 20:26:07,349][main.py][line:100][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.1592 loss2:0.9053 loss3:0.0254 | AUC:0.8181 Anomaly AUC:0.6701
[2023-08-26 20:27:13,038][main.py][line:100][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.1463 loss2:0.8999 loss3:0.0240 | AUC:0.8334 Anomaly AUC:0.6734
[2023-08-26 20:28:29,961][main.py][line:100][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.1112 loss2:0.8273 loss3:0.0188 | AUC:0.8025 Anomaly AUC:0.6371
[2023-08-26 20:29:34,399][main.py][line:100][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.0861 loss2:0.7794 loss3:0.0161 | AUC:0.8173 Anomaly AUC:0.6642
[2023-08-26 20:30:44,928][main.py][line:100][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0717 loss2:0.7491 loss3:0.0142 | AUC:0.8294 Anomaly AUC:0.6541
[2023-08-26 20:31:57,185][main.py][line:100][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0616 loss2:0.7137 loss3:0.0123 | AUC:0.8354 Anomaly AUC:0.6619
[2023-08-26 20:32:55,681][main.py][line:100][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0527 loss2:0.6884 loss3:0.0111 | AUC:0.8080 Anomaly AUC:0.6684
[2023-08-26 20:34:22,693][main.py][line:100][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0461 loss2:0.6495 loss3:0.0097 | AUC:0.8139 Anomaly AUC:0.6813
[2023-08-26 20:35:31,237][main.py][line:100][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0251 loss2:0.5978 loss3:0.0072 | AUC:0.8079 Anomaly AUC:0.6385
[2023-08-26 20:36:46,582][main.py][line:100][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0310 loss2:0.5221 loss3:0.0065 | AUC:0.7736 Anomaly AUC:0.5806
[2023-08-26 20:37:50,185][main.py][line:100][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0194 loss2:0.4848 loss3:0.0055 | AUC:0.8193 Anomaly AUC:0.6568
[2023-08-26 20:38:39,147][main.py][line:100][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0220 loss2:0.3071 loss3:0.0053 | AUC:0.7685 Anomaly AUC:0.6379
[2023-08-26 20:39:33,378][main.py][line:100][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0232 loss2:0.3946 loss3:0.0057 | AUC:0.7442 Anomaly AUC:0.5453
[2023-08-26 20:40:23,335][main.py][line:100][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0167 loss2:0.2027 loss3:0.0045 | AUC:0.7382 Anomaly AUC:0.6006
[2023-08-26 20:41:09,804][main.py][line:100][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0434 loss2:0.4665 loss3:0.0092 | AUC:0.8024 Anomaly AUC:0.6414
[2023-08-26 20:41:51,113][main.py][line:100][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0191 loss2:0.4960 loss3:0.0049 | AUC:0.7627 Anomaly AUC:0.5932
[2023-08-26 20:42:37,505][main.py][line:100][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0125 loss2:0.4059 loss3:0.0036 | AUC:0.8004 Anomaly AUC:0.6661
[2023-08-26 20:43:35,111][main.py][line:100][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0100 loss2:0.3261 loss3:0.0035 | AUC:0.7881 Anomaly AUC:0.6447
[2023-08-26 20:44:31,573][main.py][line:115][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 20:44:31,718][main.py][line:151][INFO] total params:7.5707M
[2023-08-26 20:44:31,718][main.py][line:154][INFO] Training Mode
[2023-08-26 20:44:31,719][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 20:44:31,719][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 20:44:42,032][main.py][line:77][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-26 20:45:39,741][main.py][line:100][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.3744 loss2:1.1221 loss3:0.2346 | AUC:0.8227 Anomaly AUC:0.6356
[2023-08-26 20:46:54,791][main.py][line:100][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.1542 loss2:0.8680 loss3:0.0549 | AUC:0.8145 Anomaly AUC:0.6670
[2023-08-26 20:47:47,561][main.py][line:100][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.0676 loss2:0.7569 loss3:0.0231 | AUC:0.8332 Anomaly AUC:0.6733
[2023-08-26 20:48:56,856][main.py][line:100][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.0404 loss2:0.6888 loss3:0.0139 | AUC:0.8661 Anomaly AUC:0.7058
[2023-08-26 20:50:07,067][main.py][line:100][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.0235 loss2:0.5921 loss3:0.0067 | AUC:0.8582 Anomaly AUC:0.7050
[2023-08-26 20:51:32,717][main.py][line:100][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.0222 loss2:0.5251 loss3:0.0071 | AUC:0.8472 Anomaly AUC:0.6976
[2023-08-26 20:52:54,674][main.py][line:100][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.0246 loss2:0.4537 loss3:0.0079 | AUC:0.8078 Anomaly AUC:0.6991
[2023-08-26 20:54:29,507][main.py][line:100][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.0184 loss2:0.3736 loss3:0.0068 | AUC:0.8350 Anomaly AUC:0.6601
[2023-08-26 20:56:09,328][main.py][line:100][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0161 loss2:0.2963 loss3:0.0066 | AUC:0.8275 Anomaly AUC:0.6512
[2023-08-26 20:57:07,753][main.py][line:100][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0302 loss2:0.2674 loss3:0.0097 | AUC:0.8339 Anomaly AUC:0.6701
[2023-08-26 20:58:47,141][main.py][line:100][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0097 loss2:0.1757 loss3:0.0039 | AUC:0.8343 Anomaly AUC:0.6590
[2023-08-26 21:00:03,297][main.py][line:100][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0162 loss2:0.1349 loss3:0.0047 | AUC:0.8250 Anomaly AUC:0.6457
[2023-08-26 21:01:11,565][main.py][line:100][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0125 loss2:0.0971 loss3:0.0043 | AUC:0.8129 Anomaly AUC:0.6227
[2023-08-26 21:02:43,358][main.py][line:100][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0064 loss2:0.0622 loss3:0.0030 | AUC:0.8274 Anomaly AUC:0.5999
[2023-08-26 21:03:48,205][main.py][line:100][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0130 loss2:0.0570 loss3:0.0038 | AUC:0.8169 Anomaly AUC:0.5995
[2023-08-26 21:04:48,336][main.py][line:100][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0044 loss2:0.0343 loss3:0.0020 | AUC:0.8352 Anomaly AUC:0.6216
[2023-08-26 21:05:57,406][main.py][line:100][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0048 loss2:0.0282 loss3:0.0022 | AUC:0.8250 Anomaly AUC:0.6086
[2023-08-26 21:07:00,341][main.py][line:100][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0068 loss2:0.0202 loss3:0.0034 | AUC:0.8257 Anomaly AUC:0.6300
[2023-08-26 21:08:28,067][main.py][line:100][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0077 loss2:0.0391 loss3:0.0037 | AUC:0.8421 Anomaly AUC:0.6473
[2023-08-26 21:09:52,729][main.py][line:100][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0230 loss2:0.0684 loss3:0.0076 | AUC:0.8066 Anomaly AUC:0.5968
[2023-08-26 21:11:06,254][main.py][line:100][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0121 loss2:0.0518 loss3:0.0050 | AUC:0.8119 Anomaly AUC:0.6261
[2023-08-26 21:12:31,737][main.py][line:100][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0056 loss2:0.0228 loss3:0.0024 | AUC:0.8075 Anomaly AUC:0.6232
[2023-08-26 21:13:33,497][main.py][line:100][INFO] [Epoch:23/100]: lr:0.00080 | loss1:0.0248 loss2:0.0642 loss3:0.0086 | AUC:0.8056 Anomaly AUC:0.5847
[2023-08-26 21:15:01,099][main.py][line:100][INFO] [Epoch:24/100]: lr:0.00080 | loss1:0.0056 loss2:0.0219 loss3:0.0025 | AUC:0.8056 Anomaly AUC:0.5896
[2023-08-26 21:16:23,066][main.py][line:100][INFO] [Epoch:25/100]: lr:0.00080 | loss1:0.0060 loss2:0.0206 loss3:0.0024 | AUC:0.8056 Anomaly AUC:0.6010
[2023-08-26 21:17:54,988][main.py][line:100][INFO] [Epoch:26/100]: lr:0.00080 | loss1:0.0091 loss2:0.0312 loss3:0.0043 | AUC:0.8084 Anomaly AUC:0.6099
[2023-08-26 21:19:20,900][main.py][line:100][INFO] [Epoch:27/100]: lr:0.00080 | loss1:0.0024 loss2:0.0101 loss3:0.0016 | AUC:0.8003 Anomaly AUC:0.5944
[2023-08-26 21:20:20,982][main.py][line:100][INFO] [Epoch:28/100]: lr:0.00080 | loss1:0.0034 loss2:0.0127 loss3:0.0017 | AUC:0.7813 Anomaly AUC:0.5801
[2023-08-26 21:21:15,276][main.py][line:100][INFO] [Epoch:29/100]: lr:0.00080 | loss1:0.0064 loss2:0.0100 loss3:0.0024 | AUC:0.7886 Anomaly AUC:0.5451
[2023-08-26 21:22:18,559][main.py][line:100][INFO] [Epoch:30/100]: lr:0.00080 | loss1:0.0053 loss2:0.0158 loss3:0.0025 | AUC:0.8124 Anomaly AUC:0.6034
[2023-08-26 21:23:25,663][main.py][line:100][INFO] [Epoch:31/100]: lr:0.00080 | loss1:0.0150 loss2:0.0423 loss3:0.0047 | AUC:0.7999 Anomaly AUC:0.5788
[2023-08-26 21:24:45,271][main.py][line:100][INFO] [Epoch:32/100]: lr:0.00080 | loss1:0.0093 loss2:0.0231 loss3:0.0038 | AUC:0.8014 Anomaly AUC:0.5764
[2023-08-26 21:25:56,963][main.py][line:100][INFO] [Epoch:33/100]: lr:0.00080 | loss1:0.0114 loss2:0.0339 loss3:0.0033 | AUC:0.7765 Anomaly AUC:0.5617
[2023-08-26 21:26:48,917][main.py][line:100][INFO] [Epoch:34/100]: lr:0.00080 | loss1:0.0092 loss2:0.0276 loss3:0.0033 | AUC:0.8176 Anomaly AUC:0.6055
[2023-08-26 21:28:10,359][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 21:28:10,499][main.py][line:152][INFO] total params:7.5707M
[2023-08-26 21:28:10,499][main.py][line:161][INFO] Test Mode
[2023-08-26 21:28:10,499][main.py][line:34][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-26 21:28:18,732][infer.py][line:47][INFO] offline AUC:0.8663 AP:0.3465 FAR:0.0325 | Complete in 0m 8s

[2023-08-26 21:28:30,594][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 21:28:30,719][main.py][line:152][INFO] total params:7.5707M
[2023-08-26 21:28:30,719][main.py][line:155][INFO] Training Mode
[2023-08-26 21:28:30,720][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 21:28:30,720][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 21:28:38,241][main.py][line:77][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-26 21:29:24,703][main.py][line:101][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.3744 loss2:1.1221 loss3:0.2346 | AUC:0.8227 Anomaly AUC:0.6356
[2023-08-26 21:30:03,724][main.py][line:101][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.1542 loss2:0.8680 loss3:0.0549 | AUC:0.8145 Anomaly AUC:0.6670
[2023-08-26 21:30:52,757][main.py][line:101][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.0676 loss2:0.7569 loss3:0.0231 | AUC:0.8332 Anomaly AUC:0.6733
[2023-08-26 21:31:43,116][main.py][line:101][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.0404 loss2:0.6888 loss3:0.0139 | AUC:0.8661 Anomaly AUC:0.7058
[2023-08-26 21:32:55,515][main.py][line:101][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.0235 loss2:0.5921 loss3:0.0067 | AUC:0.8582 Anomaly AUC:0.7050
[2023-08-26 21:34:00,677][main.py][line:101][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.0222 loss2:0.5251 loss3:0.0071 | AUC:0.8472 Anomaly AUC:0.6976
[2023-08-26 21:35:26,705][main.py][line:101][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.0246 loss2:0.4537 loss3:0.0079 | AUC:0.8078 Anomaly AUC:0.6991
[2023-08-26 21:36:29,758][main.py][line:101][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.0184 loss2:0.3736 loss3:0.0068 | AUC:0.8350 Anomaly AUC:0.6601
[2023-08-26 21:37:45,972][main.py][line:101][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0161 loss2:0.2963 loss3:0.0066 | AUC:0.8275 Anomaly AUC:0.6512
[2023-08-26 21:38:37,967][main.py][line:101][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0302 loss2:0.2674 loss3:0.0097 | AUC:0.8339 Anomaly AUC:0.6701
[2023-08-26 21:39:29,981][main.py][line:101][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0097 loss2:0.1757 loss3:0.0039 | AUC:0.8343 Anomaly AUC:0.6590
[2023-08-26 21:40:42,996][main.py][line:101][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0162 loss2:0.1349 loss3:0.0047 | AUC:0.8250 Anomaly AUC:0.6457
[2023-08-26 21:41:39,356][main.py][line:101][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0125 loss2:0.0971 loss3:0.0043 | AUC:0.8129 Anomaly AUC:0.6227
[2023-08-26 21:42:44,363][main.py][line:101][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0064 loss2:0.0622 loss3:0.0030 | AUC:0.8274 Anomaly AUC:0.5999
[2023-08-26 21:43:40,369][main.py][line:101][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0130 loss2:0.0570 loss3:0.0038 | AUC:0.8169 Anomaly AUC:0.5995
[2023-08-26 21:44:30,496][main.py][line:101][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0044 loss2:0.0343 loss3:0.0020 | AUC:0.8352 Anomaly AUC:0.6216
[2023-08-26 21:45:49,123][main.py][line:101][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0048 loss2:0.0282 loss3:0.0022 | AUC:0.8250 Anomaly AUC:0.6086
[2023-08-26 21:46:45,862][main.py][line:101][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0068 loss2:0.0202 loss3:0.0034 | AUC:0.8257 Anomaly AUC:0.6300
[2023-08-26 21:48:09,069][main.py][line:101][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0077 loss2:0.0391 loss3:0.0037 | AUC:0.8421 Anomaly AUC:0.6473
[2023-08-26 21:49:20,775][main.py][line:101][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0230 loss2:0.0684 loss3:0.0076 | AUC:0.8066 Anomaly AUC:0.5968
[2023-08-26 21:50:04,512][main.py][line:101][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0121 loss2:0.0518 loss3:0.0050 | AUC:0.8119 Anomaly AUC:0.6261
[2023-08-26 21:50:52,579][main.py][line:101][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0056 loss2:0.0228 loss3:0.0024 | AUC:0.8075 Anomaly AUC:0.6232
[2023-08-26 21:51:59,936][main.py][line:101][INFO] [Epoch:23/100]: lr:0.00080 | loss1:0.0248 loss2:0.0642 loss3:0.0086 | AUC:0.8056 Anomaly AUC:0.5847
[2023-08-26 21:53:02,763][main.py][line:101][INFO] [Epoch:24/100]: lr:0.00080 | loss1:0.0056 loss2:0.0219 loss3:0.0025 | AUC:0.8056 Anomaly AUC:0.5896
[2023-08-26 21:54:19,548][main.py][line:101][INFO] [Epoch:25/100]: lr:0.00080 | loss1:0.0060 loss2:0.0206 loss3:0.0024 | AUC:0.8056 Anomaly AUC:0.6010
[2023-08-26 21:55:24,885][main.py][line:101][INFO] [Epoch:26/100]: lr:0.00080 | loss1:0.0091 loss2:0.0312 loss3:0.0043 | AUC:0.8084 Anomaly AUC:0.6099
[2023-08-26 21:55:32,020][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 21:55:32,165][main.py][line:152][INFO] total params:7.5707M
[2023-08-26 21:55:32,165][main.py][line:161][INFO] Test Mode
[2023-08-26 21:55:32,165][main.py][line:34][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-26 21:55:40,455][infer.py][line:47][INFO] offline AUC:0.8663 AP:0.3465 FAR:0.0325 | Complete in 0m 8s

[2023-08-26 21:56:49,473][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 21:56:49,609][main.py][line:152][INFO] total params:9.6689M
[2023-08-26 21:56:49,609][main.py][line:161][INFO] Test Mode
[2023-08-26 21:56:49,609][main.py][line:34][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-26 21:56:53,263][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 21:56:53,384][main.py][line:152][INFO] total params:9.6689M
[2023-08-26 21:56:53,384][main.py][line:155][INFO] Training Mode
[2023-08-26 21:56:53,384][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 21:56:53,385][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 21:57:00,864][main.py][line:77][INFO] Random initialize AUCAUC:0.4668 Anomaly AUC:0.48475
[2023-08-26 21:57:48,876][main.py][line:101][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.3825 loss2:1.1156 loss3:0.2396 | AUC:0.8141 Anomaly AUC:0.6220
[2023-08-26 21:58:28,605][main.py][line:101][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.1878 loss2:0.9072 loss3:0.0580 | AUC:0.8505 Anomaly AUC:0.6714
[2023-08-26 21:59:17,373][main.py][line:101][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.0986 loss2:0.8039 loss3:0.0320 | AUC:0.8322 Anomaly AUC:0.6638
[2023-08-26 21:59:57,898][main.py][line:101][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.0501 loss2:0.7232 loss3:0.0202 | AUC:0.8195 Anomaly AUC:0.6816
[2023-08-26 22:00:52,241][main.py][line:101][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.0515 loss2:0.6654 loss3:0.0145 | AUC:0.8267 Anomaly AUC:0.6594
[2023-08-26 22:02:11,015][main.py][line:101][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.0200 loss2:0.5811 loss3:0.0072 | AUC:0.8127 Anomaly AUC:0.6343
[2023-08-26 22:03:30,499][main.py][line:101][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.0271 loss2:0.5241 loss3:0.0081 | AUC:0.8199 Anomaly AUC:0.6419
[2023-08-26 22:04:27,520][main.py][line:101][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.0249 loss2:0.4674 loss3:0.0068 | AUC:0.8423 Anomaly AUC:0.6674
[2023-08-26 22:05:20,044][main.py][line:101][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0064 loss2:0.3739 loss3:0.0028 | AUC:0.8396 Anomaly AUC:0.6617
[2023-08-26 22:06:42,441][main.py][line:101][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0232 loss2:0.3412 loss3:0.0058 | AUC:0.8223 Anomaly AUC:0.6398
[2023-08-26 22:07:52,263][main.py][line:101][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0190 loss2:0.2676 loss3:0.0049 | AUC:0.8459 Anomaly AUC:0.6574
[2023-08-26 22:08:47,148][main.py][line:101][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0141 loss2:0.2110 loss3:0.0041 | AUC:0.8305 Anomaly AUC:0.6378
[2023-08-26 22:09:39,312][main.py][line:101][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0147 loss2:0.1991 loss3:0.0041 | AUC:0.8509 Anomaly AUC:0.6718
[2023-08-26 22:10:49,227][main.py][line:101][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0126 loss2:0.1418 loss3:0.0033 | AUC:0.8179 Anomaly AUC:0.6341
[2023-08-26 22:11:35,886][main.py][line:101][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0165 loss2:0.1201 loss3:0.0039 | AUC:0.8220 Anomaly AUC:0.6385
[2023-08-26 22:12:49,972][main.py][line:101][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0150 loss2:0.1361 loss3:0.0041 | AUC:0.8275 Anomaly AUC:0.6190
[2023-08-26 22:13:54,599][main.py][line:101][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0134 loss2:0.0836 loss3:0.0035 | AUC:0.8208 Anomaly AUC:0.6337
[2023-08-26 22:14:52,471][main.py][line:101][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0136 loss2:0.0858 loss3:0.0036 | AUC:0.8256 Anomaly AUC:0.6473
[2023-08-26 22:15:45,888][main.py][line:101][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0105 loss2:0.0857 loss3:0.0032 | AUC:0.8236 Anomaly AUC:0.6363
[2023-08-26 22:16:34,375][main.py][line:101][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0127 loss2:0.0725 loss3:0.0034 | AUC:0.8309 Anomaly AUC:0.6393
[2023-08-26 22:18:10,814][main.py][line:101][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0123 loss2:0.0577 loss3:0.0032 | AUC:0.8251 Anomaly AUC:0.6328
[2023-08-26 22:19:19,731][main.py][line:101][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0075 loss2:0.0336 loss3:0.0025 | AUC:0.8282 Anomaly AUC:0.6311
[2023-08-26 22:20:41,161][main.py][line:101][INFO] [Epoch:23/100]: lr:0.00080 | loss1:0.0134 loss2:0.0479 loss3:0.0030 | AUC:0.8374 Anomaly AUC:0.6459
[2023-08-26 22:21:33,929][main.py][line:101][INFO] [Epoch:24/100]: lr:0.00080 | loss1:0.0032 loss2:0.0334 loss3:0.0017 | AUC:0.8230 Anomaly AUC:0.6198
[2023-08-26 22:23:02,882][main.py][line:101][INFO] [Epoch:25/100]: lr:0.00080 | loss1:0.0228 loss2:0.0720 loss3:0.0056 | AUC:0.8321 Anomaly AUC:0.6425
[2023-08-26 22:23:43,982][main.py][line:101][INFO] [Epoch:26/100]: lr:0.00080 | loss1:0.0111 loss2:0.0625 loss3:0.0031 | AUC:0.8448 Anomaly AUC:0.6653
[2023-08-26 22:24:42,203][main.py][line:101][INFO] [Epoch:27/100]: lr:0.00080 | loss1:0.0129 loss2:0.0569 loss3:0.0032 | AUC:0.8330 Anomaly AUC:0.6594
[2023-08-26 22:25:33,001][main.py][line:101][INFO] [Epoch:28/100]: lr:0.00080 | loss1:0.0182 loss2:0.0556 loss3:0.0038 | AUC:0.8222 Anomaly AUC:0.6502
[2023-08-26 22:26:54,789][main.py][line:101][INFO] [Epoch:29/100]: lr:0.00080 | loss1:0.0062 loss2:0.0337 loss3:0.0017 | AUC:0.8128 Anomaly AUC:0.6307
[2023-08-26 22:27:54,479][main.py][line:101][INFO] [Epoch:30/100]: lr:0.00080 | loss1:0.0014 loss2:0.0109 loss3:0.0011 | AUC:0.8238 Anomaly AUC:0.6441
[2023-08-26 22:29:04,832][main.py][line:101][INFO] [Epoch:31/100]: lr:0.00080 | loss1:0.0042 loss2:0.0248 loss3:0.0017 | AUC:0.8183 Anomaly AUC:0.6230
[2023-08-26 22:30:10,275][main.py][line:101][INFO] [Epoch:32/100]: lr:0.00080 | loss1:0.0042 loss2:0.0163 loss3:0.0016 | AUC:0.8148 Anomaly AUC:0.6152
[2023-08-26 22:31:27,167][main.py][line:101][INFO] [Epoch:33/100]: lr:0.00080 | loss1:0.0078 loss2:0.0181 loss3:0.0021 | AUC:0.8212 Anomaly AUC:0.6128
[2023-08-26 22:32:46,104][main.py][line:101][INFO] [Epoch:34/100]: lr:0.00080 | loss1:0.0250 loss2:0.0862 loss3:0.0057 | AUC:0.7929 Anomaly AUC:0.5936
[2023-08-26 22:33:54,754][main.py][line:101][INFO] [Epoch:35/100]: lr:0.00080 | loss1:0.0239 loss2:0.0546 loss3:0.0049 | AUC:0.8076 Anomaly AUC:0.6152
[2023-08-26 22:34:52,196][main.py][line:101][INFO] [Epoch:36/100]: lr:0.00080 | loss1:0.0083 loss2:0.0299 loss3:0.0020 | AUC:0.7766 Anomaly AUC:0.5868
[2023-08-26 22:36:03,583][main.py][line:101][INFO] [Epoch:37/100]: lr:0.00080 | loss1:0.0112 loss2:0.0252 loss3:0.0030 | AUC:0.7924 Anomaly AUC:0.5941
[2023-08-26 22:36:55,351][main.py][line:101][INFO] [Epoch:38/100]: lr:0.00080 | loss1:0.0023 loss2:0.0065 loss3:0.0012 | AUC:0.8122 Anomaly AUC:0.6264
[2023-08-26 22:37:56,748][main.py][line:101][INFO] [Epoch:39/100]: lr:0.00080 | loss1:0.0018 loss2:0.0041 loss3:0.0011 | AUC:0.8451 Anomaly AUC:0.6495
[2023-08-26 22:39:05,918][main.py][line:101][INFO] [Epoch:40/100]: lr:0.00080 | loss1:0.0051 loss2:0.0132 loss3:0.0020 | AUC:0.7801 Anomaly AUC:0.5849
[2023-08-26 22:40:00,863][main.py][line:101][INFO] [Epoch:41/100]: lr:0.00080 | loss1:0.0027 loss2:0.0153 loss3:0.0015 | AUC:0.8315 Anomaly AUC:0.6488
[2023-08-26 22:40:43,176][main.py][line:101][INFO] [Epoch:42/100]: lr:0.00080 | loss1:0.0251 loss2:0.0563 loss3:0.0046 | AUC:0.7851 Anomaly AUC:0.6031
[2023-08-26 22:41:41,250][main.py][line:101][INFO] [Epoch:43/100]: lr:0.00080 | loss1:0.0200 loss2:0.0343 loss3:0.0032 | AUC:0.7884 Anomaly AUC:0.6209
[2023-08-26 22:42:39,425][main.py][line:101][INFO] [Epoch:44/100]: lr:0.00080 | loss1:0.0141 loss2:0.0478 loss3:0.0029 | AUC:0.7817 Anomaly AUC:0.6143
[2023-08-26 22:43:39,865][main.py][line:101][INFO] [Epoch:45/100]: lr:0.00080 | loss1:0.0179 loss2:0.0261 loss3:0.0046 | AUC:0.8063 Anomaly AUC:0.6298
[2023-08-26 22:44:28,554][main.py][line:101][INFO] [Epoch:46/100]: lr:0.00080 | loss1:0.0155 loss2:0.0297 loss3:0.0032 | AUC:0.7610 Anomaly AUC:0.5887
[2023-08-26 22:45:06,272][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 22:45:06,427][main.py][line:152][INFO] total params:9.6689M
[2023-08-26 22:45:06,427][main.py][line:155][INFO] Training Mode
[2023-08-26 22:45:06,427][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (cat): Linear(in_features=2048, out_features=1024, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 22:45:06,427][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 22:45:17,190][main.py][line:77][INFO] Random initialize AUCAUC:0.4508 Anomaly AUC:0.47965
[2023-08-26 22:46:32,533][main.py][line:101][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.3776 loss2:1.1169 loss3:0.2479 | AUC:0.8411 Anomaly AUC:0.6299
[2023-08-26 22:48:44,041][main.py][line:101][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.1606 loss2:0.8872 loss3:0.0553 | AUC:0.8203 Anomaly AUC:0.6360
[2023-08-26 22:49:39,812][main.py][line:101][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.0840 loss2:0.7896 loss3:0.0284 | AUC:0.8131 Anomaly AUC:0.6637
[2023-08-26 22:50:31,180][main.py][line:101][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.0432 loss2:0.7072 loss3:0.0130 | AUC:0.8006 Anomaly AUC:0.6438
[2023-08-26 22:52:45,856][main.py][line:101][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.0336 loss2:0.6371 loss3:0.0097 | AUC:0.8064 Anomaly AUC:0.6374
[2023-08-26 22:53:33,279][main.py][line:101][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.0242 loss2:0.5685 loss3:0.0072 | AUC:0.7989 Anomaly AUC:0.6410
[2023-08-26 22:54:28,727][main.py][line:101][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.0174 loss2:0.4900 loss3:0.0057 | AUC:0.8106 Anomaly AUC:0.6383
[2023-08-26 22:55:21,002][main.py][line:101][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.0172 loss2:0.4332 loss3:0.0053 | AUC:0.8125 Anomaly AUC:0.6594
[2023-08-26 22:57:06,892][main.py][line:101][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0231 loss2:0.3843 loss3:0.0057 | AUC:0.8278 Anomaly AUC:0.6502
[2023-08-26 22:58:31,388][main.py][line:101][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0246 loss2:0.3185 loss3:0.0069 | AUC:0.8270 Anomaly AUC:0.6584
[2023-08-26 23:00:14,882][main.py][line:101][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0104 loss2:0.2482 loss3:0.0045 | AUC:0.8324 Anomaly AUC:0.6475
[2023-08-26 23:01:53,129][main.py][line:101][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0107 loss2:0.1911 loss3:0.0040 | AUC:0.8259 Anomaly AUC:0.6517
[2023-08-26 23:02:58,026][main.py][line:101][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0111 loss2:0.1528 loss3:0.0037 | AUC:0.8422 Anomaly AUC:0.6565
[2023-08-26 23:04:43,331][main.py][line:101][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0045 loss2:0.1014 loss3:0.0025 | AUC:0.8429 Anomaly AUC:0.6573
[2023-08-26 23:06:19,502][main.py][line:101][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0103 loss2:0.0973 loss3:0.0041 | AUC:0.8448 Anomaly AUC:0.6692
[2023-08-26 23:07:54,154][main.py][line:101][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0147 loss2:0.0959 loss3:0.0044 | AUC:0.8398 Anomaly AUC:0.6556
[2023-08-26 23:08:58,585][main.py][line:101][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0145 loss2:0.0869 loss3:0.0040 | AUC:0.8294 Anomaly AUC:0.6359
[2023-08-26 23:10:12,294][main.py][line:101][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0122 loss2:0.0974 loss3:0.0039 | AUC:0.8377 Anomaly AUC:0.6739
[2023-08-26 23:11:38,893][main.py][line:101][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0087 loss2:0.0633 loss3:0.0030 | AUC:0.8210 Anomaly AUC:0.6275
[2023-08-26 23:12:53,206][main.py][line:101][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0031 loss2:0.0217 loss3:0.0016 | AUC:0.8263 Anomaly AUC:0.6450
[2023-08-26 23:14:38,004][main.py][line:101][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0097 loss2:0.0760 loss3:0.0033 | AUC:0.8136 Anomaly AUC:0.6204
[2023-08-26 23:15:53,227][main.py][line:101][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0069 loss2:0.0328 loss3:0.0023 | AUC:0.8359 Anomaly AUC:0.6483
[2023-08-26 23:16:07,663][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-26 23:16:07,804][main.py][line:152][INFO] total params:7.5810M
[2023-08-26 23:16:07,804][main.py][line:155][INFO] Training Mode
[2023-08-26 23:16:07,804][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-26 23:16:07,804][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-26 23:16:15,556][main.py][line:77][INFO] Random initialize AUCAUC:0.4992 Anomaly AUC:0.51600
[2023-08-26 23:16:52,649][main.py][line:101][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.3913 loss2:1.1524 loss3:0.2446 | AUC:0.8294 Anomaly AUC:0.6367
[2023-08-26 23:17:36,463][main.py][line:101][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.1777 loss2:0.8984 loss3:0.0686 | AUC:0.8369 Anomaly AUC:0.6549
[2023-08-26 23:18:08,635][main.py][line:101][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.0673 loss2:0.7765 loss3:0.0247 | AUC:0.8552 Anomaly AUC:0.6713
[2023-08-26 23:18:43,625][main.py][line:101][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.0467 loss2:0.7084 loss3:0.0153 | AUC:0.8241 Anomaly AUC:0.6695
[2023-08-26 23:19:34,553][main.py][line:101][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.0393 loss2:0.6502 loss3:0.0110 | AUC:0.8407 Anomaly AUC:0.6685
[2023-08-26 23:21:16,014][main.py][line:101][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.0237 loss2:0.5800 loss3:0.0076 | AUC:0.8265 Anomaly AUC:0.6752
[2023-08-26 23:22:12,963][main.py][line:101][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.0183 loss2:0.5002 loss3:0.0063 | AUC:0.8443 Anomaly AUC:0.6686
[2023-08-26 23:22:52,330][main.py][line:101][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.0232 loss2:0.4366 loss3:0.0073 | AUC:0.8417 Anomaly AUC:0.6819
[2023-08-26 23:23:40,934][main.py][line:101][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0138 loss2:0.3530 loss3:0.0051 | AUC:0.8566 Anomaly AUC:0.6959
[2023-08-26 23:25:10,518][main.py][line:101][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0099 loss2:0.2549 loss3:0.0037 | AUC:0.8528 Anomaly AUC:0.6863
[2023-08-26 23:26:26,654][main.py][line:101][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0107 loss2:0.1887 loss3:0.0043 | AUC:0.8474 Anomaly AUC:0.6912
[2023-08-26 23:27:51,491][main.py][line:101][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0177 loss2:0.1714 loss3:0.0060 | AUC:0.8489 Anomaly AUC:0.6603
[2023-08-26 23:29:05,133][main.py][line:101][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0116 loss2:0.1086 loss3:0.0042 | AUC:0.8322 Anomaly AUC:0.6230
[2023-08-26 23:30:24,888][main.py][line:101][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0174 loss2:0.1177 loss3:0.0064 | AUC:0.8365 Anomaly AUC:0.6477
[2023-08-26 23:31:41,093][main.py][line:101][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0199 loss2:0.0967 loss3:0.0056 | AUC:0.8287 Anomaly AUC:0.6438
[2023-08-26 23:32:57,166][main.py][line:101][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0075 loss2:0.0539 loss3:0.0027 | AUC:0.8345 Anomaly AUC:0.6487
[2023-08-26 23:34:08,404][main.py][line:101][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0045 loss2:0.0317 loss3:0.0019 | AUC:0.8378 Anomaly AUC:0.6509
[2023-08-26 23:35:07,072][main.py][line:101][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0025 loss2:0.0162 loss3:0.0011 | AUC:0.7935 Anomaly AUC:0.5909
[2023-08-26 23:36:15,868][main.py][line:101][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0122 loss2:0.0553 loss3:0.0044 | AUC:0.8166 Anomaly AUC:0.6169
[2023-08-26 23:37:01,263][main.py][line:101][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0139 loss2:0.0528 loss3:0.0046 | AUC:0.8292 Anomaly AUC:0.6414
[2023-08-26 23:37:59,659][main.py][line:101][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0123 loss2:0.0559 loss3:0.0048 | AUC:0.7950 Anomaly AUC:0.6058
[2023-08-26 23:39:08,680][main.py][line:101][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0088 loss2:0.0314 loss3:0.0034 | AUC:0.8402 Anomaly AUC:0.6616
[2023-08-26 23:40:20,614][main.py][line:101][INFO] [Epoch:23/100]: lr:0.00080 | loss1:0.0046 loss2:0.0198 loss3:0.0020 | AUC:0.8389 Anomaly AUC:0.6460
[2023-08-26 23:41:25,246][main.py][line:101][INFO] [Epoch:24/100]: lr:0.00080 | loss1:0.0002 loss2:0.0057 loss3:0.0008 | AUC:0.8391 Anomaly AUC:0.6565
[2023-08-26 23:42:55,588][main.py][line:101][INFO] [Epoch:25/100]: lr:0.00080 | loss1:0.0000 loss2:0.0033 loss3:0.0007 | AUC:0.8401 Anomaly AUC:0.6535
[2023-08-26 23:44:11,689][main.py][line:101][INFO] [Epoch:26/100]: lr:0.00080 | loss1:0.0000 loss2:0.0028 loss3:0.0007 | AUC:0.8424 Anomaly AUC:0.6570
[2023-08-26 23:45:05,950][main.py][line:101][INFO] [Epoch:27/100]: lr:0.00080 | loss1:0.0000 loss2:0.0028 loss3:0.0007 | AUC:0.8418 Anomaly AUC:0.6560
[2023-08-26 23:46:10,684][main.py][line:101][INFO] [Epoch:28/100]: lr:0.00080 | loss1:0.0000 loss2:0.0027 loss3:0.0008 | AUC:0.8416 Anomaly AUC:0.6543
[2023-08-26 23:47:03,552][main.py][line:101][INFO] [Epoch:29/100]: lr:0.00080 | loss1:0.0000 loss2:0.0026 loss3:0.0007 | AUC:0.8411 Anomaly AUC:0.6550
[2023-08-26 23:47:59,199][main.py][line:101][INFO] [Epoch:30/100]: lr:0.00080 | loss1:0.0000 loss2:0.0023 loss3:0.0007 | AUC:0.8401 Anomaly AUC:0.6506
[2023-08-26 23:48:56,177][main.py][line:101][INFO] [Epoch:31/100]: lr:0.00080 | loss1:0.0000 loss2:0.0023 loss3:0.0007 | AUC:0.8399 Anomaly AUC:0.6515
[2023-08-26 23:49:35,095][main.py][line:101][INFO] [Epoch:32/100]: lr:0.00080 | loss1:0.0000 loss2:0.0039 loss3:0.0008 | AUC:0.8386 Anomaly AUC:0.6498
[2023-08-26 23:50:22,428][main.py][line:101][INFO] [Epoch:33/100]: lr:0.00080 | loss1:0.0000 loss2:0.0044 loss3:0.0010 | AUC:0.8380 Anomaly AUC:0.6456
[2023-08-26 23:51:17,826][main.py][line:101][INFO] [Epoch:34/100]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.8371 Anomaly AUC:0.6430
[2023-08-26 23:52:31,632][main.py][line:101][INFO] [Epoch:35/100]: lr:0.00080 | loss1:0.0388 loss2:0.0528 loss3:0.0073 | AUC:0.7982 Anomaly AUC:0.5674
[2023-08-26 23:53:46,228][main.py][line:101][INFO] [Epoch:36/100]: lr:0.00080 | loss1:0.0688 loss2:0.2212 loss3:0.0228 | AUC:0.7959 Anomaly AUC:0.5816
[2023-08-26 23:54:39,597][main.py][line:101][INFO] [Epoch:37/100]: lr:0.00080 | loss1:0.0115 loss2:0.0484 loss3:0.0039 | AUC:0.8106 Anomaly AUC:0.5926
[2023-08-26 23:55:30,752][main.py][line:101][INFO] [Epoch:38/100]: lr:0.00080 | loss1:0.0075 loss2:0.0281 loss3:0.0031 | AUC:0.8199 Anomaly AUC:0.6222
[2023-08-26 23:56:25,107][main.py][line:101][INFO] [Epoch:39/100]: lr:0.00080 | loss1:0.0011 loss2:0.0097 loss3:0.0013 | AUC:0.8206 Anomaly AUC:0.6122
[2023-08-26 23:57:13,518][main.py][line:101][INFO] [Epoch:40/100]: lr:0.00080 | loss1:0.0002 loss2:0.0034 loss3:0.0007 | AUC:0.8188 Anomaly AUC:0.6019
[2023-08-26 23:58:38,700][main.py][line:101][INFO] [Epoch:41/100]: lr:0.00080 | loss1:0.0156 loss2:0.0402 loss3:0.0046 | AUC:0.8105 Anomaly AUC:0.5966
[2023-08-26 23:59:55,788][main.py][line:101][INFO] [Epoch:42/100]: lr:0.00080 | loss1:0.0225 loss2:0.0539 loss3:0.0059 | AUC:0.8160 Anomaly AUC:0.6085
[2023-08-27 00:00:41,006][main.py][line:101][INFO] [Epoch:43/100]: lr:0.00080 | loss1:0.0218 loss2:0.0604 loss3:0.0053 | AUC:0.8002 Anomaly AUC:0.5964
[2023-08-27 00:01:33,054][main.py][line:101][INFO] [Epoch:44/100]: lr:0.00080 | loss1:0.0084 loss2:0.0324 loss3:0.0027 | AUC:0.8258 Anomaly AUC:0.6048
[2023-08-27 00:02:32,839][main.py][line:101][INFO] [Epoch:45/100]: lr:0.00080 | loss1:0.0007 loss2:0.0068 loss3:0.0008 | AUC:0.8201 Anomaly AUC:0.5917
[2023-08-27 00:03:49,747][main.py][line:101][INFO] [Epoch:46/100]: lr:0.00080 | loss1:0.0001 loss2:0.0027 loss3:0.0005 | AUC:0.8132 Anomaly AUC:0.5871
[2023-08-27 00:04:26,586][main.py][line:101][INFO] [Epoch:47/100]: lr:0.00080 | loss1:0.0000 loss2:0.0038 loss3:0.0005 | AUC:0.8095 Anomaly AUC:0.5838
[2023-08-27 00:05:15,109][main.py][line:101][INFO] [Epoch:48/100]: lr:0.00080 | loss1:0.0000 loss2:0.0019 loss3:0.0005 | AUC:0.8067 Anomaly AUC:0.5786
[2023-08-27 00:06:22,772][main.py][line:101][INFO] [Epoch:49/100]: lr:0.00080 | loss1:0.0000 loss2:0.0017 loss3:0.0005 | AUC:0.8067 Anomaly AUC:0.5771
[2023-08-27 00:07:16,995][main.py][line:101][INFO] [Epoch:50/100]: lr:0.00080 | loss1:0.0000 loss2:0.0017 loss3:0.0005 | AUC:0.8067 Anomaly AUC:0.5783
[2023-08-27 00:08:10,167][main.py][line:101][INFO] [Epoch:51/100]: lr:0.00080 | loss1:0.0000 loss2:0.0017 loss3:0.0005 | AUC:0.8046 Anomaly AUC:0.5722
[2023-08-27 00:09:12,781][main.py][line:101][INFO] [Epoch:52/100]: lr:0.00080 | loss1:0.0000 loss2:0.0017 loss3:0.0005 | AUC:0.8034 Anomaly AUC:0.5683
[2023-08-27 00:10:00,523][main.py][line:101][INFO] [Epoch:53/100]: lr:0.00080 | loss1:0.0000 loss2:0.0015 loss3:0.0005 | AUC:0.8062 Anomaly AUC:0.5753
[2023-08-27 00:10:46,249][main.py][line:101][INFO] [Epoch:54/100]: lr:0.00080 | loss1:0.0001 loss2:0.0017 loss3:0.0005 | AUC:0.7995 Anomaly AUC:0.5648
[2023-08-27 00:11:25,706][main.py][line:101][INFO] [Epoch:55/100]: lr:0.00080 | loss1:0.0179 loss2:0.0170 loss3:0.0027 | AUC:0.7727 Anomaly AUC:0.5622
[2023-08-27 00:12:26,096][main.py][line:101][INFO] [Epoch:56/100]: lr:0.00080 | loss1:0.0737 loss2:0.2216 loss3:0.0212 | AUC:0.8142 Anomaly AUC:0.6025
[2023-08-27 00:13:12,549][main.py][line:101][INFO] [Epoch:57/100]: lr:0.00080 | loss1:0.0162 loss2:0.0511 loss3:0.0047 | AUC:0.8138 Anomaly AUC:0.5932
[2023-08-27 00:13:48,000][main.py][line:101][INFO] [Epoch:58/100]: lr:0.00080 | loss1:0.0032 loss2:0.0133 loss3:0.0018 | AUC:0.7963 Anomaly AUC:0.5956
[2023-08-27 00:14:41,632][main.py][line:101][INFO] [Epoch:59/100]: lr:0.00080 | loss1:0.0088 loss2:0.0225 loss3:0.0030 | AUC:0.8133 Anomaly AUC:0.6012
[2023-08-27 00:15:55,288][main.py][line:101][INFO] [Epoch:60/100]: lr:0.00080 | loss1:0.0008 loss2:0.0059 loss3:0.0010 | AUC:0.8092 Anomaly AUC:0.6001
[2023-08-27 00:16:35,021][main.py][line:101][INFO] [Epoch:61/100]: lr:0.00080 | loss1:0.0000 loss2:0.0030 loss3:0.0006 | AUC:0.8122 Anomaly AUC:0.6028
[2023-08-27 00:17:19,306][main.py][line:101][INFO] [Epoch:62/100]: lr:0.00080 | loss1:0.0000 loss2:0.0021 loss3:0.0005 | AUC:0.8109 Anomaly AUC:0.6026
[2023-08-27 00:18:30,096][main.py][line:101][INFO] [Epoch:63/100]: lr:0.00080 | loss1:0.0000 loss2:0.0019 loss3:0.0005 | AUC:0.8121 Anomaly AUC:0.6049
[2023-08-27 00:19:29,713][main.py][line:101][INFO] [Epoch:64/100]: lr:0.00080 | loss1:0.0000 loss2:0.0017 loss3:0.0005 | AUC:0.8087 Anomaly AUC:0.5989
[2023-08-27 00:20:47,179][main.py][line:101][INFO] [Epoch:65/100]: lr:0.00080 | loss1:0.0000 loss2:0.0015 loss3:0.0005 | AUC:0.8086 Anomaly AUC:0.5988
[2023-08-27 00:21:38,202][main.py][line:101][INFO] [Epoch:66/100]: lr:0.00080 | loss1:0.0000 loss2:0.0021 loss3:0.0005 | AUC:0.7979 Anomaly AUC:0.5839
[2023-08-27 00:22:45,766][main.py][line:101][INFO] [Epoch:67/100]: lr:0.00080 | loss1:0.0000 loss2:0.0018 loss3:0.0005 | AUC:0.8028 Anomaly AUC:0.5898
[2023-08-27 00:23:27,801][main.py][line:101][INFO] [Epoch:68/100]: lr:0.00080 | loss1:0.0000 loss2:0.0018 loss3:0.0005 | AUC:0.7998 Anomaly AUC:0.5861
[2023-08-27 00:24:36,256][main.py][line:101][INFO] [Epoch:69/100]: lr:0.00080 | loss1:0.0000 loss2:0.0018 loss3:0.0005 | AUC:0.7987 Anomaly AUC:0.5868
[2023-08-27 00:25:50,866][main.py][line:101][INFO] [Epoch:70/100]: lr:0.00080 | loss1:0.0000 loss2:0.0015 loss3:0.0005 | AUC:0.8005 Anomaly AUC:0.5895
[2023-08-27 00:26:53,406][main.py][line:101][INFO] [Epoch:71/100]: lr:0.00080 | loss1:0.0000 loss2:0.0079 loss3:0.0008 | AUC:0.7934 Anomaly AUC:0.5873
[2023-08-27 00:27:50,340][main.py][line:101][INFO] [Epoch:72/100]: lr:0.00080 | loss1:0.0439 loss2:0.1394 loss3:0.0127 | AUC:0.8147 Anomaly AUC:0.5934
[2023-08-27 00:28:25,409][main.py][line:101][INFO] [Epoch:73/100]: lr:0.00080 | loss1:0.0261 loss2:0.0819 loss3:0.0063 | AUC:0.7863 Anomaly AUC:0.5810
[2023-08-27 00:29:27,683][main.py][line:101][INFO] [Epoch:74/100]: lr:0.00080 | loss1:0.0136 loss2:0.0323 loss3:0.0038 | AUC:0.7578 Anomaly AUC:0.5525
[2023-08-27 00:29:45,068][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 00:29:45,211][main.py][line:152][INFO] total params:7.5707M
[2023-08-27 00:29:45,211][main.py][line:155][INFO] Training Mode
[2023-08-27 00:29:45,211][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 00:29:45,211][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 00:29:54,278][main.py][line:77][INFO] Random initialize AUCAUC:0.4863 Anomaly AUC:0.49064
[2023-08-27 00:31:05,438][main.py][line:101][INFO] [Epoch:1/100]: lr:0.00080 | loss1:0.0604 loss2:0.9577 loss3:0.3791 | AUC:0.7920 Anomaly AUC:0.6329
[2023-08-27 00:32:16,069][main.py][line:101][INFO] [Epoch:2/100]: lr:0.00080 | loss1:0.0010 loss2:0.6109 loss3:0.3579 | AUC:0.7790 Anomaly AUC:0.6320
[2023-08-27 00:32:56,253][main.py][line:101][INFO] [Epoch:3/100]: lr:0.00080 | loss1:0.0005 loss2:0.4363 loss3:0.3455 | AUC:0.7937 Anomaly AUC:0.6336
[2023-08-27 00:33:58,746][main.py][line:101][INFO] [Epoch:4/100]: lr:0.00080 | loss1:0.0005 loss2:0.3033 loss3:0.3106 | AUC:0.7730 Anomaly AUC:0.6402
[2023-08-27 00:35:52,666][main.py][line:101][INFO] [Epoch:5/100]: lr:0.00080 | loss1:0.0012 loss2:0.2124 loss3:0.1711 | AUC:0.7944 Anomaly AUC:0.6497
[2023-08-27 00:37:13,369][main.py][line:101][INFO] [Epoch:6/100]: lr:0.00080 | loss1:0.0046 loss2:0.2259 loss3:0.1366 | AUC:0.8037 Anomaly AUC:0.6623
[2023-08-27 00:39:12,113][main.py][line:101][INFO] [Epoch:7/100]: lr:0.00080 | loss1:0.0007 loss2:0.1089 loss3:0.0959 | AUC:0.8043 Anomaly AUC:0.6463
[2023-08-27 00:41:25,717][main.py][line:101][INFO] [Epoch:8/100]: lr:0.00080 | loss1:0.1077 loss2:0.5364 loss3:0.2816 | AUC:0.7771 Anomaly AUC:0.6254
[2023-08-27 00:42:16,333][main.py][line:101][INFO] [Epoch:9/100]: lr:0.00080 | loss1:0.0032 loss2:0.3562 loss3:0.1286 | AUC:0.7893 Anomaly AUC:0.6439
[2023-08-27 00:44:20,731][main.py][line:101][INFO] [Epoch:10/100]: lr:0.00080 | loss1:0.0014 loss2:0.1774 loss3:0.0928 | AUC:0.7965 Anomaly AUC:0.6506
[2023-08-27 00:45:43,149][main.py][line:101][INFO] [Epoch:11/100]: lr:0.00080 | loss1:0.0009 loss2:0.1026 loss3:0.0799 | AUC:0.8003 Anomaly AUC:0.6388
[2023-08-27 00:48:00,804][main.py][line:101][INFO] [Epoch:12/100]: lr:0.00080 | loss1:0.0008 loss2:0.0665 loss3:0.0698 | AUC:0.8083 Anomaly AUC:0.6461
[2023-08-27 00:49:49,262][main.py][line:101][INFO] [Epoch:13/100]: lr:0.00080 | loss1:0.0007 loss2:0.0469 loss3:0.0633 | AUC:0.8187 Anomaly AUC:0.6519
[2023-08-27 00:50:49,345][main.py][line:101][INFO] [Epoch:14/100]: lr:0.00080 | loss1:0.0007 loss2:0.0367 loss3:0.0593 | AUC:0.8145 Anomaly AUC:0.6525
[2023-08-27 00:51:41,163][main.py][line:101][INFO] [Epoch:15/100]: lr:0.00080 | loss1:0.0006 loss2:0.0305 loss3:0.0564 | AUC:0.7885 Anomaly AUC:0.6171
[2023-08-27 00:53:00,481][main.py][line:101][INFO] [Epoch:16/100]: lr:0.00080 | loss1:0.0346 loss2:0.2454 loss3:0.1259 | AUC:0.7936 Anomaly AUC:0.6446
[2023-08-27 00:54:23,783][main.py][line:101][INFO] [Epoch:17/100]: lr:0.00080 | loss1:0.0028 loss2:0.1444 loss3:0.1032 | AUC:0.8088 Anomaly AUC:0.6666
[2023-08-27 00:55:57,294][main.py][line:101][INFO] [Epoch:18/100]: lr:0.00080 | loss1:0.0010 loss2:0.0571 loss3:0.0795 | AUC:0.8154 Anomaly AUC:0.6635
[2023-08-27 00:57:08,928][main.py][line:101][INFO] [Epoch:19/100]: lr:0.00080 | loss1:0.0009 loss2:0.0352 loss3:0.0672 | AUC:0.8095 Anomaly AUC:0.6551
[2023-08-27 00:58:35,085][main.py][line:101][INFO] [Epoch:20/100]: lr:0.00080 | loss1:0.0007 loss2:0.0236 loss3:0.0581 | AUC:0.8199 Anomaly AUC:0.6612
[2023-08-27 00:59:26,117][main.py][line:101][INFO] [Epoch:21/100]: lr:0.00080 | loss1:0.0008 loss2:0.0189 loss3:0.0535 | AUC:0.8152 Anomaly AUC:0.6554
[2023-08-27 01:00:40,436][main.py][line:101][INFO] [Epoch:22/100]: lr:0.00080 | loss1:0.0005 loss2:0.0140 loss3:0.0490 | AUC:0.8264 Anomaly AUC:0.6604
[2023-08-27 01:02:42,384][main.py][line:101][INFO] [Epoch:23/100]: lr:0.00080 | loss1:0.0004 loss2:0.0127 loss3:0.0449 | AUC:0.8289 Anomaly AUC:0.6620
[2023-08-27 01:04:06,010][main.py][line:101][INFO] [Epoch:24/100]: lr:0.00080 | loss1:0.0008 loss2:0.0322 loss3:0.0442 | AUC:0.8267 Anomaly AUC:0.6596
[2023-08-27 01:05:51,621][main.py][line:101][INFO] [Epoch:25/100]: lr:0.00080 | loss1:0.0010 loss2:0.0488 loss3:0.0468 | AUC:0.8259 Anomaly AUC:0.6647
[2023-08-27 01:07:42,099][main.py][line:101][INFO] [Epoch:26/100]: lr:0.00080 | loss1:0.0025 loss2:0.0535 loss3:0.0540 | AUC:0.8073 Anomaly AUC:0.6551
[2023-08-27 01:08:40,299][main.py][line:101][INFO] [Epoch:27/100]: lr:0.00080 | loss1:0.0006 loss2:0.0277 loss3:0.0548 | AUC:0.8119 Anomaly AUC:0.6439
[2023-08-27 01:09:38,660][main.py][line:101][INFO] [Epoch:28/100]: lr:0.00080 | loss1:0.0004 loss2:0.0130 loss3:0.0472 | AUC:0.8155 Anomaly AUC:0.6511
[2023-08-27 01:11:01,763][main.py][line:101][INFO] [Epoch:29/100]: lr:0.00080 | loss1:0.0036 loss2:0.0662 loss3:0.0749 | AUC:0.8044 Anomaly AUC:0.6503
[2023-08-27 01:12:19,867][main.py][line:101][INFO] [Epoch:30/100]: lr:0.00080 | loss1:0.0002 loss2:0.0317 loss3:0.0529 | AUC:0.8150 Anomaly AUC:0.6617
[2023-08-27 01:13:30,358][main.py][line:101][INFO] [Epoch:31/100]: lr:0.00080 | loss1:0.0002 loss2:0.0115 loss3:0.0454 | AUC:0.8222 Anomaly AUC:0.6648
[2023-08-27 01:14:32,132][main.py][line:101][INFO] [Epoch:32/100]: lr:0.00080 | loss1:0.0006 loss2:0.0116 loss3:0.0487 | AUC:0.8074 Anomaly AUC:0.6558
[2023-08-27 01:15:50,472][main.py][line:101][INFO] [Epoch:33/100]: lr:0.00080 | loss1:0.0797 loss2:0.1881 loss3:0.3238 | AUC:0.7902 Anomaly AUC:0.6255
[2023-08-27 01:17:36,398][main.py][line:101][INFO] [Epoch:34/100]: lr:0.00080 | loss1:0.0071 loss2:0.0452 loss3:0.1377 | AUC:0.7921 Anomaly AUC:0.6193
[2023-08-27 01:18:43,688][main.py][line:101][INFO] [Epoch:35/100]: lr:0.00080 | loss1:0.0020 loss2:0.0065 loss3:0.0827 | AUC:0.8122 Anomaly AUC:0.6389
[2023-08-27 01:19:35,685][main.py][line:101][INFO] [Epoch:36/100]: lr:0.00080 | loss1:0.0015 loss2:0.0691 loss3:0.0620 | AUC:0.8095 Anomaly AUC:0.6400
[2023-08-27 01:21:18,231][main.py][line:101][INFO] [Epoch:37/100]: lr:0.00080 | loss1:0.0026 loss2:0.0545 loss3:0.0601 | AUC:0.7894 Anomaly AUC:0.6349
[2023-08-27 01:22:17,911][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 01:22:18,056][main.py][line:152][INFO] total params:7.5707M
[2023-08-27 01:22:18,056][main.py][line:155][INFO] Training Mode
[2023-08-27 01:22:18,057][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 01:22:18,057][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0007
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 01:22:28,443][main.py][line:77][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-27 01:22:50,747][main-autotune.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 01:22:50,875][main-autotune.py][line:166][INFO] total params:7.5707M
[2023-08-27 01:22:50,875][main-autotune.py][line:169][INFO] Training Mode
[2023-08-27 01:23:36,089][main-autotune.py][line:106][INFO] [Epoch:1/100]: lr:0.00020 | loss1:0.3780 loss2:1.0682 loss3:0.3074 | AUC:0.8305 Anomaly AUC:0.6541
[2023-08-27 01:24:54,324][main-autotune.py][line:106][INFO] [Epoch:2/100]: lr:0.00020 | loss1:0.1508 loss2:0.8230 loss3:0.1638 | AUC:0.8232 Anomaly AUC:0.6762
[2023-08-27 01:25:59,873][main-autotune.py][line:106][INFO] [Epoch:3/100]: lr:0.00020 | loss1:0.0555 loss2:0.7092 loss3:0.0749 | AUC:0.8220 Anomaly AUC:0.6549
[2023-08-27 01:27:38,714][main-autotune.py][line:106][INFO] [Epoch:4/100]: lr:0.00020 | loss1:0.0390 loss2:0.6321 loss3:0.0385 | AUC:0.8230 Anomaly AUC:0.6535
[2023-08-27 01:29:43,371][main-autotune.py][line:106][INFO] [Epoch:5/100]: lr:0.00020 | loss1:0.0261 loss2:0.5525 loss3:0.0242 | AUC:0.8212 Anomaly AUC:0.6541
[2023-08-27 01:31:47,034][main-autotune.py][line:106][INFO] [Epoch:6/100]: lr:0.00020 | loss1:0.0087 loss2:0.4712 loss3:0.0159 | AUC:0.8563 Anomaly AUC:0.6901
[2023-08-27 01:34:03,768][main-autotune.py][line:106][INFO] [Epoch:7/100]: lr:0.00020 | loss1:0.0207 loss2:0.4320 loss3:0.0155 | AUC:0.8466 Anomaly AUC:0.6765
[2023-08-27 01:36:05,070][main-autotune.py][line:106][INFO] [Epoch:8/100]: lr:0.00020 | loss1:0.0042 loss2:0.3497 loss3:0.0083 | AUC:0.8465 Anomaly AUC:0.6827
[2023-08-27 01:37:46,199][main-autotune.py][line:106][INFO] [Epoch:9/100]: lr:0.00020 | loss1:0.0022 loss2:0.2964 loss3:0.0043 | AUC:0.8397 Anomaly AUC:0.6804
[2023-08-27 01:40:07,049][main-autotune.py][line:106][INFO] [Epoch:10/100]: lr:0.00020 | loss1:0.0007 loss2:0.2512 loss3:0.0029 | AUC:0.8438 Anomaly AUC:0.6854
[2023-08-27 01:42:00,195][main-autotune.py][line:106][INFO] [Epoch:11/100]: lr:0.00020 | loss1:0.0005 loss2:0.2127 loss3:0.0022 | AUC:0.8457 Anomaly AUC:0.6868
[2023-08-27 01:43:58,479][main-autotune.py][line:106][INFO] [Epoch:12/100]: lr:0.00020 | loss1:0.0004 loss2:0.1832 loss3:0.0020 | AUC:0.8472 Anomaly AUC:0.6874
[2023-08-27 01:45:50,637][main-autotune.py][line:106][INFO] [Epoch:13/100]: lr:0.00020 | loss1:0.0811 loss2:0.3031 loss3:0.0177 | AUC:0.8309 Anomaly AUC:0.6957
[2023-08-27 01:47:55,612][main-autotune.py][line:106][INFO] [Epoch:14/100]: lr:0.00020 | loss1:0.0144 loss2:0.2489 loss3:0.0065 | AUC:0.8366 Anomaly AUC:0.6715
[2023-08-27 01:49:49,733][main-autotune.py][line:106][INFO] [Epoch:15/100]: lr:0.00020 | loss1:0.0048 loss2:0.1699 loss3:0.0031 | AUC:0.8575 Anomaly AUC:0.7006
[2023-08-27 01:51:38,069][main-autotune.py][line:106][INFO] [Epoch:16/100]: lr:0.00020 | loss1:0.0012 loss2:0.1435 loss3:0.0022 | AUC:0.8523 Anomaly AUC:0.6907
[2023-08-27 01:53:45,620][main-autotune.py][line:106][INFO] [Epoch:17/100]: lr:0.00020 | loss1:0.0005 loss2:0.1234 loss3:0.0017 | AUC:0.8472 Anomaly AUC:0.6870
[2023-08-27 01:55:30,418][main-autotune.py][line:106][INFO] [Epoch:18/100]: lr:0.00020 | loss1:0.0004 loss2:0.1107 loss3:0.0015 | AUC:0.8503 Anomaly AUC:0.6876
[2023-08-27 01:57:19,818][main-autotune.py][line:106][INFO] [Epoch:19/100]: lr:0.00020 | loss1:0.0003 loss2:0.1006 loss3:0.0014 | AUC:0.8504 Anomaly AUC:0.6879
[2023-08-27 01:58:51,236][main-autotune.py][line:106][INFO] [Epoch:20/100]: lr:0.00020 | loss1:0.0003 loss2:0.0908 loss3:0.0014 | AUC:0.8501 Anomaly AUC:0.6855
[2023-08-27 02:00:41,816][main-autotune.py][line:106][INFO] [Epoch:21/100]: lr:0.00020 | loss1:0.0002 loss2:0.0832 loss3:0.0013 | AUC:0.8502 Anomaly AUC:0.6875
[2023-08-27 02:02:38,557][main-autotune.py][line:106][INFO] [Epoch:22/100]: lr:0.00020 | loss1:0.0002 loss2:0.0775 loss3:0.0012 | AUC:0.8510 Anomaly AUC:0.6873
[2023-08-27 02:04:08,552][main-autotune.py][line:106][INFO] [Epoch:23/100]: lr:0.00020 | loss1:0.0002 loss2:0.0709 loss3:0.0012 | AUC:0.8491 Anomaly AUC:0.6843
[2023-08-27 02:04:33,000][main-autotune.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 02:04:33,191][main-autotune.py][line:166][INFO] total params:7.5707M
[2023-08-27 02:04:33,191][main-autotune.py][line:169][INFO] Training Mode
[2023-08-27 02:05:14,063][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.3630 loss2:1.0876 loss3:0.2999 | AUC:0.8336 Anomaly AUC:0.6611
[2023-08-27 02:06:10,864][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.1245 loss2:0.8161 loss3:0.1392 | AUC:0.8205 Anomaly AUC:0.6795
[2023-08-27 02:06:57,331][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0508 loss2:0.6979 loss3:0.0609 | AUC:0.8333 Anomaly AUC:0.6800
[2023-08-27 02:07:39,702][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0302 loss2:0.5952 loss3:0.0338 | AUC:0.8137 Anomaly AUC:0.6608
[2023-08-27 02:08:44,216][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0154 loss2:0.4919 loss3:0.0226 | AUC:0.8221 Anomaly AUC:0.6738
[2023-08-27 02:10:02,114][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0179 loss2:0.4139 loss3:0.0205 | AUC:0.8458 Anomaly AUC:0.6801
[2023-08-27 02:11:18,937][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0204 loss2:0.3504 loss3:0.0207 | AUC:0.8147 Anomaly AUC:0.6874
[2023-08-27 02:12:07,551][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0073 loss2:0.2550 loss3:0.0144 | AUC:0.8533 Anomaly AUC:0.6917
[2023-08-27 02:12:53,735][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0094 loss2:0.2042 loss3:0.0137 | AUC:0.8429 Anomaly AUC:0.6802
[2023-08-27 02:13:44,763][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0118 loss2:0.1743 loss3:0.0136 | AUC:0.8527 Anomaly AUC:0.7039
[2023-08-27 02:14:27,251][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0167 loss2:0.1670 loss3:0.0155 | AUC:0.8339 Anomaly AUC:0.6932
[2023-08-27 02:15:13,554][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0022 loss2:0.0894 loss3:0.0091 | AUC:0.8262 Anomaly AUC:0.6814
[2023-08-27 02:16:11,224][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0002 loss2:0.0558 loss3:0.0055 | AUC:0.8304 Anomaly AUC:0.6810
[2023-08-27 02:17:21,629][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0002 loss2:0.0414 loss3:0.0025 | AUC:0.8324 Anomaly AUC:0.6814
[2023-08-27 02:18:34,194][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0001 loss2:0.0313 loss3:0.0009 | AUC:0.8329 Anomaly AUC:0.6817
[2023-08-27 02:18:34,221][main-autotune.py][line:114][INFO] Training completes in 14m 1s | best AUCAUC:0.8533 Anomaly AUC:0.6917

[2023-08-27 02:19:17,237][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.0612 loss2:0.3685 loss3:0.0362 | AUC:0.8454 Anomaly AUC:0.6786
[2023-08-27 02:19:54,159][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.0280 loss2:0.2013 loss3:0.0200 | AUC:0.8327 Anomaly AUC:0.6856
[2023-08-27 02:20:35,922][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0300 loss2:0.1530 loss3:0.0171 | AUC:0.8400 Anomaly AUC:0.6756
[2023-08-27 02:21:16,420][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0313 loss2:0.1148 loss3:0.0153 | AUC:0.8391 Anomaly AUC:0.6939
[2023-08-27 02:21:58,643][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0175 loss2:0.0790 loss3:0.0103 | AUC:0.8204 Anomaly AUC:0.6825
[2023-08-27 02:22:45,605][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0299 loss2:0.0942 loss3:0.0124 | AUC:0.8014 Anomaly AUC:0.6702
[2023-08-27 02:23:33,675][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0132 loss2:0.0583 loss3:0.0072 | AUC:0.8307 Anomaly AUC:0.6634
[2023-08-27 02:24:24,051][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0092 loss2:0.0349 loss3:0.0035 | AUC:0.8426 Anomaly AUC:0.6645
[2023-08-27 02:25:12,754][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0049 loss2:0.0226 loss3:0.0020 | AUC:0.8171 Anomaly AUC:0.6319
[2023-08-27 02:25:58,142][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0134 loss2:0.0360 loss3:0.0035 | AUC:0.8399 Anomaly AUC:0.6734
[2023-08-27 02:26:47,979][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0137 loss2:0.0365 loss3:0.0040 | AUC:0.8272 Anomaly AUC:0.6590
[2023-08-27 02:27:38,023][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0367 loss2:0.0603 loss3:0.0099 | AUC:0.8137 Anomaly AUC:0.6337
[2023-08-27 02:28:26,379][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0102 loss2:0.0318 loss3:0.0038 | AUC:0.8407 Anomaly AUC:0.6747
[2023-08-27 02:29:12,530][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0064 loss2:0.0233 loss3:0.0025 | AUC:0.8227 Anomaly AUC:0.6780
[2023-08-27 02:30:11,527][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0047 loss2:0.0141 loss3:0.0018 | AUC:0.8299 Anomaly AUC:0.6569
[2023-08-27 02:30:11,576][main-autotune.py][line:114][INFO] Training completes in 11m 37s | best AUCAUC:0.8454 Anomaly AUC:0.6786

[2023-08-27 02:30:50,734][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.0297 loss2:0.2072 loss3:0.0161 | AUC:0.8467 Anomaly AUC:0.6903
[2023-08-27 02:31:30,250][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.0130 loss2:0.1333 loss3:0.0082 | AUC:0.8455 Anomaly AUC:0.7137
[2023-08-27 02:32:26,160][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0097 loss2:0.1077 loss3:0.0034 | AUC:0.8408 Anomaly AUC:0.6768
[2023-08-27 02:33:03,389][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0154 loss2:0.1072 loss3:0.0042 | AUC:0.8460 Anomaly AUC:0.7000
[2023-08-27 02:33:50,306][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0092 loss2:0.0847 loss3:0.0025 | AUC:0.8427 Anomaly AUC:0.6552
[2023-08-27 02:34:45,452][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0081 loss2:0.0763 loss3:0.0023 | AUC:0.8493 Anomaly AUC:0.6828
[2023-08-27 02:35:35,111][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0084 loss2:0.0693 loss3:0.0021 | AUC:0.8579 Anomaly AUC:0.6806
[2023-08-27 02:36:22,924][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0128 loss2:0.0764 loss3:0.0030 | AUC:0.8569 Anomaly AUC:0.6845
[2023-08-27 02:37:11,774][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0150 loss2:0.0712 loss3:0.0035 | AUC:0.8527 Anomaly AUC:0.6734
[2023-08-27 02:38:02,351][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0042 loss2:0.0562 loss3:0.0017 | AUC:0.8545 Anomaly AUC:0.6799
[2023-08-27 02:38:47,401][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0029 loss2:0.0440 loss3:0.0011 | AUC:0.8468 Anomaly AUC:0.6567
[2023-08-27 02:39:30,244][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0123 loss2:0.0596 loss3:0.0028 | AUC:0.8486 Anomaly AUC:0.6632
[2023-08-27 02:40:30,653][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0021 loss2:0.0424 loss3:0.0010 | AUC:0.8521 Anomaly AUC:0.6756
[2023-08-27 02:41:24,165][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0004 loss2:0.0331 loss3:0.0005 | AUC:0.8497 Anomaly AUC:0.6650
[2023-08-27 02:42:20,567][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0002 loss2:0.0299 loss3:0.0004 | AUC:0.8496 Anomaly AUC:0.6646
[2023-08-27 02:42:20,593][main-autotune.py][line:114][INFO] Training completes in 12m 9s | best AUCAUC:0.8579 Anomaly AUC:0.6806

[2023-08-27 02:43:04,474][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.0176 loss2:0.0714 loss3:0.0038 | AUC:0.8441 Anomaly AUC:0.6736
[2023-08-27 02:43:51,356][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0055 loss2:0.0485 loss3:0.0029 | AUC:0.8554 Anomaly AUC:0.6829
[2023-08-27 02:44:37,176][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0003 loss2:0.0216 loss3:0.0013 | AUC:0.8408 Anomaly AUC:0.6517
[2023-08-27 02:45:22,897][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0267 loss2:0.0624 loss3:0.0082 | AUC:0.8467 Anomaly AUC:0.6740
[2023-08-27 02:46:09,386][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0011 loss2:0.0210 loss3:0.0030 | AUC:0.8514 Anomaly AUC:0.6919
[2023-08-27 02:46:53,844][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0001 loss2:0.0094 loss3:0.0014 | AUC:0.8459 Anomaly AUC:0.6827
[2023-08-27 02:47:44,639][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0000 loss2:0.0067 loss3:0.0013 | AUC:0.8440 Anomaly AUC:0.6793
[2023-08-27 02:48:39,687][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0000 loss2:0.0053 loss3:0.0013 | AUC:0.8433 Anomaly AUC:0.6774
[2023-08-27 02:49:27,409][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0000 loss2:0.0043 loss3:0.0014 | AUC:0.8430 Anomaly AUC:0.6752
[2023-08-27 02:50:16,309][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0000 loss2:0.0037 loss3:0.0015 | AUC:0.8435 Anomaly AUC:0.6734
[2023-08-27 02:51:03,928][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0000 loss2:0.0033 loss3:0.0016 | AUC:0.8429 Anomaly AUC:0.6714
[2023-08-27 02:51:53,756][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0000 loss2:0.0030 loss3:0.0017 | AUC:0.8437 Anomaly AUC:0.6713
[2023-08-27 02:52:38,091][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0000 loss2:0.0026 loss3:0.0018 | AUC:0.8430 Anomaly AUC:0.6690
[2023-08-27 02:53:37,097][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0000 loss2:0.0023 loss3:0.0019 | AUC:0.8424 Anomaly AUC:0.6667
[2023-08-27 02:54:30,257][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0000 loss2:0.0021 loss3:0.0019 | AUC:0.8429 Anomaly AUC:0.6663
[2023-08-27 02:54:30,305][main-autotune.py][line:114][INFO] Training completes in 12m 10s | best AUCAUC:0.8554 Anomaly AUC:0.6829

[2023-08-27 02:55:11,120][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.0145 loss2:0.0621 loss3:0.0078 | AUC:0.8586 Anomaly AUC:0.7050
[2023-08-27 02:55:51,628][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0241 loss2:0.0702 loss3:0.0114 | AUC:0.8528 Anomaly AUC:0.7110
[2023-08-27 02:56:42,063][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0156 loss2:0.0461 loss3:0.0099 | AUC:0.8554 Anomaly AUC:0.7044
[2023-08-27 02:57:30,288][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0185 loss2:0.0348 loss3:0.0095 | AUC:0.8539 Anomaly AUC:0.6846
[2023-08-27 02:58:25,506][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0151 loss2:0.0386 loss3:0.0109 | AUC:0.8514 Anomaly AUC:0.6658
[2023-08-27 02:59:15,227][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0085 loss2:0.0209 loss3:0.0079 | AUC:0.8499 Anomaly AUC:0.6810
[2023-08-27 02:59:59,770][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0130 loss2:0.0333 loss3:0.0097 | AUC:0.8489 Anomaly AUC:0.6657
[2023-08-27 03:00:43,992][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0064 loss2:0.0154 loss3:0.0070 | AUC:0.8379 Anomaly AUC:0.6870
[2023-08-27 03:01:45,395][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0245 loss2:0.0442 loss3:0.0141 | AUC:0.8524 Anomaly AUC:0.6799
[2023-08-27 03:02:41,230][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0056 loss2:0.0146 loss3:0.0073 | AUC:0.8586 Anomaly AUC:0.6972
[2023-08-27 03:03:34,625][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0039 loss2:0.0143 loss3:0.0068 | AUC:0.8689 Anomaly AUC:0.7100
[2023-08-27 03:04:28,161][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0034 | AUC:0.8661 Anomaly AUC:0.7058
[2023-08-27 03:05:09,028][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0020 | AUC:0.8649 Anomaly AUC:0.7024
[2023-08-27 03:05:55,930][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0020 | AUC:0.8643 Anomaly AUC:0.6993
[2023-08-27 03:06:38,958][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0021 | AUC:0.8637 Anomaly AUC:0.6968
[2023-08-27 03:06:38,983][main-autotune.py][line:114][INFO] Training completes in 12m 8s | best AUCAUC:0.8689 Anomaly AUC:0.7100

[2023-08-27 03:07:22,608][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.0020 loss2:0.0041 loss3:0.0052 | AUC:0.8486 Anomaly AUC:0.6783
[2023-08-27 03:08:03,776][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.0008 loss2:0.0036 loss3:0.0064 | AUC:0.8607 Anomaly AUC:0.6925
[2023-08-27 03:08:48,936][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0000 loss2:0.0014 loss3:0.0056 | AUC:0.8621 Anomaly AUC:0.6995
[2023-08-27 03:09:34,981][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0000 loss2:0.0003 loss3:0.0049 | AUC:0.8616 Anomaly AUC:0.6978
[2023-08-27 03:10:20,852][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0045 | AUC:0.8614 Anomaly AUC:0.6960
[2023-08-27 03:11:06,362][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0042 | AUC:0.8614 Anomaly AUC:0.6954
[2023-08-27 03:11:47,230][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0040 | AUC:0.8613 Anomaly AUC:0.6940
[2023-08-27 03:12:28,107][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0037 | AUC:0.8606 Anomaly AUC:0.6908
[2023-08-27 03:13:10,110][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0034 | AUC:0.8595 Anomaly AUC:0.6873
[2023-08-27 03:13:54,239][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0036 | AUC:0.8581 Anomaly AUC:0.6843
[2023-08-27 03:14:33,918][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0037 | AUC:0.8561 Anomaly AUC:0.6807
[2023-08-27 03:15:25,151][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0038 | AUC:0.8559 Anomaly AUC:0.6803
[2023-08-27 03:16:05,683][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0038 | AUC:0.8554 Anomaly AUC:0.6797
[2023-08-27 03:16:48,427][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0039 | AUC:0.8537 Anomaly AUC:0.6775
[2023-08-27 03:17:30,253][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0039 | AUC:0.8531 Anomaly AUC:0.6765
[2023-08-27 03:17:30,279][main-autotune.py][line:114][INFO] Training completes in 10m 51s | best AUCAUC:0.8621 Anomaly AUC:0.6995

[2023-08-27 03:18:15,111][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.0016 loss2:0.0039 loss3:0.0016 | AUC:0.8495 Anomaly AUC:0.6798
[2023-08-27 03:18:56,416][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0276 loss2:0.0230 loss3:0.0028 | AUC:0.8468 Anomaly AUC:0.6764
[2023-08-27 03:19:39,932][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0021 loss2:0.0034 loss3:0.0012 | AUC:0.8625 Anomaly AUC:0.7092
[2023-08-27 03:20:20,320][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.8600 Anomaly AUC:0.7009
[2023-08-27 03:21:01,499][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8592 Anomaly AUC:0.6989
[2023-08-27 03:21:44,102][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8583 Anomaly AUC:0.6966
[2023-08-27 03:22:30,053][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8574 Anomaly AUC:0.6942
[2023-08-27 03:23:13,630][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8568 Anomaly AUC:0.6926
[2023-08-27 03:23:56,951][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8562 Anomaly AUC:0.6910
[2023-08-27 03:24:43,486][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8549 Anomaly AUC:0.6866
[2023-08-27 03:25:23,562][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8552 Anomaly AUC:0.6863
[2023-08-27 03:26:08,057][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8567 Anomaly AUC:0.6867
[2023-08-27 03:26:52,713][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8530 Anomaly AUC:0.6819
[2023-08-27 03:27:37,011][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8515 Anomaly AUC:0.6776
[2023-08-27 03:28:20,571][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8501 Anomaly AUC:0.6770
[2023-08-27 03:28:20,617][main-autotune.py][line:114][INFO] Training completes in 10m 50s | best AUCAUC:0.8625 Anomaly AUC:0.7092

[2023-08-27 03:29:04,693][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.0048 loss2:0.0056 loss3:0.0016 | AUC:0.8535 Anomaly AUC:0.6794
[2023-08-27 03:29:46,748][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0091 loss2:0.0179 loss3:0.0024 | AUC:0.8626 Anomaly AUC:0.6891
[2023-08-27 03:30:26,842][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0042 loss2:0.0118 loss3:0.0016 | AUC:0.8548 Anomaly AUC:0.6732
[2023-08-27 03:31:09,579][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0031 loss2:0.0073 loss3:0.0012 | AUC:0.8487 Anomaly AUC:0.6866
[2023-08-27 03:31:47,865][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0047 loss2:0.0121 loss3:0.0019 | AUC:0.8205 Anomaly AUC:0.6453
[2023-08-27 03:32:37,815][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0001 loss2:0.0039 loss3:0.0008 | AUC:0.8470 Anomaly AUC:0.6681
[2023-08-27 03:33:22,871][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0008 loss2:0.0042 loss3:0.0008 | AUC:0.8422 Anomaly AUC:0.6529
[2023-08-27 03:34:06,253][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0212 loss2:0.0376 loss3:0.0049 | AUC:0.8318 Anomaly AUC:0.6349
[2023-08-27 03:34:54,161][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0057 loss2:0.0164 loss3:0.0023 | AUC:0.8452 Anomaly AUC:0.6441
[2023-08-27 03:35:41,206][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0038 loss2:0.0103 loss3:0.0012 | AUC:0.8385 Anomaly AUC:0.6505
[2023-08-27 03:36:51,468][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0045 loss2:0.0097 loss3:0.0021 | AUC:0.8321 Anomaly AUC:0.6325
[2023-08-27 03:38:06,769][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0000 loss2:0.0012 loss3:0.0007 | AUC:0.8343 Anomaly AUC:0.6328
[2023-08-27 03:38:55,222][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0000 loss2:0.0005 loss3:0.0006 | AUC:0.8353 Anomaly AUC:0.6329
[2023-08-27 03:39:51,671][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0000 loss2:0.0001 loss3:0.0006 | AUC:0.8362 Anomaly AUC:0.6341
[2023-08-27 03:40:46,967][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.8375 Anomaly AUC:0.6366
[2023-08-27 03:40:46,993][main-autotune.py][line:114][INFO] Training completes in 12m 26s | best AUCAUC:0.8626 Anomaly AUC:0.6891

[2023-08-27 03:41:35,224][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.0108 loss2:0.0380 loss3:0.0024 | AUC:0.8476 Anomaly AUC:0.6665
[2023-08-27 03:42:15,389][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0038 loss2:0.0086 loss3:0.0010 | AUC:0.8472 Anomaly AUC:0.6592
[2023-08-27 03:42:59,735][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0004 loss2:0.0049 loss3:0.0005 | AUC:0.8461 Anomaly AUC:0.6542
[2023-08-27 03:43:44,568][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0000 loss2:0.0003 loss3:0.0003 | AUC:0.8457 Anomaly AUC:0.6532
[2023-08-27 03:44:27,784][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8439 Anomaly AUC:0.6490
[2023-08-27 03:45:10,911][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8419 Anomaly AUC:0.6447
[2023-08-27 03:45:49,225][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8407 Anomaly AUC:0.6451
[2023-08-27 03:46:28,967][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8389 Anomaly AUC:0.6422
[2023-08-27 03:47:11,569][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8386 Anomaly AUC:0.6463
[2023-08-27 03:47:52,852][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.1252 loss2:0.2578 loss3:0.0166 | AUC:0.8483 Anomaly AUC:0.6751
[2023-08-27 03:48:33,668][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0147 loss2:0.0882 loss3:0.0041 | AUC:0.8439 Anomaly AUC:0.6652
[2023-08-27 03:49:11,714][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0021 loss2:0.0198 loss3:0.0013 | AUC:0.8377 Anomaly AUC:0.6615
[2023-08-27 03:49:59,347][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0121 loss2:0.0458 loss3:0.0027 | AUC:0.8291 Anomaly AUC:0.6413
[2023-08-27 03:50:49,703][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0104 loss2:0.0408 loss3:0.0026 | AUC:0.8254 Anomaly AUC:0.6239
[2023-08-27 03:51:38,381][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0020 loss2:0.0110 loss3:0.0008 | AUC:0.8367 Anomaly AUC:0.6372
[2023-08-27 03:51:38,409][main-autotune.py][line:114][INFO] Training completes in 10m 51s | best AUCAUC:0.8483 Anomaly AUC:0.6751

[2023-08-27 03:52:20,217][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.0087 loss2:0.0429 loss3:0.0058 | AUC:0.8424 Anomaly AUC:0.6480
[2023-08-27 03:52:59,307][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.0260 loss2:0.0147 loss3:0.0028 | AUC:0.8308 Anomaly AUC:0.6259
[2023-08-27 03:53:41,515][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0182 loss2:0.0320 loss3:0.0038 | AUC:0.8335 Anomaly AUC:0.6433
[2023-08-27 03:54:29,211][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0072 loss2:0.0150 loss3:0.0023 | AUC:0.8390 Anomaly AUC:0.6465
[2023-08-27 03:55:08,465][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0076 loss2:0.0129 loss3:0.0022 | AUC:0.8487 Anomaly AUC:0.6873
[2023-08-27 03:55:54,962][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0069 loss2:0.0111 loss3:0.0024 | AUC:0.8069 Anomaly AUC:0.6267
[2023-08-27 03:56:42,352][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0017 loss2:0.0075 loss3:0.0013 | AUC:0.8330 Anomaly AUC:0.6551
[2023-08-27 03:57:28,634][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0108 loss2:0.0089 loss3:0.0016 | AUC:0.8364 Anomaly AUC:0.6668
[2023-08-27 03:58:13,904][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0065 loss2:0.0123 loss3:0.0020 | AUC:0.8369 Anomaly AUC:0.6537
[2023-08-27 03:58:55,212][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0036 loss2:0.0083 loss3:0.0013 | AUC:0.8257 Anomaly AUC:0.6641
[2023-08-27 03:59:36,967][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0065 loss2:0.0027 loss3:0.0005 | AUC:0.8252 Anomaly AUC:0.6617
[2023-08-27 04:00:26,135][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0000 loss2:0.0014 loss3:0.0003 | AUC:0.8279 Anomaly AUC:0.6627
[2023-08-27 04:01:27,551][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0000 loss2:0.0012 loss3:0.0003 | AUC:0.8308 Anomaly AUC:0.6580
[2023-08-27 04:02:07,436][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0000 loss2:0.0010 loss3:0.0003 | AUC:0.8307 Anomaly AUC:0.6542
[2023-08-27 04:02:51,691][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0000 loss2:0.0007 loss3:0.0003 | AUC:0.8305 Anomaly AUC:0.6500
[2023-08-27 04:02:51,719][main-autotune.py][line:114][INFO] Training completes in 11m 13s | best AUCAUC:0.8487 Anomaly AUC:0.6873

[2023-08-27 04:03:38,132][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00080 | loss1:0.0169 loss2:0.0482 loss3:0.0072 | AUC:0.8176 Anomaly AUC:0.6263
[2023-08-27 04:04:23,458][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00080 | loss1:0.0650 loss2:0.0631 loss3:0.0141 | AUC:0.8304 Anomaly AUC:0.6566
[2023-08-27 04:05:02,951][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00080 | loss1:0.0058 loss2:0.0129 loss3:0.0040 | AUC:0.8171 Anomaly AUC:0.6656
[2023-08-27 04:05:46,614][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00080 | loss1:0.0193 loss2:0.0239 loss3:0.0057 | AUC:0.8265 Anomaly AUC:0.6307
[2023-08-27 04:06:28,112][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00080 | loss1:0.0228 loss2:0.0195 loss3:0.0048 | AUC:0.8255 Anomaly AUC:0.6232
[2023-08-27 04:07:16,854][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00080 | loss1:0.0657 loss2:0.0355 loss3:0.0115 | AUC:0.8237 Anomaly AUC:0.6316
[2023-08-27 04:08:10,476][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00080 | loss1:0.0036 loss2:0.0104 loss3:0.0048 | AUC:0.8315 Anomaly AUC:0.6280
[2023-08-27 04:08:57,280][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00080 | loss1:0.0138 loss2:0.0204 loss3:0.0056 | AUC:0.8046 Anomaly AUC:0.6075
[2023-08-27 04:09:49,525][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00080 | loss1:0.0168 loss2:0.0178 loss3:0.0049 | AUC:0.8360 Anomaly AUC:0.6340
[2023-08-27 04:10:36,356][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00080 | loss1:0.0047 loss2:0.0122 loss3:0.0031 | AUC:0.8239 Anomaly AUC:0.6175
[2023-08-27 04:11:25,888][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00080 | loss1:0.0084 loss2:0.0079 loss3:0.0021 | AUC:0.8249 Anomaly AUC:0.6140
[2023-08-27 04:12:14,847][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00080 | loss1:0.0008 loss2:0.0029 loss3:0.0015 | AUC:0.8290 Anomaly AUC:0.6116
[2023-08-27 04:13:00,664][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00080 | loss1:0.0015 loss2:0.0028 loss3:0.0021 | AUC:0.8163 Anomaly AUC:0.6185
[2023-08-27 04:13:40,422][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00080 | loss1:0.0499 loss2:0.0699 loss3:0.0143 | AUC:0.8017 Anomaly AUC:0.5921
[2023-08-27 04:14:29,901][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00080 | loss1:0.0213 loss2:0.0261 loss3:0.0066 | AUC:0.8093 Anomaly AUC:0.6070
[2023-08-27 04:14:29,928][main-autotune.py][line:114][INFO] Training completes in 11m 38s | best AUCAUC:0.8360 Anomaly AUC:0.6340

[2023-08-27 04:15:13,953][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.0044 loss2:0.0094 loss3:0.0021 | AUC:0.7940 Anomaly AUC:0.6017
[2023-08-27 04:15:58,027][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.0054 loss2:0.0111 loss3:0.0019 | AUC:0.7758 Anomaly AUC:0.5860
[2023-08-27 04:16:47,964][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0042 loss2:0.0187 loss3:0.0023 | AUC:0.8227 Anomaly AUC:0.6235
[2023-08-27 04:17:30,838][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0081 loss2:0.0159 loss3:0.0028 | AUC:0.8068 Anomaly AUC:0.5747
[2023-08-27 04:18:15,456][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0011 loss2:0.0074 loss3:0.0013 | AUC:0.7941 Anomaly AUC:0.5727
[2023-08-27 04:19:01,493][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0016 loss2:0.0064 loss3:0.0012 | AUC:0.8068 Anomaly AUC:0.5708
[2023-08-27 04:19:45,382][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0017 loss2:0.0056 loss3:0.0015 | AUC:0.8038 Anomaly AUC:0.5651
[2023-08-27 04:20:31,433][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0050 loss2:0.0130 loss3:0.0024 | AUC:0.8161 Anomaly AUC:0.5822
[2023-08-27 04:21:23,671][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0004 loss2:0.0066 loss3:0.0013 | AUC:0.8161 Anomaly AUC:0.5793
[2023-08-27 04:22:05,231][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0000 loss2:0.0019 loss3:0.0008 | AUC:0.8174 Anomaly AUC:0.5824
[2023-08-27 04:22:50,760][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0000 loss2:0.0013 loss3:0.0007 | AUC:0.8185 Anomaly AUC:0.5841
[2023-08-27 04:23:40,069][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0000 loss2:0.0013 loss3:0.0008 | AUC:0.8195 Anomaly AUC:0.5873
[2023-08-27 04:24:32,234][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0000 loss2:0.0014 loss3:0.0007 | AUC:0.8187 Anomaly AUC:0.5856
[2023-08-27 04:25:17,331][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0000 loss2:0.0009 loss3:0.0007 | AUC:0.8191 Anomaly AUC:0.5880
[2023-08-27 04:26:01,306][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0000 loss2:0.0010 loss3:0.0008 | AUC:0.8170 Anomaly AUC:0.5839
[2023-08-27 04:26:01,356][main-autotune.py][line:114][INFO] Training completes in 11m 31s | best AUCAUC:0.8227 Anomaly AUC:0.6235

[2023-08-27 04:26:43,826][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.0087 loss2:0.0202 loss3:0.0025 | AUC:0.8204 Anomaly AUC:0.6106
[2023-08-27 04:27:24,652][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0080 loss2:0.0206 loss3:0.0025 | AUC:0.8118 Anomaly AUC:0.5881
[2023-08-27 04:28:10,151][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0034 loss2:0.0105 loss3:0.0012 | AUC:0.8115 Anomaly AUC:0.5933
[2023-08-27 04:28:54,073][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0057 loss2:0.0107 loss3:0.0017 | AUC:0.8111 Anomaly AUC:0.5768
[2023-08-27 04:29:36,972][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0288 loss2:0.0266 loss3:0.0031 | AUC:0.8215 Anomaly AUC:0.6157
[2023-08-27 04:30:20,746][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0151 loss2:0.0281 loss3:0.0026 | AUC:0.8289 Anomaly AUC:0.6199
[2023-08-27 04:31:05,290][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0033 loss2:0.0088 loss3:0.0013 | AUC:0.8220 Anomaly AUC:0.5924
[2023-08-27 04:31:52,228][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0004 loss2:0.0029 loss3:0.0005 | AUC:0.8284 Anomaly AUC:0.6080
[2023-08-27 04:32:39,896][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0000 loss2:0.0018 loss3:0.0004 | AUC:0.8299 Anomaly AUC:0.6100
[2023-08-27 04:33:22,092][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0000 loss2:0.0012 loss3:0.0004 | AUC:0.8281 Anomaly AUC:0.6075
[2023-08-27 04:34:10,023][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0000 loss2:0.0008 loss3:0.0004 | AUC:0.8275 Anomaly AUC:0.6071
[2023-08-27 04:35:02,530][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0000 loss2:0.0006 loss3:0.0004 | AUC:0.8264 Anomaly AUC:0.6046
[2023-08-27 04:35:57,992][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0000 loss2:0.0012 loss3:0.0004 | AUC:0.8233 Anomaly AUC:0.6003
[2023-08-27 04:36:44,746][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0000 loss2:0.0004 loss3:0.0004 | AUC:0.8214 Anomaly AUC:0.5975
[2023-08-27 04:37:29,813][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0000 loss2:0.0002 loss3:0.0004 | AUC:0.8183 Anomaly AUC:0.5914
[2023-08-27 04:37:29,841][main-autotune.py][line:114][INFO] Training completes in 11m 28s | best AUCAUC:0.8299 Anomaly AUC:0.6100

[2023-08-27 04:38:09,922][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.0049 loss2:0.0323 loss3:0.0013 | AUC:0.8189 Anomaly AUC:0.5925
[2023-08-27 04:38:59,293][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.0008 loss2:0.0218 loss3:0.0008 | AUC:0.7967 Anomaly AUC:0.5832
[2023-08-27 04:39:38,311][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0000 loss2:0.0084 loss3:0.0005 | AUC:0.7954 Anomaly AUC:0.5816
[2023-08-27 04:40:23,081][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0000 loss2:0.0050 loss3:0.0005 | AUC:0.8003 Anomaly AUC:0.5748
[2023-08-27 04:41:02,900][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0000 loss2:0.0016 loss3:0.0004 | AUC:0.7996 Anomaly AUC:0.5778
[2023-08-27 04:41:45,756][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0000 loss2:0.0003 loss3:0.0004 | AUC:0.7992 Anomaly AUC:0.5741
[2023-08-27 04:42:26,594][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7964 Anomaly AUC:0.5686
[2023-08-27 04:43:02,358][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7972 Anomaly AUC:0.5652
[2023-08-27 04:43:41,300][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7987 Anomaly AUC:0.5682
[2023-08-27 04:44:23,030][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.8113 Anomaly AUC:0.5700
[2023-08-27 04:45:06,926][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0773 loss2:0.6373 loss3:0.0082 | AUC:0.8112 Anomaly AUC:0.5722
[2023-08-27 04:45:51,528][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0093 loss2:0.5307 loss3:0.0024 | AUC:0.8201 Anomaly AUC:0.5832
[2023-08-27 04:46:36,292][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0021 loss2:0.3588 loss3:0.0012 | AUC:0.8134 Anomaly AUC:0.5737
[2023-08-27 04:47:26,430][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0036 loss2:0.2511 loss3:0.0013 | AUC:0.8159 Anomaly AUC:0.5692
[2023-08-27 04:48:09,170][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0025 loss2:0.1718 loss3:0.0011 | AUC:0.8121 Anomaly AUC:0.5720
[2023-08-27 04:48:09,198][main-autotune.py][line:114][INFO] Training completes in 10m 39s | best AUCAUC:0.8201 Anomaly AUC:0.5832

[2023-08-27 04:48:49,738][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.0077 loss2:0.0974 loss3:0.0067 | AUC:0.8091 Anomaly AUC:0.5752
[2023-08-27 04:49:30,152][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.0084 loss2:0.0227 loss3:0.0056 | AUC:0.8146 Anomaly AUC:0.5754
[2023-08-27 04:50:12,587][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0007 loss2:0.0047 loss3:0.0024 | AUC:0.8165 Anomaly AUC:0.5776
[2023-08-27 04:50:54,015][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0000 loss2:0.0023 loss3:0.0015 | AUC:0.8156 Anomaly AUC:0.5758
[2023-08-27 04:51:35,410][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0000 loss2:0.0019 loss3:0.0012 | AUC:0.8169 Anomaly AUC:0.5771
[2023-08-27 04:52:19,608][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0000 loss2:0.0011 loss3:0.0011 | AUC:0.8170 Anomaly AUC:0.5768
[2023-08-27 04:53:02,616][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0000 loss2:0.0012 loss3:0.0011 | AUC:0.8167 Anomaly AUC:0.5755
[2023-08-27 04:53:47,560][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0000 loss2:0.0008 loss3:0.0011 | AUC:0.8161 Anomaly AUC:0.5745
[2023-08-27 04:54:27,997][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0000 loss2:0.0010 loss3:0.0011 | AUC:0.8168 Anomaly AUC:0.5770
[2023-08-27 04:55:10,501][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0000 loss2:0.0008 loss3:0.0011 | AUC:0.8146 Anomaly AUC:0.5748
[2023-08-27 04:55:54,758][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0000 loss2:0.0005 loss3:0.0011 | AUC:0.8137 Anomaly AUC:0.5734
[2023-08-27 04:56:42,670][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0000 loss2:0.0002 loss3:0.0011 | AUC:0.8117 Anomaly AUC:0.5735
[2023-08-27 04:57:35,235][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0011 | AUC:0.8112 Anomaly AUC:0.5762
[2023-08-27 04:58:18,454][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0011 | AUC:0.8119 Anomaly AUC:0.5783
[2023-08-27 04:59:08,995][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0011 | AUC:0.8113 Anomaly AUC:0.5788
[2023-08-27 04:59:09,035][main-autotune.py][line:114][INFO] Training completes in 10m 60s | best AUCAUC:0.8170 Anomaly AUC:0.5768

[2023-08-27 04:59:54,897][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.0248 loss2:0.0739 loss3:0.0055 | AUC:0.8205 Anomaly AUC:0.5895
[2023-08-27 05:00:34,090][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.0114 loss2:0.0437 loss3:0.0041 | AUC:0.7970 Anomaly AUC:0.5502
[2023-08-27 05:01:13,444][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0261 loss2:0.0648 loss3:0.0061 | AUC:0.8120 Anomaly AUC:0.5708
[2023-08-27 05:01:54,716][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0033 loss2:0.0264 loss3:0.0024 | AUC:0.8114 Anomaly AUC:0.5774
[2023-08-27 05:02:41,999][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0195 loss2:0.0487 loss3:0.0055 | AUC:0.8213 Anomaly AUC:0.5804
[2023-08-27 05:03:22,853][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0025 loss2:0.0150 loss3:0.0015 | AUC:0.8161 Anomaly AUC:0.5675
[2023-08-27 05:04:07,800][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0161 loss2:0.0286 loss3:0.0030 | AUC:0.7897 Anomaly AUC:0.5598
[2023-08-27 05:04:50,894][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0076 loss2:0.0217 loss3:0.0030 | AUC:0.8077 Anomaly AUC:0.5673
[2023-08-27 05:05:34,467][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0062 loss2:0.0218 loss3:0.0026 | AUC:0.7972 Anomaly AUC:0.5547
[2023-08-27 05:06:19,496][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0015 loss2:0.0064 loss3:0.0010 | AUC:0.7980 Anomaly AUC:0.5570
[2023-08-27 05:07:05,107][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0004 loss2:0.0067 loss3:0.0008 | AUC:0.7982 Anomaly AUC:0.5574
[2023-08-27 05:07:47,270][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0000 loss2:0.0022 loss3:0.0006 | AUC:0.7982 Anomaly AUC:0.5666
[2023-08-27 05:08:35,173][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0000 loss2:0.0017 loss3:0.0006 | AUC:0.7947 Anomaly AUC:0.5621
[2023-08-27 05:09:16,342][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0000 loss2:0.0014 loss3:0.0006 | AUC:0.7879 Anomaly AUC:0.5656
[2023-08-27 05:09:59,227][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0000 loss2:0.0016 loss3:0.0006 | AUC:0.7848 Anomaly AUC:0.5658
[2023-08-27 05:09:59,254][main-autotune.py][line:114][INFO] Training completes in 10m 50s | best AUCAUC:0.8213 Anomaly AUC:0.5804

[2023-08-27 05:10:42,712][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.0045 loss2:0.0203 loss3:0.0048 | AUC:0.8104 Anomaly AUC:0.5769
[2023-08-27 05:11:22,403][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.0059 loss2:0.0173 loss3:0.0092 | AUC:0.8027 Anomaly AUC:0.5607
[2023-08-27 05:12:03,067][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0029 loss2:0.0070 loss3:0.0080 | AUC:0.8132 Anomaly AUC:0.5968
[2023-08-27 05:12:45,378][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0021 loss2:0.0048 loss3:0.0068 | AUC:0.7820 Anomaly AUC:0.5638
[2023-08-27 05:13:31,345][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0000 loss2:0.0013 loss3:0.0059 | AUC:0.7880 Anomaly AUC:0.5754
[2023-08-27 05:14:19,500][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0000 loss2:0.0013 loss3:0.0063 | AUC:0.7895 Anomaly AUC:0.5806
[2023-08-27 05:15:06,839][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0000 loss2:0.0012 loss3:0.0068 | AUC:0.7903 Anomaly AUC:0.5825
[2023-08-27 05:15:55,716][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0000 loss2:0.0009 loss3:0.0073 | AUC:0.7906 Anomaly AUC:0.5835
[2023-08-27 05:16:41,471][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0000 loss2:0.0006 loss3:0.0080 | AUC:0.7923 Anomaly AUC:0.5793
[2023-08-27 05:17:29,510][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0000 loss2:0.0003 loss3:0.0087 | AUC:0.7932 Anomaly AUC:0.5805
[2023-08-27 05:18:11,894][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0000 loss2:0.0005 loss3:0.0094 | AUC:0.7977 Anomaly AUC:0.5811
[2023-08-27 05:18:50,281][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0102 | AUC:0.8004 Anomaly AUC:0.5838
[2023-08-27 05:19:33,577][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0108 | AUC:0.8027 Anomaly AUC:0.5856
[2023-08-27 05:20:12,389][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0114 | AUC:0.8047 Anomaly AUC:0.5874
[2023-08-27 05:20:50,977][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0121 | AUC:0.8067 Anomaly AUC:0.5920
[2023-08-27 05:20:51,025][main-autotune.py][line:114][INFO] Training completes in 10m 52s | best AUCAUC:0.8132 Anomaly AUC:0.5968

[2023-08-27 05:21:32,620][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.0369 loss2:0.0361 loss3:0.0048 | AUC:0.7925 Anomaly AUC:0.5489
[2023-08-27 05:22:10,157][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0025 loss2:0.0101 loss3:0.0029 | AUC:0.7987 Anomaly AUC:0.5652
[2023-08-27 05:22:53,071][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0003 loss2:0.0035 loss3:0.0017 | AUC:0.8018 Anomaly AUC:0.5575
[2023-08-27 05:23:37,127][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0003 loss2:0.0018 loss3:0.0013 | AUC:0.7925 Anomaly AUC:0.5757
[2023-08-27 05:24:17,413][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0170 loss2:0.0314 loss3:0.0062 | AUC:0.7987 Anomaly AUC:0.5580
[2023-08-27 05:25:02,200][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0170 loss2:0.0239 loss3:0.0045 | AUC:0.7753 Anomaly AUC:0.5414
[2023-08-27 05:25:43,525][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0124 loss2:0.0301 loss3:0.0044 | AUC:0.7954 Anomaly AUC:0.5403
[2023-08-27 05:26:34,656][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0008 loss2:0.0044 loss3:0.0018 | AUC:0.8037 Anomaly AUC:0.5578
[2023-08-27 05:27:19,569][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0000 loss2:0.0019 loss3:0.0011 | AUC:0.8044 Anomaly AUC:0.5579
[2023-08-27 05:28:01,139][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0000 loss2:0.0016 loss3:0.0010 | AUC:0.8048 Anomaly AUC:0.5556
[2023-08-27 05:28:52,477][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0000 loss2:0.0013 loss3:0.0009 | AUC:0.8047 Anomaly AUC:0.5545
[2023-08-27 05:29:39,010][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0000 loss2:0.0014 loss3:0.0009 | AUC:0.8044 Anomaly AUC:0.5529
[2023-08-27 05:30:24,430][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0000 loss2:0.0014 loss3:0.0009 | AUC:0.8038 Anomaly AUC:0.5501
[2023-08-27 05:31:12,179][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0000 loss2:0.0012 loss3:0.0009 | AUC:0.8004 Anomaly AUC:0.5407
[2023-08-27 05:32:00,219][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0000 loss2:0.0014 loss3:0.0009 | AUC:0.8016 Anomaly AUC:0.5466
[2023-08-27 05:32:00,246][main-autotune.py][line:114][INFO] Training completes in 11m 9s | best AUCAUC:0.8048 Anomaly AUC:0.5556

[2023-08-27 05:32:44,585][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.0116 loss2:0.0280 loss3:0.0021 | AUC:0.7716 Anomaly AUC:0.5187
[2023-08-27 05:33:25,791][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0025 loss2:0.0056 loss3:0.0011 | AUC:0.7674 Anomaly AUC:0.5031
[2023-08-27 05:34:10,626][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0005 loss2:0.0031 loss3:0.0006 | AUC:0.8010 Anomaly AUC:0.5579
[2023-08-27 05:34:53,207][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0133 loss2:0.0135 loss3:0.0017 | AUC:0.7734 Anomaly AUC:0.4975
[2023-08-27 05:35:32,400][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0297 loss2:0.0330 loss3:0.0036 | AUC:0.7606 Anomaly AUC:0.5076
[2023-08-27 05:36:21,473][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0007 loss2:0.0069 loss3:0.0010 | AUC:0.7850 Anomaly AUC:0.5263
[2023-08-27 05:37:09,010][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0006 loss2:0.0042 loss3:0.0006 | AUC:0.7702 Anomaly AUC:0.5376
[2023-08-27 05:37:50,096][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0002 loss2:0.0026 loss3:0.0004 | AUC:0.7996 Anomaly AUC:0.5274
[2023-08-27 05:38:34,041][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0000 loss2:0.0004 loss3:0.0004 | AUC:0.8037 Anomaly AUC:0.5473
[2023-08-27 05:39:19,595][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8030 Anomaly AUC:0.5470
[2023-08-27 05:40:03,099][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8016 Anomaly AUC:0.5433
[2023-08-27 05:40:46,669][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8021 Anomaly AUC:0.5420
[2023-08-27 05:41:30,215][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8009 Anomaly AUC:0.5403
[2023-08-27 05:42:11,813][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.8027 Anomaly AUC:0.5388
[2023-08-27 05:42:48,589][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7994 Anomaly AUC:0.5388
[2023-08-27 05:42:48,639][main-autotune.py][line:114][INFO] Training completes in 10m 48s | best AUCAUC:0.8037 Anomaly AUC:0.5473

[2023-08-27 05:43:30,480][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.0099 loss2:0.0272 loss3:0.0051 | AUC:0.7794 Anomaly AUC:0.5225
[2023-08-27 05:44:11,471][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.0083 loss2:0.0223 loss3:0.0061 | AUC:0.8057 Anomaly AUC:0.5899
[2023-08-27 05:44:58,001][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0173 loss2:0.0289 loss3:0.0064 | AUC:0.7761 Anomaly AUC:0.5500
[2023-08-27 05:45:37,821][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0151 loss2:0.0212 loss3:0.0065 | AUC:0.7593 Anomaly AUC:0.5610
[2023-08-27 05:46:14,282][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0203 loss2:0.0348 loss3:0.0092 | AUC:0.7908 Anomaly AUC:0.5351
[2023-08-27 05:46:55,909][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0074 loss2:0.0152 loss3:0.0044 | AUC:0.7531 Anomaly AUC:0.4644
[2023-08-27 05:47:37,625][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0060 loss2:0.0120 loss3:0.0047 | AUC:0.7580 Anomaly AUC:0.4858
[2023-08-27 05:48:25,957][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0093 loss2:0.0199 loss3:0.0068 | AUC:0.7331 Anomaly AUC:0.4929
[2023-08-27 05:49:16,983][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0005 loss2:0.0046 loss3:0.0036 | AUC:0.7212 Anomaly AUC:0.4651
[2023-08-27 05:49:56,056][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0138 loss2:0.0137 loss3:0.0058 | AUC:0.7532 Anomaly AUC:0.5192
[2023-08-27 05:50:39,636][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0285 loss2:0.0479 loss3:0.0134 | AUC:0.7595 Anomaly AUC:0.4977
[2023-08-27 05:51:32,474][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0019 loss2:0.0080 loss3:0.0045 | AUC:0.6825 Anomaly AUC:0.4990
[2023-08-27 05:52:19,869][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0002 loss2:0.0022 loss3:0.0026 | AUC:0.7371 Anomaly AUC:0.4803
[2023-08-27 05:53:11,704][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0001 loss2:0.0011 loss3:0.0023 | AUC:0.7110 Anomaly AUC:0.4817
[2023-08-27 05:54:00,570][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0000 loss2:0.0003 loss3:0.0020 | AUC:0.7027 Anomaly AUC:0.4854
[2023-08-27 05:54:00,596][main-autotune.py][line:114][INFO] Training completes in 11m 12s | best AUCAUC:0.8057 Anomaly AUC:0.5899

[2023-08-27 05:54:40,841][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.0032 loss2:0.0194 loss3:0.0026 | AUC:0.7861 Anomaly AUC:0.5525
[2023-08-27 05:55:23,545][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.0001 loss2:0.0076 loss3:0.0009 | AUC:0.7956 Anomaly AUC:0.5600
[2023-08-27 05:56:05,488][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0000 loss2:0.0051 loss3:0.0006 | AUC:0.7986 Anomaly AUC:0.5636
[2023-08-27 05:56:44,810][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0000 loss2:0.0047 loss3:0.0005 | AUC:0.8080 Anomaly AUC:0.5729
[2023-08-27 05:57:28,562][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0000 loss2:0.0047 loss3:0.0005 | AUC:0.8137 Anomaly AUC:0.5749
[2023-08-27 05:58:19,285][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0000 loss2:0.0048 loss3:0.0005 | AUC:0.8149 Anomaly AUC:0.5747
[2023-08-27 05:59:05,082][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0000 loss2:0.0046 loss3:0.0005 | AUC:0.8060 Anomaly AUC:0.5551
[2023-08-27 05:59:46,130][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0000 loss2:0.0061 loss3:0.0005 | AUC:0.8052 Anomaly AUC:0.5634
[2023-08-27 06:00:30,087][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0000 loss2:0.0057 loss3:0.0005 | AUC:0.8018 Anomaly AUC:0.5637
[2023-08-27 06:01:18,479][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0000 loss2:0.0094 loss3:0.0005 | AUC:0.8111 Anomaly AUC:0.5750
[2023-08-27 06:02:10,837][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0000 loss2:0.0063 loss3:0.0005 | AUC:0.8017 Anomaly AUC:0.5581
[2023-08-27 06:02:53,814][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0000 loss2:0.0198 loss3:0.0005 | AUC:0.8069 Anomaly AUC:0.5698
[2023-08-27 06:03:42,215][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0000 loss2:0.0057 loss3:0.0005 | AUC:0.7980 Anomaly AUC:0.5721
[2023-08-27 06:04:29,083][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0629 loss2:0.1679 loss3:0.0047 | AUC:0.8066 Anomaly AUC:0.5629
[2023-08-27 06:05:13,726][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0275 loss2:0.5362 loss3:0.0061 | AUC:0.7998 Anomaly AUC:0.5503
[2023-08-27 06:05:13,772][main-autotune.py][line:114][INFO] Training completes in 11m 13s | best AUCAUC:0.8149 Anomaly AUC:0.5747

[2023-08-27 06:05:59,837][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.0217 loss2:0.0187 loss3:0.0020 | AUC:0.7972 Anomaly AUC:0.5456
[2023-08-27 06:06:40,375][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0019 loss2:0.0058 loss3:0.0010 | AUC:0.7649 Anomaly AUC:0.5310
[2023-08-27 06:07:22,707][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0001 loss2:0.0023 loss3:0.0006 | AUC:0.7876 Anomaly AUC:0.5501
[2023-08-27 06:08:09,101][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0000 loss2:0.0017 loss3:0.0005 | AUC:0.7845 Anomaly AUC:0.5553
[2023-08-27 06:08:50,378][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0000 loss2:0.0016 loss3:0.0005 | AUC:0.7815 Anomaly AUC:0.5507
[2023-08-27 06:09:35,836][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0000 loss2:0.0012 loss3:0.0004 | AUC:0.7777 Anomaly AUC:0.5530
[2023-08-27 06:10:21,932][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0000 loss2:0.0010 loss3:0.0004 | AUC:0.7777 Anomaly AUC:0.5535
[2023-08-27 06:11:04,170][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7798 Anomaly AUC:0.5563
[2023-08-27 06:11:53,513][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7932 Anomaly AUC:0.5786
[2023-08-27 06:12:33,370][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8027 Anomaly AUC:0.5901
[2023-08-27 06:13:15,365][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8000 Anomaly AUC:0.5618
[2023-08-27 06:14:00,069][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7981 Anomaly AUC:0.5612
[2023-08-27 06:14:40,805][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7964 Anomaly AUC:0.5596
[2023-08-27 06:15:27,926][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7959 Anomaly AUC:0.5577
[2023-08-27 06:16:10,342][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7949 Anomaly AUC:0.5554
[2023-08-27 06:16:10,369][main-autotune.py][line:114][INFO] Training completes in 10m 56s | best AUCAUC:0.8027 Anomaly AUC:0.5901

[2023-08-27 06:16:56,859][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.0033 loss2:0.0021 loss3:0.0008 | AUC:0.7441 Anomaly AUC:0.5331
[2023-08-27 06:17:40,300][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0001 loss2:0.0027 loss3:0.0005 | AUC:0.7404 Anomaly AUC:0.5558
[2023-08-27 06:18:22,300][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7489 Anomaly AUC:0.5483
[2023-08-27 06:19:02,131][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7317 Anomaly AUC:0.5424
[2023-08-27 06:19:44,873][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7209 Anomaly AUC:0.5276
[2023-08-27 06:20:25,428][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7308 Anomaly AUC:0.5228
[2023-08-27 06:21:05,528][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7351 Anomaly AUC:0.5240
[2023-08-27 06:21:48,278][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7385 Anomaly AUC:0.5248
[2023-08-27 06:22:28,789][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7467 Anomaly AUC:0.5274
[2023-08-27 06:23:06,656][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7480 Anomaly AUC:0.5215
[2023-08-27 06:23:49,056][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0535 loss2:0.0814 loss3:0.0066 | AUC:0.7691 Anomaly AUC:0.5629
[2023-08-27 06:24:32,596][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0205 loss2:0.0253 loss3:0.0044 | AUC:0.8135 Anomaly AUC:0.5701
[2023-08-27 06:25:19,470][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0034 loss2:0.0062 loss3:0.0019 | AUC:0.7434 Anomaly AUC:0.5707
[2023-08-27 06:26:02,054][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0234 loss2:0.0251 loss3:0.0028 | AUC:0.7495 Anomaly AUC:0.5663
[2023-08-27 06:26:44,276][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0004 loss2:0.0013 loss3:0.0010 | AUC:0.7309 Anomaly AUC:0.5690
[2023-08-27 06:26:44,302][main-autotune.py][line:114][INFO] Training completes in 10m 34s | best AUCAUC:0.8135 Anomaly AUC:0.5701

[2023-08-27 06:27:25,123][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.0265 loss2:0.0112 loss3:0.0025 | AUC:0.7818 Anomaly AUC:0.5290
[2023-08-27 06:28:03,033][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0305 loss2:0.0126 loss3:0.0032 | AUC:0.7681 Anomaly AUC:0.5162
[2023-08-27 06:28:44,824][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0013 loss2:0.0018 loss3:0.0011 | AUC:0.7674 Anomaly AUC:0.5240
[2023-08-27 06:29:30,842][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0001 loss2:0.0025 loss3:0.0007 | AUC:0.7563 Anomaly AUC:0.5356
[2023-08-27 06:30:16,092][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0001 loss2:0.0010 loss3:0.0006 | AUC:0.7739 Anomaly AUC:0.5125
[2023-08-27 06:30:57,676][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0000 loss2:0.0001 loss3:0.0005 | AUC:0.7705 Anomaly AUC:0.5094
[2023-08-27 06:31:41,474][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7899 Anomaly AUC:0.5258
[2023-08-27 06:32:19,753][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7778 Anomaly AUC:0.5155
[2023-08-27 06:33:00,354][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7748 Anomaly AUC:0.5125
[2023-08-27 06:33:40,477][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7795 Anomaly AUC:0.5177
[2023-08-27 06:34:22,385][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7791 Anomaly AUC:0.5169
[2023-08-27 06:35:04,825][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7761 Anomaly AUC:0.5131
[2023-08-27 06:35:48,543][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7808 Anomaly AUC:0.5110
[2023-08-27 06:36:29,037][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7835 Anomaly AUC:0.5169
[2023-08-27 06:37:13,088][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7900 Anomaly AUC:0.5208
[2023-08-27 06:37:13,108][main-autotune.py][line:114][INFO] Training completes in 10m 29s | best AUCAUC:0.7900 Anomaly AUC:0.5208

[2023-08-27 06:37:58,304][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00080 | loss1:0.0119 loss2:0.0286 loss3:0.0031 | AUC:0.7673 Anomaly AUC:0.5730
[2023-08-27 06:38:40,573][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00080 | loss1:0.0019 loss2:0.0020 loss3:0.0016 | AUC:0.7769 Anomaly AUC:0.5649
[2023-08-27 06:39:21,359][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00080 | loss1:0.0332 loss2:0.0491 loss3:0.0055 | AUC:0.7227 Anomaly AUC:0.5363
[2023-08-27 06:40:00,097][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00080 | loss1:0.0086 loss2:0.0181 loss3:0.0035 | AUC:0.7812 Anomaly AUC:0.5584
[2023-08-27 06:40:43,518][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00080 | loss1:0.0011 loss2:0.0019 loss3:0.0016 | AUC:0.7530 Anomaly AUC:0.5714
[2023-08-27 06:41:26,228][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00080 | loss1:0.0126 loss2:0.0083 loss3:0.0025 | AUC:0.7185 Anomaly AUC:0.5535
[2023-08-27 06:42:11,233][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00080 | loss1:0.0060 loss2:0.0122 loss3:0.0028 | AUC:0.7941 Anomaly AUC:0.5712
[2023-08-27 06:42:51,039][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00080 | loss1:0.0074 loss2:0.0341 loss3:0.0038 | AUC:0.7894 Anomaly AUC:0.5691
[2023-08-27 06:43:34,088][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00080 | loss1:0.0554 loss2:0.0329 loss3:0.0063 | AUC:0.7906 Anomaly AUC:0.5515
[2023-08-27 06:44:20,594][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00080 | loss1:0.0075 loss2:0.0178 loss3:0.0041 | AUC:0.7862 Anomaly AUC:0.5461
[2023-08-27 06:45:05,372][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00080 | loss1:0.0047 loss2:0.0097 loss3:0.0027 | AUC:0.7793 Anomaly AUC:0.5374
[2023-08-27 06:45:57,207][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00080 | loss1:0.0070 loss2:0.0154 loss3:0.0030 | AUC:0.7508 Anomaly AUC:0.5733
[2023-08-27 06:46:37,855][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00080 | loss1:0.0085 loss2:0.0088 loss3:0.0019 | AUC:0.7232 Anomaly AUC:0.5744
[2023-08-27 06:47:23,021][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00080 | loss1:0.0088 loss2:0.0070 loss3:0.0018 | AUC:0.7849 Anomaly AUC:0.6008
[2023-08-27 06:48:06,641][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00080 | loss1:0.0053 loss2:0.0102 loss3:0.0025 | AUC:0.7860 Anomaly AUC:0.5895
[2023-08-27 06:48:06,668][main-autotune.py][line:114][INFO] Training completes in 10m 53s | best AUCAUC:0.7941 Anomaly AUC:0.5712

[2023-08-27 06:48:52,328][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00080 | loss1:0.0152 loss2:0.0095 loss3:0.0022 | AUC:0.7555 Anomaly AUC:0.5828
[2023-08-27 06:49:35,969][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00080 | loss1:0.0001 loss2:0.0025 loss3:0.0008 | AUC:0.7752 Anomaly AUC:0.5934
[2023-08-27 06:50:16,256][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7668 Anomaly AUC:0.5887
[2023-08-27 06:50:52,943][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7590 Anomaly AUC:0.5847
[2023-08-27 06:51:36,936][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7444 Anomaly AUC:0.5773
[2023-08-27 06:52:20,773][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7572 Anomaly AUC:0.5855
[2023-08-27 06:53:06,373][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00080 | loss1:0.0000 loss2:0.0010 loss3:0.0005 | AUC:0.8143 Anomaly AUC:0.5759
[2023-08-27 06:53:50,584][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00080 | loss1:0.0518 loss2:0.0725 loss3:0.0056 | AUC:0.7895 Anomaly AUC:0.5926
[2023-08-27 06:54:40,109][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00080 | loss1:0.0592 loss2:0.0563 loss3:0.0060 | AUC:0.7800 Anomaly AUC:0.5516
[2023-08-27 06:55:31,792][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00080 | loss1:0.0182 loss2:0.0227 loss3:0.0034 | AUC:0.7917 Anomaly AUC:0.5893
[2023-08-27 06:56:14,258][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00080 | loss1:0.0314 loss2:0.0263 loss3:0.0033 | AUC:0.8127 Anomaly AUC:0.5955
[2023-08-27 06:57:05,191][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00080 | loss1:0.0169 loss2:0.0160 loss3:0.0030 | AUC:0.8089 Anomaly AUC:0.6046
[2023-08-27 06:57:46,776][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00080 | loss1:0.0061 loss2:0.0157 loss3:0.0022 | AUC:0.7935 Anomaly AUC:0.5676
[2023-08-27 06:58:28,117][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00080 | loss1:0.0001 loss2:0.0039 loss3:0.0007 | AUC:0.7743 Anomaly AUC:0.5791
[2023-08-27 06:59:08,307][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00080 | loss1:0.0012 loss2:0.0049 loss3:0.0008 | AUC:0.7569 Anomaly AUC:0.5604
[2023-08-27 06:59:08,335][main-autotune.py][line:114][INFO] Training completes in 11m 2s | best AUCAUC:0.8143 Anomaly AUC:0.5759

[2023-08-27 06:59:59,812][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.0059 loss2:0.0000 loss3:0.0013 | AUC:0.8076 Anomaly AUC:0.5695
[2023-08-27 07:00:42,595][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0002 loss2:0.0108 loss3:0.0011 | AUC:0.8026 Anomaly AUC:0.5626
[2023-08-27 07:01:20,944][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0059 loss2:0.0196 loss3:0.0019 | AUC:0.7879 Anomaly AUC:0.5594
[2023-08-27 07:02:07,787][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0065 loss2:0.0157 loss3:0.0024 | AUC:0.7492 Anomaly AUC:0.5092
[2023-08-27 07:02:50,009][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0091 loss2:0.0079 loss3:0.0019 | AUC:0.7651 Anomaly AUC:0.5217
[2023-08-27 07:03:38,564][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0006 loss2:0.0023 loss3:0.0013 | AUC:0.7892 Anomaly AUC:0.5439
[2023-08-27 07:04:22,284][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0010 | AUC:0.8097 Anomaly AUC:0.5718
[2023-08-27 07:05:18,249][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0009 | AUC:0.8094 Anomaly AUC:0.5700
[2023-08-27 07:05:59,602][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.8100 Anomaly AUC:0.5695
[2023-08-27 07:06:47,089][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.8137 Anomaly AUC:0.5712
[2023-08-27 07:07:27,132][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.8142 Anomaly AUC:0.5703
[2023-08-27 07:08:11,157][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.8143 Anomaly AUC:0.5674
[2023-08-27 07:09:00,352][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.8147 Anomaly AUC:0.5669
[2023-08-27 07:09:51,771][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.8150 Anomaly AUC:0.5666
[2023-08-27 07:10:35,454][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.8155 Anomaly AUC:0.5675
[2023-08-27 07:10:35,495][main-autotune.py][line:114][INFO] Training completes in 11m 27s | best AUCAUC:0.8155 Anomaly AUC:0.5675

[2023-08-27 07:11:22,862][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.0194 loss2:0.0218 loss3:0.0019 | AUC:0.6916 Anomaly AUC:0.5492
[2023-08-27 07:12:06,501][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0001 loss2:0.0021 loss3:0.0008 | AUC:0.7249 Anomaly AUC:0.5402
[2023-08-27 07:12:50,181][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0000 loss2:0.0010 loss3:0.0006 | AUC:0.7320 Anomaly AUC:0.5417
[2023-08-27 07:13:36,723][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7560 Anomaly AUC:0.5567
[2023-08-27 07:14:20,223][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7578 Anomaly AUC:0.5552
[2023-08-27 07:15:02,541][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7549 Anomaly AUC:0.5520
[2023-08-27 07:15:43,839][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7520 Anomaly AUC:0.5498
[2023-08-27 07:16:29,355][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7484 Anomaly AUC:0.5469
[2023-08-27 07:17:08,572][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8061 Anomaly AUC:0.5752
[2023-08-27 07:17:52,440][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8041 Anomaly AUC:0.5520
[2023-08-27 07:18:36,359][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8048 Anomaly AUC:0.5548
[2023-08-27 07:19:19,385][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.8052 Anomaly AUC:0.5569
[2023-08-27 07:20:02,476][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7965 Anomaly AUC:0.5353
[2023-08-27 07:20:42,903][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7963 Anomaly AUC:0.5357
[2023-08-27 07:21:24,674][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7969 Anomaly AUC:0.5367
[2023-08-27 07:21:24,700][main-autotune.py][line:114][INFO] Training completes in 10m 49s | best AUCAUC:0.8061 Anomaly AUC:0.5752

[2023-08-27 07:22:04,568][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.1414 loss2:0.0385 loss3:0.0067 | AUC:0.7586 Anomaly AUC:0.5579
[2023-08-27 07:22:48,159][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0174 loss2:0.0152 loss3:0.0040 | AUC:0.7709 Anomaly AUC:0.5475
[2023-08-27 07:23:34,049][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0625 loss2:0.0391 loss3:0.0080 | AUC:0.8037 Anomaly AUC:0.5503
[2023-08-27 07:24:15,022][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0019 loss2:0.0100 loss3:0.0049 | AUC:0.7833 Anomaly AUC:0.5369
[2023-08-27 07:25:02,773][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0037 loss2:0.0102 loss3:0.0042 | AUC:0.7733 Anomaly AUC:0.5755
[2023-08-27 07:25:46,039][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0015 loss2:0.0029 loss3:0.0032 | AUC:0.7752 Anomaly AUC:0.5461
[2023-08-27 07:26:34,967][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0323 loss2:0.0263 loss3:0.0056 | AUC:0.7669 Anomaly AUC:0.5172
[2023-08-27 07:27:23,450][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0295 loss2:0.0560 loss3:0.0102 | AUC:0.7975 Anomaly AUC:0.5395
[2023-08-27 07:28:08,323][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0286 loss2:0.0325 loss3:0.0095 | AUC:0.7690 Anomaly AUC:0.5722
[2023-08-27 07:28:51,791][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0280 loss2:0.0222 loss3:0.0075 | AUC:0.7942 Anomaly AUC:0.5629
[2023-08-27 07:29:33,507][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0020 loss2:0.0044 loss3:0.0037 | AUC:0.7567 Anomaly AUC:0.5698
[2023-08-27 07:30:16,875][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0004 loss2:0.0001 loss3:0.0024 | AUC:0.7484 Anomaly AUC:0.5569
[2023-08-27 07:31:00,959][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0002 loss2:0.0000 loss3:0.0021 | AUC:0.7945 Anomaly AUC:0.5557
[2023-08-27 07:31:45,798][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0019 | AUC:0.7894 Anomaly AUC:0.5483
[2023-08-27 07:32:32,417][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0000 loss2:0.0000 loss3:0.0017 | AUC:0.7859 Anomaly AUC:0.5458
[2023-08-27 07:32:32,453][main-autotune.py][line:114][INFO] Training completes in 11m 8s | best AUCAUC:0.8037 Anomaly AUC:0.5503

[2023-08-27 07:33:13,324][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.0026 loss2:0.0058 loss3:0.0041 | AUC:0.8159 Anomaly AUC:0.5892
[2023-08-27 07:33:52,333][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.0006 loss2:0.0002 loss3:0.0026 | AUC:0.8044 Anomaly AUC:0.5806
[2023-08-27 07:34:37,076][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0015 | AUC:0.8080 Anomaly AUC:0.5915
[2023-08-27 07:35:19,466][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0325 loss2:0.0118 loss3:0.0025 | AUC:0.7904 Anomaly AUC:0.5502
[2023-08-27 07:35:58,143][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0003 loss2:0.0033 loss3:0.0016 | AUC:0.7792 Anomaly AUC:0.5411
[2023-08-27 07:36:39,999][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0000 loss2:0.0001 loss3:0.0011 | AUC:0.7809 Anomaly AUC:0.5458
[2023-08-27 07:37:22,518][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0009 | AUC:0.7836 Anomaly AUC:0.5475
[2023-08-27 07:38:06,342][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.7827 Anomaly AUC:0.5475
[2023-08-27 07:38:51,447][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7821 Anomaly AUC:0.5486
[2023-08-27 07:39:33,787][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0001 loss2:0.0000 loss3:0.0007 | AUC:0.7753 Anomaly AUC:0.5406
[2023-08-27 07:40:19,881][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.7727 Anomaly AUC:0.5389
[2023-08-27 07:41:06,587][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.7699 Anomaly AUC:0.5372
[2023-08-27 07:41:49,055][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.7684 Anomaly AUC:0.5376
[2023-08-27 07:42:31,449][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7668 Anomaly AUC:0.5378
[2023-08-27 07:43:16,383][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0003 loss2:0.0000 loss3:0.0006 | AUC:0.7994 Anomaly AUC:0.5408
[2023-08-27 07:43:16,410][main-autotune.py][line:114][INFO] Training completes in 10m 44s | best AUCAUC:0.8159 Anomaly AUC:0.5892

[2023-08-27 07:44:02,691][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.0156 loss2:0.0248 loss3:0.0030 | AUC:0.7832 Anomaly AUC:0.5911
[2023-08-27 07:44:41,194][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.0033 loss2:0.0122 loss3:0.0020 | AUC:0.7845 Anomaly AUC:0.5210
[2023-08-27 07:45:22,623][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0080 loss2:0.0041 loss3:0.0014 | AUC:0.7947 Anomaly AUC:0.5538
[2023-08-27 07:46:06,571][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7934 Anomaly AUC:0.5580
[2023-08-27 07:46:49,300][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.7878 Anomaly AUC:0.5511
[2023-08-27 07:47:33,629][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7818 Anomaly AUC:0.5443
[2023-08-27 07:48:15,315][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0001 loss2:0.0000 loss3:0.0006 | AUC:0.7713 Anomaly AUC:0.5435
[2023-08-27 07:48:57,479][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7620 Anomaly AUC:0.5399
[2023-08-27 07:49:35,205][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0063 loss2:0.0000 loss3:0.0006 | AUC:0.7567 Anomaly AUC:0.5277
[2023-08-27 07:50:17,278][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.1141 loss2:0.1670 loss3:0.0136 | AUC:0.7859 Anomaly AUC:0.5389
[2023-08-27 07:50:59,783][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0277 loss2:0.1279 loss3:0.0072 | AUC:0.7758 Anomaly AUC:0.5076
[2023-08-27 07:51:38,827][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0429 loss2:0.0624 loss3:0.0050 | AUC:0.7007 Anomaly AUC:0.5273
[2023-08-27 07:52:23,419][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0107 loss2:0.0495 loss3:0.0026 | AUC:0.7535 Anomaly AUC:0.5743
[2023-08-27 07:53:04,008][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0099 loss2:0.0268 loss3:0.0018 | AUC:0.6820 Anomaly AUC:0.5302
[2023-08-27 07:53:51,553][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0112 loss2:0.0225 loss3:0.0019 | AUC:0.7229 Anomaly AUC:0.5169
[2023-08-27 07:53:51,580][main-autotune.py][line:114][INFO] Training completes in 10m 35s | best AUCAUC:0.7947 Anomaly AUC:0.5538

[2023-08-27 07:54:35,413][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.0025 loss2:0.0000 loss3:0.0015 | AUC:0.7679 Anomaly AUC:0.5524
[2023-08-27 07:55:15,291][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0013 | AUC:0.7678 Anomaly AUC:0.5464
[2023-08-27 07:55:52,867][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0014 | AUC:0.7671 Anomaly AUC:0.5440
[2023-08-27 07:56:33,639][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0017 | AUC:0.7687 Anomaly AUC:0.5440
[2023-08-27 07:57:18,800][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0020 | AUC:0.7678 Anomaly AUC:0.5409
[2023-08-27 07:58:01,377][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0025 | AUC:0.7726 Anomaly AUC:0.5173
[2023-08-27 07:58:47,457][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0029 | AUC:0.7746 Anomaly AUC:0.5193
[2023-08-27 07:59:28,971][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0035 | AUC:0.7766 Anomaly AUC:0.5217
[2023-08-27 08:00:03,580][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0041 | AUC:0.7836 Anomaly AUC:0.5299
[2023-08-27 08:00:46,235][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0047 | AUC:0.7996 Anomaly AUC:0.5479
[2023-08-27 08:01:27,557][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0053 | AUC:0.7985 Anomaly AUC:0.5457
[2023-08-27 08:02:14,787][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0059 | AUC:0.7970 Anomaly AUC:0.5364
[2023-08-27 08:02:59,373][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0066 | AUC:0.7986 Anomaly AUC:0.5369
[2023-08-27 08:03:39,585][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0070 | AUC:0.7990 Anomaly AUC:0.5367
[2023-08-27 08:04:21,429][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0074 | AUC:0.8004 Anomaly AUC:0.5373
[2023-08-27 08:04:21,467][main-autotune.py][line:114][INFO] Training completes in 10m 30s | best AUCAUC:0.8004 Anomaly AUC:0.5373

[2023-08-27 08:05:02,950][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.0112 loss2:0.0000 loss3:0.0062 | AUC:0.7903 Anomaly AUC:0.5284
[2023-08-27 08:05:43,156][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.0076 loss2:0.0056 loss3:0.0069 | AUC:0.8028 Anomaly AUC:0.5429
[2023-08-27 08:06:25,487][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0065 | AUC:0.8013 Anomaly AUC:0.5426
[2023-08-27 08:07:06,744][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0061 | AUC:0.8004 Anomaly AUC:0.5421
[2023-08-27 08:07:51,067][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0057 | AUC:0.8002 Anomaly AUC:0.5425
[2023-08-27 08:08:33,350][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0054 | AUC:0.8016 Anomaly AUC:0.5451
[2023-08-27 08:09:19,330][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0051 | AUC:0.8009 Anomaly AUC:0.5448
[2023-08-27 08:09:59,804][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0048 | AUC:0.8004 Anomaly AUC:0.5455
[2023-08-27 08:10:38,745][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0046 | AUC:0.8005 Anomaly AUC:0.5462
[2023-08-27 08:11:21,396][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0043 | AUC:0.8002 Anomaly AUC:0.5458
[2023-08-27 08:11:59,200][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0041 | AUC:0.7999 Anomaly AUC:0.5454
[2023-08-27 08:12:43,963][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0063 loss2:0.0000 loss3:0.0039 | AUC:0.7996 Anomaly AUC:0.5451
[2023-08-27 08:13:29,581][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0037 loss2:0.0103 loss3:0.0042 | AUC:0.7901 Anomaly AUC:0.5521
[2023-08-27 08:14:09,635][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0109 loss2:0.0501 loss3:0.0121 | AUC:0.7077 Anomaly AUC:0.5669
[2023-08-27 08:14:51,010][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0003 loss2:0.0037 loss3:0.0095 | AUC:0.5701 Anomaly AUC:0.5140
[2023-08-27 08:14:51,037][main-autotune.py][line:114][INFO] Training completes in 10m 29s | best AUCAUC:0.8028 Anomaly AUC:0.5429

[2023-08-27 08:15:33,325][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.0062 loss2:0.0234 loss3:0.0049 | AUC:0.6399 Anomaly AUC:0.5636
[2023-08-27 08:16:11,190][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0030 loss2:0.0102 loss3:0.0074 | AUC:0.7154 Anomaly AUC:0.5537
[2023-08-27 08:16:51,837][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0133 loss2:0.0013 loss3:0.0060 | AUC:0.6718 Anomaly AUC:0.5388
[2023-08-27 08:17:31,992][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0154 loss2:0.0259 loss3:0.0063 | AUC:0.6765 Anomaly AUC:0.5248
[2023-08-27 08:18:14,119][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0005 loss2:0.0000 loss3:0.0041 | AUC:0.6716 Anomaly AUC:0.5193
[2023-08-27 08:18:57,536][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0035 | AUC:0.6794 Anomaly AUC:0.5168
[2023-08-27 08:19:39,980][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0033 | AUC:0.6793 Anomaly AUC:0.5131
[2023-08-27 08:20:25,428][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0030 | AUC:0.6809 Anomaly AUC:0.5127
[2023-08-27 08:21:05,661][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0028 | AUC:0.6898 Anomaly AUC:0.5080
[2023-08-27 08:21:44,053][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0027 | AUC:0.6889 Anomaly AUC:0.5080
[2023-08-27 08:22:26,806][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0026 | AUC:0.6890 Anomaly AUC:0.5072
[2023-08-27 08:23:08,561][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0025 | AUC:0.6892 Anomaly AUC:0.5073
[2023-08-27 08:23:50,504][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0024 | AUC:0.6897 Anomaly AUC:0.5069
[2023-08-27 08:24:34,001][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0023 | AUC:0.6913 Anomaly AUC:0.5059
[2023-08-27 08:25:15,583][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0023 | AUC:0.6917 Anomaly AUC:0.5055
[2023-08-27 08:25:15,611][main-autotune.py][line:114][INFO] Training completes in 10m 24s | best AUCAUC:0.7154 Anomaly AUC:0.5537

[2023-08-27 08:26:01,664][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.0768 loss2:0.1087 loss3:0.0054 | AUC:0.7235 Anomaly AUC:0.5388
[2023-08-27 08:26:43,197][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.0104 loss2:0.0153 loss3:0.0040 | AUC:0.7297 Anomaly AUC:0.5201
[2023-08-27 08:27:23,649][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0014 loss2:0.0063 loss3:0.0028 | AUC:0.6900 Anomaly AUC:0.5191
[2023-08-27 08:27:59,501][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0112 loss2:0.0054 loss3:0.0026 | AUC:0.7425 Anomaly AUC:0.5291
[2023-08-27 08:28:41,016][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0359 loss2:0.0429 loss3:0.0063 | AUC:0.6984 Anomaly AUC:0.5293
[2023-08-27 08:29:28,799][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0206 loss2:0.0268 loss3:0.0043 | AUC:0.6815 Anomaly AUC:0.4985
[2023-08-27 08:30:12,496][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0075 loss2:0.0058 loss3:0.0031 | AUC:0.6563 Anomaly AUC:0.4889
[2023-08-27 08:30:52,594][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0003 loss2:0.0000 loss3:0.0021 | AUC:0.6855 Anomaly AUC:0.4914
[2023-08-27 08:31:33,294][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0263 loss2:0.0507 loss3:0.0067 | AUC:0.7153 Anomaly AUC:0.5195
[2023-08-27 08:32:15,447][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0026 loss2:0.0129 loss3:0.0035 | AUC:0.7047 Anomaly AUC:0.5120
[2023-08-27 08:32:54,448][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0024 | AUC:0.7071 Anomaly AUC:0.5073
[2023-08-27 08:33:34,176][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0019 | AUC:0.7246 Anomaly AUC:0.5062
[2023-08-27 08:34:13,957][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0001 loss2:0.0000 loss3:0.0017 | AUC:0.7335 Anomaly AUC:0.4998
[2023-08-27 08:34:52,473][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0001 loss2:0.0000 loss3:0.0016 | AUC:0.7908 Anomaly AUC:0.5175
[2023-08-27 08:35:42,142][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0000 loss2:0.0000 loss3:0.0015 | AUC:0.7927 Anomaly AUC:0.5211
[2023-08-27 08:35:42,162][main-autotune.py][line:114][INFO] Training completes in 10m 26s | best AUCAUC:0.7927 Anomaly AUC:0.5211

[2023-08-27 08:36:28,667][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.0072 loss2:0.0222 loss3:0.0022 | AUC:0.6360 Anomaly AUC:0.4977
[2023-08-27 08:37:09,868][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.0138 loss2:0.0101 loss3:0.0014 | AUC:0.6836 Anomaly AUC:0.4854
[2023-08-27 08:37:54,830][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0002 loss2:0.0059 loss3:0.0009 | AUC:0.6633 Anomaly AUC:0.4779
[2023-08-27 08:38:35,902][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0115 loss2:0.0204 loss3:0.0032 | AUC:0.7259 Anomaly AUC:0.5275
[2023-08-27 08:39:19,057][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0219 loss2:0.0148 loss3:0.0029 | AUC:0.6681 Anomaly AUC:0.4991
[2023-08-27 08:40:02,802][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0032 loss2:0.0020 loss3:0.0022 | AUC:0.6971 Anomaly AUC:0.5104
[2023-08-27 08:40:45,125][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0011 loss2:0.0000 loss3:0.0012 | AUC:0.7872 Anomaly AUC:0.5659
[2023-08-27 08:41:26,831][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0011 loss2:0.0094 loss3:0.0012 | AUC:0.7966 Anomaly AUC:0.5250
[2023-08-27 08:42:15,028][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0000 loss2:0.0008 loss3:0.0007 | AUC:0.7935 Anomaly AUC:0.5158
[2023-08-27 08:42:54,591][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.7925 Anomaly AUC:0.5161
[2023-08-27 08:43:39,419][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7915 Anomaly AUC:0.5154
[2023-08-27 08:44:25,690][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7907 Anomaly AUC:0.5153
[2023-08-27 08:45:11,947][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7903 Anomaly AUC:0.5153
[2023-08-27 08:45:54,903][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7912 Anomaly AUC:0.5193
[2023-08-27 08:46:36,060][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7901 Anomaly AUC:0.5192
[2023-08-27 08:46:36,086][main-autotune.py][line:114][INFO] Training completes in 10m 54s | best AUCAUC:0.7966 Anomaly AUC:0.5250

[2023-08-27 08:47:20,039][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.0027 loss2:0.0026 loss3:0.0010 | AUC:0.7635 Anomaly AUC:0.5352
[2023-08-27 08:47:58,617][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.0174 loss2:0.0113 loss3:0.0023 | AUC:0.7125 Anomaly AUC:0.5114
[2023-08-27 08:48:38,905][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0012 loss2:0.0035 loss3:0.0014 | AUC:0.7329 Anomaly AUC:0.5136
[2023-08-27 08:49:21,199][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0001 loss2:0.0022 loss3:0.0011 | AUC:0.7305 Anomaly AUC:0.5225
[2023-08-27 08:50:03,936][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0000 loss2:0.0015 loss3:0.0009 | AUC:0.7369 Anomaly AUC:0.5280
[2023-08-27 08:50:47,766][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0000 loss2:0.0005 loss3:0.0009 | AUC:0.7387 Anomaly AUC:0.5300
[2023-08-27 08:51:29,524][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0000 loss2:0.0001 loss3:0.0008 | AUC:0.7367 Anomaly AUC:0.5295
[2023-08-27 08:52:17,746][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0001 loss2:0.0001 loss3:0.0008 | AUC:0.7150 Anomaly AUC:0.5298
[2023-08-27 08:52:57,587][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.7145 Anomaly AUC:0.5308
[2023-08-27 08:53:41,384][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.7146 Anomaly AUC:0.5316
[2023-08-27 08:54:20,657][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7147 Anomaly AUC:0.5312
[2023-08-27 08:55:07,020][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7144 Anomaly AUC:0.5317
[2023-08-27 08:55:49,047][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7142 Anomaly AUC:0.5318
[2023-08-27 08:56:28,853][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7144 Anomaly AUC:0.5314
[2023-08-27 08:57:15,747][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7151 Anomaly AUC:0.5307
[2023-08-27 08:57:15,773][main-autotune.py][line:114][INFO] Training completes in 10m 40s | best AUCAUC:0.7635 Anomaly AUC:0.5352

[2023-08-27 08:57:59,335][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.0181 loss2:0.0237 loss3:0.0040 | AUC:0.7222 Anomaly AUC:0.5255
[2023-08-27 08:58:39,901][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0068 loss2:0.0159 loss3:0.0040 | AUC:0.7641 Anomaly AUC:0.5496
[2023-08-27 08:59:23,345][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0129 loss2:0.0238 loss3:0.0047 | AUC:0.6311 Anomaly AUC:0.4708
[2023-08-27 09:00:07,526][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0659 loss2:0.0324 loss3:0.0091 | AUC:0.6330 Anomaly AUC:0.4741
[2023-08-27 09:00:47,690][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0118 loss2:0.0113 loss3:0.0068 | AUC:0.6406 Anomaly AUC:0.5539
[2023-08-27 09:01:32,399][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0279 loss2:0.0295 loss3:0.0111 | AUC:0.7032 Anomaly AUC:0.4928
[2023-08-27 09:02:24,144][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0248 loss2:0.0311 loss3:0.0088 | AUC:0.6744 Anomaly AUC:0.4484
[2023-08-27 09:03:10,441][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0247 loss2:0.0285 loss3:0.0106 | AUC:0.6723 Anomaly AUC:0.4715
[2023-08-27 09:03:50,366][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0116 loss2:0.0196 loss3:0.0106 | AUC:0.7710 Anomaly AUC:0.5090
[2023-08-27 09:04:30,357][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0090 loss2:0.0235 loss3:0.0106 | AUC:0.6813 Anomaly AUC:0.4743
[2023-08-27 09:05:09,516][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0152 loss2:0.0289 loss3:0.0101 | AUC:0.7588 Anomaly AUC:0.5127
[2023-08-27 09:05:56,943][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0075 loss2:0.0008 loss3:0.0055 | AUC:0.7479 Anomaly AUC:0.5069
[2023-08-27 09:06:36,937][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0100 loss2:0.0286 loss3:0.0084 | AUC:0.6948 Anomaly AUC:0.4735
[2023-08-27 09:07:23,594][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0023 loss2:0.0064 loss3:0.0053 | AUC:0.6647 Anomaly AUC:0.4481
[2023-08-27 09:08:10,762][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0015 loss2:0.0034 loss3:0.0048 | AUC:0.6572 Anomaly AUC:0.4672
[2023-08-27 09:08:10,807][main-autotune.py][line:114][INFO] Training completes in 10m 55s | best AUCAUC:0.7710 Anomaly AUC:0.5090

[2023-08-27 09:08:50,182][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00080 | loss1:0.0108 loss2:0.0110 loss3:0.0044 | AUC:0.6825 Anomaly AUC:0.4878
[2023-08-27 09:09:30,529][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00080 | loss1:0.0005 loss2:0.0024 loss3:0.0023 | AUC:0.6369 Anomaly AUC:0.4766
[2023-08-27 09:10:13,618][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0014 | AUC:0.6229 Anomaly AUC:0.4739
[2023-08-27 09:10:52,371][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00080 | loss1:0.0006 loss2:0.0000 loss3:0.0010 | AUC:0.7714 Anomaly AUC:0.5044
[2023-08-27 09:11:32,136][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0008 | AUC:0.7715 Anomaly AUC:0.5064
[2023-08-27 09:12:16,325][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.7664 Anomaly AUC:0.5041
[2023-08-27 09:12:56,565][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7605 Anomaly AUC:0.4990
[2023-08-27 09:13:44,215][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.7554 Anomaly AUC:0.4943
[2023-08-27 09:14:25,704][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7523 Anomaly AUC:0.4906
[2023-08-27 09:15:09,159][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7516 Anomaly AUC:0.4885
[2023-08-27 09:15:55,859][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7515 Anomaly AUC:0.4897
[2023-08-27 09:16:39,854][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7534 Anomaly AUC:0.4892
[2023-08-27 09:17:23,732][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7545 Anomaly AUC:0.4891
[2023-08-27 09:18:08,186][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7659 Anomaly AUC:0.5019
[2023-08-27 09:18:47,601][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00080 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7697 Anomaly AUC:0.5031
[2023-08-27 09:18:47,650][main-autotune.py][line:114][INFO] Training completes in 10m 37s | best AUCAUC:0.7715 Anomaly AUC:0.5064

[2023-08-27 09:19:23,339][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.0170 loss2:0.0204 loss3:0.0059 | AUC:0.5752 Anomaly AUC:0.4777
[2023-08-27 09:20:02,128][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.0007 loss2:0.0066 loss3:0.0028 | AUC:0.6734 Anomaly AUC:0.5000
[2023-08-27 09:20:41,888][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0070 loss2:0.0006 loss3:0.0024 | AUC:0.6909 Anomaly AUC:0.5046
[2023-08-27 09:21:22,763][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0048 loss2:0.0130 loss3:0.0037 | AUC:0.7043 Anomaly AUC:0.5356
[2023-08-27 09:22:09,095][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0086 loss2:0.0167 loss3:0.0052 | AUC:0.6982 Anomaly AUC:0.5203
[2023-08-27 09:22:53,155][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0091 loss2:0.0244 loss3:0.0055 | AUC:0.7728 Anomaly AUC:0.5597
[2023-08-27 09:23:36,850][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0262 loss2:0.0253 loss3:0.0060 | AUC:0.8125 Anomaly AUC:0.5878
[2023-08-27 09:24:17,567][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0152 loss2:0.0253 loss3:0.0063 | AUC:0.7912 Anomaly AUC:0.5817
[2023-08-27 09:24:58,083][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0152 loss2:0.0028 loss3:0.0039 | AUC:0.7458 Anomaly AUC:0.5807
[2023-08-27 09:25:51,729][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0098 loss2:0.0058 loss3:0.0035 | AUC:0.7327 Anomaly AUC:0.5842
[2023-08-27 09:26:37,329][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0159 loss2:0.0118 loss3:0.0044 | AUC:0.7708 Anomaly AUC:0.5518
[2023-08-27 09:27:20,110][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0230 loss2:0.0381 loss3:0.0105 | AUC:0.7863 Anomaly AUC:0.5574
[2023-08-27 09:28:01,991][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0040 loss2:0.0133 loss3:0.0055 | AUC:0.7920 Anomaly AUC:0.5958
[2023-08-27 09:28:51,479][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0011 loss2:0.0008 loss3:0.0033 | AUC:0.7835 Anomaly AUC:0.5793
[2023-08-27 09:29:35,779][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0120 loss2:0.0169 loss3:0.0066 | AUC:0.8080 Anomaly AUC:0.6463
[2023-08-27 09:29:35,821][main-autotune.py][line:114][INFO] Training completes in 10m 48s | best AUCAUC:0.8125 Anomaly AUC:0.5878

[2023-08-27 09:30:17,637][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.0400 loss2:0.0397 loss3:0.0059 | AUC:0.6783 Anomaly AUC:0.5267
[2023-08-27 09:30:55,110][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0281 loss2:0.0359 loss3:0.0053 | AUC:0.7438 Anomaly AUC:0.5405
[2023-08-27 09:31:39,135][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0124 loss2:0.0210 loss3:0.0042 | AUC:0.7827 Anomaly AUC:0.5570
[2023-08-27 09:32:17,582][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0147 loss2:0.0136 loss3:0.0026 | AUC:0.7839 Anomaly AUC:0.5523
[2023-08-27 09:33:00,318][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0528 loss2:0.0209 loss3:0.0050 | AUC:0.7047 Anomaly AUC:0.5553
[2023-08-27 09:33:49,551][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0270 loss2:0.0290 loss3:0.0051 | AUC:0.7356 Anomaly AUC:0.5648
[2023-08-27 09:34:33,031][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0323 loss2:0.0527 loss3:0.0068 | AUC:0.6915 Anomaly AUC:0.5542
[2023-08-27 09:35:13,722][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0074 loss2:0.0145 loss3:0.0029 | AUC:0.6889 Anomaly AUC:0.5508
[2023-08-27 09:35:56,860][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0230 loss2:0.0215 loss3:0.0036 | AUC:0.7035 Anomaly AUC:0.5437
[2023-08-27 09:36:41,601][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0119 loss2:0.0195 loss3:0.0036 | AUC:0.6962 Anomaly AUC:0.5380
[2023-08-27 09:37:23,586][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0143 loss2:0.0259 loss3:0.0046 | AUC:0.6523 Anomaly AUC:0.5511
[2023-08-27 09:38:05,093][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0199 loss2:0.0163 loss3:0.0029 | AUC:0.6970 Anomaly AUC:0.5389
[2023-08-27 09:38:47,984][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0029 loss2:0.0061 loss3:0.0015 | AUC:0.6654 Anomaly AUC:0.5396
[2023-08-27 09:39:38,027][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0083 loss2:0.0040 loss3:0.0010 | AUC:0.6859 Anomaly AUC:0.5680
[2023-08-27 09:40:30,174][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0000 loss2:0.0013 loss3:0.0006 | AUC:0.7130 Anomaly AUC:0.5853
[2023-08-27 09:40:30,200][main-autotune.py][line:114][INFO] Training completes in 10m 54s | best AUCAUC:0.7839 Anomaly AUC:0.5523

[2023-08-27 09:41:17,528][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.0182 loss2:0.0147 loss3:0.0027 | AUC:0.7060 Anomaly AUC:0.5344
[2023-08-27 09:41:58,463][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.0137 loss2:0.0140 loss3:0.0023 | AUC:0.7501 Anomaly AUC:0.5039
[2023-08-27 09:42:39,094][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0004 loss2:0.0015 loss3:0.0008 | AUC:0.7578 Anomaly AUC:0.5137
[2023-08-27 09:43:24,936][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7528 Anomaly AUC:0.5083
[2023-08-27 09:44:05,265][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7427 Anomaly AUC:0.5032
[2023-08-27 09:44:48,038][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7332 Anomaly AUC:0.5005
[2023-08-27 09:45:36,523][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7205 Anomaly AUC:0.4967
[2023-08-27 09:46:20,611][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7100 Anomaly AUC:0.4953
[2023-08-27 09:47:03,531][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6896 Anomaly AUC:0.4854
[2023-08-27 09:47:43,160][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6849 Anomaly AUC:0.4798
[2023-08-27 09:48:21,169][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6817 Anomaly AUC:0.4782
[2023-08-27 09:49:06,585][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6754 Anomaly AUC:0.4801
[2023-08-27 09:49:50,446][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0629 loss2:0.0615 loss3:0.0080 | AUC:0.7586 Anomaly AUC:0.5483
[2023-08-27 09:50:30,014][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0401 loss2:0.0822 loss3:0.0103 | AUC:0.7237 Anomaly AUC:0.5443
[2023-08-27 09:51:18,160][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0104 loss2:0.0174 loss3:0.0042 | AUC:0.7195 Anomaly AUC:0.5214
[2023-08-27 09:51:18,185][main-autotune.py][line:114][INFO] Training completes in 10m 48s | best AUCAUC:0.7586 Anomaly AUC:0.5483

[2023-08-27 09:52:02,298][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.0293 loss2:0.0378 loss3:0.0071 | AUC:0.7617 Anomaly AUC:0.5546
[2023-08-27 09:52:46,408][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.0084 loss2:0.0053 loss3:0.0028 | AUC:0.7380 Anomaly AUC:0.5530
[2023-08-27 09:53:31,115][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0039 loss2:0.0048 loss3:0.0025 | AUC:0.7482 Anomaly AUC:0.5599
[2023-08-27 09:54:13,025][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0014 loss2:0.0045 loss3:0.0018 | AUC:0.7706 Anomaly AUC:0.5760
[2023-08-27 09:54:57,763][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0112 loss2:0.0024 loss3:0.0035 | AUC:0.7193 Anomaly AUC:0.5683
[2023-08-27 09:55:35,897][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0404 loss2:0.0101 loss3:0.0033 | AUC:0.7698 Anomaly AUC:0.5555
[2023-08-27 09:56:13,936][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0879 loss2:0.0108 loss3:0.0033 | AUC:0.6990 Anomaly AUC:0.5319
[2023-08-27 09:57:00,824][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0338 loss2:0.0167 loss3:0.0037 | AUC:0.7563 Anomaly AUC:0.5618
[2023-08-27 09:57:43,202][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0114 loss2:0.0081 loss3:0.0027 | AUC:0.6839 Anomaly AUC:0.5553
[2023-08-27 09:58:29,536][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0193 loss2:0.0000 loss3:0.0013 | AUC:0.6675 Anomaly AUC:0.5561
[2023-08-27 09:59:12,923][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0120 loss2:0.0085 loss3:0.0023 | AUC:0.6804 Anomaly AUC:0.5453
[2023-08-27 09:59:56,970][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0002 loss2:0.0019 loss3:0.0012 | AUC:0.6748 Anomaly AUC:0.5256
[2023-08-27 10:00:41,386][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.6742 Anomaly AUC:0.5279
[2023-08-27 10:01:28,691][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0006 | AUC:0.6722 Anomaly AUC:0.5290
[2023-08-27 10:02:08,166][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.6692 Anomaly AUC:0.5300
[2023-08-27 10:02:08,192][main-autotune.py][line:114][INFO] Training completes in 10m 50s | best AUCAUC:0.7706 Anomaly AUC:0.5760

[2023-08-27 10:02:51,868][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.0275 loss2:0.0162 loss3:0.0030 | AUC:0.7066 Anomaly AUC:0.5272
[2023-08-27 10:03:35,740][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.0170 loss2:0.0171 loss3:0.0036 | AUC:0.7489 Anomaly AUC:0.5715
[2023-08-27 10:04:22,330][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0082 loss2:0.0112 loss3:0.0029 | AUC:0.7000 Anomaly AUC:0.5492
[2023-08-27 10:05:03,397][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0369 loss2:0.0183 loss3:0.0038 | AUC:0.6984 Anomaly AUC:0.5469
[2023-08-27 10:05:47,020][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0746 loss2:0.0087 loss3:0.0033 | AUC:0.6896 Anomaly AUC:0.5455
[2023-08-27 10:06:35,539][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0054 loss2:0.0096 loss3:0.0030 | AUC:0.6255 Anomaly AUC:0.5377
[2023-08-27 10:07:19,399][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0044 loss2:0.0064 loss3:0.0023 | AUC:0.6938 Anomaly AUC:0.5395
[2023-08-27 10:08:01,245][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0073 loss2:0.0086 loss3:0.0035 | AUC:0.7046 Anomaly AUC:0.5159
[2023-08-27 10:08:43,960][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0384 loss2:0.0215 loss3:0.0058 | AUC:0.6709 Anomaly AUC:0.5076
[2023-08-27 10:09:24,023][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0092 loss2:0.0154 loss3:0.0035 | AUC:0.6239 Anomaly AUC:0.4955
[2023-08-27 10:10:07,511][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0193 loss2:0.0193 loss3:0.0046 | AUC:0.7672 Anomaly AUC:0.5686
[2023-08-27 10:10:48,306][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0019 loss2:0.0041 loss3:0.0018 | AUC:0.7020 Anomaly AUC:0.5661
[2023-08-27 10:11:26,867][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0003 loss2:0.0012 loss3:0.0008 | AUC:0.6880 Anomaly AUC:0.5392
[2023-08-27 10:12:03,790][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0001 loss2:0.0003 loss3:0.0006 | AUC:0.6500 Anomaly AUC:0.5270
[2023-08-27 10:12:47,272][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.6498 Anomaly AUC:0.5282
[2023-08-27 10:12:47,298][main-autotune.py][line:114][INFO] Training completes in 10m 39s | best AUCAUC:0.7672 Anomaly AUC:0.5686

[2023-08-27 10:13:33,208][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.0043 loss2:0.0064 loss3:0.0019 | AUC:0.7008 Anomaly AUC:0.5358
[2023-08-27 10:14:18,230][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.0006 loss2:0.0010 loss3:0.0010 | AUC:0.6910 Anomaly AUC:0.5520
[2023-08-27 10:15:04,181][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0033 loss2:0.0027 loss3:0.0012 | AUC:0.7483 Anomaly AUC:0.5566
[2023-08-27 10:15:45,016][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0406 loss2:0.0204 loss3:0.0047 | AUC:0.7081 Anomaly AUC:0.5345
[2023-08-27 10:16:26,604][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0143 loss2:0.0071 loss3:0.0020 | AUC:0.7298 Anomaly AUC:0.5481
[2023-08-27 10:17:11,477][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0022 loss2:0.0011 loss3:0.0012 | AUC:0.7432 Anomaly AUC:0.5274
[2023-08-27 10:17:53,629][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0012 loss2:0.0044 loss3:0.0011 | AUC:0.6815 Anomaly AUC:0.5276
[2023-08-27 10:18:36,154][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0005 | AUC:0.6796 Anomaly AUC:0.5293
[2023-08-27 10:19:18,098][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.6737 Anomaly AUC:0.5244
[2023-08-27 10:20:02,567][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.6688 Anomaly AUC:0.5194
[2023-08-27 10:20:42,602][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.6669 Anomaly AUC:0.5329
[2023-08-27 10:21:28,342][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0001 loss2:0.0000 loss3:0.0004 | AUC:0.6678 Anomaly AUC:0.5274
[2023-08-27 10:22:09,469][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.6651 Anomaly AUC:0.5240
[2023-08-27 10:22:56,731][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6567 Anomaly AUC:0.5212
[2023-08-27 10:23:34,345][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0007 loss2:0.0003 loss3:0.0006 | AUC:0.7387 Anomaly AUC:0.5506
[2023-08-27 10:23:34,373][main-autotune.py][line:114][INFO] Training completes in 10m 47s | best AUCAUC:0.7483 Anomaly AUC:0.5566

[2023-08-27 10:24:17,377][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.0033 loss2:0.0085 loss3:0.0019 | AUC:0.7603 Anomaly AUC:0.5831
[2023-08-27 10:24:58,633][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.0063 loss2:0.0075 loss3:0.0018 | AUC:0.7466 Anomaly AUC:0.6021
[2023-08-27 10:25:42,113][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0194 loss2:0.0164 loss3:0.0027 | AUC:0.6892 Anomaly AUC:0.5512
[2023-08-27 10:26:27,090][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0040 loss2:0.0051 loss3:0.0015 | AUC:0.7250 Anomaly AUC:0.5661
[2023-08-27 10:27:06,395][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0007 loss2:0.0023 loss3:0.0009 | AUC:0.6797 Anomaly AUC:0.5464
[2023-08-27 10:27:49,119][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0000 loss2:0.0002 loss3:0.0005 | AUC:0.6705 Anomaly AUC:0.5434
[2023-08-27 10:28:34,623][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.6596 Anomaly AUC:0.5385
[2023-08-27 10:29:17,936][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0011 loss2:0.0000 loss3:0.0006 | AUC:0.7169 Anomaly AUC:0.5542
[2023-08-27 10:30:00,604][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0074 loss2:0.0060 loss3:0.0010 | AUC:0.6145 Anomaly AUC:0.5193
[2023-08-27 10:30:43,803][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0000 loss2:0.0008 loss3:0.0004 | AUC:0.5950 Anomaly AUC:0.5237
[2023-08-27 10:31:21,095][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0000 loss2:0.0002 loss3:0.0004 | AUC:0.5932 Anomaly AUC:0.5193
[2023-08-27 10:32:01,348][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.5961 Anomaly AUC:0.5157
[2023-08-27 10:32:42,075][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.5940 Anomaly AUC:0.5111
[2023-08-27 10:33:30,788][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.5977 Anomaly AUC:0.5063
[2023-08-27 10:34:14,331][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.5861 Anomaly AUC:0.4983
[2023-08-27 10:34:14,357][main-autotune.py][line:114][INFO] Training completes in 10m 40s | best AUCAUC:0.7603 Anomaly AUC:0.5831

[2023-08-27 10:34:57,378][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.0078 loss2:0.0142 loss3:0.0020 | AUC:0.6275 Anomaly AUC:0.5057
[2023-08-27 10:35:47,181][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.0108 loss2:0.0106 loss3:0.0013 | AUC:0.7490 Anomaly AUC:0.5359
[2023-08-27 10:36:34,674][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0298 loss2:0.0465 loss3:0.0039 | AUC:0.7011 Anomaly AUC:0.5609
[2023-08-27 10:37:20,624][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0146 loss2:0.0219 loss3:0.0018 | AUC:0.6871 Anomaly AUC:0.5584
[2023-08-27 10:38:02,244][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0089 loss2:0.0343 loss3:0.0020 | AUC:0.6565 Anomaly AUC:0.5628
[2023-08-27 10:38:45,184][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0044 loss2:0.0178 loss3:0.0012 | AUC:0.7690 Anomaly AUC:0.5927
[2023-08-27 10:39:29,447][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0124 loss2:0.0252 loss3:0.0017 | AUC:0.7570 Anomaly AUC:0.6046
[2023-08-27 10:40:12,282][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0001 loss2:0.0005 loss3:0.0004 | AUC:0.7598 Anomaly AUC:0.6107
[2023-08-27 10:40:51,604][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0001 loss2:0.0000 loss3:0.0004 | AUC:0.7980 Anomaly AUC:0.6031
[2023-08-27 10:41:36,909][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7920 Anomaly AUC:0.5991
[2023-08-27 10:42:19,892][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7876 Anomaly AUC:0.5986
[2023-08-27 10:43:01,486][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7821 Anomaly AUC:0.5964
[2023-08-27 10:43:43,303][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7780 Anomaly AUC:0.5945
[2023-08-27 10:44:30,811][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7739 Anomaly AUC:0.5934
[2023-08-27 10:45:15,737][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7701 Anomaly AUC:0.5920
[2023-08-27 10:45:15,764][main-autotune.py][line:114][INFO] Training completes in 11m 1s | best AUCAUC:0.7980 Anomaly AUC:0.6031

[2023-08-27 10:45:57,338][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.0296 loss2:0.0000 loss3:0.0008 | AUC:0.7904 Anomaly AUC:0.5495
[2023-08-27 10:46:41,198][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.0062 loss2:0.0170 loss3:0.0018 | AUC:0.6585 Anomaly AUC:0.5595
[2023-08-27 10:47:23,539][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0001 loss2:0.0011 loss3:0.0005 | AUC:0.6302 Anomaly AUC:0.5500
[2023-08-27 10:48:06,351][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0000 loss2:0.0004 loss3:0.0004 | AUC:0.6362 Anomaly AUC:0.5375
[2023-08-27 10:48:45,940][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0000 loss2:0.0001 loss3:0.0004 | AUC:0.6432 Anomaly AUC:0.5415
[2023-08-27 10:49:31,599][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6665 Anomaly AUC:0.5519
[2023-08-27 10:50:20,051][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6670 Anomaly AUC:0.5497
[2023-08-27 10:51:03,300][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6648 Anomaly AUC:0.5456
[2023-08-27 10:51:51,528][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6623 Anomaly AUC:0.5405
[2023-08-27 10:52:36,436][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6593 Anomaly AUC:0.5346
[2023-08-27 10:53:21,036][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.6579 Anomaly AUC:0.5295
[2023-08-27 10:53:58,988][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0006 loss2:0.0000 loss3:0.0004 | AUC:0.7766 Anomaly AUC:0.5429
[2023-08-27 10:54:41,180][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7685 Anomaly AUC:0.5377
[2023-08-27 10:55:25,138][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7645 Anomaly AUC:0.5341
[2023-08-27 10:56:09,827][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7645 Anomaly AUC:0.5324
[2023-08-27 10:56:09,854][main-autotune.py][line:114][INFO] Training completes in 10m 54s | best AUCAUC:0.7904 Anomaly AUC:0.5495

[2023-08-27 10:56:51,208][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.0263 loss2:0.0342 loss3:0.0029 | AUC:0.7809 Anomaly AUC:0.6076
[2023-08-27 10:57:30,674][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0096 loss2:0.0109 loss3:0.0022 | AUC:0.7257 Anomaly AUC:0.5443
[2023-08-27 10:58:14,289][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0251 loss2:0.0287 loss3:0.0052 | AUC:0.5770 Anomaly AUC:0.5222
[2023-08-27 10:58:57,790][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0120 loss2:0.0243 loss3:0.0048 | AUC:0.7803 Anomaly AUC:0.6473
[2023-08-27 10:59:41,977][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0097 loss2:0.0074 loss3:0.0029 | AUC:0.7176 Anomaly AUC:0.6019
[2023-08-27 11:00:23,198][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0014 loss2:0.0000 loss3:0.0024 | AUC:0.7770 Anomaly AUC:0.5887
[2023-08-27 11:01:10,991][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0009 loss2:0.0032 loss3:0.0015 | AUC:0.7767 Anomaly AUC:0.5589
[2023-08-27 11:01:56,346][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0001 loss2:0.0000 loss3:0.0011 | AUC:0.7838 Anomaly AUC:0.5770
[2023-08-27 11:02:36,539][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0000 loss2:0.0000 loss3:0.0009 | AUC:0.7855 Anomaly AUC:0.5800
[2023-08-27 11:03:19,925][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0001 loss2:0.0000 loss3:0.0010 | AUC:0.7912 Anomaly AUC:0.5477
[2023-08-27 11:04:01,772][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0963 loss2:0.0489 loss3:0.0181 | AUC:0.7318 Anomaly AUC:0.5332
[2023-08-27 11:04:40,620][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0414 loss2:0.0426 loss3:0.0101 | AUC:0.6952 Anomaly AUC:0.5426
[2023-08-27 11:05:22,154][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0360 loss2:0.0231 loss3:0.0078 | AUC:0.7398 Anomaly AUC:0.5507
[2023-08-27 11:06:07,004][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0024 loss2:0.0128 loss3:0.0028 | AUC:0.7378 Anomaly AUC:0.5576
[2023-08-27 11:06:47,449][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0513 loss2:0.0275 loss3:0.0081 | AUC:0.7232 Anomaly AUC:0.5753
[2023-08-27 11:06:47,498][main-autotune.py][line:114][INFO] Training completes in 10m 38s | best AUCAUC:0.7912 Anomaly AUC:0.5477

[2023-08-27 11:07:28,515][main-autotune.py][line:106][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.1498 loss2:0.0000 loss3:0.0032 | AUC:0.7842 Anomaly AUC:0.5505
[2023-08-27 11:08:09,384][main-autotune.py][line:106][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.0085 loss2:0.0123 loss3:0.0032 | AUC:0.7941 Anomaly AUC:0.5613
[2023-08-27 11:08:50,228][main-autotune.py][line:106][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0007 | AUC:0.7927 Anomaly AUC:0.5579
[2023-08-27 11:09:28,503][main-autotune.py][line:106][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0004 | AUC:0.7917 Anomaly AUC:0.5566
[2023-08-27 11:10:12,546][main-autotune.py][line:106][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7914 Anomaly AUC:0.5571
[2023-08-27 11:10:59,989][main-autotune.py][line:106][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7923 Anomaly AUC:0.5591
[2023-08-27 11:11:49,478][main-autotune.py][line:106][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7931 Anomaly AUC:0.5616
[2023-08-27 11:12:32,085][main-autotune.py][line:106][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7925 Anomaly AUC:0.5623
[2023-08-27 11:13:13,914][main-autotune.py][line:106][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0003 | AUC:0.7930 Anomaly AUC:0.5632
[2023-08-27 11:13:56,377][main-autotune.py][line:106][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7954 Anomaly AUC:0.5649
[2023-08-27 11:14:37,823][main-autotune.py][line:106][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7928 Anomaly AUC:0.5641
[2023-08-27 11:15:22,124][main-autotune.py][line:106][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7925 Anomaly AUC:0.5635
[2023-08-27 11:16:07,098][main-autotune.py][line:106][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7927 Anomaly AUC:0.5644
[2023-08-27 11:16:50,427][main-autotune.py][line:106][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7941 Anomaly AUC:0.5651
[2023-08-27 11:17:32,610][main-autotune.py][line:106][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.7919 Anomaly AUC:0.5637
[2023-08-27 11:17:32,635][main-autotune.py][line:114][INFO] Training completes in 10m 45s | best AUCAUC:0.7954 Anomaly AUC:0.5649

[2023-08-27 12:07:17,063][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:07:17,200][main.py][line:152][INFO] total params:7.5707M
[2023-08-27 12:07:17,200][main.py][line:155][INFO] Training Mode
[2023-08-27 12:07:17,200][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 12:07:17,200][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 12:07:25,070][main.py][line:77][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-27 12:08:15,747][main.py][line:101][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.3375 loss2:1.0431 loss3:0.4343 | AUC:0.8235 Anomaly AUC:0.6818
[2023-08-27 12:08:58,074][main.py][line:101][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0058 loss2:0.6555 loss3:0.3833 | AUC:0.8263 Anomaly AUC:0.6720
[2023-08-27 12:09:47,550][main.py][line:101][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0033 loss2:0.4399 loss3:0.3383 | AUC:0.8112 Anomaly AUC:0.6972
[2023-08-27 12:10:47,720][main.py][line:101][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0014 loss2:0.2528 loss3:0.2819 | AUC:0.8276 Anomaly AUC:0.6600
[2023-08-27 12:11:55,880][main.py][line:101][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0052 loss2:0.1521 loss3:0.2322 | AUC:0.8043 Anomaly AUC:0.6724
[2023-08-27 12:12:44,978][main.py][line:101][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0023 loss2:0.1568 loss3:0.2301 | AUC:0.8219 Anomaly AUC:0.6747
[2023-08-27 12:13:38,737][main.py][line:101][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0019 loss2:0.0745 loss3:0.1613 | AUC:0.8172 Anomaly AUC:0.6840
[2023-08-27 12:14:59,255][main.py][line:101][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0010 loss2:0.0466 loss3:0.1160 | AUC:0.8226 Anomaly AUC:0.6813
[2023-08-27 12:15:51,551][main.py][line:101][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.2198 loss2:0.0983 loss3:2.2483 | AUC:0.7114 Anomaly AUC:0.5626
[2023-08-27 12:16:40,575][main.py][line:101][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0598 loss2:0.3245 loss3:0.6576 | AUC:0.7829 Anomaly AUC:0.6225
[2023-08-27 12:18:07,591][main.py][line:101][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0015 loss2:0.0977 loss3:0.2802 | AUC:0.7834 Anomaly AUC:0.6480
[2023-08-27 12:18:18,066][main.py][line:116][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:18:18,217][main.py][line:152][INFO] total params:7.5707M
[2023-08-27 12:18:18,217][main.py][line:155][INFO] Training Mode
[2023-08-27 12:18:18,217][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 12:18:18,217][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 12:18:30,047][main.py][line:77][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-27 12:19:49,410][main.py][line:101][INFO] [Epoch:1/50]: lr:0.00100 | loss1:0.3375 loss2:1.0431 loss3:0.4343 | AUC:0.8235 Anomaly AUC:0.6818
[2023-08-27 12:20:14,433][main.py][line:117][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:20:14,569][main.py][line:153][INFO] total params:7.5707M
[2023-08-27 12:20:14,569][main.py][line:156][INFO] Training Mode
[2023-08-27 12:20:14,569][main.py][line:74][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 12:20:14,570][main.py][line:75][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 12:20:25,958][main.py][line:78][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-27 12:21:18,962][main.py][line:102][INFO] [Epoch:1/50]: lr:0.00100 | loss1:0.2927 loss2:1.0213 loss3:0.4774 | AUC:0.7911 Anomaly AUC:0.6831
[2023-08-27 12:21:39,874][main.py][line:117][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:21:40,009][main.py][line:153][INFO] total params:7.5707M
[2023-08-27 12:21:40,010][main.py][line:156][INFO] Training Mode
[2023-08-27 12:21:40,010][main.py][line:74][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 12:21:40,010][main.py][line:75][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 12:21:47,661][main.py][line:78][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-27 12:22:41,811][main.py][line:102][INFO] [Epoch:1/50]: lr:0.00100 | loss1:0.3375 loss2:1.0431 loss3:0.4343 | AUC:0.8235 Anomaly AUC:0.6818
[2023-08-27 12:24:47,356][main.py][line:117][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__8689.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:24:47,493][main.py][line:153][INFO] total params:7.5707M
[2023-08-27 12:24:47,493][main.py][line:162][INFO] Test Mode
[2023-08-27 12:24:47,493][main.py][line:35][INFO] loading pretrained checkpoint from ./ckpt/ucf__8689.pkl.
[2023-08-27 12:24:55,492][infer.py][line:47][INFO] offline AUC:0.8702 AP:0.2980 FAR:0.0281 | Complete in 0m 8s

[2023-08-27 12:25:14,659][main-autotune.py][line:122][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:25:14,771][main-autotune.py][line:166][INFO] total params:7.5707M
[2023-08-27 12:25:14,771][main-autotune.py][line:169][INFO] Training Mode
[2023-08-27 12:25:58,714][main-autotune.py][line:106][INFO] [Epoch:1/50]: lr:0.00080 | loss1:0.3749 loss2:1.0312 loss3:0.2236 | AUC:0.8249 Anomaly AUC:0.6640
[2023-08-27 12:27:17,612][main-autotune.py][line:106][INFO] [Epoch:2/50]: lr:0.00080 | loss1:0.1377 loss2:0.7523 loss3:0.0643 | AUC:0.8402 Anomaly AUC:0.6665
[2023-08-27 12:28:11,228][main-autotune.py][line:106][INFO] [Epoch:3/50]: lr:0.00080 | loss1:0.0636 loss2:0.6162 loss3:0.0367 | AUC:0.8096 Anomaly AUC:0.6277
[2023-08-27 12:29:08,442][main-autotune.py][line:106][INFO] [Epoch:4/50]: lr:0.00080 | loss1:0.0464 loss2:0.5028 loss3:0.0285 | AUC:0.8367 Anomaly AUC:0.6879
[2023-08-27 12:29:53,133][main-autotune.py][line:106][INFO] [Epoch:5/50]: lr:0.00080 | loss1:0.0284 loss2:0.3676 loss3:0.0224 | AUC:0.8437 Anomaly AUC:0.6752
[2023-08-27 12:31:30,119][main-autotune.py][line:106][INFO] [Epoch:6/50]: lr:0.00080 | loss1:0.0181 loss2:0.2644 loss3:0.0206 | AUC:0.8228 Anomaly AUC:0.6507
[2023-08-27 12:33:04,239][main-autotune.py][line:106][INFO] [Epoch:7/50]: lr:0.00080 | loss1:0.0168 loss2:0.1744 loss3:0.0167 | AUC:0.8401 Anomaly AUC:0.6620
[2023-08-27 12:34:35,814][main-autotune.py][line:106][INFO] [Epoch:8/50]: lr:0.00080 | loss1:0.0198 loss2:0.1378 loss3:0.0155 | AUC:0.8406 Anomaly AUC:0.6603
[2023-08-27 12:35:44,176][main-autotune.py][line:106][INFO] [Epoch:9/50]: lr:0.00080 | loss1:0.0182 loss2:0.0965 loss3:0.0133 | AUC:0.8458 Anomaly AUC:0.6974
[2023-08-27 12:37:34,447][main-autotune.py][line:106][INFO] [Epoch:10/50]: lr:0.00080 | loss1:0.0165 loss2:0.0776 loss3:0.0127 | AUC:0.8413 Anomaly AUC:0.6722
[2023-08-27 12:38:50,452][main-autotune.py][line:106][INFO] [Epoch:11/50]: lr:0.00080 | loss1:0.0138 loss2:0.0551 loss3:0.0102 | AUC:0.8478 Anomaly AUC:0.6558
[2023-08-27 12:39:59,911][main-autotune.py][line:106][INFO] [Epoch:12/50]: lr:0.00080 | loss1:0.0256 loss2:0.0727 loss3:0.0117 | AUC:0.8652 Anomaly AUC:0.6864
[2023-08-27 12:41:21,186][main-autotune.py][line:106][INFO] [Epoch:13/50]: lr:0.00080 | loss1:0.0100 loss2:0.0360 loss3:0.0070 | AUC:0.8626 Anomaly AUC:0.6931
[2023-08-27 12:42:56,475][main-autotune.py][line:106][INFO] [Epoch:14/50]: lr:0.00080 | loss1:0.0084 loss2:0.0290 loss3:0.0037 | AUC:0.8319 Anomaly AUC:0.6561
[2023-08-27 12:44:26,861][main-autotune.py][line:106][INFO] [Epoch:15/50]: lr:0.00080 | loss1:0.0055 loss2:0.0215 loss3:0.0021 | AUC:0.8469 Anomaly AUC:0.6511
[2023-08-27 12:46:22,750][main-autotune.py][line:106][INFO] [Epoch:16/50]: lr:0.00080 | loss1:0.0205 loss2:0.0500 loss3:0.0065 | AUC:0.8401 Anomaly AUC:0.6900
[2023-08-27 12:46:46,124][main.py][line:117][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 12:46:46,282][main.py][line:153][INFO] total params:7.5707M
[2023-08-27 12:46:46,283][main.py][line:156][INFO] Training Mode
[2023-08-27 12:46:46,283][main.py][line:74][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 12:46:46,283][main.py][line:75][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 12:46:54,030][main.py][line:78][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54580
[2023-08-27 12:47:50,704][main.py][line:102][INFO] [Epoch:1/50]: lr:0.00100 | loss1:0.3594 loss2:1.0446 loss3:0.3312 | AUC:0.8424 Anomaly AUC:0.6718
[2023-08-27 12:48:50,211][main.py][line:102][INFO] [Epoch:2/50]: lr:0.00100 | loss1:0.1139 loss2:0.7612 loss3:0.1524 | AUC:0.8160 Anomaly AUC:0.6824
[2023-08-27 12:49:33,811][main.py][line:102][INFO] [Epoch:3/50]: lr:0.00100 | loss1:0.0541 loss2:0.6189 loss3:0.0465 | AUC:0.8253 Anomaly AUC:0.6737
[2023-08-27 12:50:23,151][main.py][line:102][INFO] [Epoch:4/50]: lr:0.00100 | loss1:0.0463 loss2:0.5225 loss3:0.0344 | AUC:0.8427 Anomaly AUC:0.6760
[2023-08-27 12:51:24,184][main.py][line:102][INFO] [Epoch:5/50]: lr:0.00100 | loss1:0.0219 loss2:0.3846 loss3:0.0226 | AUC:0.8531 Anomaly AUC:0.6739
[2023-08-27 12:53:01,539][main.py][line:102][INFO] [Epoch:6/50]: lr:0.00100 | loss1:0.0174 loss2:0.2748 loss3:0.0197 | AUC:0.8326 Anomaly AUC:0.6633
[2023-08-27 12:54:24,943][main.py][line:102][INFO] [Epoch:7/50]: lr:0.00100 | loss1:0.0273 loss2:0.2255 loss3:0.0228 | AUC:0.8435 Anomaly AUC:0.6618
[2023-08-27 12:55:35,570][main.py][line:102][INFO] [Epoch:8/50]: lr:0.00100 | loss1:0.0185 loss2:0.1425 loss3:0.0173 | AUC:0.8415 Anomaly AUC:0.6816
[2023-08-27 12:57:07,543][main.py][line:102][INFO] [Epoch:9/50]: lr:0.00100 | loss1:0.0217 loss2:0.1199 loss3:0.0182 | AUC:0.8479 Anomaly AUC:0.6919
[2023-08-27 12:58:26,523][main.py][line:102][INFO] [Epoch:10/50]: lr:0.00100 | loss1:0.0094 loss2:0.0576 loss3:0.0139 | AUC:0.8322 Anomaly AUC:0.6649
[2023-08-27 12:59:50,631][main.py][line:102][INFO] [Epoch:11/50]: lr:0.00100 | loss1:0.0255 loss2:0.0998 loss3:0.0174 | AUC:0.8263 Anomaly AUC:0.6618
[2023-08-27 13:01:00,180][main.py][line:102][INFO] [Epoch:12/50]: lr:0.00100 | loss1:0.0093 loss2:0.0549 loss3:0.0121 | AUC:0.8338 Anomaly AUC:0.6646
[2023-08-27 13:02:15,573][main.py][line:102][INFO] [Epoch:13/50]: lr:0.00100 | loss1:0.0069 loss2:0.0292 loss3:0.0102 | AUC:0.8228 Anomaly AUC:0.6844
[2023-08-27 13:03:19,221][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:03:19,380][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:03:19,380][main.py][line:158][INFO] Training Mode
[2023-08-27 13:03:19,381][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:03:19,381][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:03:29,240][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:03:54,033][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:03:54,161][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:03:54,161][main.py][line:158][INFO] Training Mode
[2023-08-27 13:03:54,161][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:03:54,161][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:04:49,347][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:04:49,459][main.py][line:154][INFO] total params:7.5707M
[2023-08-27 13:04:49,459][main.py][line:157][INFO] Training Mode
[2023-08-27 13:04:49,459][main.py][line:72][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:04:49,459][main.py][line:73][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:04:57,607][main.py][line:79][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:06:57,808][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:06:57,918][main.py][line:156][INFO] total params:7.5707M
[2023-08-27 13:06:57,918][main.py][line:159][INFO] Training Mode
[2023-08-27 13:06:57,919][main.py][line:73][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:06:57,919][main.py][line:74][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:07:06,327][main.py][line:79][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:07:51,519][main.py][line:105][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.3594 loss2:1.0446 loss3:0.3312 | AUC:0.8424 Anomaly AUC:0.6717
[2023-08-27 13:08:48,521][main.py][line:105][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.1139 loss2:0.7612 loss3:0.1524 | AUC:0.8157 Anomaly AUC:0.6816
[2023-08-27 13:09:45,029][main.py][line:105][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0541 loss2:0.6189 loss3:0.0465 | AUC:0.8253 Anomaly AUC:0.6736
[2023-08-27 13:10:42,978][main.py][line:105][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0463 loss2:0.5225 loss3:0.0344 | AUC:0.8425 Anomaly AUC:0.6755
[2023-08-27 13:11:47,919][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:11:48,077][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:11:48,077][main.py][line:158][INFO] Training Mode
[2023-08-27 13:11:48,078][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:11:48,078][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:11:59,235][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:17:09,320][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:17:09,445][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:17:09,445][main.py][line:158][INFO] Training Mode
[2023-08-27 13:17:09,445][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:17:09,445][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:17:17,622][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:17:53,607][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:17:53,732][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:17:53,732][main.py][line:158][INFO] Training Mode
[2023-08-27 13:17:53,732][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:17:53,732][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:18:02,257][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:22:26,640][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:22:26,766][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:22:26,766][main.py][line:158][INFO] Training Mode
[2023-08-27 13:22:26,767][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:22:26,767][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:22:35,114][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:26:56,143][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:26:56,265][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:26:56,265][main.py][line:158][INFO] Training Mode
[2023-08-27 13:26:56,265][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:26:56,265][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:27:04,520][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:28:33,994][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:28:34,110][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:28:34,110][main.py][line:158][INFO] Training Mode
[2023-08-27 13:28:34,111][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:28:34,111][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:28:42,366][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:29:25,631][main.py][line:119][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:29:25,758][main.py][line:155][INFO] total params:7.5707M
[2023-08-27 13:29:25,758][main.py][line:158][INFO] Training Mode
[2023-08-27 13:29:25,758][main.py][line:76][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:29:25,758][main.py][line:77][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:29:33,946][main.py][line:80][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:30:06,771][main.py][line:104][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.3611 loss2:1.0525 loss3:0.3307 | AUC:0.8248 Anomaly AUC:0.6548
[2023-08-27 13:30:49,772][main.py][line:104][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.1166 loss2:0.7734 loss3:0.1270 | AUC:0.8044 Anomaly AUC:0.6493
[2023-08-27 13:31:38,455][main.py][line:104][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0545 loss2:0.6296 loss3:0.0493 | AUC:0.8101 Anomaly AUC:0.6594
[2023-08-27 13:32:23,986][main.py][line:104][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0447 loss2:0.5196 loss3:0.0354 | AUC:0.8191 Anomaly AUC:0.6700
[2023-08-27 13:32:59,088][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:32:59,248][main.py][line:154][INFO] total params:7.5707M
[2023-08-27 13:32:59,248][main.py][line:157][INFO] Training Mode
[2023-08-27 13:32:59,248][main.py][line:75][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 13:32:59,248][main.py][line:76][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 13:33:08,074][main.py][line:79][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 13:33:52,432][main.py][line:103][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.3594 loss2:1.0446 loss3:0.3312 | AUC:0.8424 Anomaly AUC:0.6717
[2023-08-27 13:34:25,160][main-autotune.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:34:25,306][main-autotune.py][line:167][INFO] total params:7.5707M
[2023-08-27 13:34:25,306][main-autotune.py][line:170][INFO] Training Mode
[2023-08-27 13:34:42,376][main-autotune.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:34:42,498][main-autotune.py][line:167][INFO] total params:7.5707M
[2023-08-27 13:34:42,498][main-autotune.py][line:170][INFO] Training Mode
[2023-08-27 13:35:26,257][main-autotune.py][line:107][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.3507 loss2:0.9943 loss3:0.3984 | AUC:0.8089 Anomaly AUC:0.6856
[2023-08-27 13:35:33,092][main-autotune.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:35:33,220][main-autotune.py][line:167][INFO] total params:7.5707M
[2023-08-27 13:35:33,220][main-autotune.py][line:170][INFO] Training Mode
[2023-08-27 13:36:04,593][main-autotune.py][line:107][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.3708 loss2:1.1392 loss3:0.3993 | AUC:0.8373 Anomaly AUC:0.6409
[2023-08-27 13:36:40,820][main-autotune.py][line:107][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.0316 loss2:0.7819 loss3:1.4656 | AUC:0.8360 Anomaly AUC:0.7045
[2023-08-27 13:37:20,328][main-autotune.py][line:107][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0016 loss2:0.6069 loss3:0.7423 | AUC:0.8336 Anomaly AUC:0.6986
[2023-08-27 13:38:06,345][main-autotune.py][line:107][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0016 loss2:0.4234 loss3:0.4853 | AUC:0.8492 Anomaly AUC:0.7133
[2023-08-27 13:38:47,087][main-autotune.py][line:107][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0024 loss2:0.3650 loss3:1.0913 | AUC:0.8339 Anomaly AUC:0.6967
[2023-08-27 13:39:31,351][main-autotune.py][line:107][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0005 loss2:0.1860 loss3:0.3914 | AUC:0.8407 Anomaly AUC:0.7018
[2023-08-27 13:40:32,954][main-autotune.py][line:107][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0013 loss2:0.1354 loss3:0.5414 | AUC:0.8007 Anomaly AUC:0.6751
[2023-08-27 13:41:10,572][main-autotune.py][line:107][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0004 loss2:0.0824 loss3:0.3564 | AUC:0.8099 Anomaly AUC:0.6690
[2023-08-27 13:41:57,007][main-autotune.py][line:107][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0005 loss2:0.0739 loss3:0.3366 | AUC:0.8116 Anomaly AUC:0.6668
[2023-08-27 13:42:47,804][main-autotune.py][line:107][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0004 loss2:0.0518 loss3:0.4188 | AUC:0.8102 Anomaly AUC:0.6796
[2023-08-27 13:51:05,006][main-autotune.py][line:125][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:51:05,283][main-autotune.py][line:171][INFO] total params:7.5707M
[2023-08-27 13:51:05,283][main-autotune.py][line:174][INFO] Training Mode
[2023-08-27 13:51:19,581][main-autotune.py][line:125][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 15, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 13:51:19,703][main-autotune.py][line:170][INFO] total params:7.5707M
[2023-08-27 13:51:19,703][main-autotune.py][line:173][INFO] Training Mode
[2023-08-27 13:51:44,617][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.3781 loss2:1.1085 loss3:0.2755 | AUC:0.8341 Anomaly AUC:0.6555
[2023-08-27 13:52:05,106][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.1868 loss2:0.8484 loss3:0.1344 | AUC:0.8453 Anomaly AUC:0.6867
[2023-08-27 13:52:29,717][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0752 loss2:0.7170 loss3:0.0750 | AUC:0.8504 Anomaly AUC:0.6723
[2023-08-27 13:52:52,350][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0618 loss2:0.6477 loss3:0.0598 | AUC:0.8441 Anomaly AUC:0.6832
[2023-08-27 13:53:14,516][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0375 loss2:0.5669 loss3:0.0495 | AUC:0.8550 Anomaly AUC:0.6899
[2023-08-27 13:53:35,481][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0271 loss2:0.4914 loss3:0.0410 | AUC:0.8442 Anomaly AUC:0.6868
[2023-08-27 13:53:59,265][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0157 loss2:0.4043 loss3:0.0375 | AUC:0.8448 Anomaly AUC:0.6703
[2023-08-27 13:54:24,106][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0153 loss2:0.3269 loss3:0.0322 | AUC:0.8493 Anomaly AUC:0.6834
[2023-08-27 13:54:45,169][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0138 loss2:0.2554 loss3:0.0296 | AUC:0.8382 Anomaly AUC:0.6575
[2023-08-27 13:55:07,384][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0119 loss2:0.1962 loss3:0.0279 | AUC:0.8483 Anomaly AUC:0.6797
[2023-08-27 13:55:28,744][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0108 loss2:0.1496 loss3:0.0250 | AUC:0.8403 Anomaly AUC:0.6669
[2023-08-27 13:55:54,101][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0168 loss2:0.1393 loss3:0.0271 | AUC:0.8560 Anomaly AUC:0.6802
[2023-08-27 13:56:19,545][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0174 loss2:0.1157 loss3:0.0272 | AUC:0.8307 Anomaly AUC:0.6297
[2023-08-27 13:56:40,521][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0153 loss2:0.0957 loss3:0.0243 | AUC:0.8346 Anomaly AUC:0.6446
[2023-08-27 13:57:02,029][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0116 loss2:0.0739 loss3:0.0220 | AUC:0.8365 Anomaly AUC:0.6240
[2023-08-27 13:57:02,032][main-autotune.py][line:117][INFO] Training completes in 5m 42s | best AUCAUC:0.8560 Anomaly AUC:0.6802

[2023-08-27 13:57:23,022][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.2798 loss2:0.9660 loss3:0.4823 | AUC:0.7982 Anomaly AUC:0.6971
[2023-08-27 13:57:48,249][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0061 loss2:0.5902 loss3:0.4537 | AUC:0.7967 Anomaly AUC:0.6934
[2023-08-27 13:58:13,787][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0042 loss2:0.4188 loss3:0.4305 | AUC:0.7997 Anomaly AUC:0.7003
[2023-08-27 13:58:34,861][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0011 loss2:0.2279 loss3:0.3724 | AUC:0.8297 Anomaly AUC:0.6867
[2023-08-27 13:59:01,454][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0008 loss2:0.1082 loss3:0.3414 | AUC:0.8422 Anomaly AUC:0.6859
[2023-08-27 13:59:26,675][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0014 loss2:0.0868 loss3:0.3453 | AUC:0.7495 Anomaly AUC:0.6516
[2023-08-27 13:59:47,641][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0005 loss2:0.0569 loss3:0.3293 | AUC:0.8270 Anomaly AUC:0.6833
[2023-08-27 14:00:13,112][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0004 loss2:0.0278 loss3:0.2890 | AUC:0.8242 Anomaly AUC:0.6823
[2023-08-27 14:00:34,030][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.3410 loss2:0.3233 loss3:0.8479 | AUC:0.6102 Anomaly AUC:0.6313
[2023-08-27 14:00:57,473][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0020 loss2:0.3067 loss3:0.4366 | AUC:0.7369 Anomaly AUC:0.6375
[2023-08-27 14:01:20,223][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0010 loss2:0.0532 loss3:0.3425 | AUC:0.7907 Anomaly AUC:0.6565
[2023-08-27 14:01:41,919][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0008 loss2:0.0250 loss3:0.3107 | AUC:0.7996 Anomaly AUC:0.6547
[2023-08-27 14:02:03,043][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0009 loss2:0.0175 loss3:0.2854 | AUC:0.7692 Anomaly AUC:0.6506
[2023-08-27 14:02:25,994][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0010 loss2:0.0189 loss3:0.2738 | AUC:0.8099 Anomaly AUC:0.6528
[2023-08-27 14:02:47,159][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0005 loss2:0.0132 loss3:0.2507 | AUC:0.7995 Anomaly AUC:0.6434
[2023-08-27 14:02:47,161][main-autotune.py][line:117][INFO] Training completes in 5m 45s | best AUCAUC:0.8422 Anomaly AUC:0.6859

[2023-08-27 14:03:14,181][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.3842 loss2:1.0400 loss3:0.1772 | AUC:0.8083 Anomaly AUC:0.6541
[2023-08-27 14:03:37,731][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.1565 loss2:0.7953 loss3:0.0415 | AUC:0.8347 Anomaly AUC:0.6574
[2023-08-27 14:03:59,914][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0886 loss2:0.6898 loss3:0.0210 | AUC:0.8033 Anomaly AUC:0.6624
[2023-08-27 14:04:23,559][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0404 loss2:0.5814 loss3:0.0110 | AUC:0.8399 Anomaly AUC:0.6735
[2023-08-27 14:04:45,622][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0349 loss2:0.5035 loss3:0.0085 | AUC:0.8441 Anomaly AUC:0.6612
[2023-08-27 14:05:14,313][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0295 loss2:0.4357 loss3:0.0074 | AUC:0.8407 Anomaly AUC:0.6789
[2023-08-27 14:05:42,066][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0116 loss2:0.3424 loss3:0.0036 | AUC:0.8327 Anomaly AUC:0.6571
[2023-08-27 14:06:06,680][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0148 loss2:0.2883 loss3:0.0042 | AUC:0.8335 Anomaly AUC:0.6490
[2023-08-27 14:06:27,740][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0061 loss2:0.2214 loss3:0.0023 | AUC:0.8326 Anomaly AUC:0.6442
[2023-08-27 14:06:55,456][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0081 loss2:0.1927 loss3:0.0028 | AUC:0.8286 Anomaly AUC:0.6333
[2023-08-27 14:07:20,796][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0085 loss2:0.1679 loss3:0.0026 | AUC:0.8177 Anomaly AUC:0.6689
[2023-08-27 14:07:41,827][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0158 loss2:0.1635 loss3:0.0038 | AUC:0.8303 Anomaly AUC:0.6674
[2023-08-27 14:08:06,649][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0114 loss2:0.1458 loss3:0.0034 | AUC:0.8316 Anomaly AUC:0.6573
[2023-08-27 14:08:27,801][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0111 loss2:0.1207 loss3:0.0027 | AUC:0.8373 Anomaly AUC:0.6586
[2023-08-27 14:08:50,468][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0112 loss2:0.1119 loss3:0.0028 | AUC:0.8346 Anomaly AUC:0.6690
[2023-08-27 14:08:50,471][main-autotune.py][line:117][INFO] Training completes in 6m 3s | best AUCAUC:0.8441 Anomaly AUC:0.6612

[2023-08-27 14:09:11,428][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.3669 loss2:1.1213 loss3:0.1952 | AUC:0.8451 Anomaly AUC:0.6575
[2023-08-27 14:09:36,628][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.1518 loss2:0.8897 loss3:0.0453 | AUC:0.8265 Anomaly AUC:0.6824
[2023-08-27 14:10:03,697][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0660 loss2:0.7708 loss3:0.0169 | AUC:0.8468 Anomaly AUC:0.6693
[2023-08-27 14:10:30,982][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0351 loss2:0.6952 loss3:0.0089 | AUC:0.8348 Anomaly AUC:0.6726
[2023-08-27 14:10:59,345][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0366 loss2:0.6386 loss3:0.0084 | AUC:0.8413 Anomaly AUC:0.6684
[2023-08-27 14:11:25,526][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0227 loss2:0.5513 loss3:0.0057 | AUC:0.8480 Anomaly AUC:0.6637
[2023-08-27 14:11:48,475][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0165 loss2:0.4572 loss3:0.0039 | AUC:0.8546 Anomaly AUC:0.6855
[2023-08-27 14:12:10,559][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0170 loss2:0.3752 loss3:0.0039 | AUC:0.8259 Anomaly AUC:0.6786
[2023-08-27 14:12:37,310][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0180 loss2:0.2939 loss3:0.0051 | AUC:0.8331 Anomaly AUC:0.6581
[2023-08-27 14:12:58,420][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0166 loss2:0.2335 loss3:0.0043 | AUC:0.8461 Anomaly AUC:0.6834
[2023-08-27 14:13:21,434][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0199 loss2:0.1746 loss3:0.0048 | AUC:0.8326 Anomaly AUC:0.6653
[2023-08-27 14:13:48,723][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0143 loss2:0.1415 loss3:0.0039 | AUC:0.8458 Anomaly AUC:0.6663
[2023-08-27 14:14:09,672][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0314 loss2:0.1284 loss3:0.0077 | AUC:0.8427 Anomaly AUC:0.6813
[2023-08-27 14:14:32,750][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0137 loss2:0.0965 loss3:0.0037 | AUC:0.8359 Anomaly AUC:0.6884
[2023-08-27 14:14:53,697][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0094 loss2:0.0517 loss3:0.0023 | AUC:0.8462 Anomaly AUC:0.6586
[2023-08-27 14:14:53,700][main-autotune.py][line:117][INFO] Training completes in 6m 3s | best AUCAUC:0.8546 Anomaly AUC:0.6855

[2023-08-27 14:15:19,051][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00100 | loss1:0.2894 loss2:1.0341 loss3:0.4155 | AUC:0.8000 Anomaly AUC:0.6996
[2023-08-27 14:15:40,404][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00100 | loss1:0.0047 loss2:0.6703 loss3:0.3918 | AUC:0.8148 Anomaly AUC:0.7110
[2023-08-27 14:16:04,220][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00100 | loss1:0.0071 loss2:0.5114 loss3:0.3747 | AUC:0.8052 Anomaly AUC:0.6896
[2023-08-27 14:16:25,201][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00100 | loss1:0.0021 loss2:0.3149 loss3:0.3413 | AUC:0.8072 Anomaly AUC:0.6925
[2023-08-27 14:16:49,725][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00100 | loss1:0.0016 loss2:0.1951 loss3:0.3269 | AUC:0.8318 Anomaly AUC:0.6860
[2023-08-27 14:17:12,861][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00100 | loss1:0.0024 loss2:0.1073 loss3:0.2753 | AUC:0.6954 Anomaly AUC:0.6537
[2023-08-27 14:17:35,128][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00100 | loss1:0.0023 loss2:0.1148 loss3:0.2640 | AUC:0.8325 Anomaly AUC:0.6977
[2023-08-27 14:18:01,587][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00100 | loss1:0.0014 loss2:0.0435 loss3:0.1665 | AUC:0.8273 Anomaly AUC:0.6936
[2023-08-27 14:18:29,384][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00100 | loss1:0.0925 loss2:0.1896 loss3:0.3504 | AUC:0.5841 Anomaly AUC:0.5025
[2023-08-27 14:18:50,158][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00100 | loss1:0.0023 loss2:0.3032 loss3:0.2884 | AUC:0.8208 Anomaly AUC:0.6768
[2023-08-27 14:19:14,719][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00100 | loss1:0.0014 loss2:0.1331 loss3:0.1646 | AUC:0.8298 Anomaly AUC:0.6730
[2023-08-27 14:19:35,783][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00100 | loss1:0.0008 loss2:0.0490 loss3:0.1270 | AUC:0.8394 Anomaly AUC:0.6789
[2023-08-27 14:19:59,394][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00100 | loss1:0.0017 loss2:0.0313 loss3:0.1111 | AUC:0.8283 Anomaly AUC:0.6922
[2023-08-27 14:20:26,613][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00100 | loss1:0.0005 loss2:0.0208 loss3:0.0981 | AUC:0.8414 Anomaly AUC:0.6773
[2023-08-27 14:20:49,765][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00100 | loss1:0.0008 loss2:0.0156 loss3:0.0826 | AUC:0.8396 Anomaly AUC:0.6964
[2023-08-27 14:20:49,767][main-autotune.py][line:117][INFO] Training completes in 5m 56s | best AUCAUC:0.8414 Anomaly AUC:0.6773

[2023-08-27 14:21:11,737][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00080 | loss1:0.3402 loss2:1.1020 loss3:0.3186 | AUC:0.8178 Anomaly AUC:0.6450
[2023-08-27 14:21:39,404][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00080 | loss1:0.0282 loss2:0.7949 loss3:0.1949 | AUC:0.8161 Anomaly AUC:0.6750
[2023-08-27 14:22:06,432][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00080 | loss1:0.0337 loss2:0.7290 loss3:0.1252 | AUC:0.8385 Anomaly AUC:0.6886
[2023-08-27 14:22:33,802][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00080 | loss1:0.0085 loss2:0.5941 loss3:0.0403 | AUC:0.8313 Anomaly AUC:0.6646
[2023-08-27 14:22:57,053][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00080 | loss1:0.0035 loss2:0.4618 loss3:0.0263 | AUC:0.8393 Anomaly AUC:0.6523
[2023-08-27 14:23:19,228][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00080 | loss1:0.0142 loss2:0.4069 loss3:0.0367 | AUC:0.7495 Anomaly AUC:0.5089
[2023-08-27 14:23:48,253][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00080 | loss1:0.0074 loss2:0.3245 loss3:0.0278 | AUC:0.8194 Anomaly AUC:0.6446
[2023-08-27 14:24:17,201][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00080 | loss1:0.0027 loss2:0.2080 loss3:0.0233 | AUC:0.8262 Anomaly AUC:0.6346
[2023-08-27 14:24:39,907][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00080 | loss1:0.0006 loss2:0.1069 loss3:0.0109 | AUC:0.8378 Anomaly AUC:0.6557
[2023-08-27 14:25:01,740][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00080 | loss1:0.0003 loss2:0.0613 loss3:0.0083 | AUC:0.8256 Anomaly AUC:0.6298
[2023-08-27 14:25:22,794][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00080 | loss1:0.0003 loss2:0.0396 loss3:0.0074 | AUC:0.8348 Anomaly AUC:0.6383
[2023-08-27 14:25:46,517][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00080 | loss1:0.0059 loss2:0.0708 loss3:0.0124 | AUC:0.8041 Anomaly AUC:0.6289
[2023-08-27 14:26:09,569][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00080 | loss1:0.0167 loss2:0.2131 loss3:0.0476 | AUC:0.6680 Anomaly AUC:0.4924
[2023-08-27 14:26:31,136][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00080 | loss1:0.0008 loss2:0.0441 loss3:0.0120 | AUC:0.7674 Anomaly AUC:0.5247
[2023-08-27 14:26:56,311][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00080 | loss1:0.0002 loss2:0.0221 loss3:0.0076 | AUC:0.7262 Anomaly AUC:0.4859
[2023-08-27 14:26:56,314][main-autotune.py][line:117][INFO] Training completes in 6m 6s | best AUCAUC:0.8393 Anomaly AUC:0.6523

[2023-08-27 14:27:17,354][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.3070 loss2:1.0126 loss3:0.3265 | AUC:0.8263 Anomaly AUC:0.6942
[2023-08-27 14:27:45,993][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0105 loss2:0.6552 loss3:0.1817 | AUC:0.8324 Anomaly AUC:0.6782
[2023-08-27 14:28:06,701][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0655 loss2:0.4469 loss3:0.1546 | AUC:0.7519 Anomaly AUC:0.6406
[2023-08-27 14:28:31,213][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0241 loss2:0.5244 loss3:0.2332 | AUC:0.8178 Anomaly AUC:0.6874
[2023-08-27 14:28:54,334][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0025 loss2:0.3457 loss3:0.0824 | AUC:0.8324 Anomaly AUC:0.6794
[2023-08-27 14:29:16,633][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0057 loss2:0.2477 loss3:0.1049 | AUC:0.8233 Anomaly AUC:0.6749
[2023-08-27 14:29:43,320][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0024 loss2:0.1337 loss3:0.0769 | AUC:0.8113 Anomaly AUC:0.6526
[2023-08-27 14:30:11,944][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0021 loss2:0.0859 loss3:0.0747 | AUC:0.8223 Anomaly AUC:0.6565
[2023-08-27 14:30:35,191][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.1114 loss2:0.4552 loss3:0.2268 | AUC:0.8307 Anomaly AUC:0.6652
[2023-08-27 14:30:57,531][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0032 loss2:0.1295 loss3:0.0879 | AUC:0.8160 Anomaly AUC:0.6687
[2023-08-27 14:31:18,597][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0030 loss2:0.0691 loss3:0.0781 | AUC:0.8267 Anomaly AUC:0.6550
[2023-08-27 14:31:42,547][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0017 loss2:0.0419 loss3:0.0584 | AUC:0.8286 Anomaly AUC:0.6679
[2023-08-27 14:32:03,653][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0028 loss2:0.0391 loss3:0.0734 | AUC:0.8028 Anomaly AUC:0.6577
[2023-08-27 14:32:27,257][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0022 loss2:0.0265 loss3:0.0539 | AUC:0.8116 Anomaly AUC:0.6531
[2023-08-27 14:32:55,018][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0019 loss2:0.0316 loss3:0.0612 | AUC:0.8309 Anomaly AUC:0.6610
[2023-08-27 14:32:55,024][main-autotune.py][line:117][INFO] Training completes in 5m 59s | best AUCAUC:0.8324 Anomaly AUC:0.6794

[2023-08-27 14:33:18,142][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.3967 loss2:1.1156 loss3:0.2117 | AUC:0.8287 Anomaly AUC:0.6401
[2023-08-27 14:33:40,808][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.1669 loss2:0.8599 loss3:0.0510 | AUC:0.8424 Anomaly AUC:0.6687
[2023-08-27 14:34:04,621][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0633 loss2:0.7449 loss3:0.0182 | AUC:0.8373 Anomaly AUC:0.6704
[2023-08-27 14:34:25,566][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0308 loss2:0.6623 loss3:0.0088 | AUC:0.8515 Anomaly AUC:0.6680
[2023-08-27 14:34:50,933][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0258 loss2:0.5932 loss3:0.0073 | AUC:0.8549 Anomaly AUC:0.6887
[2023-08-27 14:35:11,833][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0244 loss2:0.5292 loss3:0.0062 | AUC:0.8389 Anomaly AUC:0.6853
[2023-08-27 14:35:38,049][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0134 loss2:0.4604 loss3:0.0046 | AUC:0.8540 Anomaly AUC:0.6937
[2023-08-27 14:36:01,357][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0263 loss2:0.4450 loss3:0.0068 | AUC:0.8394 Anomaly AUC:0.6898
[2023-08-27 14:36:23,697][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0144 loss2:0.3718 loss3:0.0040 | AUC:0.8465 Anomaly AUC:0.6949
[2023-08-27 14:36:51,927][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0063 loss2:0.3108 loss3:0.0025 | AUC:0.8535 Anomaly AUC:0.7041
[2023-08-27 14:37:19,820][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0075 loss2:0.2739 loss3:0.0029 | AUC:0.8483 Anomaly AUC:0.6782
[2023-08-27 14:37:42,596][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0159 loss2:0.2731 loss3:0.0049 | AUC:0.8565 Anomaly AUC:0.6904
[2023-08-27 14:38:04,915][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0031 loss2:0.2008 loss3:0.0020 | AUC:0.8621 Anomaly AUC:0.7130
[2023-08-27 14:38:26,214][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0032 loss2:0.1733 loss3:0.0020 | AUC:0.8530 Anomaly AUC:0.6888
[2023-08-27 14:38:50,058][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0083 loss2:0.1752 loss3:0.0036 | AUC:0.8580 Anomaly AUC:0.6916
[2023-08-27 14:38:50,060][main-autotune.py][line:117][INFO] Training completes in 5m 55s | best AUCAUC:0.8621 Anomaly AUC:0.7130

[2023-08-27 14:39:20,357][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00090 | loss1:0.3078 loss2:1.0171 loss3:0.3940 | AUC:0.8090 Anomaly AUC:0.6843
[2023-08-27 14:39:41,594][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00090 | loss1:0.0045 loss2:0.6767 loss3:0.4636 | AUC:0.8162 Anomaly AUC:0.7075
[2023-08-27 14:40:06,664][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00090 | loss1:0.0017 loss2:0.5002 loss3:0.4504 | AUC:0.8065 Anomaly AUC:0.6898
[2023-08-27 14:40:32,309][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00090 | loss1:0.0010 loss2:0.3430 loss3:0.4335 | AUC:0.8082 Anomaly AUC:0.6934
[2023-08-27 14:40:53,285][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00090 | loss1:0.0119 loss2:0.3368 loss3:0.5249 | AUC:0.7309 Anomaly AUC:0.6664
[2023-08-27 14:41:19,745][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00090 | loss1:0.0005 loss2:0.1605 loss3:0.5061 | AUC:0.7080 Anomaly AUC:0.6472
[2023-08-27 14:41:43,000][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00090 | loss1:0.0004 loss2:0.0903 loss3:0.4609 | AUC:0.7349 Anomaly AUC:0.6640
[2023-08-27 14:42:05,114][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00090 | loss1:0.0003 loss2:0.0545 loss3:0.4383 | AUC:0.7328 Anomaly AUC:0.6578
[2023-08-27 14:42:33,940][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00090 | loss1:0.0002 loss2:0.0361 loss3:0.4231 | AUC:0.7490 Anomaly AUC:0.6624
[2023-08-27 14:42:55,145][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00090 | loss1:0.0002 loss2:0.0250 loss3:0.4130 | AUC:0.7503 Anomaly AUC:0.6574
[2023-08-27 14:43:19,025][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00090 | loss1:0.0002 loss2:0.0192 loss3:0.4057 | AUC:0.7634 Anomaly AUC:0.6672
[2023-08-27 14:43:40,124][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00090 | loss1:0.0001 loss2:0.0142 loss3:0.4001 | AUC:0.7619 Anomaly AUC:0.6649
[2023-08-27 14:44:03,879][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00090 | loss1:0.0001 loss2:0.0117 loss3:0.3956 | AUC:0.7692 Anomaly AUC:0.6709
[2023-08-27 14:44:25,166][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00090 | loss1:0.0001 loss2:0.0112 loss3:0.3915 | AUC:0.7607 Anomaly AUC:0.6637
[2023-08-27 14:44:48,930][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00090 | loss1:0.0001 loss2:0.0076 loss3:0.3879 | AUC:0.7647 Anomaly AUC:0.6557
[2023-08-27 14:44:48,932][main-autotune.py][line:117][INFO] Training completes in 5m 59s | best AUCAUC:0.8162 Anomaly AUC:0.7075

[2023-08-27 14:45:12,147][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.3669 loss2:1.0099 loss3:0.2965 | AUC:0.8198 Anomaly AUC:0.6463
[2023-08-27 14:45:34,412][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.1462 loss2:0.7587 loss3:0.1148 | AUC:0.8222 Anomaly AUC:0.6701
[2023-08-27 14:46:02,441][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0782 loss2:0.6329 loss3:0.0671 | AUC:0.8412 Anomaly AUC:0.6665
[2023-08-27 14:46:32,731][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0330 loss2:0.4968 loss3:0.0430 | AUC:0.8381 Anomaly AUC:0.6874
[2023-08-27 14:46:56,335][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0325 loss2:0.4111 loss3:0.0362 | AUC:0.8462 Anomaly AUC:0.6819
[2023-08-27 14:47:17,458][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0315 loss2:0.3144 loss3:0.0299 | AUC:0.8221 Anomaly AUC:0.6478
[2023-08-27 14:47:40,421][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0157 loss2:0.2157 loss3:0.0232 | AUC:0.7859 Anomaly AUC:0.6335
[2023-08-27 14:48:02,545][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0202 loss2:0.1832 loss3:0.0221 | AUC:0.8337 Anomaly AUC:0.6554
[2023-08-27 14:48:31,531][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0168 loss2:0.1167 loss3:0.0205 | AUC:0.8309 Anomaly AUC:0.6466
[2023-08-27 14:48:54,385][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0165 loss2:0.0941 loss3:0.0211 | AUC:0.8387 Anomaly AUC:0.6727
[2023-08-27 14:49:17,003][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0059 loss2:0.0558 loss3:0.0172 | AUC:0.8392 Anomaly AUC:0.6660
[2023-08-27 14:49:38,339][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0115 loss2:0.0603 loss3:0.0182 | AUC:0.8351 Anomaly AUC:0.6501
[2023-08-27 14:50:02,351][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0118 loss2:0.0570 loss3:0.0189 | AUC:0.8090 Anomaly AUC:0.6371
[2023-08-27 14:50:23,583][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0158 loss2:0.0505 loss3:0.0186 | AUC:0.8271 Anomaly AUC:0.6088
[2023-08-27 14:50:47,445][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0104 loss2:0.0434 loss3:0.0184 | AUC:0.8221 Anomaly AUC:0.6474
[2023-08-27 14:50:47,449][main-autotune.py][line:117][INFO] Training completes in 5m 58s | best AUCAUC:0.8462 Anomaly AUC:0.6819

[2023-08-27 14:51:10,952][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.3891 loss2:1.2537 loss3:0.2212 | AUC:0.8147 Anomaly AUC:0.6024
[2023-08-27 14:51:32,638][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.1706 loss2:1.0691 loss3:0.0638 | AUC:0.8245 Anomaly AUC:0.6246
[2023-08-27 14:51:57,585][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0774 loss2:0.9638 loss3:0.0280 | AUC:0.8421 Anomaly AUC:0.6441
[2023-08-27 14:52:18,536][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0525 loss2:0.9248 loss3:0.0196 | AUC:0.8450 Anomaly AUC:0.6661
[2023-08-27 14:52:45,642][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0227 loss2:0.8627 loss3:0.0084 | AUC:0.8575 Anomaly AUC:0.6859
[2023-08-27 14:53:15,428][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0152 loss2:0.8404 loss3:0.0057 | AUC:0.8460 Anomaly AUC:0.6497
[2023-08-27 14:53:44,262][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0191 loss2:0.8329 loss3:0.0069 | AUC:0.8421 Anomaly AUC:0.6528
[2023-08-27 14:54:12,793][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0097 loss2:0.8175 loss3:0.0049 | AUC:0.8356 Anomaly AUC:0.6455
[2023-08-27 14:54:35,569][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0093 loss2:0.8052 loss3:0.0048 | AUC:0.8446 Anomaly AUC:0.6742
[2023-08-27 14:54:57,751][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0149 loss2:0.7912 loss3:0.0051 | AUC:0.8495 Anomaly AUC:0.6573
[2023-08-27 14:55:18,781][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0037 loss2:0.7692 loss3:0.0024 | AUC:0.8592 Anomaly AUC:0.6954
[2023-08-27 14:55:42,521][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0096 loss2:0.7550 loss3:0.0037 | AUC:0.8204 Anomaly AUC:0.6452
[2023-08-27 14:56:03,588][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0140 loss2:0.7535 loss3:0.0055 | AUC:0.8492 Anomaly AUC:0.6768
[2023-08-27 14:56:27,204][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0115 loss2:0.7397 loss3:0.0044 | AUC:0.8427 Anomaly AUC:0.6696
[2023-08-27 14:56:55,010][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0102 loss2:0.7218 loss3:0.0034 | AUC:0.8389 Anomaly AUC:0.6784
[2023-08-27 14:56:55,013][main-autotune.py][line:117][INFO] Training completes in 6m 7s | best AUCAUC:0.8592 Anomaly AUC:0.6954

[2023-08-27 14:57:16,005][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.3708 loss2:1.3609 loss3:0.2533 | AUC:0.7962 Anomaly AUC:0.5987
[2023-08-27 14:57:41,460][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.1654 loss2:1.2871 loss3:0.1015 | AUC:0.8037 Anomaly AUC:0.6001
[2023-08-27 14:58:09,329][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0835 loss2:1.2211 loss3:0.0507 | AUC:0.8240 Anomaly AUC:0.6169
[2023-08-27 14:58:39,900][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0516 loss2:1.1894 loss3:0.0275 | AUC:0.8161 Anomaly AUC:0.6204
[2023-08-27 14:59:05,288][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0230 loss2:1.0741 loss3:0.0128 | AUC:0.8292 Anomaly AUC:0.6236
[2023-08-27 14:59:26,291][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0220 loss2:1.0328 loss3:0.0109 | AUC:0.8349 Anomaly AUC:0.6269
[2023-08-27 14:59:53,676][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0134 loss2:0.9914 loss3:0.0077 | AUC:0.8373 Anomaly AUC:0.6327
[2023-08-27 15:00:20,304][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0123 loss2:0.9473 loss3:0.0066 | AUC:0.8295 Anomaly AUC:0.6185
[2023-08-27 15:00:43,364][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0129 loss2:0.9378 loss3:0.0068 | AUC:0.8295 Anomaly AUC:0.6267
[2023-08-27 15:01:05,389][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0056 loss2:0.9068 loss3:0.0040 | AUC:0.8461 Anomaly AUC:0.6623
[2023-08-27 15:01:26,487][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0099 loss2:0.8900 loss3:0.0041 | AUC:0.8331 Anomaly AUC:0.6492
[2023-08-27 15:01:50,288][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0148 loss2:0.8897 loss3:0.0060 | AUC:0.8399 Anomaly AUC:0.6524
[2023-08-27 15:02:11,424][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0099 loss2:0.8765 loss3:0.0045 | AUC:0.8429 Anomaly AUC:0.6518
[2023-08-27 15:02:34,917][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0079 loss2:0.8607 loss3:0.0032 | AUC:0.8343 Anomaly AUC:0.6481
[2023-08-27 15:02:56,011][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0103 loss2:0.8512 loss3:0.0034 | AUC:0.8444 Anomaly AUC:0.6383
[2023-08-27 15:02:56,014][main-autotune.py][line:117][INFO] Training completes in 6m 1s | best AUCAUC:0.8461 Anomaly AUC:0.6623

[2023-08-27 15:03:21,089][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.3756 loss2:1.2575 loss3:0.2339 | AUC:0.8098 Anomaly AUC:0.6064
[2023-08-27 15:03:46,146][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.1577 loss2:1.0754 loss3:0.0674 | AUC:0.8467 Anomaly AUC:0.6375
[2023-08-27 15:04:07,219][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0747 loss2:0.9499 loss3:0.0260 | AUC:0.8444 Anomaly AUC:0.6478
[2023-08-27 15:04:34,046][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0355 loss2:0.8876 loss3:0.0121 | AUC:0.8409 Anomaly AUC:0.6746
[2023-08-27 15:05:01,150][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0273 loss2:0.8532 loss3:0.0077 | AUC:0.8290 Anomaly AUC:0.6703
[2023-08-27 15:05:26,707][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0184 loss2:0.8382 loss3:0.0055 | AUC:0.8364 Anomaly AUC:0.6770
[2023-08-27 15:05:47,739][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0145 loss2:0.8216 loss3:0.0040 | AUC:0.8228 Anomaly AUC:0.6827
[2023-08-27 15:06:14,056][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0096 loss2:0.8128 loss3:0.0028 | AUC:0.8405 Anomaly AUC:0.6949
[2023-08-27 15:06:42,698][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0171 loss2:0.8113 loss3:0.0044 | AUC:0.8291 Anomaly AUC:0.6772
[2023-08-27 15:07:10,871][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0095 loss2:0.7979 loss3:0.0028 | AUC:0.8090 Anomaly AUC:0.6835
[2023-08-27 15:07:34,047][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0126 loss2:0.7919 loss3:0.0029 | AUC:0.8325 Anomaly AUC:0.6839
[2023-08-27 15:07:56,102][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0099 loss2:0.7799 loss3:0.0022 | AUC:0.8356 Anomaly AUC:0.6805
[2023-08-27 15:08:17,240][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0148 loss2:0.7715 loss3:0.0046 | AUC:0.8154 Anomaly AUC:0.6802
[2023-08-27 15:08:40,911][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0205 loss2:0.7751 loss3:0.0051 | AUC:0.8369 Anomaly AUC:0.6700
[2023-08-27 15:09:02,093][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0048 loss2:0.7490 loss3:0.0015 | AUC:0.8229 Anomaly AUC:0.6594
[2023-08-27 15:09:02,096][main-autotune.py][line:117][INFO] Training completes in 6m 6s | best AUCAUC:0.8467 Anomaly AUC:0.6375

[2023-08-27 15:09:27,733][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.3831 loss2:1.1637 loss3:0.1995 | AUC:0.8396 Anomaly AUC:0.6436
[2023-08-27 15:09:58,502][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.1623 loss2:0.9598 loss3:0.0464 | AUC:0.8429 Anomaly AUC:0.6829
[2023-08-27 15:10:19,524][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0704 loss2:0.8528 loss3:0.0178 | AUC:0.8535 Anomaly AUC:0.6822
[2023-08-27 15:10:44,722][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0413 loss2:0.7847 loss3:0.0105 | AUC:0.8508 Anomaly AUC:0.6907
[2023-08-27 15:11:08,346][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0251 loss2:0.7354 loss3:0.0068 | AUC:0.8500 Anomaly AUC:0.6858
[2023-08-27 15:11:30,796][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0147 loss2:0.6875 loss3:0.0047 | AUC:0.8509 Anomaly AUC:0.6977
[2023-08-27 15:11:54,317][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0165 loss2:0.6398 loss3:0.0039 | AUC:0.8507 Anomaly AUC:0.6888
[2023-08-27 15:12:16,758][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0117 loss2:0.5778 loss3:0.0027 | AUC:0.8426 Anomaly AUC:0.6857
[2023-08-27 15:12:45,516][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0141 loss2:0.5464 loss3:0.0035 | AUC:0.8478 Anomaly AUC:0.6815
[2023-08-27 15:13:06,628][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0145 loss2:0.4879 loss3:0.0034 | AUC:0.8450 Anomaly AUC:0.6812
[2023-08-27 15:13:30,852][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0133 loss2:0.4362 loss3:0.0031 | AUC:0.8446 Anomaly AUC:0.6743
[2023-08-27 15:13:52,139][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0142 loss2:0.4019 loss3:0.0032 | AUC:0.8517 Anomaly AUC:0.6744
[2023-08-27 15:14:15,900][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0136 loss2:0.3478 loss3:0.0031 | AUC:0.8515 Anomaly AUC:0.6750
[2023-08-27 15:14:37,031][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0053 loss2:0.2860 loss3:0.0016 | AUC:0.8588 Anomaly AUC:0.6855
[2023-08-27 15:15:01,089][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0032 loss2:0.2227 loss3:0.0011 | AUC:0.8535 Anomaly AUC:0.6748
[2023-08-27 15:15:01,092][main-autotune.py][line:117][INFO] Training completes in 5m 59s | best AUCAUC:0.8588 Anomaly AUC:0.6855

[2023-08-27 15:15:22,171][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.3674 loss2:1.0536 loss3:0.2583 | AUC:0.8063 Anomaly AUC:0.6495
[2023-08-27 15:15:48,094][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.1416 loss2:0.8017 loss3:0.0752 | AUC:0.8453 Anomaly AUC:0.6814
[2023-08-27 15:16:08,934][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0567 loss2:0.6813 loss3:0.0294 | AUC:0.8330 Anomaly AUC:0.6795
[2023-08-27 15:16:32,944][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0320 loss2:0.5839 loss3:0.0176 | AUC:0.8224 Anomaly AUC:0.6758
[2023-08-27 15:16:59,908][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0168 loss2:0.4807 loss3:0.0103 | AUC:0.8222 Anomaly AUC:0.6791
[2023-08-27 15:17:25,211][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0213 loss2:0.4237 loss3:0.0080 | AUC:0.8188 Anomaly AUC:0.6787
[2023-08-27 15:17:46,276][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0110 loss2:0.3403 loss3:0.0046 | AUC:0.8337 Anomaly AUC:0.6643
[2023-08-27 15:18:15,512][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0131 loss2:0.2859 loss3:0.0046 | AUC:0.8354 Anomaly AUC:0.6863
[2023-08-27 15:18:38,792][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0089 loss2:0.2319 loss3:0.0036 | AUC:0.8462 Anomaly AUC:0.6956
[2023-08-27 15:19:01,067][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0059 loss2:0.1906 loss3:0.0029 | AUC:0.8560 Anomaly AUC:0.7050
[2023-08-27 15:19:24,152][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0032 loss2:0.1455 loss3:0.0022 | AUC:0.8542 Anomaly AUC:0.6996
[2023-08-27 15:19:46,304][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0028 loss2:0.1227 loss3:0.0023 | AUC:0.8573 Anomaly AUC:0.6963
[2023-08-27 15:20:07,400][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0006 loss2:0.0954 loss3:0.0015 | AUC:0.8566 Anomaly AUC:0.6957
[2023-08-27 15:20:31,690][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0002 loss2:0.0806 loss3:0.0014 | AUC:0.8565 Anomaly AUC:0.6935
[2023-08-27 15:20:58,106][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0002 loss2:0.0696 loss3:0.0013 | AUC:0.8590 Anomaly AUC:0.6981
[2023-08-27 15:20:58,107][main-autotune.py][line:117][INFO] Training completes in 5m 57s | best AUCAUC:0.8590 Anomaly AUC:0.6981

[2023-08-27 15:21:19,207][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.3774 loss2:1.1285 loss3:0.1815 | AUC:0.8348 Anomaly AUC:0.6563
[2023-08-27 15:21:45,272][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.1757 loss2:0.9035 loss3:0.0462 | AUC:0.8419 Anomaly AUC:0.6613
[2023-08-27 15:22:06,342][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.1021 loss2:0.8088 loss3:0.0231 | AUC:0.8503 Anomaly AUC:0.6680
[2023-08-27 15:22:31,580][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0456 loss2:0.7335 loss3:0.0111 | AUC:0.8459 Anomaly AUC:0.6656
[2023-08-27 15:23:01,772][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0305 loss2:0.6806 loss3:0.0077 | AUC:0.8497 Anomaly AUC:0.6642
[2023-08-27 15:23:25,041][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0223 loss2:0.6196 loss3:0.0054 | AUC:0.8516 Anomaly AUC:0.6793
[2023-08-27 15:23:46,868][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0173 loss2:0.5524 loss3:0.0042 | AUC:0.8474 Anomaly AUC:0.6607
[2023-08-27 15:24:10,897][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0171 loss2:0.4985 loss3:0.0039 | AUC:0.8469 Anomaly AUC:0.6699
[2023-08-27 15:24:32,175][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0153 loss2:0.4558 loss3:0.0037 | AUC:0.8470 Anomaly AUC:0.6717
[2023-08-27 15:25:00,395][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0092 loss2:0.3868 loss3:0.0026 | AUC:0.8536 Anomaly AUC:0.6763
[2023-08-27 15:25:23,875][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0148 loss2:0.3477 loss3:0.0038 | AUC:0.8347 Anomaly AUC:0.6674
[2023-08-27 15:25:45,735][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0130 loss2:0.3134 loss3:0.0033 | AUC:0.8378 Anomaly AUC:0.6624
[2023-08-27 15:26:12,548][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0061 loss2:0.2531 loss3:0.0022 | AUC:0.8383 Anomaly AUC:0.6609
[2023-08-27 15:26:33,684][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0101 loss2:0.2384 loss3:0.0032 | AUC:0.8280 Anomaly AUC:0.6451
[2023-08-27 15:26:57,903][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0096 loss2:0.2091 loss3:0.0028 | AUC:0.8430 Anomaly AUC:0.6620
[2023-08-27 15:26:57,909][main-autotune.py][line:117][INFO] Training completes in 5m 60s | best AUCAUC:0.8536 Anomaly AUC:0.6763

[2023-08-27 15:27:25,913][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.3772 loss2:1.1854 loss3:0.2210 | AUC:0.8292 Anomaly AUC:0.6230
[2023-08-27 15:27:49,845][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.1471 loss2:0.9798 loss3:0.0571 | AUC:0.8386 Anomaly AUC:0.6579
[2023-08-27 15:28:11,942][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0608 loss2:0.8603 loss3:0.0210 | AUC:0.8550 Anomaly AUC:0.6854
[2023-08-27 15:28:40,056][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0386 loss2:0.7906 loss3:0.0129 | AUC:0.8531 Anomaly AUC:0.6755
[2023-08-27 15:29:10,354][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0421 loss2:0.7558 loss3:0.0115 | AUC:0.8476 Anomaly AUC:0.6912
[2023-08-27 15:29:35,810][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0155 loss2:0.7000 loss3:0.0050 | AUC:0.8476 Anomaly AUC:0.6981
[2023-08-27 15:29:56,838][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0135 loss2:0.6556 loss3:0.0037 | AUC:0.8393 Anomaly AUC:0.6899
[2023-08-27 15:30:23,244][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0177 loss2:0.6145 loss3:0.0047 | AUC:0.8526 Anomaly AUC:0.6829
[2023-08-27 15:30:46,344][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0133 loss2:0.5734 loss3:0.0037 | AUC:0.8578 Anomaly AUC:0.6731
[2023-08-27 15:31:08,781][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0126 loss2:0.5252 loss3:0.0033 | AUC:0.8382 Anomaly AUC:0.6626
[2023-08-27 15:31:36,841][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0070 loss2:0.4435 loss3:0.0024 | AUC:0.8457 Anomaly AUC:0.6745
[2023-08-27 15:31:57,984][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0157 loss2:0.4216 loss3:0.0042 | AUC:0.8299 Anomaly AUC:0.6486
[2023-08-27 15:32:21,816][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0126 loss2:0.3985 loss3:0.0043 | AUC:0.8180 Anomaly AUC:0.6483
[2023-08-27 15:32:42,818][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0222 loss2:0.3493 loss3:0.0055 | AUC:0.8276 Anomaly AUC:0.6283
[2023-08-27 15:33:06,727][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0190 loss2:0.3421 loss3:0.0063 | AUC:0.8328 Anomaly AUC:0.6446
[2023-08-27 15:33:06,730][main-autotune.py][line:117][INFO] Training completes in 6m 9s | best AUCAUC:0.8578 Anomaly AUC:0.6731

[2023-08-27 15:33:27,700][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.3512 loss2:1.0532 loss3:0.2853 | AUC:0.8385 Anomaly AUC:0.6720
[2023-08-27 15:33:51,350][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.1219 loss2:0.7881 loss3:0.1234 | AUC:0.8253 Anomaly AUC:0.6612
[2023-08-27 15:34:12,339][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0453 loss2:0.6659 loss3:0.0515 | AUC:0.8276 Anomaly AUC:0.6708
[2023-08-27 15:34:39,503][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0470 loss2:0.5973 loss3:0.0363 | AUC:0.8252 Anomaly AUC:0.6649
[2023-08-27 15:35:06,675][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0117 loss2:0.4791 loss3:0.0209 | AUC:0.8372 Anomaly AUC:0.6741
[2023-08-27 15:35:36,345][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0262 loss2:0.4184 loss3:0.0210 | AUC:0.8515 Anomaly AUC:0.6832
[2023-08-27 15:36:06,047][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0124 loss2:0.3324 loss3:0.0153 | AUC:0.8425 Anomaly AUC:0.6683
[2023-08-27 15:36:31,403][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0127 loss2:0.2735 loss3:0.0137 | AUC:0.8469 Anomaly AUC:0.6753
[2023-08-27 15:36:52,509][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0034 loss2:0.1971 loss3:0.0088 | AUC:0.8587 Anomaly AUC:0.6898
[2023-08-27 15:37:15,827][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0109 loss2:0.1753 loss3:0.0085 | AUC:0.8508 Anomaly AUC:0.6744
[2023-08-27 15:37:37,421][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0196 loss2:0.1841 loss3:0.0104 | AUC:0.8475 Anomaly AUC:0.6772
[2023-08-27 15:38:04,989][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0080 loss2:0.1309 loss3:0.0060 | AUC:0.8476 Anomaly AUC:0.6813
[2023-08-27 15:38:26,096][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0008 loss2:0.0804 loss3:0.0015 | AUC:0.8515 Anomaly AUC:0.6911
[2023-08-27 15:38:50,389][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0007 loss2:0.0640 loss3:0.0013 | AUC:0.8448 Anomaly AUC:0.6810
[2023-08-27 15:39:15,986][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0002 loss2:0.0521 loss3:0.0011 | AUC:0.8415 Anomaly AUC:0.6709
[2023-08-27 15:39:15,989][main-autotune.py][line:117][INFO] Training completes in 6m 9s | best AUCAUC:0.8587 Anomaly AUC:0.6898

[2023-08-27 15:39:37,002][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00010 | loss1:0.3979 loss2:1.1427 loss3:0.1905 | AUC:0.8381 Anomaly AUC:0.6292
[2023-08-27 15:40:05,786][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00010 | loss1:0.1851 loss2:0.9349 loss3:0.0529 | AUC:0.8397 Anomaly AUC:0.6462
[2023-08-27 15:40:26,795][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00010 | loss1:0.0915 loss2:0.8196 loss3:0.0218 | AUC:0.8420 Anomaly AUC:0.6627
[2023-08-27 15:40:52,164][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00010 | loss1:0.0518 loss2:0.7663 loss3:0.0123 | AUC:0.8395 Anomaly AUC:0.6563
[2023-08-27 15:41:22,148][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00010 | loss1:0.0287 loss2:0.7182 loss3:0.0076 | AUC:0.8395 Anomaly AUC:0.6727
[2023-08-27 15:41:51,836][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00010 | loss1:0.0227 loss2:0.6790 loss3:0.0064 | AUC:0.8423 Anomaly AUC:0.6763
[2023-08-27 15:42:15,226][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00010 | loss1:0.0260 loss2:0.6450 loss3:0.0057 | AUC:0.8627 Anomaly AUC:0.6919
[2023-08-27 15:42:36,971][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00010 | loss1:0.0192 loss2:0.5998 loss3:0.0048 | AUC:0.8621 Anomaly AUC:0.7010
[2023-08-27 15:42:58,523][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00010 | loss1:0.0187 loss2:0.5656 loss3:0.0042 | AUC:0.8565 Anomaly AUC:0.6992
[2023-08-27 15:43:22,896][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00010 | loss1:0.0160 loss2:0.5277 loss3:0.0039 | AUC:0.8616 Anomaly AUC:0.6997
[2023-08-27 15:43:43,951][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00010 | loss1:0.0097 loss2:0.4760 loss3:0.0028 | AUC:0.8550 Anomaly AUC:0.6947
[2023-08-27 15:44:08,214][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00010 | loss1:0.0401 loss2:0.5135 loss3:0.0143 | AUC:0.8495 Anomaly AUC:0.6801
[2023-08-27 15:44:31,075][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00010 | loss1:0.0062 loss2:0.4209 loss3:0.0018 | AUC:0.8479 Anomaly AUC:0.6780
[2023-08-27 15:44:52,878][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00010 | loss1:0.0014 loss2:0.3628 loss3:0.0011 | AUC:0.8454 Anomaly AUC:0.6767
[2023-08-27 15:45:14,048][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00010 | loss1:0.0015 loss2:0.3177 loss3:0.0012 | AUC:0.8487 Anomaly AUC:0.6792
[2023-08-27 15:45:14,050][main-autotune.py][line:117][INFO] Training completes in 5m 58s | best AUCAUC:0.8627 Anomaly AUC:0.6919

[2023-08-27 15:45:39,261][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.3668 loss2:1.0851 loss3:0.1728 | AUC:0.8350 Anomaly AUC:0.6482
[2023-08-27 15:46:00,892][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.1405 loss2:0.8395 loss3:0.0379 | AUC:0.8456 Anomaly AUC:0.6791
[2023-08-27 15:46:26,581][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0667 loss2:0.7287 loss3:0.0154 | AUC:0.8407 Anomaly AUC:0.6670
[2023-08-27 15:46:48,171][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0428 loss2:0.6430 loss3:0.0103 | AUC:0.8435 Anomaly AUC:0.6865
[2023-08-27 15:47:13,152][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0352 loss2:0.5606 loss3:0.0076 | AUC:0.8318 Anomaly AUC:0.6847
[2023-08-27 15:47:40,439][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0242 loss2:0.4674 loss3:0.0057 | AUC:0.8582 Anomaly AUC:0.6877
[2023-08-27 15:48:03,838][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0219 loss2:0.3947 loss3:0.0052 | AUC:0.8595 Anomaly AUC:0.6908
[2023-08-27 15:48:25,555][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0176 loss2:0.2921 loss3:0.0037 | AUC:0.8426 Anomaly AUC:0.6820
[2023-08-27 15:48:53,096][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0157 loss2:0.2408 loss3:0.0046 | AUC:0.8533 Anomaly AUC:0.6848
[2023-08-27 15:49:16,471][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0144 loss2:0.1663 loss3:0.0034 | AUC:0.8269 Anomaly AUC:0.6621
[2023-08-27 15:49:38,520][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0088 loss2:0.1129 loss3:0.0024 | AUC:0.8508 Anomaly AUC:0.6873
[2023-08-27 15:50:07,188][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0008 loss2:0.0571 loss3:0.0008 | AUC:0.8542 Anomaly AUC:0.6936
[2023-08-27 15:50:33,446][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0139 loss2:0.0758 loss3:0.0037 | AUC:0.8485 Anomaly AUC:0.6974
[2023-08-27 15:50:54,707][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0306 loss2:0.1125 loss3:0.0072 | AUC:0.8344 Anomaly AUC:0.6588
[2023-08-27 15:51:18,756][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0141 loss2:0.0759 loss3:0.0035 | AUC:0.8423 Anomaly AUC:0.6706
[2023-08-27 15:51:18,759][main-autotune.py][line:117][INFO] Training completes in 6m 5s | best AUCAUC:0.8595 Anomaly AUC:0.6908

[2023-08-27 15:51:39,679][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.3906 loss2:1.0575 loss3:0.1666 | AUC:0.8286 Anomaly AUC:0.6598
[2023-08-27 15:52:05,888][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.1853 loss2:0.8357 loss3:0.0399 | AUC:0.8226 Anomaly AUC:0.6582
[2023-08-27 15:52:26,802][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0976 loss2:0.7403 loss3:0.0197 | AUC:0.8213 Anomaly AUC:0.6604
[2023-08-27 15:52:51,954][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0474 loss2:0.6621 loss3:0.0104 | AUC:0.8370 Anomaly AUC:0.6580
[2023-08-27 15:53:19,690][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0270 loss2:0.5798 loss3:0.0061 | AUC:0.8428 Anomaly AUC:0.6721
[2023-08-27 15:53:47,104][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0252 loss2:0.5190 loss3:0.0057 | AUC:0.8289 Anomaly AUC:0.6556
[2023-08-27 15:54:08,365][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0199 loss2:0.4596 loss3:0.0046 | AUC:0.8068 Anomaly AUC:0.6511
[2023-08-27 15:54:30,762][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0198 loss2:0.4105 loss3:0.0048 | AUC:0.8355 Anomaly AUC:0.6476
[2023-08-27 15:55:00,026][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0140 loss2:0.3418 loss3:0.0036 | AUC:0.8355 Anomaly AUC:0.6447
[2023-08-27 15:55:24,603][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0083 loss2:0.2871 loss3:0.0028 | AUC:0.8406 Anomaly AUC:0.6531
[2023-08-27 15:55:45,716][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0109 loss2:0.2504 loss3:0.0035 | AUC:0.8387 Anomaly AUC:0.6531
[2023-08-27 15:56:11,202][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0158 loss2:0.2464 loss3:0.0044 | AUC:0.8424 Anomaly AUC:0.6600
[2023-08-27 15:56:32,328][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0112 loss2:0.2055 loss3:0.0035 | AUC:0.8422 Anomaly AUC:0.6540
[2023-08-27 15:56:58,754][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0043 loss2:0.1691 loss3:0.0018 | AUC:0.8464 Anomaly AUC:0.6548
[2023-08-27 15:57:19,837][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0069 loss2:0.1632 loss3:0.0023 | AUC:0.8492 Anomaly AUC:0.6781
[2023-08-27 15:57:19,838][main-autotune.py][line:117][INFO] Training completes in 6m 1s | best AUCAUC:0.8492 Anomaly AUC:0.6781

[2023-08-27 15:57:43,481][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.3640 loss2:1.0715 loss3:0.1761 | AUC:0.8277 Anomaly AUC:0.6776
[2023-08-27 15:58:04,600][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.1510 loss2:0.8365 loss3:0.0357 | AUC:0.8521 Anomaly AUC:0.6786
[2023-08-27 15:58:27,918][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0737 loss2:0.7334 loss3:0.0162 | AUC:0.8429 Anomaly AUC:0.6742
[2023-08-27 15:58:48,885][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0452 loss2:0.6631 loss3:0.0091 | AUC:0.8386 Anomaly AUC:0.6488
[2023-08-27 15:59:15,907][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0304 loss2:0.5715 loss3:0.0072 | AUC:0.8545 Anomaly AUC:0.6735
[2023-08-27 15:59:37,199][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0369 loss2:0.5093 loss3:0.0079 | AUC:0.8365 Anomaly AUC:0.6581
[2023-08-27 16:00:02,094][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0169 loss2:0.3932 loss3:0.0041 | AUC:0.8227 Anomaly AUC:0.6188
[2023-08-27 16:00:31,545][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0170 loss2:0.3157 loss3:0.0042 | AUC:0.8224 Anomaly AUC:0.6167
[2023-08-27 16:01:01,132][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0119 loss2:0.2349 loss3:0.0031 | AUC:0.8299 Anomaly AUC:0.6354
[2023-08-27 16:01:30,353][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0190 loss2:0.1905 loss3:0.0040 | AUC:0.8200 Anomaly AUC:0.6359
[2023-08-27 16:01:58,795][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0083 loss2:0.1240 loss3:0.0022 | AUC:0.8543 Anomaly AUC:0.6716
[2023-08-27 16:02:22,087][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0218 loss2:0.1217 loss3:0.0047 | AUC:0.8244 Anomaly AUC:0.6228
[2023-08-27 16:02:43,904][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0165 loss2:0.0914 loss3:0.0035 | AUC:0.7874 Anomaly AUC:0.6151
[2023-08-27 16:03:07,803][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0146 loss2:0.0725 loss3:0.0030 | AUC:0.8210 Anomaly AUC:0.6214
[2023-08-27 16:03:30,049][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0101 loss2:0.0506 loss3:0.0024 | AUC:0.8341 Anomaly AUC:0.6479
[2023-08-27 16:03:30,055][main-autotune.py][line:117][INFO] Training completes in 6m 10s | best AUCAUC:0.8545 Anomaly AUC:0.6735

[2023-08-27 16:03:53,310][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00070 | loss1:0.3702 loss2:1.0664 loss3:0.1863 | AUC:0.8319 Anomaly AUC:0.6537
[2023-08-27 16:04:16,013][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00070 | loss1:0.1563 loss2:0.8274 loss3:0.0412 | AUC:0.8325 Anomaly AUC:0.6685
[2023-08-27 16:04:37,340][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00070 | loss1:0.0814 loss2:0.7333 loss3:0.0194 | AUC:0.8556 Anomaly AUC:0.6812
[2023-08-27 16:05:03,021][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00070 | loss1:0.0361 loss2:0.6326 loss3:0.0082 | AUC:0.8424 Anomaly AUC:0.6680
[2023-08-27 16:05:30,507][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00070 | loss1:0.0403 loss2:0.5703 loss3:0.0095 | AUC:0.8183 Anomaly AUC:0.6519
[2023-08-27 16:05:58,091][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00070 | loss1:0.0179 loss2:0.4565 loss3:0.0047 | AUC:0.8253 Anomaly AUC:0.6674
[2023-08-27 16:06:27,888][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00070 | loss1:0.0153 loss2:0.3598 loss3:0.0041 | AUC:0.8202 Anomaly AUC:0.6747
[2023-08-27 16:06:48,996][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00070 | loss1:0.0245 loss2:0.3061 loss3:0.0058 | AUC:0.8287 Anomaly AUC:0.6508
[2023-08-27 16:07:13,694][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00070 | loss1:0.0289 loss2:0.2212 loss3:0.0063 | AUC:0.8197 Anomaly AUC:0.6752
[2023-08-27 16:07:42,719][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00070 | loss1:0.0130 loss2:0.1768 loss3:0.0034 | AUC:0.8229 Anomaly AUC:0.6567
[2023-08-27 16:08:06,020][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00070 | loss1:0.0094 loss2:0.1023 loss3:0.0022 | AUC:0.8321 Anomaly AUC:0.6654
[2023-08-27 16:08:27,860][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00070 | loss1:0.0078 loss2:0.0866 loss3:0.0023 | AUC:0.8210 Anomaly AUC:0.6547
[2023-08-27 16:08:55,169][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00070 | loss1:0.0073 loss2:0.0593 loss3:0.0017 | AUC:0.8339 Anomaly AUC:0.6579
[2023-08-27 16:09:16,312][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00070 | loss1:0.0097 loss2:0.0589 loss3:0.0023 | AUC:0.8417 Anomaly AUC:0.6742
[2023-08-27 16:09:40,429][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00070 | loss1:0.0107 loss2:0.0522 loss3:0.0023 | AUC:0.8327 Anomaly AUC:0.6712
[2023-08-27 16:09:40,432][main-autotune.py][line:117][INFO] Training completes in 6m 10s | best AUCAUC:0.8556 Anomaly AUC:0.6812

[2023-08-27 16:10:01,304][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00060 | loss1:0.3819 loss2:1.1005 loss3:0.1792 | AUC:0.8135 Anomaly AUC:0.6465
[2023-08-27 16:10:27,957][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00060 | loss1:0.1657 loss2:0.8644 loss3:0.0402 | AUC:0.8413 Anomaly AUC:0.6703
[2023-08-27 16:10:48,830][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00060 | loss1:0.0784 loss2:0.7646 loss3:0.0179 | AUC:0.8408 Anomaly AUC:0.6861
[2023-08-27 16:11:13,930][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00060 | loss1:0.0349 loss2:0.6869 loss3:0.0083 | AUC:0.8389 Anomaly AUC:0.6665
[2023-08-27 16:11:43,959][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00060 | loss1:0.0373 loss2:0.6312 loss3:0.0091 | AUC:0.8327 Anomaly AUC:0.6729
[2023-08-27 16:12:11,798][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00060 | loss1:0.0256 loss2:0.5570 loss3:0.0060 | AUC:0.8375 Anomaly AUC:0.6814
[2023-08-27 16:12:37,477][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00060 | loss1:0.0146 loss2:0.4629 loss3:0.0043 | AUC:0.8479 Anomaly AUC:0.6922
[2023-08-27 16:12:58,492][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00060 | loss1:0.0216 loss2:0.4039 loss3:0.0052 | AUC:0.8399 Anomaly AUC:0.6853
[2023-08-27 16:13:25,111][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00060 | loss1:0.0165 loss2:0.3312 loss3:0.0043 | AUC:0.8316 Anomaly AUC:0.6748
[2023-08-27 16:13:46,246][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00060 | loss1:0.0281 loss2:0.2954 loss3:0.0072 | AUC:0.8253 Anomaly AUC:0.6628
[2023-08-27 16:14:10,527][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00060 | loss1:0.0212 loss2:0.2456 loss3:0.0056 | AUC:0.8369 Anomaly AUC:0.6597
[2023-08-27 16:14:33,618][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00060 | loss1:0.0081 loss2:0.1437 loss3:0.0030 | AUC:0.8449 Anomaly AUC:0.6777
[2023-08-27 16:14:55,715][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00060 | loss1:0.0178 loss2:0.1241 loss3:0.0040 | AUC:0.8234 Anomaly AUC:0.6653
[2023-08-27 16:15:24,725][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00060 | loss1:0.0142 loss2:0.1340 loss3:0.0048 | AUC:0.8483 Anomaly AUC:0.6829
[2023-08-27 16:15:47,748][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00060 | loss1:0.0066 loss2:0.0665 loss3:0.0018 | AUC:0.8361 Anomaly AUC:0.6694
[2023-08-27 16:15:47,751][main-autotune.py][line:117][INFO] Training completes in 6m 7s | best AUCAUC:0.8483 Anomaly AUC:0.6829

[2023-08-27 16:16:11,043][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.3759 loss2:1.1613 loss3:0.1886 | AUC:0.8328 Anomaly AUC:0.6293
[2023-08-27 16:16:32,273][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.1762 loss2:0.9541 loss3:0.0473 | AUC:0.8297 Anomaly AUC:0.6372
[2023-08-27 16:16:58,455][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0828 loss2:0.8625 loss3:0.0214 | AUC:0.8359 Anomaly AUC:0.6579
[2023-08-27 16:17:19,494][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0370 loss2:0.7923 loss3:0.0094 | AUC:0.8476 Anomaly AUC:0.6980
[2023-08-27 16:17:44,472][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0332 loss2:0.7577 loss3:0.0077 | AUC:0.8297 Anomaly AUC:0.6841
[2023-08-27 16:18:14,861][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0142 loss2:0.7177 loss3:0.0042 | AUC:0.8367 Anomaly AUC:0.6834
[2023-08-27 16:18:44,303][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0146 loss2:0.6911 loss3:0.0035 | AUC:0.8429 Anomaly AUC:0.6638
[2023-08-27 16:19:13,843][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0128 loss2:0.6486 loss3:0.0030 | AUC:0.8431 Anomaly AUC:0.6684
[2023-08-27 16:19:42,936][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0307 loss2:0.6429 loss3:0.0064 | AUC:0.8583 Anomaly AUC:0.7002
[2023-08-27 16:20:10,124][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0175 loss2:0.6066 loss3:0.0037 | AUC:0.8468 Anomaly AUC:0.6752
[2023-08-27 16:20:33,428][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0031 loss2:0.5365 loss3:0.0012 | AUC:0.8469 Anomaly AUC:0.6781
[2023-08-27 16:20:55,112][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0095 loss2:0.4974 loss3:0.0023 | AUC:0.8360 Anomaly AUC:0.6541
[2023-08-27 16:21:22,343][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0131 loss2:0.4932 loss3:0.0032 | AUC:0.8478 Anomaly AUC:0.6577
[2023-08-27 16:21:45,633][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0167 loss2:0.4864 loss3:0.0040 | AUC:0.8323 Anomaly AUC:0.6430
[2023-08-27 16:22:07,821][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0105 loss2:0.4325 loss3:0.0023 | AUC:0.8612 Anomaly AUC:0.6904
[2023-08-27 16:22:07,823][main-autotune.py][line:117][INFO] Training completes in 6m 20s | best AUCAUC:0.8612 Anomaly AUC:0.6904

[2023-08-27 16:22:33,658][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00020 | loss1:0.3856 loss2:1.1645 loss3:0.2111 | AUC:0.8116 Anomaly AUC:0.6255
[2023-08-27 16:22:54,758][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00020 | loss1:0.1595 loss2:0.9606 loss3:0.0526 | AUC:0.8313 Anomaly AUC:0.6505
[2023-08-27 16:23:18,166][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00020 | loss1:0.0620 loss2:0.8437 loss3:0.0178 | AUC:0.8447 Anomaly AUC:0.6803
[2023-08-27 16:23:39,153][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00020 | loss1:0.0359 loss2:0.7917 loss3:0.0107 | AUC:0.8422 Anomaly AUC:0.6698
[2023-08-27 16:24:08,401][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00020 | loss1:0.0316 loss2:0.7491 loss3:0.0081 | AUC:0.8483 Anomaly AUC:0.6863
[2023-08-27 16:24:36,253][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00020 | loss1:0.0154 loss2:0.6996 loss3:0.0046 | AUC:0.8550 Anomaly AUC:0.6893
[2023-08-27 16:25:06,264][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00020 | loss1:0.0211 loss2:0.6615 loss3:0.0048 | AUC:0.8524 Anomaly AUC:0.6805
[2023-08-27 16:25:35,850][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00020 | loss1:0.0130 loss2:0.6164 loss3:0.0034 | AUC:0.8396 Anomaly AUC:0.6752
[2023-08-27 16:25:59,172][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00020 | loss1:0.0078 loss2:0.5628 loss3:0.0023 | AUC:0.8529 Anomaly AUC:0.6975
[2023-08-27 16:26:21,443][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00020 | loss1:0.0076 loss2:0.5033 loss3:0.0024 | AUC:0.8551 Anomaly AUC:0.7017
[2023-08-27 16:26:48,530][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00020 | loss1:0.0062 loss2:0.4529 loss3:0.0019 | AUC:0.8473 Anomaly AUC:0.6851
[2023-08-27 16:27:14,241][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00020 | loss1:0.0159 loss2:0.4247 loss3:0.0039 | AUC:0.8409 Anomaly AUC:0.6862
[2023-08-27 16:27:35,413][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00020 | loss1:0.0039 loss2:0.3639 loss3:0.0016 | AUC:0.8580 Anomaly AUC:0.6985
[2023-08-27 16:27:58,890][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00020 | loss1:0.0093 loss2:0.3173 loss3:0.0025 | AUC:0.8444 Anomaly AUC:0.6709
[2023-08-27 16:28:20,041][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00020 | loss1:0.0131 loss2:0.3153 loss3:0.0035 | AUC:0.8554 Anomaly AUC:0.6924
[2023-08-27 16:28:20,044][main-autotune.py][line:117][INFO] Training completes in 6m 12s | best AUCAUC:0.8580 Anomaly AUC:0.6985

[2023-08-27 16:28:43,261][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.3958 loss2:1.1823 loss3:0.2495 | AUC:0.8356 Anomaly AUC:0.6283
[2023-08-27 16:29:05,592][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.1487 loss2:0.9392 loss3:0.0583 | AUC:0.8438 Anomaly AUC:0.6655
[2023-08-27 16:29:30,037][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0585 loss2:0.8400 loss3:0.0206 | AUC:0.8517 Anomaly AUC:0.6961
[2023-08-27 16:29:51,060][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0309 loss2:0.7849 loss3:0.0087 | AUC:0.8500 Anomaly AUC:0.6826
[2023-08-27 16:30:20,866][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0215 loss2:0.7369 loss3:0.0062 | AUC:0.8468 Anomaly AUC:0.6679
[2023-08-27 16:30:48,206][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0177 loss2:0.6950 loss3:0.0045 | AUC:0.8382 Anomaly AUC:0.6844
[2023-08-27 16:31:11,774][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0300 loss2:0.6790 loss3:0.0073 | AUC:0.8457 Anomaly AUC:0.7056
[2023-08-27 16:31:34,516][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0151 loss2:0.6322 loss3:0.0038 | AUC:0.8546 Anomaly AUC:0.6884
[2023-08-27 16:31:58,088][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0135 loss2:0.5855 loss3:0.0032 | AUC:0.8587 Anomaly AUC:0.6959
[2023-08-27 16:32:20,278][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0050 loss2:0.5071 loss3:0.0016 | AUC:0.8494 Anomaly AUC:0.6860
[2023-08-27 16:32:44,127][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0044 loss2:0.4343 loss3:0.0018 | AUC:0.8338 Anomaly AUC:0.6889
[2023-08-27 16:33:05,868][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0233 loss2:0.4194 loss3:0.0052 | AUC:0.8516 Anomaly AUC:0.6974
[2023-08-27 16:33:33,726][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0197 loss2:0.3970 loss3:0.0047 | AUC:0.8479 Anomaly AUC:0.6889
[2023-08-27 16:33:56,789][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0083 loss2:0.3060 loss3:0.0024 | AUC:0.8624 Anomaly AUC:0.6962
[2023-08-27 16:34:19,110][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0053 loss2:0.2527 loss3:0.0020 | AUC:0.8636 Anomaly AUC:0.7023
[2023-08-27 16:34:19,111][main-autotune.py][line:117][INFO] Training completes in 5m 59s | best AUCAUC:0.8636 Anomaly AUC:0.7023

[2023-08-27 16:34:40,081][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.3755 loss2:1.0746 loss3:0.2828 | AUC:0.8065 Anomaly AUC:0.6259
[2023-08-27 16:35:06,742][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.1346 loss2:0.8229 loss3:0.0651 | AUC:0.8282 Anomaly AUC:0.6692
[2023-08-27 16:35:27,734][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0626 loss2:0.7170 loss3:0.0253 | AUC:0.8144 Anomaly AUC:0.6553
[2023-08-27 16:35:53,738][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0261 loss2:0.6150 loss3:0.0125 | AUC:0.8421 Anomaly AUC:0.6808
[2023-08-27 16:36:14,971][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0295 loss2:0.5428 loss3:0.0100 | AUC:0.8103 Anomaly AUC:0.6679
[2023-08-27 16:36:40,592][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0180 loss2:0.4640 loss3:0.0061 | AUC:0.8085 Anomaly AUC:0.6715
[2023-08-27 16:37:10,339][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0106 loss2:0.3683 loss3:0.0041 | AUC:0.8194 Anomaly AUC:0.6621
[2023-08-27 16:37:39,718][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0073 loss2:0.2957 loss3:0.0032 | AUC:0.8444 Anomaly AUC:0.6796
[2023-08-27 16:38:06,989][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0123 loss2:0.2517 loss3:0.0037 | AUC:0.8084 Anomaly AUC:0.6556
[2023-08-27 16:38:32,888][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0329 loss2:0.2818 loss3:0.0075 | AUC:0.8503 Anomaly AUC:0.6852
[2023-08-27 16:38:54,054][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0066 loss2:0.1874 loss3:0.0026 | AUC:0.8527 Anomaly AUC:0.6790
[2023-08-27 16:39:20,884][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0033 loss2:0.1310 loss3:0.0014 | AUC:0.8510 Anomaly AUC:0.6770
[2023-08-27 16:39:47,483][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0021 loss2:0.0940 loss3:0.0012 | AUC:0.8443 Anomaly AUC:0.6749
[2023-08-27 16:40:16,222][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0035 loss2:0.0796 loss3:0.0014 | AUC:0.8412 Anomaly AUC:0.6678
[2023-08-27 16:40:37,377][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0161 loss2:0.1012 loss3:0.0037 | AUC:0.8325 Anomaly AUC:0.6539
[2023-08-27 16:40:37,379][main-autotune.py][line:117][INFO] Training completes in 6m 18s | best AUCAUC:0.8527 Anomaly AUC:0.6790

[2023-08-27 16:41:01,468][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.3499 loss2:0.9902 loss3:0.3595 | AUC:0.8176 Anomaly AUC:0.6688
[2023-08-27 16:41:22,756][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0958 loss2:0.7196 loss3:0.2801 | AUC:0.8197 Anomaly AUC:0.6723
[2023-08-27 16:41:46,385][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0535 loss2:0.5947 loss3:0.1699 | AUC:0.8442 Anomaly AUC:0.6794
[2023-08-27 16:42:07,408][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0227 loss2:0.4734 loss3:0.0593 | AUC:0.8380 Anomaly AUC:0.6890
[2023-08-27 16:42:30,659][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0263 loss2:0.3821 loss3:0.0362 | AUC:0.8390 Anomaly AUC:0.6878
[2023-08-27 16:42:51,673][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0154 loss2:0.3059 loss3:0.0263 | AUC:0.8567 Anomaly AUC:0.7044
[2023-08-27 16:43:15,107][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0085 loss2:0.2324 loss3:0.0189 | AUC:0.8562 Anomaly AUC:0.6921
[2023-08-27 16:43:37,463][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0259 loss2:0.2228 loss3:0.0227 | AUC:0.8656 Anomaly AUC:0.6964
[2023-08-27 16:44:01,274][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0078 loss2:0.1613 loss3:0.0159 | AUC:0.8557 Anomaly AUC:0.6815
[2023-08-27 16:44:23,631][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0032 loss2:0.1161 loss3:0.0134 | AUC:0.8554 Anomaly AUC:0.7017
[2023-08-27 16:44:47,436][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0101 loss2:0.1104 loss3:0.0141 | AUC:0.8424 Anomaly AUC:0.6898
[2023-08-27 16:45:09,233][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0091 loss2:0.0874 loss3:0.0132 | AUC:0.8339 Anomaly AUC:0.6756
[2023-08-27 16:45:36,717][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0202 loss2:0.0986 loss3:0.0169 | AUC:0.8388 Anomaly AUC:0.6839
[2023-08-27 16:46:00,340][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0088 loss2:0.0783 loss3:0.0140 | AUC:0.8374 Anomaly AUC:0.6633
[2023-08-27 16:46:22,487][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0125 loss2:0.0664 loss3:0.0126 | AUC:0.8311 Anomaly AUC:0.6737
[2023-08-27 16:46:22,490][main-autotune.py][line:117][INFO] Training completes in 5m 45s | best AUCAUC:0.8656 Anomaly AUC:0.6964

[2023-08-27 16:46:43,607][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.3682 loss2:1.0301 loss3:0.3293 | AUC:0.8228 Anomaly AUC:0.6688
[2023-08-27 16:47:07,734][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0776 loss2:0.7483 loss3:0.2416 | AUC:0.8196 Anomaly AUC:0.6920
[2023-08-27 16:47:28,708][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0205 loss2:0.6131 loss3:0.1743 | AUC:0.8286 Anomaly AUC:0.6841
[2023-08-27 16:47:54,991][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0056 loss2:0.4694 loss3:0.1161 | AUC:0.8359 Anomaly AUC:0.6791
[2023-08-27 16:48:16,142][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0082 loss2:0.3635 loss3:0.0857 | AUC:0.8444 Anomaly AUC:0.6880
[2023-08-27 16:48:41,106][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0020 loss2:0.2616 loss3:0.0576 | AUC:0.8278 Anomaly AUC:0.6764
[2023-08-27 16:49:07,244][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00040 | loss1:0.0161 loss2:0.2949 loss3:0.1165 | AUC:0.8499 Anomaly AUC:0.6867
[2023-08-27 16:49:28,312][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00040 | loss1:0.0018 loss2:0.1772 loss3:0.0478 | AUC:0.8501 Anomaly AUC:0.6881
[2023-08-27 16:49:51,936][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00040 | loss1:0.0069 loss2:0.1470 loss3:0.0410 | AUC:0.8354 Anomaly AUC:0.6769
[2023-08-27 16:50:13,036][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00040 | loss1:0.0024 loss2:0.1181 loss3:0.0416 | AUC:0.8388 Anomaly AUC:0.6758
[2023-08-27 16:50:38,925][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00040 | loss1:0.0026 loss2:0.1010 loss3:0.0389 | AUC:0.8338 Anomaly AUC:0.6927
[2023-08-27 16:51:00,072][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00040 | loss1:0.0007 loss2:0.0757 loss3:0.0245 | AUC:0.8404 Anomaly AUC:0.6840
[2023-08-27 16:51:26,909][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00040 | loss1:0.0894 loss2:0.2012 loss3:0.1049 | AUC:0.8214 Anomaly AUC:0.7051
[2023-08-27 16:51:56,047][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00040 | loss1:0.0018 loss2:0.1038 loss3:0.0506 | AUC:0.8494 Anomaly AUC:0.7017
[2023-08-27 16:52:19,427][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00040 | loss1:0.0013 loss2:0.0682 loss3:0.0369 | AUC:0.8531 Anomaly AUC:0.6945
[2023-08-27 16:52:19,428][main-autotune.py][line:117][INFO] Training completes in 5m 57s | best AUCAUC:0.8531 Anomaly AUC:0.6945

[2023-08-27 16:52:42,162][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00050 | loss1:0.3449 loss2:1.1758 loss3:0.3382 | AUC:0.7927 Anomaly AUC:0.6162
[2023-08-27 16:53:05,948][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00050 | loss1:0.0539 loss2:0.9327 loss3:0.2555 | AUC:0.8116 Anomaly AUC:0.6566
[2023-08-27 16:53:28,289][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00050 | loss1:0.0077 loss2:0.8128 loss3:0.1732 | AUC:0.8328 Anomaly AUC:0.6616
[2023-08-27 16:53:52,608][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00050 | loss1:0.0054 loss2:0.7342 loss3:0.1443 | AUC:0.8218 Anomaly AUC:0.6763
[2023-08-27 16:54:13,676][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00050 | loss1:0.0029 loss2:0.6517 loss3:0.1084 | AUC:0.8094 Anomaly AUC:0.6958
[2023-08-27 16:54:43,324][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00050 | loss1:0.0368 loss2:0.6171 loss3:0.2090 | AUC:0.7999 Anomaly AUC:0.6537
[2023-08-27 16:55:13,492][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00050 | loss1:0.0039 loss2:0.6960 loss3:0.1391 | AUC:0.8157 Anomaly AUC:0.6652
[2023-08-27 16:55:40,698][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00050 | loss1:0.0066 loss2:0.6022 loss3:0.1471 | AUC:0.7872 Anomaly AUC:0.6702
[2023-08-27 16:56:10,288][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00050 | loss1:0.0016 loss2:0.5183 loss3:0.0900 | AUC:0.8171 Anomaly AUC:0.6638
[2023-08-27 16:56:33,762][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00050 | loss1:0.0011 loss2:0.4336 loss3:0.0723 | AUC:0.8283 Anomaly AUC:0.6655
[2023-08-27 16:56:56,334][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00050 | loss1:0.0012 loss2:0.3481 loss3:0.0617 | AUC:0.8295 Anomaly AUC:0.6616
[2023-08-27 16:57:23,355][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00050 | loss1:0.0007 loss2:0.2686 loss3:0.0463 | AUC:0.8357 Anomaly AUC:0.6624
[2023-08-27 16:57:46,931][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00050 | loss1:0.0042 loss2:0.2049 loss3:0.0407 | AUC:0.8027 Anomaly AUC:0.6492
[2023-08-27 16:58:09,133][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00050 | loss1:0.0030 loss2:0.2843 loss3:0.1052 | AUC:0.8163 Anomaly AUC:0.6542
[2023-08-27 16:58:34,708][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00050 | loss1:0.0022 loss2:0.1640 loss3:0.0613 | AUC:0.8064 Anomaly AUC:0.6549
[2023-08-27 16:58:34,711][main-autotune.py][line:117][INFO] Training completes in 6m 15s | best AUCAUC:0.8357 Anomaly AUC:0.6624

[2023-08-27 16:58:55,670][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00030 | loss1:0.3665 loss2:1.0031 loss3:0.2538 | AUC:0.8393 Anomaly AUC:0.6813
[2023-08-27 16:59:19,342][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00030 | loss1:0.1315 loss2:0.7499 loss3:0.0765 | AUC:0.8228 Anomaly AUC:0.6689
[2023-08-27 16:59:41,007][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00030 | loss1:0.0438 loss2:0.6101 loss3:0.0296 | AUC:0.8547 Anomaly AUC:0.6999
[2023-08-27 17:00:11,447][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00030 | loss1:0.0169 loss2:0.4848 loss3:0.0160 | AUC:0.8509 Anomaly AUC:0.6865
[2023-08-27 17:00:32,526][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00030 | loss1:0.0357 loss2:0.4365 loss3:0.0163 | AUC:0.8633 Anomaly AUC:0.7060
[2023-08-27 17:00:57,681][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00030 | loss1:0.0095 loss2:0.3307 loss3:0.0067 | AUC:0.8487 Anomaly AUC:0.6884
[2023-08-27 17:01:23,701][main-autotune.py][line:109][INFO] [Epoch:7/15]: lr:0.00030 | loss1:0.0034 loss2:0.2526 loss3:0.0026 | AUC:0.8401 Anomaly AUC:0.6763
[2023-08-27 17:01:44,878][main-autotune.py][line:109][INFO] [Epoch:8/15]: lr:0.00030 | loss1:0.0226 loss2:0.2531 loss3:0.0059 | AUC:0.8400 Anomaly AUC:0.6858
[2023-08-27 17:02:08,386][main-autotune.py][line:109][INFO] [Epoch:9/15]: lr:0.00030 | loss1:0.0132 loss2:0.2091 loss3:0.0047 | AUC:0.8181 Anomaly AUC:0.6675
[2023-08-27 17:02:29,737][main-autotune.py][line:109][INFO] [Epoch:10/15]: lr:0.00030 | loss1:0.0065 loss2:0.1624 loss3:0.0027 | AUC:0.8365 Anomaly AUC:0.6878
[2023-08-27 17:02:53,035][main-autotune.py][line:109][INFO] [Epoch:11/15]: lr:0.00030 | loss1:0.0080 loss2:0.1392 loss3:0.0025 | AUC:0.8297 Anomaly AUC:0.6716
[2023-08-27 17:03:15,286][main-autotune.py][line:109][INFO] [Epoch:12/15]: lr:0.00030 | loss1:0.0013 loss2:0.1119 loss3:0.0016 | AUC:0.8326 Anomaly AUC:0.6756
[2023-08-27 17:03:44,137][main-autotune.py][line:109][INFO] [Epoch:13/15]: lr:0.00030 | loss1:0.0004 loss2:0.0903 loss3:0.0013 | AUC:0.8314 Anomaly AUC:0.6687
[2023-08-27 17:04:13,266][main-autotune.py][line:109][INFO] [Epoch:14/15]: lr:0.00030 | loss1:0.0003 loss2:0.0780 loss3:0.0012 | AUC:0.8323 Anomaly AUC:0.6703
[2023-08-27 17:04:36,603][main-autotune.py][line:109][INFO] [Epoch:15/15]: lr:0.00030 | loss1:0.0003 loss2:0.0679 loss3:0.0012 | AUC:0.8334 Anomaly AUC:0.6695
[2023-08-27 17:04:36,606][main-autotune.py][line:117][INFO] Training completes in 6m 2s | best AUCAUC:0.8633 Anomaly AUC:0.7060

[2023-08-27 17:05:00,650][main-autotune.py][line:109][INFO] [Epoch:1/15]: lr:0.00040 | loss1:0.3785 loss2:1.0243 loss3:0.3376 | AUC:0.8314 Anomaly AUC:0.6685
[2023-08-27 17:05:29,288][main-autotune.py][line:109][INFO] [Epoch:2/15]: lr:0.00040 | loss1:0.0843 loss2:0.7415 loss3:0.2472 | AUC:0.8261 Anomaly AUC:0.6856
[2023-08-27 17:05:50,535][main-autotune.py][line:109][INFO] [Epoch:3/15]: lr:0.00040 | loss1:0.0178 loss2:0.5956 loss3:0.1690 | AUC:0.8419 Anomaly AUC:0.6876
[2023-08-27 17:06:16,910][main-autotune.py][line:109][INFO] [Epoch:4/15]: lr:0.00040 | loss1:0.0093 loss2:0.4722 loss3:0.1250 | AUC:0.8473 Anomaly AUC:0.6893
[2023-08-27 17:06:40,225][main-autotune.py][line:109][INFO] [Epoch:5/15]: lr:0.00040 | loss1:0.0084 loss2:0.3724 loss3:0.0904 | AUC:0.8328 Anomaly AUC:0.6676
[2023-08-27 17:07:05,260][main-autotune.py][line:109][INFO] [Epoch:6/15]: lr:0.00040 | loss1:0.0016 loss2:0.2832 loss3:0.0689 | AUC:0.8536 Anomaly AUC:0.6899
[2023-08-27 20:33:22,742][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 20:33:22,851][main.py][line:154][INFO] total params:7.5707M
[2023-08-27 20:33:22,851][main.py][line:157][INFO] Training Mode
[2023-08-27 20:33:22,852][main.py][line:75][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 20:33:22,852][main.py][line:76][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 20:33:31,027][main.py][line:79][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 20:33:51,611][main.py][line:103][INFO] [Epoch:1/30]: lr:0.00040 | loss1:0.3663 loss2:1.0031 loss3:0.3563 | AUC:0.8135 Anomaly AUC:0.6628
[2023-08-27 20:34:12,919][main.py][line:103][INFO] [Epoch:2/30]: lr:0.00040 | loss1:0.1132 loss2:0.7355 loss3:0.2724 | AUC:0.8219 Anomaly AUC:0.6513
[2023-08-27 20:44:26,000][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 20:44:26,123][main.py][line:154][INFO] total params:7.5707M
[2023-08-27 20:44:26,123][main.py][line:157][INFO] Training Mode
[2023-08-27 20:44:26,123][main.py][line:75][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 20:44:26,123][main.py][line:76][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 20:44:34,708][main.py][line:79][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 20:44:53,271][main.py][line:103][INFO] [Epoch:1/30]: lr:0.00040 | loss1:0.3663 loss2:1.0031 loss3:0.3563 | AUC:0.8135 Anomaly AUC:0.6628
[2023-08-27 20:45:15,864][main.py][line:103][INFO] [Epoch:2/30]: lr:0.00040 | loss1:0.1132 loss2:0.7355 loss3:0.2724 | AUC:0.8219 Anomaly AUC:0.6513
[2023-08-27 20:45:34,204][main.py][line:103][INFO] [Epoch:3/30]: lr:0.00040 | loss1:0.0402 loss2:0.5816 loss3:0.1780 | AUC:0.8153 Anomaly AUC:0.6409
[2023-08-27 20:45:56,175][main.py][line:103][INFO] [Epoch:4/30]: lr:0.00040 | loss1:0.0322 loss2:0.4772 loss3:0.0571 | AUC:0.8217 Anomaly AUC:0.6671
[2023-08-27 20:46:18,032][main.py][line:103][INFO] [Epoch:5/30]: lr:0.00040 | loss1:0.0188 loss2:0.3766 loss3:0.0331 | AUC:0.8408 Anomaly AUC:0.6629
[2023-08-27 20:46:36,685][main.py][line:103][INFO] [Epoch:6/30]: lr:0.00040 | loss1:0.0038 loss2:0.2664 loss3:0.0188 | AUC:0.8384 Anomaly AUC:0.6582
[2023-08-27 20:46:58,576][main.py][line:103][INFO] [Epoch:7/30]: lr:0.00040 | loss1:0.0063 loss2:0.2121 loss3:0.0153 | AUC:0.8424 Anomaly AUC:0.6669
[2023-08-27 20:47:22,051][main.py][line:103][INFO] [Epoch:8/30]: lr:0.00040 | loss1:0.0232 loss2:0.2144 loss3:0.0200 | AUC:0.8293 Anomaly AUC:0.6524
[2023-08-27 20:47:40,891][main.py][line:103][INFO] [Epoch:9/30]: lr:0.00040 | loss1:0.0064 loss2:0.1478 loss3:0.0139 | AUC:0.8140 Anomaly AUC:0.6498
[2023-08-27 20:48:00,659][main.py][line:103][INFO] [Epoch:10/30]: lr:0.00040 | loss1:0.0172 loss2:0.1394 loss3:0.0154 | AUC:0.8063 Anomaly AUC:0.6523
[2023-08-27 20:48:24,296][main.py][line:103][INFO] [Epoch:11/30]: lr:0.00040 | loss1:0.0116 loss2:0.1186 loss3:0.0142 | AUC:0.8381 Anomaly AUC:0.6747
[2023-08-27 20:48:47,857][main.py][line:103][INFO] [Epoch:12/30]: lr:0.00040 | loss1:0.0105 loss2:0.1006 loss3:0.0126 | AUC:0.8487 Anomaly AUC:0.6832
[2023-08-27 20:49:11,724][main.py][line:103][INFO] [Epoch:13/30]: lr:0.00040 | loss1:0.0063 loss2:0.0779 loss3:0.0112 | AUC:0.8469 Anomaly AUC:0.6798
[2023-08-27 20:49:35,017][main.py][line:103][INFO] [Epoch:14/30]: lr:0.00040 | loss1:0.0007 loss2:0.0530 loss3:0.0080 | AUC:0.8458 Anomaly AUC:0.6740
[2023-08-27 20:49:53,485][main.py][line:118][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 20:49:53,598][main.py][line:154][INFO] total params:7.5707M
[2023-08-27 20:49:53,598][main.py][line:157][INFO] Training Mode
[2023-08-27 20:49:53,599][main.py][line:75][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 20:49:53,599][main.py][line:76][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00030000000000000003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 20:50:01,740][main.py][line:79][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 20:50:20,363][main.py][line:103][INFO] [Epoch:1/30]: lr:0.00040 | loss1:0.3663 loss2:1.0031 loss3:0.3563 | AUC:0.8135 Anomaly AUC:0.6628
[2023-08-27 20:50:41,035][main.py][line:103][INFO] [Epoch:2/30]: lr:0.00040 | loss1:0.1132 loss2:0.7355 loss3:0.2724 | AUC:0.8219 Anomaly AUC:0.6513
[2023-08-27 20:50:59,799][main.py][line:103][INFO] [Epoch:3/30]: lr:0.00040 | loss1:0.0402 loss2:0.5816 loss3:0.1780 | AUC:0.8153 Anomaly AUC:0.6409
[2023-08-27 20:51:20,537][main.py][line:103][INFO] [Epoch:4/30]: lr:0.00040 | loss1:0.0322 loss2:0.4772 loss3:0.0571 | AUC:0.8217 Anomaly AUC:0.6671
[2023-08-27 20:51:39,518][main.py][line:103][INFO] [Epoch:5/30]: lr:0.00040 | loss1:0.0188 loss2:0.3766 loss3:0.0331 | AUC:0.8408 Anomaly AUC:0.6629
[2023-08-27 20:52:00,356][main.py][line:103][INFO] [Epoch:6/30]: lr:0.00040 | loss1:0.0038 loss2:0.2664 loss3:0.0188 | AUC:0.8384 Anomaly AUC:0.6582
[2023-08-27 20:52:19,118][main.py][line:103][INFO] [Epoch:7/30]: lr:0.00040 | loss1:0.0063 loss2:0.2121 loss3:0.0153 | AUC:0.8424 Anomaly AUC:0.6669
[2023-08-27 20:52:40,865][main.py][line:103][INFO] [Epoch:8/30]: lr:0.00040 | loss1:0.0232 loss2:0.2144 loss3:0.0200 | AUC:0.8293 Anomaly AUC:0.6524
[2023-08-27 20:52:54,396][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 20:52:54,501][main.py][line:156][INFO] total params:7.5707M
[2023-08-27 20:52:54,501][main.py][line:159][INFO] Training Mode
[2023-08-27 20:52:54,501][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 20:52:54,501][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00030000000000000003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-27 20:53:02,645][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-27 20:53:21,604][main.py][line:105][INFO] [Epoch:1/30]: lr:0.00040 | loss1:0.3663 loss2:1.0031 loss3:0.3563 | AUC:0.8135 Anomaly AUC:0.6628
[2023-08-27 20:53:47,223][main.py][line:105][INFO] [Epoch:2/30]: lr:0.00040 | loss1:0.1132 loss2:0.7355 loss3:0.2724 | AUC:0.8219 Anomaly AUC:0.6513
[2023-08-27 20:54:08,027][main.py][line:105][INFO] [Epoch:3/30]: lr:0.00040 | loss1:0.0402 loss2:0.5816 loss3:0.1780 | AUC:0.8153 Anomaly AUC:0.6409
[2023-08-27 20:54:26,692][main.py][line:105][INFO] [Epoch:4/30]: lr:0.00040 | loss1:0.0322 loss2:0.4772 loss3:0.0571 | AUC:0.8217 Anomaly AUC:0.6671
[2023-08-27 20:54:47,026][main.py][line:105][INFO] [Epoch:5/30]: lr:0.00040 | loss1:0.0188 loss2:0.3766 loss3:0.0331 | AUC:0.8408 Anomaly AUC:0.6629
[2023-08-27 20:55:05,722][main.py][line:105][INFO] [Epoch:6/30]: lr:0.00040 | loss1:0.0038 loss2:0.2664 loss3:0.0188 | AUC:0.8384 Anomaly AUC:0.6582
[2023-08-27 20:57:18,774][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-27 20:57:18,894][main.py][line:156][INFO] total params:7.5707M
[2023-08-27 20:57:18,894][main.py][line:159][INFO] Training Mode
[2023-08-27 20:57:18,895][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-27 20:57:18,895][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00030000000000000003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 00:44:11,446][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 00:44:11,570][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 00:44:11,570][main.py][line:159][INFO] Training Mode
[2023-08-28 00:44:26,367][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 00:44:26,495][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 00:44:26,495][main.py][line:159][INFO] Training Mode
[2023-08-28 00:44:26,496][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 00:44:26,496][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00030000000000000003
    maximize: False
    weight_decay: 0
)

[2023-08-28 00:44:35,004][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 00:44:53,388][main.py][line:105][INFO] [Epoch:1/30]: lr:0.00040 | loss1:0.3666 loss2:1.0034 loss3:0.3552 | AUC:0.8255 Anomaly AUC:0.6621
[2023-08-28 00:45:14,390][main.py][line:105][INFO] [Epoch:2/30]: lr:0.00040 | loss1:0.1107 loss2:0.7379 loss3:0.2524 | AUC:0.8285 Anomaly AUC:0.6675
[2023-08-28 00:45:36,130][main.py][line:105][INFO] [Epoch:3/30]: lr:0.00040 | loss1:0.0435 loss2:0.5923 loss3:0.1024 | AUC:0.8372 Anomaly AUC:0.6735
[2023-08-28 00:45:54,525][main.py][line:105][INFO] [Epoch:4/30]: lr:0.00040 | loss1:0.0212 loss2:0.4671 loss3:0.0467 | AUC:0.8274 Anomaly AUC:0.6521
[2023-08-28 00:46:17,675][main.py][line:105][INFO] [Epoch:5/30]: lr:0.00040 | loss1:0.0255 loss2:0.3862 loss3:0.0309 | AUC:0.8466 Anomaly AUC:0.6663
[2023-08-28 00:46:36,191][main.py][line:105][INFO] [Epoch:6/30]: lr:0.00040 | loss1:0.0113 loss2:0.2854 loss3:0.0196 | AUC:0.8399 Anomaly AUC:0.6621
[2023-08-28 00:46:55,753][main.py][line:105][INFO] [Epoch:7/30]: lr:0.00040 | loss1:0.0150 loss2:0.2434 loss3:0.0178 | AUC:0.8371 Anomaly AUC:0.6502
[2023-08-28 00:47:17,070][main.py][line:105][INFO] [Epoch:8/30]: lr:0.00040 | loss1:0.0182 loss2:0.2026 loss3:0.0166 | AUC:0.8394 Anomaly AUC:0.6557
[2023-08-28 00:47:38,324][main.py][line:105][INFO] [Epoch:9/30]: lr:0.00040 | loss1:0.0031 loss2:0.1461 loss3:0.0117 | AUC:0.8367 Anomaly AUC:0.6496
[2023-08-28 00:48:00,824][main.py][line:105][INFO] [Epoch:10/30]: lr:0.00040 | loss1:0.0113 loss2:0.1313 loss3:0.0122 | AUC:0.8324 Anomaly AUC:0.6573
[2023-08-28 00:48:24,091][main.py][line:105][INFO] [Epoch:11/30]: lr:0.00040 | loss1:0.0217 loss2:0.1373 loss3:0.0147 | AUC:0.8281 Anomaly AUC:0.6567
[2023-08-28 10:58:20,842][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 10:58:20,951][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 10:58:20,951][main.py][line:159][INFO] Training Mode
[2023-08-28 10:58:20,952][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 10:58:20,952][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00030000000000000003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 10:58:44,994][main.py][line:105][INFO] [Epoch:1/30]: lr:0.00030 | loss1:0.5960 loss2:1.2624 loss3:0.1819 | AUC:0.8167 Anomaly AUC:0.6354
[2023-08-28 10:59:07,009][main.py][line:105][INFO] [Epoch:2/30]: lr:0.00030 | loss1:0.6681 loss2:1.2935 loss3:0.2590 | AUC:0.7914 Anomaly AUC:0.6000
[2023-08-28 10:59:34,238][main.py][line:105][INFO] [Epoch:3/30]: lr:0.00030 | loss1:0.5262 loss2:1.1275 loss3:0.2426 | AUC:0.8210 Anomaly AUC:0.5900
[2023-08-28 11:00:06,190][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:00:06,313][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 11:00:06,313][main.py][line:159][INFO] Training Mode
[2023-08-28 11:00:06,314][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 11:00:06,314][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0004
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00030000000000000003
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 11:00:30,338][main.py][line:105][INFO] [Epoch:1/30]: lr:0.00040 | loss1:0.3732 loss2:1.0093 loss3:0.3005 | AUC:0.8375 Anomaly AUC:0.6738
[2023-08-28 11:00:52,136][main.py][line:105][INFO] [Epoch:2/30]: lr:0.00040 | loss1:0.1280 loss2:0.7390 loss3:0.1574 | AUC:0.8289 Anomaly AUC:0.6677
[2023-08-28 11:01:18,342][main.py][line:105][INFO] [Epoch:3/30]: lr:0.00040 | loss1:0.0473 loss2:0.5920 loss3:0.0748 | AUC:0.8327 Anomaly AUC:0.6706
[2023-08-28 11:01:40,490][main.py][line:105][INFO] [Epoch:4/30]: lr:0.00040 | loss1:0.0271 loss2:0.4699 loss3:0.0390 | AUC:0.8199 Anomaly AUC:0.6655
[2023-08-28 11:02:02,590][main.py][line:105][INFO] [Epoch:5/30]: lr:0.00040 | loss1:0.0182 loss2:0.3760 loss3:0.0259 | AUC:0.8444 Anomaly AUC:0.6780
[2023-08-28 11:02:24,485][main.py][line:105][INFO] [Epoch:6/30]: lr:0.00040 | loss1:0.0200 loss2:0.3016 loss3:0.0209 | AUC:0.8480 Anomaly AUC:0.6872
[2023-08-28 11:02:45,973][main.py][line:105][INFO] [Epoch:7/30]: lr:0.00040 | loss1:0.0104 loss2:0.2338 loss3:0.0168 | AUC:0.8438 Anomaly AUC:0.6895
[2023-08-28 11:03:08,049][main.py][line:105][INFO] [Epoch:8/30]: lr:0.00040 | loss1:0.0165 loss2:0.1992 loss3:0.0164 | AUC:0.8464 Anomaly AUC:0.7065
[2023-08-28 11:03:29,026][main.py][line:105][INFO] [Epoch:9/30]: lr:0.00040 | loss1:0.0047 loss2:0.1492 loss3:0.0132 | AUC:0.8378 Anomaly AUC:0.6810
[2023-08-28 11:03:50,781][main.py][line:105][INFO] [Epoch:10/30]: lr:0.00040 | loss1:0.0017 loss2:0.1099 loss3:0.0101 | AUC:0.8296 Anomaly AUC:0.6772
[2023-08-28 11:04:12,496][main.py][line:105][INFO] [Epoch:11/30]: lr:0.00040 | loss1:0.0003 loss2:0.0846 loss3:0.0078 | AUC:0.8351 Anomaly AUC:0.6754
[2023-08-28 11:04:33,578][main.py][line:105][INFO] [Epoch:12/30]: lr:0.00040 | loss1:0.0002 loss2:0.0692 loss3:0.0058 | AUC:0.8363 Anomaly AUC:0.6722
[2023-08-28 11:04:55,382][main.py][line:105][INFO] [Epoch:13/30]: lr:0.00040 | loss1:0.0002 loss2:0.0586 loss3:0.0034 | AUC:0.8369 Anomaly AUC:0.6741
[2023-08-28 11:05:16,680][main.py][line:105][INFO] [Epoch:14/30]: lr:0.00040 | loss1:0.0001 loss2:0.0497 loss3:0.0012 | AUC:0.8402 Anomaly AUC:0.6767
[2023-08-28 11:05:37,993][main.py][line:105][INFO] [Epoch:15/30]: lr:0.00040 | loss1:0.0001 loss2:0.0418 loss3:0.0010 | AUC:0.8424 Anomaly AUC:0.6752
[2023-08-28 11:05:59,423][main.py][line:105][INFO] [Epoch:16/30]: lr:0.00040 | loss1:0.0001 loss2:0.0360 loss3:0.0009 | AUC:0.8408 Anomaly AUC:0.6691
[2023-08-28 11:06:20,830][main.py][line:105][INFO] [Epoch:17/30]: lr:0.00040 | loss1:0.0001 loss2:0.0311 loss3:0.0009 | AUC:0.8410 Anomaly AUC:0.6728
[2023-08-28 11:06:42,210][main.py][line:105][INFO] [Epoch:18/30]: lr:0.00040 | loss1:0.0001 loss2:0.0270 loss3:0.0009 | AUC:0.8401 Anomaly AUC:0.6726
[2023-08-28 11:07:03,677][main.py][line:105][INFO] [Epoch:19/30]: lr:0.00040 | loss1:0.0001 loss2:0.0237 loss3:0.0008 | AUC:0.8373 Anomaly AUC:0.6706
[2023-08-28 11:07:25,126][main.py][line:105][INFO] [Epoch:20/30]: lr:0.00040 | loss1:0.0001 loss2:0.0207 loss3:0.0008 | AUC:0.8369 Anomaly AUC:0.6700
[2023-08-28 11:07:46,854][main.py][line:105][INFO] [Epoch:21/30]: lr:0.00040 | loss1:0.0001 loss2:0.0181 loss3:0.0009 | AUC:0.8353 Anomaly AUC:0.6661
[2023-08-28 11:08:08,177][main.py][line:105][INFO] [Epoch:22/30]: lr:0.00040 | loss1:0.0001 loss2:0.0166 loss3:0.0009 | AUC:0.8383 Anomaly AUC:0.6719
[2023-08-28 11:08:29,684][main.py][line:105][INFO] [Epoch:23/30]: lr:0.00040 | loss1:0.0000 loss2:0.0144 loss3:0.0008 | AUC:0.8356 Anomaly AUC:0.6671
[2023-08-28 11:08:52,359][main.py][line:105][INFO] [Epoch:24/30]: lr:0.00040 | loss1:0.0000 loss2:0.0127 loss3:0.0008 | AUC:0.8344 Anomaly AUC:0.6668
[2023-08-28 11:09:15,220][main.py][line:105][INFO] [Epoch:25/30]: lr:0.00040 | loss1:0.0000 loss2:0.0113 loss3:0.0010 | AUC:0.8343 Anomaly AUC:0.6661
[2023-08-28 11:09:36,813][main.py][line:105][INFO] [Epoch:26/30]: lr:0.00040 | loss1:0.0000 loss2:0.0101 loss3:0.0009 | AUC:0.8323 Anomaly AUC:0.6665
[2023-08-28 11:09:59,561][main.py][line:105][INFO] [Epoch:27/30]: lr:0.00040 | loss1:0.0000 loss2:0.0093 loss3:0.0009 | AUC:0.8278 Anomaly AUC:0.6630
[2023-08-28 11:10:21,923][main.py][line:105][INFO] [Epoch:28/30]: lr:0.00040 | loss1:0.0000 loss2:0.0085 loss3:0.0009 | AUC:0.8290 Anomaly AUC:0.6632
[2023-08-28 11:11:14,046][main-autotune.py][line:125][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:16:44,820][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 30, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:16:57,811][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:17:28,215][main-autotune.py][line:110][INFO] [Epoch:1/2]: lr:0.00040 | loss1:0.3629 loss2:1.0051 loss3:0.3226 | AUC:0.8346 Anomaly AUC:0.6621
[2023-08-28 11:17:46,462][main-autotune.py][line:110][INFO] [Epoch:2/2]: lr:0.00040 | loss1:0.1309 loss2:0.7457 loss3:0.0985 | AUC:0.7911 Anomaly AUC:0.6537
[2023-08-28 11:17:46,463][main-autotune.py][line:120][INFO] Training completes in 0m 40s | best AUCAUC:0.8346 Anomaly AUC:0.6621

[2023-08-28 11:17:48,128][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:19:21,291][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:19:48,268][main-autotune.py][line:110][INFO] [Epoch:1/2]: lr:0.00040 | loss1:0.3641 loss2:1.1851 loss3:0.3119 | AUC:0.8022 Anomaly AUC:0.5918
[2023-08-28 11:20:09,429][main-autotune.py][line:110][INFO] [Epoch:2/2]: lr:0.00040 | loss1:0.1248 loss2:0.9831 loss3:0.1164 | AUC:0.8376 Anomaly AUC:0.6523
[2023-08-28 11:20:09,429][main-autotune.py][line:120][INFO] Training completes in 0m 40s | best AUCAUC:0.8376 Anomaly AUC:0.6523

[2023-08-28 11:20:46,028][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:21:13,212][main-autotune.py][line:110][INFO] [Epoch:1/2]: lr:0.00040 | loss1:0.3753 loss2:1.0540 loss3:0.2485 | AUC:0.8053 Anomaly AUC:0.6518
[2023-08-28 11:21:36,133][main-autotune.py][line:110][INFO] [Epoch:2/2]: lr:0.00040 | loss1:0.1698 loss2:0.8238 loss3:0.0894 | AUC:0.7977 Anomaly AUC:0.6604
[2023-08-28 11:21:36,134][main-autotune.py][line:120][INFO] Training completes in 0m 42s | best AUCAUC:0.8053 Anomaly AUC:0.6518

[2023-08-28 11:21:37,773][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:21:53,006][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:22:21,753][main-autotune.py][line:110][INFO] [Epoch:1/2]: lr:0.00040 | loss1:0.3791 loss2:1.1963 loss3:0.2136 | AUC:0.8051 Anomaly AUC:0.5915
[2023-08-28 11:22:40,178][main-autotune.py][line:110][INFO] [Epoch:2/2]: lr:0.00040 | loss1:0.1776 loss2:0.9845 loss3:0.0621 | AUC:0.8088 Anomaly AUC:0.6400
[2023-08-28 11:22:40,179][main-autotune.py][line:120][INFO] Training completes in 0m 39s | best AUCAUC:0.8088 Anomaly AUC:0.6400

[2023-08-28 11:23:42,324][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:24:12,258][main-autotune.py][line:110][INFO] [Epoch:1/2]: lr:0.00040 | loss1:0.3753 loss2:1.0540 loss3:0.2485 | AUC:0.8053 Anomaly AUC:0.6518
[2023-08-28 11:24:28,706][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 2, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:24:43,016][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:25:11,352][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3753 loss2:1.0540 loss3:0.2485 | AUC:0.8053 Anomaly AUC:0.6518
[2023-08-28 11:25:29,687][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1698 loss2:0.8238 loss3:0.0894 | AUC:0.7977 Anomaly AUC:0.6604
[2023-08-28 11:25:50,822][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0825 loss2:0.7080 loss3:0.0465 | AUC:0.7961 Anomaly AUC:0.6664
[2023-08-28 11:26:09,375][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0386 loss2:0.6081 loss3:0.0277 | AUC:0.7972 Anomaly AUC:0.6973
[2023-08-28 11:26:30,471][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0295 loss2:0.5123 loss3:0.0216 | AUC:0.8424 Anomaly AUC:0.6696
[2023-08-28 11:26:49,158][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0293 loss2:0.4459 loss3:0.0210 | AUC:0.8364 Anomaly AUC:0.6901
[2023-08-28 11:27:08,418][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0235 loss2:0.3666 loss3:0.0189 | AUC:0.8473 Anomaly AUC:0.6721
[2023-08-28 11:27:28,781][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0168 loss2:0.2893 loss3:0.0164 | AUC:0.8476 Anomaly AUC:0.6622
[2023-08-28 11:27:48,014][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0119 loss2:0.2260 loss3:0.0150 | AUC:0.8341 Anomaly AUC:0.6671
[2023-08-28 11:28:08,938][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0098 loss2:0.1769 loss3:0.0138 | AUC:0.8468 Anomaly AUC:0.6751
[2023-08-28 11:28:31,098][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0187 loss2:0.1690 loss3:0.0160 | AUC:0.8488 Anomaly AUC:0.6735
[2023-08-28 11:28:53,036][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0055 loss2:0.1151 loss3:0.0121 | AUC:0.8465 Anomaly AUC:0.6465
[2023-08-28 11:29:12,253][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0078 loss2:0.0974 loss3:0.0127 | AUC:0.8400 Anomaly AUC:0.6485
[2023-08-28 11:29:31,737][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0178 loss2:0.1012 loss3:0.0155 | AUC:0.8290 Anomaly AUC:0.6516
[2023-08-28 11:29:51,634][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0105 loss2:0.0858 loss3:0.0137 | AUC:0.8327 Anomaly AUC:0.6449
[2023-08-28 11:30:12,593][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0173 loss2:0.0770 loss3:0.0154 | AUC:0.8266 Anomaly AUC:0.6442
[2023-08-28 11:30:32,167][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0044 loss2:0.0527 loss3:0.0132 | AUC:0.8344 Anomaly AUC:0.6349
[2023-08-28 11:30:51,467][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0080 loss2:0.0502 loss3:0.0125 | AUC:0.8391 Anomaly AUC:0.6464
[2023-08-28 11:31:11,037][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0095 loss2:0.0483 loss3:0.0128 | AUC:0.8118 Anomaly AUC:0.6248
[2023-08-28 11:31:31,716][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0064 loss2:0.0410 loss3:0.0128 | AUC:0.8242 Anomaly AUC:0.6298
[2023-08-28 11:31:31,717][main-autotune.py][line:120][INFO] Training completes in 6m 41s | best AUCAUC:0.8488 Anomaly AUC:0.6735

[2023-08-28 11:31:33,369][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:32:00,322][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3785 loss2:1.3452 loss3:0.2587 | AUC:0.7979 Anomaly AUC:0.5851
[2023-08-28 11:32:19,398][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1525 loss2:1.1539 loss3:0.0722 | AUC:0.8342 Anomaly AUC:0.6109
[2023-08-28 11:32:39,628][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0699 loss2:1.0406 loss3:0.0306 | AUC:0.8353 Anomaly AUC:0.6375
[2023-08-28 11:32:59,697][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0419 loss2:0.9569 loss3:0.0157 | AUC:0.8459 Anomaly AUC:0.6621
[2023-08-28 11:33:19,858][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0199 loss2:0.8979 loss3:0.0074 | AUC:0.8563 Anomaly AUC:0.6947
[2023-08-28 11:33:39,912][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0188 loss2:0.8746 loss3:0.0059 | AUC:0.8366 Anomaly AUC:0.6547
[2023-08-28 11:34:00,074][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0168 loss2:0.8569 loss3:0.0049 | AUC:0.8284 Anomaly AUC:0.6653
[2023-08-28 11:34:19,976][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0183 loss2:0.8444 loss3:0.0049 | AUC:0.8194 Anomaly AUC:0.6657
[2023-08-28 11:34:40,598][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0146 loss2:0.8368 loss3:0.0040 | AUC:0.8478 Anomaly AUC:0.6696
[2023-08-28 11:35:00,681][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0112 loss2:0.8293 loss3:0.0026 | AUC:0.8485 Anomaly AUC:0.6686
[2023-08-28 11:35:20,640][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0071 loss2:0.8136 loss3:0.0018 | AUC:0.8353 Anomaly AUC:0.6411
[2023-08-28 11:35:40,439][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0085 loss2:0.8072 loss3:0.0020 | AUC:0.8323 Anomaly AUC:0.6327
[2023-08-28 11:36:00,402][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0058 loss2:0.8026 loss3:0.0015 | AUC:0.8332 Anomaly AUC:0.6280
[2023-08-28 11:36:20,309][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0082 loss2:0.7999 loss3:0.0022 | AUC:0.8355 Anomaly AUC:0.6471
[2023-08-28 11:36:39,445][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0048 loss2:0.7906 loss3:0.0015 | AUC:0.8390 Anomaly AUC:0.6386
[2023-08-28 11:36:58,920][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0101 loss2:0.7888 loss3:0.0029 | AUC:0.8120 Anomaly AUC:0.6688
[2023-08-28 11:37:18,722][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0242 loss2:0.8086 loss3:0.0068 | AUC:0.8352 Anomaly AUC:0.6167
[2023-08-28 11:37:37,859][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0044 loss2:0.7906 loss3:0.0014 | AUC:0.8375 Anomaly AUC:0.6498
[2023-08-28 11:37:57,372][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0056 loss2:0.7863 loss3:0.0018 | AUC:0.8437 Anomaly AUC:0.6475
[2023-08-28 11:38:16,505][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0057 loss2:0.7783 loss3:0.0015 | AUC:0.8232 Anomaly AUC:0.6131
[2023-08-28 11:38:16,506][main-autotune.py][line:120][INFO] Training completes in 6m 35s | best AUCAUC:0.8563 Anomaly AUC:0.6947

[2023-08-28 11:38:18,199][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:38:45,266][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3683 loss2:1.0631 loss3:0.2446 | AUC:0.8234 Anomaly AUC:0.6456
[2023-08-28 11:39:04,420][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.1374 loss2:0.8111 loss3:0.0570 | AUC:0.8305 Anomaly AUC:0.6506
[2023-08-28 11:39:26,502][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0634 loss2:0.6951 loss3:0.0268 | AUC:0.8252 Anomaly AUC:0.6469
[2023-08-28 11:39:44,972][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0359 loss2:0.5950 loss3:0.0171 | AUC:0.8300 Anomaly AUC:0.6695
[2023-08-28 11:40:04,109][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0274 loss2:0.5063 loss3:0.0127 | AUC:0.8207 Anomaly AUC:0.6686
[2023-08-28 11:40:24,802][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0260 loss2:0.4263 loss3:0.0103 | AUC:0.8434 Anomaly AUC:0.6689
[2023-08-28 11:40:45,008][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0218 loss2:0.3747 loss3:0.0088 | AUC:0.8496 Anomaly AUC:0.6745
[2023-08-28 11:41:04,395][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0170 loss2:0.2769 loss3:0.0049 | AUC:0.8268 Anomaly AUC:0.6498
[2023-08-28 11:41:23,749][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0059 loss2:0.1971 loss3:0.0025 | AUC:0.8350 Anomaly AUC:0.6641
[2023-08-28 11:41:43,112][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0089 loss2:0.1485 loss3:0.0028 | AUC:0.8445 Anomaly AUC:0.6682
[2023-08-28 11:42:02,560][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0200 loss2:0.1398 loss3:0.0050 | AUC:0.8480 Anomaly AUC:0.6706
[2023-08-28 11:42:22,621][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0183 loss2:0.1373 loss3:0.0044 | AUC:0.8635 Anomaly AUC:0.7052
[2023-08-28 11:42:41,870][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0092 loss2:0.0716 loss3:0.0020 | AUC:0.8359 Anomaly AUC:0.6714
[2023-08-28 11:43:01,357][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0072 loss2:0.0538 loss3:0.0020 | AUC:0.8365 Anomaly AUC:0.6385
[2023-08-28 11:43:20,611][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0127 loss2:0.0659 loss3:0.0033 | AUC:0.8273 Anomaly AUC:0.6516
[2023-08-28 11:43:40,145][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.0098 loss2:0.0502 loss3:0.0027 | AUC:0.8612 Anomaly AUC:0.6880
[2023-08-28 11:43:59,271][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.0059 loss2:0.0296 loss3:0.0020 | AUC:0.8403 Anomaly AUC:0.6741
[2023-08-28 11:44:18,743][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.0008 loss2:0.0173 loss3:0.0008 | AUC:0.8388 Anomaly AUC:0.6591
[2023-08-28 11:44:38,850][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0108 loss2:0.0316 loss3:0.0028 | AUC:0.8118 Anomaly AUC:0.6381
[2023-08-28 11:44:57,936][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0158 loss2:0.0456 loss3:0.0039 | AUC:0.8251 Anomaly AUC:0.6475
[2023-08-28 11:44:57,937][main-autotune.py][line:120][INFO] Training completes in 6m 31s | best AUCAUC:0.8635 Anomaly AUC:0.7052

[2023-08-28 11:44:59,611][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:45:26,724][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3600 loss2:1.1183 loss3:0.3898 | AUC:0.8186 Anomaly AUC:0.6382
[2023-08-28 11:45:47,696][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.0221 loss2:0.8326 loss3:0.4550 | AUC:0.8088 Anomaly AUC:0.7092
[2023-08-28 11:46:06,077][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0054 loss2:0.7034 loss3:0.3740 | AUC:0.8422 Anomaly AUC:0.7011
[2023-08-28 11:46:25,582][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0028 loss2:0.5808 loss3:0.3282 | AUC:0.8445 Anomaly AUC:0.6764
[2023-08-28 11:46:45,713][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0057 loss2:0.4955 loss3:0.3075 | AUC:0.8315 Anomaly AUC:0.6890
[2023-08-28 11:47:05,732][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0114 loss2:0.4537 loss3:0.2917 | AUC:0.8250 Anomaly AUC:0.6909
[2023-08-28 11:47:26,074][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0017 loss2:0.3509 loss3:0.2467 | AUC:0.8116 Anomaly AUC:0.6608
[2023-08-28 11:47:45,463][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0024 loss2:0.2659 loss3:0.1862 | AUC:0.8173 Anomaly AUC:0.6683
[2023-08-28 11:48:04,527][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0020 loss2:0.2043 loss3:0.1577 | AUC:0.8362 Anomaly AUC:0.6793
[2023-08-28 11:48:24,304][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0010 loss2:0.1560 loss3:0.1312 | AUC:0.8377 Anomaly AUC:0.6846
[2023-08-28 11:48:43,812][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0566 loss2:0.2045 loss3:0.1698 | AUC:0.8106 Anomaly AUC:0.6759
[2023-08-28 11:49:03,794][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0049 loss2:0.3176 loss3:0.2402 | AUC:0.8126 Anomaly AUC:0.6812
[2023-08-28 11:49:23,795][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0016 loss2:0.1557 loss3:0.1383 | AUC:0.8040 Anomaly AUC:0.6713
[2023-08-28 11:49:42,835][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0007 loss2:0.1091 loss3:0.0993 | AUC:0.8251 Anomaly AUC:0.6719
[2023-08-28 11:50:02,262][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0005 loss2:0.0823 loss3:0.0796 | AUC:0.8273 Anomaly AUC:0.6730
[2023-08-28 11:50:21,627][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0005 loss2:0.0668 loss3:0.0681 | AUC:0.8232 Anomaly AUC:0.6658
[2023-08-28 11:50:40,386][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0019 loss2:0.0635 loss3:0.0816 | AUC:0.8224 Anomaly AUC:0.6757
[2023-08-28 11:50:59,945][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0031 loss2:0.0726 loss3:0.1114 | AUC:0.7779 Anomaly AUC:0.6709
[2023-08-28 11:51:20,018][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0019 loss2:0.0596 loss3:0.1173 | AUC:0.7678 Anomaly AUC:0.6826
[2023-08-28 11:51:39,951][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0032 loss2:0.0561 loss3:0.1217 | AUC:0.7725 Anomaly AUC:0.6808
[2023-08-28 11:51:39,953][main-autotune.py][line:120][INFO] Training completes in 6m 32s | best AUCAUC:0.8445 Anomaly AUC:0.6764

[2023-08-28 11:51:42,019][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:52:09,073][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3614 loss2:1.1100 loss3:0.3981 | AUC:0.8172 Anomaly AUC:0.6410
[2023-08-28 11:52:30,759][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.0142 loss2:0.8086 loss3:0.6788 | AUC:0.8082 Anomaly AUC:0.6858
[2023-08-28 11:52:53,180][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0033 loss2:0.6689 loss3:0.4870 | AUC:0.8204 Anomaly AUC:0.6894
[2023-08-28 11:53:15,493][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0019 loss2:0.5437 loss3:0.4150 | AUC:0.8375 Anomaly AUC:0.6877
[2023-08-28 11:53:35,724][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0014 loss2:0.4173 loss3:0.3789 | AUC:0.8367 Anomaly AUC:0.6933
[2023-08-28 11:53:56,054][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0008 loss2:0.3064 loss3:0.3418 | AUC:0.8301 Anomaly AUC:0.6890
[2023-08-28 11:54:15,387][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0007 loss2:0.2239 loss3:0.3266 | AUC:0.8187 Anomaly AUC:0.6868
[2023-08-28 11:54:35,235][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0005 loss2:0.1636 loss3:0.3084 | AUC:0.8173 Anomaly AUC:0.6831
[2023-08-28 11:54:54,909][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0563 loss2:0.3193 loss3:0.6487 | AUC:0.7483 Anomaly AUC:0.5745
[2023-08-28 11:55:14,754][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0022 loss2:0.4158 loss3:0.5341 | AUC:0.7444 Anomaly AUC:0.6072
[2023-08-28 11:55:34,190][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0015 loss2:0.3724 loss3:0.4583 | AUC:0.7429 Anomaly AUC:0.6155
[2023-08-28 11:55:53,541][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0010 loss2:0.2444 loss3:0.4089 | AUC:0.7313 Anomaly AUC:0.6009
[2023-08-28 11:56:13,687][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0008 loss2:0.1860 loss3:0.3784 | AUC:0.7355 Anomaly AUC:0.5966
[2023-08-28 11:56:33,035][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0006 loss2:0.1456 loss3:0.3563 | AUC:0.7331 Anomaly AUC:0.5963
[2023-08-28 11:56:52,529][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0005 loss2:0.1200 loss3:0.3414 | AUC:0.7418 Anomaly AUC:0.5998
[2023-08-28 11:57:11,805][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0004 loss2:0.1003 loss3:0.3285 | AUC:0.7524 Anomaly AUC:0.6005
[2023-08-28 11:57:31,206][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0003 loss2:0.0840 loss3:0.3181 | AUC:0.7539 Anomaly AUC:0.6087
[2023-08-28 11:57:50,636][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0003 loss2:0.0708 loss3:0.3064 | AUC:0.7480 Anomaly AUC:0.6100
[2023-08-28 11:58:10,081][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0002 loss2:0.0602 loss3:0.2960 | AUC:0.7683 Anomaly AUC:0.6308
[2023-08-28 11:58:29,282][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0002 loss2:0.0545 loss3:0.2845 | AUC:0.7452 Anomaly AUC:0.6257
[2023-08-28 11:58:29,283][main-autotune.py][line:120][INFO] Training completes in 6m 39s | best AUCAUC:0.8375 Anomaly AUC:0.6877

[2023-08-28 11:58:30,947][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 11:58:57,906][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3410 loss2:1.1014 loss3:0.3797 | AUC:0.8188 Anomaly AUC:0.6788
[2023-08-28 11:59:18,918][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.0205 loss2:0.8089 loss3:0.3405 | AUC:0.8285 Anomaly AUC:0.6878
[2023-08-28 11:59:37,340][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0044 loss2:0.6538 loss3:0.2505 | AUC:0.8229 Anomaly AUC:0.6885
[2023-08-28 11:59:56,610][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0089 loss2:0.5630 loss3:0.1701 | AUC:0.8269 Anomaly AUC:0.6778
[2023-08-28 12:00:19,198][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0095 loss2:0.4720 loss3:0.1300 | AUC:0.8438 Anomaly AUC:0.6881
[2023-08-28 12:00:38,535][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0020 loss2:0.3486 loss3:0.0725 | AUC:0.8421 Anomaly AUC:0.6675
[2023-08-28 12:00:57,991][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0032 loss2:0.2510 loss3:0.0502 | AUC:0.8378 Anomaly AUC:0.6804
[2023-08-28 12:01:18,223][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0017 loss2:0.1735 loss3:0.0416 | AUC:0.8325 Anomaly AUC:0.6872
[2023-08-28 12:01:37,789][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0102 loss2:0.2340 loss3:0.0726 | AUC:0.7521 Anomaly AUC:0.6811
[2023-08-28 12:01:57,268][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0038 loss2:0.2070 loss3:0.0595 | AUC:0.8153 Anomaly AUC:0.6908
[2023-08-28 12:02:16,854][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0018 loss2:0.1343 loss3:0.0536 | AUC:0.7917 Anomaly AUC:0.6943
[2023-08-28 12:02:36,352][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0007 loss2:0.0901 loss3:0.0312 | AUC:0.8354 Anomaly AUC:0.6885
[2023-08-28 12:02:55,701][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0003 loss2:0.0538 loss3:0.0149 | AUC:0.8442 Anomaly AUC:0.6852
[2023-08-28 12:03:15,272][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0004 loss2:0.0444 loss3:0.0121 | AUC:0.8401 Anomaly AUC:0.6795
[2023-08-28 12:03:34,548][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0010 loss2:0.0387 loss3:0.0130 | AUC:0.8241 Anomaly AUC:0.7006
[2023-08-28 12:03:53,936][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.4447 loss2:0.4780 loss3:0.3384 | AUC:0.7834 Anomaly AUC:0.6527
[2023-08-28 12:04:14,050][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.0030 loss2:0.2022 loss3:0.0618 | AUC:0.8353 Anomaly AUC:0.6854
[2023-08-28 12:04:34,171][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.0011 loss2:0.0708 loss3:0.0326 | AUC:0.8353 Anomaly AUC:0.6693
[2023-08-28 12:04:53,021][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0022 loss2:0.0578 loss3:0.0461 | AUC:0.8081 Anomaly AUC:0.6807
[2023-08-28 12:05:12,433][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0004 loss2:0.0253 loss3:0.0173 | AUC:0.8398 Anomaly AUC:0.6793
[2023-08-28 12:05:12,435][main-autotune.py][line:120][INFO] Training completes in 6m 33s | best AUCAUC:0.8442 Anomaly AUC:0.6852

[2023-08-28 12:05:14,450][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:05:41,530][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3736 loss2:1.1105 loss3:0.3635 | AUC:0.8098 Anomaly AUC:0.6285
[2023-08-28 12:06:00,843][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1236 loss2:0.8720 loss3:0.2778 | AUC:0.8363 Anomaly AUC:0.6810
[2023-08-28 12:06:23,386][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0320 loss2:0.7575 loss3:0.2089 | AUC:0.8188 Anomaly AUC:0.6730
[2023-08-28 12:06:43,867][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0205 loss2:0.6901 loss3:0.1620 | AUC:0.8354 Anomaly AUC:0.6659
[2023-08-28 12:07:04,560][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0232 loss2:0.6271 loss3:0.1249 | AUC:0.8224 Anomaly AUC:0.6576
[2023-08-28 12:07:24,800][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0143 loss2:0.5514 loss3:0.0948 | AUC:0.8254 Anomaly AUC:0.6618
[2023-08-28 12:07:44,420][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0217 loss2:0.5077 loss3:0.0746 | AUC:0.8199 Anomaly AUC:0.6677
[2023-08-28 12:08:03,920][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0051 loss2:0.4304 loss3:0.0509 | AUC:0.8213 Anomaly AUC:0.6679
[2023-08-28 12:08:23,626][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0017 loss2:0.3620 loss3:0.0348 | AUC:0.8408 Anomaly AUC:0.6693
[2023-08-28 12:08:43,060][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0362 loss2:0.3932 loss3:0.0405 | AUC:0.8256 Anomaly AUC:0.6655
[2023-08-28 12:09:03,416][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0042 loss2:0.3097 loss3:0.0289 | AUC:0.8366 Anomaly AUC:0.6713
[2023-08-28 12:09:22,835][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0187 loss2:0.2903 loss3:0.0267 | AUC:0.8189 Anomaly AUC:0.6619
[2023-08-28 12:09:41,605][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0032 loss2:0.2370 loss3:0.0201 | AUC:0.8414 Anomaly AUC:0.6696
[2023-08-28 12:10:00,493][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0060 loss2:0.2260 loss3:0.0192 | AUC:0.8420 Anomaly AUC:0.6750
[2023-08-28 12:10:20,003][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0005 loss2:0.1772 loss3:0.0141 | AUC:0.8394 Anomaly AUC:0.6766
[2023-08-28 12:10:40,358][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0004 loss2:0.1533 loss3:0.0120 | AUC:0.8407 Anomaly AUC:0.6789
[2023-08-28 12:11:00,589][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0003 loss2:0.1356 loss3:0.0106 | AUC:0.8432 Anomaly AUC:0.6825
[2023-08-28 12:11:20,838][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0003 loss2:0.1212 loss3:0.0093 | AUC:0.8411 Anomaly AUC:0.6791
[2023-08-28 12:11:40,228][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0002 loss2:0.1085 loss3:0.0081 | AUC:0.8437 Anomaly AUC:0.6830
[2023-08-28 12:11:59,158][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0002 loss2:0.0973 loss3:0.0068 | AUC:0.8430 Anomaly AUC:0.6804
[2023-08-28 12:11:59,159][main-autotune.py][line:120][INFO] Training completes in 6m 36s | best AUCAUC:0.8437 Anomaly AUC:0.6830

[2023-08-28 12:12:00,848][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:12:28,298][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3856 loss2:1.0496 loss3:0.1722 | AUC:0.8324 Anomaly AUC:0.6378
[2023-08-28 12:12:47,552][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1701 loss2:0.8157 loss3:0.0374 | AUC:0.8297 Anomaly AUC:0.6659
[2023-08-28 12:13:10,196][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0733 loss2:0.6938 loss3:0.0162 | AUC:0.8325 Anomaly AUC:0.6822
[2023-08-28 12:13:30,220][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0470 loss2:0.6048 loss3:0.0103 | AUC:0.8460 Anomaly AUC:0.6702
[2023-08-28 12:13:50,785][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0421 loss2:0.5319 loss3:0.0099 | AUC:0.8475 Anomaly AUC:0.6736
[2023-08-28 12:14:11,047][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0187 loss2:0.4261 loss3:0.0045 | AUC:0.8523 Anomaly AUC:0.6690
[2023-08-28 12:14:31,099][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0133 loss2:0.3298 loss3:0.0032 | AUC:0.8443 Anomaly AUC:0.6642
[2023-08-28 12:14:50,996][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0185 loss2:0.2829 loss3:0.0044 | AUC:0.8565 Anomaly AUC:0.6782
[2023-08-28 12:15:10,645][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0132 loss2:0.2222 loss3:0.0037 | AUC:0.8463 Anomaly AUC:0.6530
[2023-08-28 12:15:30,065][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0180 loss2:0.1859 loss3:0.0037 | AUC:0.8416 Anomaly AUC:0.6655
[2023-08-28 12:15:49,716][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0075 loss2:0.1332 loss3:0.0020 | AUC:0.8402 Anomaly AUC:0.6689
[2023-08-28 12:16:09,129][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0094 loss2:0.1135 loss3:0.0021 | AUC:0.8657 Anomaly AUC:0.6931
[2023-08-28 12:16:27,975][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0199 loss2:0.1312 loss3:0.0043 | AUC:0.8435 Anomaly AUC:0.6769
[2023-08-28 12:16:46,816][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0089 loss2:0.0899 loss3:0.0021 | AUC:0.8547 Anomaly AUC:0.6820
[2023-08-28 12:17:06,531][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0099 loss2:0.0768 loss3:0.0020 | AUC:0.8560 Anomaly AUC:0.6821
[2023-08-28 12:17:26,107][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0135 loss2:0.0781 loss3:0.0029 | AUC:0.8377 Anomaly AUC:0.6458
[2023-08-28 12:17:44,900][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0061 loss2:0.0554 loss3:0.0014 | AUC:0.8203 Anomaly AUC:0.6414
[2023-08-28 12:18:03,804][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0066 loss2:0.0463 loss3:0.0014 | AUC:0.8459 Anomaly AUC:0.6726
[2023-08-28 12:18:22,743][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0110 loss2:0.0469 loss3:0.0023 | AUC:0.8359 Anomaly AUC:0.6497
[2023-08-28 12:18:42,278][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0151 loss2:0.0579 loss3:0.0028 | AUC:0.8227 Anomaly AUC:0.6353
[2023-08-28 12:18:42,280][main-autotune.py][line:120][INFO] Training completes in 6m 33s | best AUCAUC:0.8657 Anomaly AUC:0.6931

[2023-08-28 12:18:44,312][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:19:11,515][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3781 loss2:1.0206 loss3:0.1812 | AUC:0.8418 Anomaly AUC:0.6578
[2023-08-28 12:19:33,479][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.1505 loss2:0.7862 loss3:0.0348 | AUC:0.8149 Anomaly AUC:0.6730
[2023-08-28 12:19:56,165][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0707 loss2:0.6579 loss3:0.0143 | AUC:0.8363 Anomaly AUC:0.6847
[2023-08-28 12:20:16,511][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0290 loss2:0.5382 loss3:0.0062 | AUC:0.8301 Anomaly AUC:0.6511
[2023-08-28 12:20:36,958][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0249 loss2:0.4270 loss3:0.0050 | AUC:0.8486 Anomaly AUC:0.6843
[2023-08-28 12:20:56,287][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0178 loss2:0.3174 loss3:0.0042 | AUC:0.8517 Anomaly AUC:0.6666
[2023-08-28 12:21:15,806][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0163 loss2:0.2296 loss3:0.0037 | AUC:0.8511 Anomaly AUC:0.6937
[2023-08-28 12:21:35,247][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0134 loss2:0.1710 loss3:0.0033 | AUC:0.8419 Anomaly AUC:0.6703
[2023-08-28 12:21:53,907][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0166 loss2:0.1312 loss3:0.0034 | AUC:0.8519 Anomaly AUC:0.7050
[2023-08-28 12:22:12,572][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0196 loss2:0.1259 loss3:0.0041 | AUC:0.8437 Anomaly AUC:0.6911
[2023-08-28 12:22:32,112][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0096 loss2:0.0700 loss3:0.0019 | AUC:0.8493 Anomaly AUC:0.7050
[2023-08-28 12:22:52,281][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0040 loss2:0.0433 loss3:0.0009 | AUC:0.8419 Anomaly AUC:0.6786
[2023-08-28 12:23:11,255][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0061 loss2:0.0418 loss3:0.0013 | AUC:0.8524 Anomaly AUC:0.6981
[2023-08-28 12:23:30,854][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0004 loss2:0.0222 loss3:0.0004 | AUC:0.8507 Anomaly AUC:0.6993
[2023-08-28 12:23:50,059][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0111 loss2:0.0333 loss3:0.0022 | AUC:0.8400 Anomaly AUC:0.6945
[2023-08-28 12:24:08,982][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.0274 loss2:0.0869 loss3:0.0054 | AUC:0.8280 Anomaly AUC:0.6870
[2023-08-28 12:24:27,831][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.0097 loss2:0.0414 loss3:0.0022 | AUC:0.7861 Anomaly AUC:0.6304
[2023-08-28 12:24:46,696][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.0067 loss2:0.0287 loss3:0.0023 | AUC:0.8319 Anomaly AUC:0.6401
[2023-08-28 12:25:06,212][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0124 loss2:0.0333 loss3:0.0025 | AUC:0.8443 Anomaly AUC:0.6783
[2023-08-28 12:25:26,430][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0089 loss2:0.0299 loss3:0.0019 | AUC:0.8336 Anomaly AUC:0.6563
[2023-08-28 12:25:26,432][main-autotune.py][line:120][INFO] Training completes in 6m 34s | best AUCAUC:0.8524 Anomaly AUC:0.6981

[2023-08-28 12:25:28,417][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:25:55,668][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00090 | loss1:0.3110 loss2:0.9877 loss3:0.4137 | AUC:0.7986 Anomaly AUC:0.6802
[2023-08-28 12:26:17,001][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00090 | loss1:0.0105 loss2:0.6475 loss3:0.3996 | AUC:0.8174 Anomaly AUC:0.7122
[2023-08-28 12:26:35,423][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00090 | loss1:0.0070 loss2:0.4548 loss3:0.3566 | AUC:0.3882 Anomaly AUC:0.4182
[2023-08-28 12:26:54,992][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00090 | loss1:0.0135 loss2:0.3970 loss3:0.3915 | AUC:0.8059 Anomaly AUC:0.6889
[2023-08-28 12:27:14,694][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00090 | loss1:0.0014 loss2:0.1907 loss3:0.3285 | AUC:0.8208 Anomaly AUC:0.6892
[2023-08-28 12:27:34,055][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00090 | loss1:0.0017 loss2:0.1196 loss3:0.3005 | AUC:0.8170 Anomaly AUC:0.6802
[2023-08-28 12:27:54,565][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00090 | loss1:0.0007 loss2:0.0659 loss3:0.2481 | AUC:0.8301 Anomaly AUC:0.6774
[2023-08-28 12:28:14,786][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00090 | loss1:0.0015 loss2:0.0546 loss3:0.1721 | AUC:0.8424 Anomaly AUC:0.6851
[2023-08-28 12:28:34,533][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00090 | loss1:0.1010 loss2:0.2895 loss3:0.3769 | AUC:0.8024 Anomaly AUC:0.6962
[2023-08-28 12:28:54,091][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00090 | loss1:0.0019 loss2:0.0903 loss3:0.3198 | AUC:0.8137 Anomaly AUC:0.6861
[2023-08-28 12:29:14,388][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00090 | loss1:0.0012 loss2:0.0415 loss3:0.2501 | AUC:0.8271 Anomaly AUC:0.6894
[2023-08-28 12:29:34,451][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00090 | loss1:0.0011 loss2:0.0277 loss3:0.1805 | AUC:0.8280 Anomaly AUC:0.6923
[2023-08-28 12:29:54,569][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00090 | loss1:0.0007 loss2:0.0188 loss3:0.1374 | AUC:0.8317 Anomaly AUC:0.6943
[2023-08-28 12:30:13,866][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00090 | loss1:0.0028 loss2:0.0289 loss3:0.1410 | AUC:0.8249 Anomaly AUC:0.6905
[2023-08-28 12:30:32,791][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00090 | loss1:0.0004 loss2:0.0130 loss3:0.1100 | AUC:0.8401 Anomaly AUC:0.6907
[2023-08-28 12:30:51,712][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00090 | loss1:0.0003 loss2:0.0086 loss3:0.0873 | AUC:0.8360 Anomaly AUC:0.6830
[2023-08-28 12:31:10,528][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00090 | loss1:0.0007 loss2:0.0126 loss3:0.0769 | AUC:0.8182 Anomaly AUC:0.6704
[2023-08-28 12:31:30,054][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00090 | loss1:0.0664 loss2:0.2587 loss3:0.2028 | AUC:0.7816 Anomaly AUC:0.6591
[2023-08-28 12:31:49,480][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00090 | loss1:0.0017 loss2:0.0571 loss3:0.1077 | AUC:0.8266 Anomaly AUC:0.6861
[2023-08-28 12:32:08,397][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00090 | loss1:0.0007 loss2:0.0184 loss3:0.0652 | AUC:0.8199 Anomaly AUC:0.6718
[2023-08-28 12:32:08,398][main-autotune.py][line:120][INFO] Training completes in 6m 31s | best AUCAUC:0.8424 Anomaly AUC:0.6851

[2023-08-28 12:32:10,074][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:32:37,264][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00090 | loss1:0.4020 loss2:1.0098 loss3:0.1808 | AUC:0.8303 Anomaly AUC:0.6701
[2023-08-28 12:32:56,365][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00090 | loss1:0.1603 loss2:0.7577 loss3:0.0405 | AUC:0.8254 Anomaly AUC:0.6658
[2023-08-28 12:33:17,028][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00090 | loss1:0.0819 loss2:0.6097 loss3:0.0215 | AUC:0.8206 Anomaly AUC:0.6717
[2023-08-28 12:33:37,423][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00090 | loss1:0.0415 loss2:0.4668 loss3:0.0101 | AUC:0.8346 Anomaly AUC:0.6685
[2023-08-28 12:33:57,100][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00090 | loss1:0.0236 loss2:0.3273 loss3:0.0057 | AUC:0.8538 Anomaly AUC:0.6825
[2023-08-28 12:34:16,495][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00090 | loss1:0.0231 loss2:0.2175 loss3:0.0060 | AUC:0.8544 Anomaly AUC:0.6768
[2023-08-28 12:34:36,175][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00090 | loss1:0.0245 loss2:0.1568 loss3:0.0053 | AUC:0.8453 Anomaly AUC:0.6833
[2023-08-28 12:34:55,616][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00090 | loss1:0.0170 loss2:0.0961 loss3:0.0043 | AUC:0.8427 Anomaly AUC:0.6716
[2023-08-28 12:35:15,215][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00090 | loss1:0.0181 loss2:0.0744 loss3:0.0039 | AUC:0.8368 Anomaly AUC:0.6712
[2023-08-28 12:35:34,745][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00090 | loss1:0.0107 loss2:0.0561 loss3:0.0028 | AUC:0.8337 Anomaly AUC:0.6687
[2023-08-28 12:35:54,309][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00090 | loss1:0.0174 loss2:0.0568 loss3:0.0047 | AUC:0.8248 Anomaly AUC:0.6576
[2023-08-28 12:36:13,903][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00090 | loss1:0.0092 loss2:0.0334 loss3:0.0022 | AUC:0.8290 Anomaly AUC:0.6711
[2023-08-28 12:36:34,225][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00090 | loss1:0.0166 loss2:0.0479 loss3:0.0040 | AUC:0.8303 Anomaly AUC:0.6724
[2023-08-28 12:36:53,191][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00090 | loss1:0.0111 loss2:0.0292 loss3:0.0027 | AUC:0.8417 Anomaly AUC:0.6713
[2023-08-28 12:37:12,672][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00090 | loss1:0.0122 loss2:0.0279 loss3:0.0027 | AUC:0.8246 Anomaly AUC:0.6636
[2023-08-28 12:37:32,623][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00090 | loss1:0.0202 loss2:0.0368 loss3:0.0041 | AUC:0.8220 Anomaly AUC:0.6253
[2023-08-28 12:37:51,883][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00090 | loss1:0.0174 loss2:0.0418 loss3:0.0039 | AUC:0.8273 Anomaly AUC:0.6680
[2023-08-28 12:38:10,733][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00090 | loss1:0.0141 loss2:0.0310 loss3:0.0030 | AUC:0.8281 Anomaly AUC:0.6582
[2023-08-28 12:38:29,565][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00090 | loss1:0.0069 loss2:0.0170 loss3:0.0018 | AUC:0.8309 Anomaly AUC:0.6789
[2023-08-28 12:38:49,236][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00090 | loss1:0.0007 loss2:0.0085 loss3:0.0006 | AUC:0.8361 Anomaly AUC:0.6816
[2023-08-28 12:38:49,238][main-autotune.py][line:120][INFO] Training completes in 6m 31s | best AUCAUC:0.8544 Anomaly AUC:0.6768

[2023-08-28 12:38:51,289][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:39:18,325][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00070 | loss1:0.3714 loss2:1.0337 loss3:0.2231 | AUC:0.8279 Anomaly AUC:0.6571
[2023-08-28 12:39:37,316][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00070 | loss1:0.1449 loss2:0.7848 loss3:0.0454 | AUC:0.7963 Anomaly AUC:0.6520
[2023-08-28 12:40:00,463][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00070 | loss1:0.0675 loss2:0.6504 loss3:0.0228 | AUC:0.8476 Anomaly AUC:0.6786
[2023-08-28 12:40:20,748][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00070 | loss1:0.0365 loss2:0.5347 loss3:0.0132 | AUC:0.8029 Anomaly AUC:0.6457
[2023-08-28 12:40:40,490][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00070 | loss1:0.0231 loss2:0.4202 loss3:0.0081 | AUC:0.8280 Anomaly AUC:0.6660
[2023-08-28 12:41:00,067][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00070 | loss1:0.0264 loss2:0.3364 loss3:0.0075 | AUC:0.8374 Anomaly AUC:0.6500
[2023-08-28 12:41:20,393][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00070 | loss1:0.0167 loss2:0.2424 loss3:0.0049 | AUC:0.8420 Anomaly AUC:0.6630
[2023-08-28 12:41:39,824][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00070 | loss1:0.0196 loss2:0.1826 loss3:0.0050 | AUC:0.8450 Anomaly AUC:0.6858
[2023-08-28 12:41:59,588][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00070 | loss1:0.0194 loss2:0.1380 loss3:0.0050 | AUC:0.8367 Anomaly AUC:0.6676
[2023-08-28 12:42:19,800][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00070 | loss1:0.0109 loss2:0.0906 loss3:0.0028 | AUC:0.8365 Anomaly AUC:0.6592
[2023-08-28 12:42:40,275][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00070 | loss1:0.0079 loss2:0.0660 loss3:0.0023 | AUC:0.7945 Anomaly AUC:0.6545
[2023-08-28 12:42:59,415][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00070 | loss1:0.0121 loss2:0.0682 loss3:0.0035 | AUC:0.8242 Anomaly AUC:0.6493
[2023-08-28 12:43:18,177][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00070 | loss1:0.0049 loss2:0.0363 loss3:0.0018 | AUC:0.8345 Anomaly AUC:0.6564
[2023-08-28 12:43:37,697][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00070 | loss1:0.0105 loss2:0.0385 loss3:0.0021 | AUC:0.8205 Anomaly AUC:0.6758
[2023-08-28 12:43:57,210][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00070 | loss1:0.0026 loss2:0.0249 loss3:0.0012 | AUC:0.8153 Anomaly AUC:0.6760
[2023-08-28 12:44:16,672][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00070 | loss1:0.0005 loss2:0.0123 loss3:0.0006 | AUC:0.8545 Anomaly AUC:0.6799
[2023-08-28 12:44:35,846][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00070 | loss1:0.0318 loss2:0.0785 loss3:0.0067 | AUC:0.7988 Anomaly AUC:0.6079
[2023-08-28 12:44:54,659][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00070 | loss1:0.0147 loss2:0.0410 loss3:0.0034 | AUC:0.8407 Anomaly AUC:0.6683
[2023-08-28 12:45:13,651][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00070 | loss1:0.0066 loss2:0.0290 loss3:0.0025 | AUC:0.8219 Anomaly AUC:0.6457
[2023-08-28 12:45:33,167][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00070 | loss1:0.0068 loss2:0.0248 loss3:0.0022 | AUC:0.8232 Anomaly AUC:0.6592
[2023-08-28 12:45:33,169][main-autotune.py][line:120][INFO] Training completes in 6m 33s | best AUCAUC:0.8545 Anomaly AUC:0.6799

[2023-08-28 12:45:35,183][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:46:02,986][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00070 | loss1:0.3684 loss2:1.1586 loss3:0.2536 | AUC:0.8167 Anomaly AUC:0.6212
[2023-08-28 12:46:22,203][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00070 | loss1:0.1415 loss2:0.9255 loss3:0.0514 | AUC:0.8306 Anomaly AUC:0.6509
[2023-08-28 12:46:44,442][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00070 | loss1:0.0564 loss2:0.8097 loss3:0.0183 | AUC:0.8228 Anomaly AUC:0.6566
[2023-08-28 12:47:02,961][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00070 | loss1:0.0401 loss2:0.7608 loss3:0.0101 | AUC:0.8437 Anomaly AUC:0.6692
[2023-08-28 12:47:21,642][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00070 | loss1:0.0275 loss2:0.7096 loss3:0.0073 | AUC:0.8442 Anomaly AUC:0.6615
[2023-08-28 12:47:41,238][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00070 | loss1:0.0154 loss2:0.6528 loss3:0.0042 | AUC:0.8387 Anomaly AUC:0.6832
[2023-08-28 12:48:01,673][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00070 | loss1:0.0161 loss2:0.6010 loss3:0.0041 | AUC:0.8359 Anomaly AUC:0.6741
[2023-08-28 12:48:21,347][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00070 | loss1:0.0158 loss2:0.5463 loss3:0.0040 | AUC:0.8466 Anomaly AUC:0.6719
[2023-08-28 12:48:40,211][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00070 | loss1:0.0191 loss2:0.4926 loss3:0.0047 | AUC:0.8447 Anomaly AUC:0.6749
[2023-08-28 12:48:59,598][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00070 | loss1:0.0149 loss2:0.4267 loss3:0.0038 | AUC:0.8287 Anomaly AUC:0.6631
[2023-08-28 12:49:19,990][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00070 | loss1:0.0234 loss2:0.4101 loss3:0.0052 | AUC:0.8394 Anomaly AUC:0.6689
[2023-08-28 12:49:40,298][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00070 | loss1:0.0114 loss2:0.3141 loss3:0.0029 | AUC:0.8388 Anomaly AUC:0.6835
[2023-08-28 12:49:59,443][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00070 | loss1:0.0214 loss2:0.2044 loss3:0.0057 | AUC:0.8370 Anomaly AUC:0.6899
[2023-08-28 12:50:18,305][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00070 | loss1:0.0101 loss2:0.2734 loss3:0.0027 | AUC:0.8436 Anomaly AUC:0.6873
[2023-08-28 12:50:37,861][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00070 | loss1:0.0126 loss2:0.2077 loss3:0.0031 | AUC:0.8408 Anomaly AUC:0.6851
[2023-08-28 12:50:57,285][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00070 | loss1:0.0028 loss2:0.1393 loss3:0.0013 | AUC:0.8305 Anomaly AUC:0.6673
[2023-08-28 12:51:16,139][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00070 | loss1:0.0065 loss2:0.0813 loss3:0.0017 | AUC:0.8312 Anomaly AUC:0.6353
[2023-08-28 12:51:35,659][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00070 | loss1:0.0130 loss2:0.1191 loss3:0.0038 | AUC:0.8433 Anomaly AUC:0.6742
[2023-08-28 12:51:55,966][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00070 | loss1:0.0053 loss2:0.0697 loss3:0.0018 | AUC:0.8390 Anomaly AUC:0.6714
[2023-08-28 12:52:15,322][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00070 | loss1:0.0100 loss2:0.0602 loss3:0.0027 | AUC:0.8165 Anomaly AUC:0.6498
[2023-08-28 12:52:15,323][main-autotune.py][line:120][INFO] Training completes in 6m 31s | best AUCAUC:0.8466 Anomaly AUC:0.6719

[2023-08-28 12:52:16,973][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:52:44,141][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00010 | loss1:0.3825 loss2:1.0586 loss3:0.2158 | AUC:0.8301 Anomaly AUC:0.6551
[2023-08-28 12:53:03,405][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00010 | loss1:0.1723 loss2:0.8423 loss3:0.0509 | AUC:0.7994 Anomaly AUC:0.6600
[2023-08-28 12:53:25,443][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00010 | loss1:0.0767 loss2:0.7447 loss3:0.0215 | AUC:0.8420 Anomaly AUC:0.6839
[2023-08-28 12:53:43,904][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00010 | loss1:0.0403 loss2:0.6726 loss3:0.0119 | AUC:0.8347 Anomaly AUC:0.6971
[2023-08-28 12:54:02,581][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00010 | loss1:0.0329 loss2:0.6117 loss3:0.0103 | AUC:0.8552 Anomaly AUC:0.6929
[2023-08-28 12:54:22,206][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00010 | loss1:0.0273 loss2:0.5531 loss3:0.0083 | AUC:0.8463 Anomaly AUC:0.6773
[2023-08-28 12:54:41,513][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00010 | loss1:0.0149 loss2:0.4807 loss3:0.0056 | AUC:0.8545 Anomaly AUC:0.6922
[2023-08-28 12:55:00,930][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00010 | loss1:0.0127 loss2:0.4134 loss3:0.0059 | AUC:0.8520 Anomaly AUC:0.6808
[2023-08-28 12:55:21,141][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00010 | loss1:0.0150 loss2:0.3818 loss3:0.0064 | AUC:0.8422 Anomaly AUC:0.6771
[2023-08-28 12:55:40,563][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00010 | loss1:0.0191 loss2:0.3687 loss3:0.0082 | AUC:0.8509 Anomaly AUC:0.6969
[2023-08-28 12:56:00,060][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00010 | loss1:0.0095 loss2:0.3100 loss3:0.0053 | AUC:0.8500 Anomaly AUC:0.6869
[2023-08-28 12:56:20,195][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00010 | loss1:0.0068 loss2:0.2806 loss3:0.0042 | AUC:0.8456 Anomaly AUC:0.6991
[2023-08-28 12:56:39,921][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00010 | loss1:0.0071 loss2:0.2611 loss3:0.0040 | AUC:0.8447 Anomaly AUC:0.6602
[2023-08-28 12:57:00,169][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00010 | loss1:0.0011 loss2:0.2285 loss3:0.0022 | AUC:0.8461 Anomaly AUC:0.6703
[2023-08-28 12:57:20,236][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00010 | loss1:0.0009 loss2:0.2127 loss3:0.0021 | AUC:0.8432 Anomaly AUC:0.6696
[2023-08-28 12:57:40,136][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00010 | loss1:0.0007 loss2:0.2025 loss3:0.0023 | AUC:0.8432 Anomaly AUC:0.6712
[2023-08-28 12:57:59,305][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00010 | loss1:0.0006 loss2:0.1943 loss3:0.0023 | AUC:0.8404 Anomaly AUC:0.6696
[2023-08-28 12:58:18,734][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00010 | loss1:0.0005 loss2:0.1866 loss3:0.0025 | AUC:0.8397 Anomaly AUC:0.6621
[2023-08-28 12:58:38,974][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00010 | loss1:0.0004 loss2:0.1791 loss3:0.0024 | AUC:0.8392 Anomaly AUC:0.6661
[2023-08-28 12:58:58,226][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00010 | loss1:0.0006 loss2:0.1729 loss3:0.0026 | AUC:0.8466 Anomaly AUC:0.6612
[2023-08-28 12:58:58,227][main-autotune.py][line:120][INFO] Training completes in 6m 33s | best AUCAUC:0.8552 Anomaly AUC:0.6929

[2023-08-28 12:58:59,912][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 12:59:26,828][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3777 loss2:1.0616 loss3:0.1719 | AUC:0.8203 Anomaly AUC:0.6541
[2023-08-28 12:59:47,867][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1789 loss2:0.8407 loss3:0.0407 | AUC:0.8227 Anomaly AUC:0.6770
[2023-08-28 13:00:06,490][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0923 loss2:0.7308 loss3:0.0186 | AUC:0.8510 Anomaly AUC:0.6820
[2023-08-28 13:00:25,889][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0385 loss2:0.6337 loss3:0.0092 | AUC:0.8150 Anomaly AUC:0.6561
[2023-08-28 13:00:46,009][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0279 loss2:0.5436 loss3:0.0073 | AUC:0.8440 Anomaly AUC:0.6797
[2023-08-28 13:01:05,888][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0298 loss2:0.4604 loss3:0.0058 | AUC:0.8381 Anomaly AUC:0.6669
[2023-08-28 13:01:25,342][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0278 loss2:0.3998 loss3:0.0058 | AUC:0.8191 Anomaly AUC:0.6958
[2023-08-28 13:01:45,260][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0155 loss2:0.2968 loss3:0.0033 | AUC:0.8536 Anomaly AUC:0.6851
[2023-08-28 13:02:05,655][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0175 loss2:0.2339 loss3:0.0040 | AUC:0.8479 Anomaly AUC:0.6799
[2023-08-28 13:02:25,912][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0218 loss2:0.2122 loss3:0.0048 | AUC:0.8481 Anomaly AUC:0.6584
[2023-08-28 13:02:45,179][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0140 loss2:0.1462 loss3:0.0030 | AUC:0.8358 Anomaly AUC:0.6524
[2023-08-28 13:03:04,517][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0082 loss2:0.0917 loss3:0.0019 | AUC:0.8430 Anomaly AUC:0.6552
[2023-08-28 13:03:24,438][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0103 loss2:0.0932 loss3:0.0027 | AUC:0.8348 Anomaly AUC:0.6306
[2023-08-28 13:03:44,968][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0009 loss2:0.0483 loss3:0.0006 | AUC:0.8381 Anomaly AUC:0.6387
[2023-08-28 13:04:04,225][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0090 loss2:0.0567 loss3:0.0021 | AUC:0.8227 Anomaly AUC:0.6527
[2023-08-28 13:04:23,095][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.0099 loss2:0.0621 loss3:0.0027 | AUC:0.8362 Anomaly AUC:0.6687
[2023-08-28 13:04:41,893][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0060 loss2:0.0425 loss3:0.0016 | AUC:0.8338 Anomaly AUC:0.6637
[2023-08-28 13:05:01,477][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0045 loss2:0.0308 loss3:0.0013 | AUC:0.8368 Anomaly AUC:0.6578
[2023-08-28 13:05:20,735][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0262 loss2:0.0866 loss3:0.0055 | AUC:0.8323 Anomaly AUC:0.6540
[2023-08-28 13:05:40,339][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0148 loss2:0.0586 loss3:0.0035 | AUC:0.8200 Anomaly AUC:0.6574
[2023-08-28 13:05:40,341][main-autotune.py][line:120][INFO] Training completes in 6m 32s | best AUCAUC:0.8536 Anomaly AUC:0.6851

[2023-08-28 13:05:42,410][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:06:09,566][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00080 | loss1:0.3532 loss2:0.9746 loss3:0.3537 | AUC:0.8251 Anomaly AUC:0.6612
[2023-08-28 13:06:28,774][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00080 | loss1:0.0694 loss2:0.6767 loss3:0.2884 | AUC:0.8400 Anomaly AUC:0.6810
[2023-08-28 13:06:51,708][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00080 | loss1:0.0064 loss2:0.4548 loss3:0.1809 | AUC:0.8330 Anomaly AUC:0.6748
[2023-08-28 13:07:14,184][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00080 | loss1:0.0115 loss2:0.3260 loss3:0.1015 | AUC:0.8370 Anomaly AUC:0.6809
[2023-08-28 13:07:34,495][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00080 | loss1:0.0063 loss2:0.2180 loss3:0.0863 | AUC:0.8304 Anomaly AUC:0.6712
[2023-08-28 13:07:54,027][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00080 | loss1:0.0058 loss2:0.1703 loss3:0.0805 | AUC:0.8412 Anomaly AUC:0.6811
[2023-08-28 13:08:12,689][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00080 | loss1:0.0033 loss2:0.0966 loss3:0.0444 | AUC:0.8341 Anomaly AUC:0.6814
[2023-08-28 13:08:31,442][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00080 | loss1:0.0006 loss2:0.0558 loss3:0.0218 | AUC:0.8354 Anomaly AUC:0.6778
[2023-08-28 13:08:50,861][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00080 | loss1:0.0004 loss2:0.0365 loss3:0.0157 | AUC:0.8409 Anomaly AUC:0.6718
[2023-08-28 13:09:10,339][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00080 | loss1:0.0041 loss2:0.0372 loss3:0.0320 | AUC:0.8107 Anomaly AUC:0.6936
[2023-08-28 13:09:29,097][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00080 | loss1:0.0021 loss2:0.0477 loss3:0.0375 | AUC:0.8413 Anomaly AUC:0.6859
[2023-08-28 13:09:48,683][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00080 | loss1:0.0004 loss2:0.0317 loss3:0.0182 | AUC:0.8382 Anomaly AUC:0.6505
[2023-08-28 13:10:08,944][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00080 | loss1:0.0012 loss2:0.0256 loss3:0.0180 | AUC:0.8319 Anomaly AUC:0.6582
[2023-08-28 13:10:28,265][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00080 | loss1:0.0010 loss2:0.0250 loss3:0.0157 | AUC:0.8059 Anomaly AUC:0.6594
[2023-08-28 13:10:47,137][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00080 | loss1:0.0068 loss2:0.0453 loss3:0.0555 | AUC:0.8094 Anomaly AUC:0.6789
[2023-08-28 13:11:06,741][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00080 | loss1:0.0066 loss2:0.0475 loss3:0.0667 | AUC:0.8143 Anomaly AUC:0.6813
[2023-08-28 13:11:26,093][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00080 | loss1:0.0062 loss2:0.0411 loss3:0.0674 | AUC:0.8268 Anomaly AUC:0.6645
[2023-08-28 13:11:45,682][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00080 | loss1:0.0026 loss2:0.0162 loss3:0.0275 | AUC:0.8347 Anomaly AUC:0.6710
[2023-08-28 13:12:05,948][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00080 | loss1:0.0005 loss2:0.0113 loss3:0.0193 | AUC:0.8361 Anomaly AUC:0.6605
[2023-08-28 13:12:26,130][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00080 | loss1:0.0003 loss2:0.0061 loss3:0.0066 | AUC:0.8384 Anomaly AUC:0.6606
[2023-08-28 13:12:26,132][main-autotune.py][line:120][INFO] Training completes in 6m 35s | best AUCAUC:0.8413 Anomaly AUC:0.6859

[2023-08-28 13:12:28,127][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:12:55,337][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3758 loss2:1.0354 loss3:0.1994 | AUC:0.8270 Anomaly AUC:0.6417
[2023-08-28 13:13:14,488][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1527 loss2:0.8010 loss3:0.0383 | AUC:0.8265 Anomaly AUC:0.6794
[2023-08-28 13:13:34,727][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0621 loss2:0.6884 loss3:0.0145 | AUC:0.8434 Anomaly AUC:0.6827
[2023-08-28 13:13:54,966][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0428 loss2:0.6036 loss3:0.0103 | AUC:0.8444 Anomaly AUC:0.6777
[2023-08-28 13:14:14,996][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0303 loss2:0.5136 loss3:0.0070 | AUC:0.8486 Anomaly AUC:0.7021
[2023-08-28 13:14:35,180][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0180 loss2:0.4296 loss3:0.0045 | AUC:0.8365 Anomaly AUC:0.6722
[2023-08-28 13:14:55,266][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0210 loss2:0.3675 loss3:0.0050 | AUC:0.8507 Anomaly AUC:0.6769
[2023-08-28 13:15:15,512][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0045 loss2:0.2721 loss3:0.0017 | AUC:0.8483 Anomaly AUC:0.6629
[2023-08-28 13:15:34,930][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0087 loss2:0.2280 loss3:0.0027 | AUC:0.8394 Anomaly AUC:0.6905
[2023-08-28 13:15:54,499][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0072 loss2:0.1833 loss3:0.0023 | AUC:0.8388 Anomaly AUC:0.6610
[2023-08-28 13:16:14,653][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0155 loss2:0.1773 loss3:0.0036 | AUC:0.8489 Anomaly AUC:0.7069
[2023-08-28 13:16:34,264][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0140 loss2:0.1606 loss3:0.0032 | AUC:0.8192 Anomaly AUC:0.6669
[2023-08-28 13:16:54,892][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0253 loss2:0.1596 loss3:0.0058 | AUC:0.8424 Anomaly AUC:0.6794
[2023-08-28 13:17:14,875][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0126 loss2:0.1331 loss3:0.0036 | AUC:0.8426 Anomaly AUC:0.6705
[2023-08-28 13:17:34,933][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0061 loss2:0.0948 loss3:0.0019 | AUC:0.8325 Anomaly AUC:0.6833
[2023-08-28 13:17:53,880][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0005 loss2:0.0680 loss3:0.0006 | AUC:0.8404 Anomaly AUC:0.6894
[2023-08-28 13:18:12,722][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0003 loss2:0.0577 loss3:0.0005 | AUC:0.8388 Anomaly AUC:0.6864
[2023-08-28 13:18:31,583][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0002 loss2:0.0502 loss3:0.0005 | AUC:0.8385 Anomaly AUC:0.6893
[2023-08-28 13:18:51,219][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0002 loss2:0.0443 loss3:0.0006 | AUC:0.8383 Anomaly AUC:0.6874
[2023-08-28 13:19:10,473][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0002 loss2:0.0396 loss3:0.0006 | AUC:0.8375 Anomaly AUC:0.6893
[2023-08-28 13:19:10,474][main-autotune.py][line:120][INFO] Training completes in 6m 34s | best AUCAUC:0.8507 Anomaly AUC:0.6769

[2023-08-28 13:19:12,121][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:19:39,220][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00100 | loss1:0.3647 loss2:1.1076 loss3:0.2546 | AUC:0.8304 Anomaly AUC:0.6370
[2023-08-28 13:19:58,223][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00100 | loss1:0.1381 loss2:0.8527 loss3:0.0545 | AUC:0.8085 Anomaly AUC:0.6586
[2023-08-28 13:20:21,054][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00100 | loss1:0.0665 loss2:0.7430 loss3:0.0250 | AUC:0.8443 Anomaly AUC:0.7066
[2023-08-28 13:20:43,803][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00100 | loss1:0.0755 loss2:0.7223 loss3:0.0246 | AUC:0.8548 Anomaly AUC:0.7046
[2023-08-28 13:21:04,277][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00100 | loss1:0.0180 loss2:0.6086 loss3:0.0113 | AUC:0.8545 Anomaly AUC:0.7026
[2023-08-28 13:21:24,863][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00100 | loss1:0.0354 loss2:0.5670 loss3:0.0124 | AUC:0.8488 Anomaly AUC:0.6797
[2023-08-28 13:21:44,116][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00100 | loss1:0.0222 loss2:0.4614 loss3:0.0067 | AUC:0.8390 Anomaly AUC:0.6740
[2023-08-28 13:22:03,637][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00100 | loss1:0.0221 loss2:0.3908 loss3:0.0063 | AUC:0.8475 Anomaly AUC:0.6794
[2023-08-28 13:22:24,095][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00100 | loss1:0.0059 loss2:0.2560 loss3:0.0027 | AUC:0.8459 Anomaly AUC:0.6728
[2023-08-28 13:22:44,162][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00100 | loss1:0.0150 loss2:0.2017 loss3:0.0050 | AUC:0.8388 Anomaly AUC:0.6641
[2023-08-28 13:23:03,554][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00100 | loss1:0.0114 loss2:0.1250 loss3:0.0043 | AUC:0.8045 Anomaly AUC:0.6672
[2023-08-28 13:23:23,073][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00100 | loss1:0.0116 loss2:0.1242 loss3:0.0044 | AUC:0.7849 Anomaly AUC:0.6609
[2023-08-28 13:23:43,223][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00100 | loss1:0.0123 loss2:0.0886 loss3:0.0037 | AUC:0.7853 Anomaly AUC:0.6502
[2023-08-28 13:24:03,131][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00100 | loss1:0.0299 loss2:0.1035 loss3:0.0078 | AUC:0.8402 Anomaly AUC:0.6613
[2023-08-28 13:24:23,055][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00100 | loss1:0.0089 loss2:0.0594 loss3:0.0028 | AUC:0.8171 Anomaly AUC:0.6558
[2023-08-28 13:24:42,365][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00100 | loss1:0.0059 loss2:0.0290 loss3:0.0020 | AUC:0.7909 Anomaly AUC:0.6266
[2023-08-28 13:25:01,856][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00100 | loss1:0.0080 loss2:0.0365 loss3:0.0024 | AUC:0.8109 Anomaly AUC:0.6768
[2023-08-28 13:25:22,195][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00100 | loss1:0.0035 loss2:0.0209 loss3:0.0015 | AUC:0.8113 Anomaly AUC:0.6589
[2023-08-28 13:25:40,993][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00100 | loss1:0.0001 loss2:0.0033 loss3:0.0006 | AUC:0.8208 Anomaly AUC:0.6652
[2023-08-28 13:25:59,355][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00100 | loss1:0.0000 loss2:0.0021 loss3:0.0006 | AUC:0.8179 Anomaly AUC:0.6518
[2023-08-28 13:25:59,356][main-autotune.py][line:120][INFO] Training completes in 6m 39s | best AUCAUC:0.8548 Anomaly AUC:0.7046

[2023-08-28 13:26:01,006][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:26:28,117][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3825 loss2:1.0830 loss3:0.2020 | AUC:0.8232 Anomaly AUC:0.6302
[2023-08-28 13:26:49,710][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1730 loss2:0.8465 loss3:0.0539 | AUC:0.8203 Anomaly AUC:0.6571
[2023-08-28 13:27:12,227][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0961 loss2:0.7458 loss3:0.0290 | AUC:0.8412 Anomaly AUC:0.6752
[2023-08-28 13:27:32,623][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0427 loss2:0.6475 loss3:0.0133 | AUC:0.8391 Anomaly AUC:0.6706
[2023-08-28 13:27:52,155][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0338 loss2:0.5591 loss3:0.0098 | AUC:0.8297 Anomaly AUC:0.6567
[2023-08-28 13:28:11,746][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0269 loss2:0.4810 loss3:0.0086 | AUC:0.8354 Anomaly AUC:0.6483
[2023-08-28 13:28:32,176][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0144 loss2:0.3749 loss3:0.0053 | AUC:0.8269 Anomaly AUC:0.6510
[2023-08-28 13:28:51,307][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0219 loss2:0.3283 loss3:0.0072 | AUC:0.8349 Anomaly AUC:0.6549
[2023-08-28 13:29:10,648][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0184 loss2:0.2697 loss3:0.0055 | AUC:0.8294 Anomaly AUC:0.6500
[2023-08-28 13:29:30,783][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0133 loss2:0.1940 loss3:0.0040 | AUC:0.8338 Anomaly AUC:0.6365
[2023-08-28 13:29:50,640][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0160 loss2:0.1576 loss3:0.0050 | AUC:0.8349 Anomaly AUC:0.6499
[2023-08-28 13:30:10,838][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0073 loss2:0.1097 loss3:0.0027 | AUC:0.8340 Anomaly AUC:0.6270
[2023-08-28 13:30:29,995][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0136 loss2:0.1034 loss3:0.0042 | AUC:0.8446 Anomaly AUC:0.6625
[2023-08-28 13:30:48,804][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0142 loss2:0.0811 loss3:0.0035 | AUC:0.8447 Anomaly AUC:0.6595
[2023-08-28 13:31:08,366][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0126 loss2:0.0810 loss3:0.0040 | AUC:0.8545 Anomaly AUC:0.6758
[2023-08-28 13:31:27,683][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.0072 loss2:0.0542 loss3:0.0026 | AUC:0.8409 Anomaly AUC:0.6718
[2023-08-28 13:31:47,159][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0008 loss2:0.0293 loss3:0.0009 | AUC:0.8371 Anomaly AUC:0.6576
[2023-08-28 13:32:06,460][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0055 loss2:0.0320 loss3:0.0019 | AUC:0.8351 Anomaly AUC:0.6448
[2023-08-28 13:32:25,225][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0245 loss2:0.0860 loss3:0.0070 | AUC:0.8332 Anomaly AUC:0.6271
[2023-08-28 13:32:44,784][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0145 loss2:0.0628 loss3:0.0049 | AUC:0.8298 Anomaly AUC:0.6469
[2023-08-28 13:32:44,786][main-autotune.py][line:120][INFO] Training completes in 6m 35s | best AUCAUC:0.8545 Anomaly AUC:0.6758

[2023-08-28 13:32:46,798][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:33:13,951][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00070 | loss1:0.3618 loss2:0.9911 loss3:0.3303 | AUC:0.8418 Anomaly AUC:0.6681
[2023-08-28 13:33:32,988][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00070 | loss1:0.1223 loss2:0.7169 loss3:0.1398 | AUC:0.8023 Anomaly AUC:0.6789
[2023-08-28 13:33:53,265][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00070 | loss1:0.0424 loss2:0.5444 loss3:0.0409 | AUC:0.8327 Anomaly AUC:0.6587
[2023-08-28 13:34:13,834][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00070 | loss1:0.0332 loss2:0.4207 loss3:0.0275 | AUC:0.8579 Anomaly AUC:0.7003
[2023-08-28 13:34:33,286][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00070 | loss1:0.0198 loss2:0.3001 loss3:0.0207 | AUC:0.8473 Anomaly AUC:0.6682
[2023-08-28 13:34:52,841][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00070 | loss1:0.0022 loss2:0.1779 loss3:0.0128 | AUC:0.8361 Anomaly AUC:0.6728
[2023-08-28 13:35:12,296][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00070 | loss1:0.0097 loss2:0.1265 loss3:0.0122 | AUC:0.8323 Anomaly AUC:0.6545
[2023-08-28 13:35:31,080][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00070 | loss1:0.0508 loss2:0.1977 loss3:0.0222 | AUC:0.8408 Anomaly AUC:0.6854
[2023-08-28 13:35:50,559][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00070 | loss1:0.0126 loss2:0.1003 loss3:0.0137 | AUC:0.8351 Anomaly AUC:0.6758
[2023-08-28 13:36:10,074][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00070 | loss1:0.0062 loss2:0.0592 loss3:0.0105 | AUC:0.8553 Anomaly AUC:0.6974
[2023-08-28 13:36:29,498][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00070 | loss1:0.0100 loss2:0.0483 loss3:0.0099 | AUC:0.8413 Anomaly AUC:0.6896
[2023-08-28 13:36:48,891][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00070 | loss1:0.0036 loss2:0.0330 loss3:0.0071 | AUC:0.8452 Anomaly AUC:0.6783
[2023-08-28 13:37:08,349][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00070 | loss1:0.0024 loss2:0.0242 loss3:0.0041 | AUC:0.8448 Anomaly AUC:0.6769
[2023-08-28 13:37:28,568][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00070 | loss1:0.0002 loss2:0.0154 loss3:0.0009 | AUC:0.8512 Anomaly AUC:0.6882
[2023-08-28 13:37:48,584][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00070 | loss1:0.0001 loss2:0.0113 loss3:0.0005 | AUC:0.8466 Anomaly AUC:0.6809
[2023-08-28 13:38:08,549][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00070 | loss1:0.0001 loss2:0.0090 loss3:0.0004 | AUC:0.8453 Anomaly AUC:0.6759
[2023-08-28 13:38:28,118][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00070 | loss1:0.0001 loss2:0.0075 loss3:0.0004 | AUC:0.8448 Anomaly AUC:0.6780
[2023-08-28 13:38:48,627][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00070 | loss1:0.0001 loss2:0.0061 loss3:0.0004 | AUC:0.8439 Anomaly AUC:0.6766
[2023-08-28 13:39:08,644][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00070 | loss1:0.0001 loss2:0.0052 loss3:0.0004 | AUC:0.8432 Anomaly AUC:0.6754
[2023-08-28 13:39:27,992][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00070 | loss1:0.0001 loss2:0.0046 loss3:0.0005 | AUC:0.8428 Anomaly AUC:0.6728
[2023-08-28 13:39:27,993][main-autotune.py][line:120][INFO] Training completes in 6m 33s | best AUCAUC:0.8579 Anomaly AUC:0.7003

[2023-08-28 13:39:29,659][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:39:56,837][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3786 loss2:1.1816 loss3:0.2161 | AUC:0.8117 Anomaly AUC:0.5934
[2023-08-28 13:40:17,994][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1670 loss2:0.9995 loss3:0.0619 | AUC:0.8416 Anomaly AUC:0.6555
[2023-08-28 13:40:36,609][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0682 loss2:0.8523 loss3:0.0221 | AUC:0.8457 Anomaly AUC:0.6528
[2023-08-28 13:40:56,158][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0391 loss2:0.7790 loss3:0.0128 | AUC:0.8526 Anomaly AUC:0.6953
[2023-08-28 13:41:18,988][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0316 loss2:0.7372 loss3:0.0094 | AUC:0.8526 Anomaly AUC:0.6781
[2023-08-28 13:41:39,172][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0243 loss2:0.7071 loss3:0.0078 | AUC:0.8581 Anomaly AUC:0.7006
[2023-08-28 13:41:59,619][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0258 loss2:0.6769 loss3:0.0081 | AUC:0.8500 Anomaly AUC:0.6697
[2023-08-28 13:42:19,900][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0137 loss2:0.6298 loss3:0.0045 | AUC:0.8584 Anomaly AUC:0.6902
[2023-08-28 13:42:40,438][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0075 loss2:0.5670 loss3:0.0029 | AUC:0.8496 Anomaly AUC:0.6633
[2023-08-28 13:42:59,897][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0164 loss2:0.5363 loss3:0.0049 | AUC:0.8494 Anomaly AUC:0.6763
[2023-08-28 13:43:18,902][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0168 loss2:0.5067 loss3:0.0054 | AUC:0.8528 Anomaly AUC:0.6795
[2023-08-28 13:43:37,708][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0142 loss2:0.4492 loss3:0.0043 | AUC:0.8481 Anomaly AUC:0.6888
[2023-08-28 13:43:57,052][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0056 loss2:0.3827 loss3:0.0026 | AUC:0.8415 Anomaly AUC:0.7103
[2023-08-28 13:44:18,025][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0094 loss2:0.3526 loss3:0.0035 | AUC:0.8302 Anomaly AUC:0.6779
[2023-08-28 13:44:38,299][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0112 loss2:0.3031 loss3:0.0037 | AUC:0.8630 Anomaly AUC:0.7008
[2023-08-28 13:44:57,944][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0098 loss2:0.2714 loss3:0.0032 | AUC:0.8566 Anomaly AUC:0.6826
[2023-08-28 13:45:17,021][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0053 loss2:0.2153 loss3:0.0024 | AUC:0.8566 Anomaly AUC:0.6817
[2023-08-28 13:45:35,865][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0180 loss2:0.2469 loss3:0.0058 | AUC:0.8553 Anomaly AUC:0.6817
[2023-08-28 13:45:54,698][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0073 loss2:0.1811 loss3:0.0024 | AUC:0.8694 Anomaly AUC:0.7097
[2023-08-28 13:46:14,396][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0134 loss2:0.1833 loss3:0.0038 | AUC:0.8414 Anomaly AUC:0.6581
[2023-08-28 13:46:14,398][main-autotune.py][line:120][INFO] Training completes in 6m 36s | best AUCAUC:0.8694 Anomaly AUC:0.7097

[2023-08-28 13:46:16,454][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:46:44,305][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3753 loss2:1.1905 loss3:0.2148 | AUC:0.8104 Anomaly AUC:0.5912
[2023-08-28 13:47:03,197][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1748 loss2:1.0305 loss3:0.0672 | AUC:0.8293 Anomaly AUC:0.6282
[2023-08-28 13:47:26,227][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0804 loss2:0.8962 loss3:0.0273 | AUC:0.8348 Anomaly AUC:0.6486
[2023-08-28 13:47:46,986][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0463 loss2:0.8216 loss3:0.0148 | AUC:0.8575 Anomaly AUC:0.6840
[2023-08-28 13:48:06,394][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0246 loss2:0.7634 loss3:0.0083 | AUC:0.8529 Anomaly AUC:0.6798
[2023-08-28 13:48:25,978][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0274 loss2:0.7329 loss3:0.0083 | AUC:0.8396 Anomaly AUC:0.6760
[2023-08-28 13:48:45,525][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0127 loss2:0.6879 loss3:0.0050 | AUC:0.8417 Anomaly AUC:0.6775
[2023-08-28 13:49:05,056][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0183 loss2:0.6666 loss3:0.0064 | AUC:0.8426 Anomaly AUC:0.6783
[2023-08-28 13:49:24,339][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0126 loss2:0.6232 loss3:0.0042 | AUC:0.8517 Anomaly AUC:0.6898
[2023-08-28 13:49:43,803][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0142 loss2:0.5956 loss3:0.0047 | AUC:0.8557 Anomaly AUC:0.6947
[2023-08-28 13:50:04,292][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0161 loss2:0.5460 loss3:0.0045 | AUC:0.8479 Anomaly AUC:0.6930
[2023-08-28 13:50:23,565][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0172 loss2:0.5336 loss3:0.0050 | AUC:0.8276 Anomaly AUC:0.6800
[2023-08-28 13:50:42,386][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0155 loss2:0.4813 loss3:0.0044 | AUC:0.8466 Anomaly AUC:0.6739
[2023-08-28 13:51:01,672][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0127 loss2:0.4288 loss3:0.0041 | AUC:0.8393 Anomaly AUC:0.6505
[2023-08-28 13:51:21,734][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0082 loss2:0.3737 loss3:0.0029 | AUC:0.8453 Anomaly AUC:0.6584
[2023-08-28 13:51:41,308][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0019 loss2:0.2986 loss3:0.0017 | AUC:0.8371 Anomaly AUC:0.6620
[2023-08-28 13:52:01,693][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0003 loss2:0.2293 loss3:0.0013 | AUC:0.8358 Anomaly AUC:0.6554
[2023-08-28 13:52:20,671][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0003 loss2:0.1738 loss3:0.0014 | AUC:0.8362 Anomaly AUC:0.6557
[2023-08-28 13:52:39,500][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0002 loss2:0.1299 loss3:0.0013 | AUC:0.8351 Anomaly AUC:0.6524
[2023-08-28 13:52:58,818][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0002 loss2:0.0990 loss3:0.0013 | AUC:0.8346 Anomaly AUC:0.6506
[2023-08-28 13:52:58,820][main-autotune.py][line:120][INFO] Training completes in 6m 33s | best AUCAUC:0.8575 Anomaly AUC:0.6840

[2023-08-28 13:53:00,861][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 13:53:28,701][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3762 loss2:1.1720 loss3:0.2280 | AUC:0.7979 Anomaly AUC:0.6023
[2023-08-28 13:53:47,781][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1673 loss2:0.9710 loss3:0.0677 | AUC:0.8223 Anomaly AUC:0.6562
[2023-08-28 13:54:10,925][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0858 loss2:0.8356 loss3:0.0314 | AUC:0.8444 Anomaly AUC:0.6770
[2023-08-28 13:54:30,935][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0454 loss2:0.7652 loss3:0.0161 | AUC:0.8486 Anomaly AUC:0.6942
[2023-08-28 13:54:51,368][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0312 loss2:0.7207 loss3:0.0119 | AUC:0.8569 Anomaly AUC:0.7058
[2023-08-28 13:55:10,951][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0301 loss2:0.6870 loss3:0.0123 | AUC:0.8510 Anomaly AUC:0.6658
[2023-08-28 13:55:29,749][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0162 loss2:0.6336 loss3:0.0076 | AUC:0.8510 Anomaly AUC:0.6709
[2023-08-28 13:55:48,679][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0158 loss2:0.5837 loss3:0.0071 | AUC:0.8469 Anomaly AUC:0.6821
[2023-08-28 13:56:08,212][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0177 loss2:0.5398 loss3:0.0072 | AUC:0.8410 Anomaly AUC:0.6614
[2023-08-28 13:56:28,723][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0239 loss2:0.5151 loss3:0.0098 | AUC:0.8398 Anomaly AUC:0.6813
[2023-08-28 13:56:48,699][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0108 loss2:0.4409 loss3:0.0055 | AUC:0.8457 Anomaly AUC:0.6775
[2023-08-28 13:57:09,012][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0139 loss2:0.3981 loss3:0.0066 | AUC:0.8284 Anomaly AUC:0.6549
[2023-08-28 13:57:29,321][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0178 loss2:0.3771 loss3:0.0071 | AUC:0.8215 Anomaly AUC:0.6404
[2023-08-28 13:57:48,694][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0069 loss2:0.3036 loss3:0.0041 | AUC:0.8504 Anomaly AUC:0.6820
[2023-08-28 13:58:08,290][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0008 loss2:0.2189 loss3:0.0023 | AUC:0.8459 Anomaly AUC:0.6776
[2023-08-28 13:58:28,233][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0006 loss2:0.1701 loss3:0.0024 | AUC:0.8433 Anomaly AUC:0.6662
[2023-08-28 13:58:48,592][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0002 loss2:0.1285 loss3:0.0024 | AUC:0.8434 Anomaly AUC:0.6677
[2023-08-28 13:59:07,908][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0002 loss2:0.0993 loss3:0.0025 | AUC:0.8424 Anomaly AUC:0.6644
[2023-08-28 13:59:26,799][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0002 loss2:0.0773 loss3:0.0022 | AUC:0.8389 Anomaly AUC:0.6600
[2023-08-28 13:59:45,741][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0002 loss2:0.0630 loss3:0.0023 | AUC:0.8352 Anomaly AUC:0.6556
[2023-08-28 13:59:45,742][main-autotune.py][line:120][INFO] Training completes in 6m 36s | best AUCAUC:0.8569 Anomaly AUC:0.7058

[2023-08-28 13:59:47,420][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:00:14,426][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3652 loss2:1.2738 loss3:0.2114 | AUC:0.8073 Anomaly AUC:0.6007
[2023-08-28 14:00:33,507][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1610 loss2:1.0892 loss3:0.0628 | AUC:0.8190 Anomaly AUC:0.6146
[2023-08-28 14:00:56,264][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0756 loss2:0.9934 loss3:0.0291 | AUC:0.8371 Anomaly AUC:0.6318
[2023-08-28 14:01:16,554][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0541 loss2:0.9419 loss3:0.0190 | AUC:0.8438 Anomaly AUC:0.6473
[2023-08-28 14:01:36,682][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0196 loss2:0.8844 loss3:0.0097 | AUC:0.8486 Anomaly AUC:0.6695
[2023-08-28 14:01:56,124][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0220 loss2:0.8526 loss3:0.0084 | AUC:0.8465 Anomaly AUC:0.6729
[2023-08-28 14:02:15,499][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0172 loss2:0.8362 loss3:0.0074 | AUC:0.8413 Anomaly AUC:0.6543
[2023-08-28 14:02:35,947][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0252 loss2:0.8250 loss3:0.0082 | AUC:0.8491 Anomaly AUC:0.6736
[2023-08-28 14:02:55,304][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0167 loss2:0.7895 loss3:0.0044 | AUC:0.8431 Anomaly AUC:0.6739
[2023-08-28 14:03:14,501][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0094 loss2:0.7711 loss3:0.0027 | AUC:0.8373 Anomaly AUC:0.6599
[2023-08-28 14:03:35,274][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0205 loss2:0.7641 loss3:0.0053 | AUC:0.8411 Anomaly AUC:0.6702
[2023-08-28 14:03:54,538][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0073 loss2:0.7389 loss3:0.0028 | AUC:0.8404 Anomaly AUC:0.6410
[2023-08-28 14:04:13,279][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0178 loss2:0.7242 loss3:0.0047 | AUC:0.8345 Anomaly AUC:0.6447
[2023-08-28 14:04:32,635][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0153 loss2:0.7035 loss3:0.0041 | AUC:0.8313 Anomaly AUC:0.6218
[2023-08-28 14:04:52,859][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0098 loss2:0.6720 loss3:0.0031 | AUC:0.8172 Anomaly AUC:0.6201
[2023-08-28 14:05:12,881][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.0097 loss2:0.6559 loss3:0.0029 | AUC:0.8234 Anomaly AUC:0.6208
[2023-08-28 14:05:31,629][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0100 loss2:0.6353 loss3:0.0029 | AUC:0.8246 Anomaly AUC:0.6362
[2023-08-28 14:05:51,397][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0077 loss2:0.6157 loss3:0.0031 | AUC:0.8083 Anomaly AUC:0.6304
[2023-08-28 14:06:11,117][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0149 loss2:0.6125 loss3:0.0051 | AUC:0.7971 Anomaly AUC:0.5921
[2023-08-28 14:06:31,022][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0087 loss2:0.5921 loss3:0.0025 | AUC:0.8086 Anomaly AUC:0.5986
[2023-08-28 14:06:31,025][main-autotune.py][line:120][INFO] Training completes in 6m 35s | best AUCAUC:0.8491 Anomaly AUC:0.6736

[2023-08-28 14:06:33,102][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:07:00,265][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00010 | loss1:0.3791 loss2:1.0659 loss3:0.2310 | AUC:0.8214 Anomaly AUC:0.6431
[2023-08-28 14:07:19,296][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00010 | loss1:0.1719 loss2:0.8435 loss3:0.0605 | AUC:0.8443 Anomaly AUC:0.6812
[2023-08-28 14:07:42,052][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00010 | loss1:0.0738 loss2:0.7425 loss3:0.0260 | AUC:0.8422 Anomaly AUC:0.6761
[2023-08-28 14:08:02,357][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00010 | loss1:0.0434 loss2:0.6737 loss3:0.0155 | AUC:0.8393 Anomaly AUC:0.6629
[2023-08-28 14:08:22,611][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00010 | loss1:0.0309 loss2:0.6096 loss3:0.0121 | AUC:0.8490 Anomaly AUC:0.6759
[2023-08-28 14:08:42,918][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00010 | loss1:0.0219 loss2:0.5435 loss3:0.0090 | AUC:0.8474 Anomaly AUC:0.6851
[2023-08-28 14:09:02,201][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00010 | loss1:0.0202 loss2:0.4824 loss3:0.0088 | AUC:0.8509 Anomaly AUC:0.6787
[2023-08-28 14:09:21,641][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00010 | loss1:0.0147 loss2:0.4342 loss3:0.0083 | AUC:0.8334 Anomaly AUC:0.6548
[2023-08-28 14:09:41,269][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00010 | loss1:0.0130 loss2:0.3854 loss3:0.0071 | AUC:0.8324 Anomaly AUC:0.6636
[2023-08-28 14:09:59,902][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00010 | loss1:0.0057 loss2:0.3378 loss3:0.0059 | AUC:0.8382 Anomaly AUC:0.6499
[2023-08-28 14:10:18,638][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00010 | loss1:0.0048 loss2:0.2890 loss3:0.0042 | AUC:0.8557 Anomaly AUC:0.6746
[2023-08-28 14:10:38,090][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00010 | loss1:0.0123 loss2:0.3023 loss3:0.0082 | AUC:0.8474 Anomaly AUC:0.6552
[2023-08-28 14:10:57,591][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00010 | loss1:0.0043 loss2:0.2573 loss3:0.0044 | AUC:0.8391 Anomaly AUC:0.6603
[2023-08-28 14:11:16,323][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00010 | loss1:0.0015 loss2:0.2319 loss3:0.0033 | AUC:0.8481 Anomaly AUC:0.6762
[2023-08-28 14:11:35,788][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00010 | loss1:0.0008 loss2:0.2130 loss3:0.0025 | AUC:0.8480 Anomaly AUC:0.6697
[2023-08-28 14:11:55,287][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00010 | loss1:0.0007 loss2:0.2022 loss3:0.0028 | AUC:0.8416 Anomaly AUC:0.6584
[2023-08-28 14:12:14,834][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00010 | loss1:0.0006 loss2:0.1940 loss3:0.0030 | AUC:0.8471 Anomaly AUC:0.6661
[2023-08-28 14:12:34,028][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00010 | loss1:0.0005 loss2:0.1862 loss3:0.0031 | AUC:0.8471 Anomaly AUC:0.6635
[2023-08-28 14:12:53,688][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00010 | loss1:0.0004 loss2:0.1784 loss3:0.0030 | AUC:0.8447 Anomaly AUC:0.6567
[2023-08-28 14:13:12,812][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00010 | loss1:0.0003 loss2:0.1720 loss3:0.0031 | AUC:0.8436 Anomaly AUC:0.6577
[2023-08-28 14:13:12,813][main-autotune.py][line:120][INFO] Training completes in 6m 31s | best AUCAUC:0.8557 Anomaly AUC:0.6746

[2023-08-28 14:13:14,482][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:13:42,291][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3902 loss2:1.2117 loss3:0.1902 | AUC:0.8284 Anomaly AUC:0.6102
[2023-08-28 14:14:01,554][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1687 loss2:1.0196 loss3:0.0511 | AUC:0.8379 Anomaly AUC:0.6470
[2023-08-28 14:14:24,750][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0895 loss2:0.9193 loss3:0.0256 | AUC:0.8510 Anomaly AUC:0.6691
[2023-08-28 14:14:44,953][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0414 loss2:0.8476 loss3:0.0110 | AUC:0.8428 Anomaly AUC:0.6626
[2023-08-28 14:15:05,635][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0380 loss2:0.8126 loss3:0.0091 | AUC:0.8540 Anomaly AUC:0.6799
[2023-08-28 14:15:26,153][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0233 loss2:0.7713 loss3:0.0053 | AUC:0.8495 Anomaly AUC:0.6668
[2023-08-28 14:15:46,224][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0184 loss2:0.7298 loss3:0.0040 | AUC:0.8351 Anomaly AUC:0.6672
[2023-08-28 14:16:07,277][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0216 loss2:0.7069 loss3:0.0043 | AUC:0.8439 Anomaly AUC:0.6691
[2023-08-28 14:16:27,649][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0118 loss2:0.6719 loss3:0.0027 | AUC:0.8469 Anomaly AUC:0.6809
[2023-08-28 14:16:47,185][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0133 loss2:0.6435 loss3:0.0033 | AUC:0.8385 Anomaly AUC:0.6518
[2023-08-28 14:17:06,002][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0228 loss2:0.6303 loss3:0.0051 | AUC:0.8355 Anomaly AUC:0.6498
[2023-08-28 14:17:25,674][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0105 loss2:0.5946 loss3:0.0027 | AUC:0.8501 Anomaly AUC:0.6567
[2023-08-28 14:17:45,163][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0017 loss2:0.5190 loss3:0.0011 | AUC:0.8524 Anomaly AUC:0.6575
[2023-08-28 14:18:04,060][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0231 loss2:0.5355 loss3:0.0061 | AUC:0.8273 Anomaly AUC:0.6466
[2023-08-28 14:18:24,210][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0053 loss2:0.4710 loss3:0.0018 | AUC:0.8342 Anomaly AUC:0.6517
[2023-08-28 14:18:45,165][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0126 loss2:0.4311 loss3:0.0031 | AUC:0.8170 Anomaly AUC:0.6040
[2023-08-28 14:19:07,044][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0120 loss2:0.3945 loss3:0.0029 | AUC:0.8127 Anomaly AUC:0.6181
[2023-08-28 14:19:29,951][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0107 loss2:0.3670 loss3:0.0031 | AUC:0.8171 Anomaly AUC:0.6111
[2023-08-28 14:19:51,553][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0084 loss2:0.3067 loss3:0.0019 | AUC:0.8470 Anomaly AUC:0.6442
[2023-08-28 14:20:12,193][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0119 loss2:0.2863 loss3:0.0029 | AUC:0.8383 Anomaly AUC:0.6338
[2023-08-28 14:20:12,194][main-autotune.py][line:120][INFO] Training completes in 6m 48s | best AUCAUC:0.8540 Anomaly AUC:0.6799

[2023-08-28 14:20:13,886][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:20:40,905][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3773 loss2:1.0992 loss3:0.1957 | AUC:0.8253 Anomaly AUC:0.6346
[2023-08-28 14:21:01,793][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.1691 loss2:0.8578 loss3:0.0470 | AUC:0.8342 Anomaly AUC:0.6620
[2023-08-28 14:21:20,446][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0796 loss2:0.7459 loss3:0.0195 | AUC:0.8428 Anomaly AUC:0.6551
[2023-08-28 14:21:39,911][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0549 loss2:0.6793 loss3:0.0132 | AUC:0.8424 Anomaly AUC:0.6819
[2023-08-28 14:22:00,728][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0359 loss2:0.6106 loss3:0.0116 | AUC:0.8213 Anomaly AUC:0.6481
[2023-08-28 14:22:21,752][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0283 loss2:0.5192 loss3:0.0068 | AUC:0.8223 Anomaly AUC:0.6551
[2023-08-28 14:22:43,630][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0212 loss2:0.4386 loss3:0.0055 | AUC:0.8324 Anomaly AUC:0.6631
[2023-08-28 14:23:04,531][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0231 loss2:0.3724 loss3:0.0061 | AUC:0.8487 Anomaly AUC:0.6878
[2023-08-28 14:23:26,246][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0134 loss2:0.2829 loss3:0.0036 | AUC:0.8384 Anomaly AUC:0.6717
[2023-08-28 14:23:46,748][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0139 loss2:0.2146 loss3:0.0037 | AUC:0.8166 Anomaly AUC:0.6214
[2023-08-28 14:24:07,313][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0329 loss2:0.2088 loss3:0.0071 | AUC:0.8492 Anomaly AUC:0.6945
[2023-08-28 14:24:27,714][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0110 loss2:0.1535 loss3:0.0034 | AUC:0.8481 Anomaly AUC:0.6712
[2023-08-28 14:24:47,575][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0040 loss2:0.0828 loss3:0.0016 | AUC:0.8449 Anomaly AUC:0.6707
[2023-08-28 14:25:09,187][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0043 loss2:0.0582 loss3:0.0017 | AUC:0.8430 Anomaly AUC:0.6694
[2023-08-28 14:25:29,799][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0034 loss2:0.0400 loss3:0.0012 | AUC:0.7997 Anomaly AUC:0.6160
[2023-08-28 14:25:49,216][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.0267 loss2:0.1288 loss3:0.0081 | AUC:0.8371 Anomaly AUC:0.6578
[2023-08-28 14:26:09,475][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.0064 loss2:0.0502 loss3:0.0018 | AUC:0.8351 Anomaly AUC:0.6503
[2023-08-28 14:26:29,781][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.0139 loss2:0.0608 loss3:0.0037 | AUC:0.8600 Anomaly AUC:0.6755
[2023-08-28 14:26:49,785][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0106 loss2:0.0371 loss3:0.0022 | AUC:0.8564 Anomaly AUC:0.6782
[2023-08-28 14:27:11,186][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0117 loss2:0.0416 loss3:0.0036 | AUC:0.8259 Anomaly AUC:0.6101
[2023-08-28 14:27:11,189][main-autotune.py][line:120][INFO] Training completes in 6m 49s | best AUCAUC:0.8600 Anomaly AUC:0.6755

[2023-08-28 14:27:13,260][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:27:40,417][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3845 loss2:1.0801 loss3:0.2264 | AUC:0.8217 Anomaly AUC:0.6375
[2023-08-28 14:28:02,190][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1779 loss2:0.8524 loss3:0.0589 | AUC:0.8186 Anomaly AUC:0.6265
[2023-08-28 14:28:25,144][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0839 loss2:0.7485 loss3:0.0286 | AUC:0.8206 Anomaly AUC:0.6682
[2023-08-28 14:28:43,752][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0520 loss2:0.6869 loss3:0.0169 | AUC:0.8196 Anomaly AUC:0.6535
[2023-08-28 14:29:03,147][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0323 loss2:0.6166 loss3:0.0116 | AUC:0.8241 Anomaly AUC:0.6521
[2023-08-28 14:29:24,868][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0226 loss2:0.5510 loss3:0.0090 | AUC:0.8247 Anomaly AUC:0.6441
[2023-08-28 14:29:47,341][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0217 loss2:0.4906 loss3:0.0088 | AUC:0.8312 Anomaly AUC:0.6630
[2023-08-28 14:30:09,760][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0117 loss2:0.4427 loss3:0.0067 | AUC:0.8281 Anomaly AUC:0.6668
[2023-08-28 14:30:30,696][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0183 loss2:0.3995 loss3:0.0078 | AUC:0.8265 Anomaly AUC:0.6363
[2023-08-28 14:30:51,720][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0167 loss2:0.3544 loss3:0.0068 | AUC:0.8368 Anomaly AUC:0.6380
[2023-08-28 14:31:12,465][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0070 loss2:0.2878 loss3:0.0044 | AUC:0.8367 Anomaly AUC:0.6574
[2023-08-28 14:31:34,262][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0086 loss2:0.2492 loss3:0.0047 | AUC:0.8195 Anomaly AUC:0.6436
[2023-08-28 14:31:54,214][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0045 loss2:0.2175 loss3:0.0045 | AUC:0.8348 Anomaly AUC:0.6597
[2023-08-28 14:32:14,799][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0006 loss2:0.1705 loss3:0.0025 | AUC:0.8358 Anomaly AUC:0.6514
[2023-08-28 14:32:33,953][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0005 loss2:0.1451 loss3:0.0024 | AUC:0.8318 Anomaly AUC:0.6418
[2023-08-28 14:32:55,524][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0004 loss2:0.1292 loss3:0.0027 | AUC:0.8284 Anomaly AUC:0.6232
[2023-08-28 14:33:15,967][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0313 loss2:0.2471 loss3:0.0121 | AUC:0.7978 Anomaly AUC:0.6263
[2023-08-28 14:33:36,217][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0205 loss2:0.2146 loss3:0.0069 | AUC:0.8241 Anomaly AUC:0.6380
[2023-08-28 14:33:56,904][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0067 loss2:0.1464 loss3:0.0034 | AUC:0.8336 Anomaly AUC:0.6545
[2023-08-28 14:34:17,080][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0044 loss2:0.1181 loss3:0.0030 | AUC:0.8059 Anomaly AUC:0.6187
[2023-08-28 14:34:17,081][main-autotune.py][line:120][INFO] Training completes in 6m 55s | best AUCAUC:0.8368 Anomaly AUC:0.6380

[2023-08-28 14:34:18,797][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:34:48,115][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3725 loss2:1.1338 loss3:0.2248 | AUC:0.8210 Anomaly AUC:0.6160
[2023-08-28 14:35:06,442][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1516 loss2:0.9057 loss3:0.0499 | AUC:0.8103 Anomaly AUC:0.6598
[2023-08-28 14:35:27,334][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0706 loss2:0.7962 loss3:0.0204 | AUC:0.8315 Anomaly AUC:0.6687
[2023-08-28 14:35:46,005][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0315 loss2:0.7305 loss3:0.0109 | AUC:0.8445 Anomaly AUC:0.6872
[2023-08-28 14:36:05,579][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0329 loss2:0.6864 loss3:0.0090 | AUC:0.8381 Anomaly AUC:0.6751
[2023-08-28 14:36:25,958][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0248 loss2:0.6427 loss3:0.0084 | AUC:0.8409 Anomaly AUC:0.6673
[2023-08-28 14:36:44,739][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0112 loss2:0.5635 loss3:0.0044 | AUC:0.8329 Anomaly AUC:0.6658
[2023-08-28 14:37:07,519][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0127 loss2:0.5036 loss3:0.0046 | AUC:0.8515 Anomaly AUC:0.6748
[2023-08-28 14:37:29,693][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0166 loss2:0.4617 loss3:0.0056 | AUC:0.8374 Anomaly AUC:0.6506
[2023-08-28 14:37:51,686][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0083 loss2:0.3870 loss3:0.0039 | AUC:0.8297 Anomaly AUC:0.6595
[2023-08-28 14:38:13,637][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0132 loss2:0.3390 loss3:0.0044 | AUC:0.8437 Anomaly AUC:0.6752
[2023-08-28 14:38:35,608][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0088 loss2:0.2835 loss3:0.0035 | AUC:0.8454 Anomaly AUC:0.6743
[2023-08-28 14:38:57,423][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0074 loss2:0.2327 loss3:0.0028 | AUC:0.8485 Anomaly AUC:0.6852
[2023-08-28 14:39:19,222][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0012 loss2:0.1643 loss3:0.0014 | AUC:0.8436 Anomaly AUC:0.6870
[2023-08-28 14:39:41,261][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0064 loss2:0.1574 loss3:0.0025 | AUC:0.8476 Anomaly AUC:0.6858
[2023-08-28 14:40:03,157][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0196 loss2:0.2007 loss3:0.0058 | AUC:0.8292 Anomaly AUC:0.6450
[2023-08-28 14:40:24,994][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0099 loss2:0.1478 loss3:0.0035 | AUC:0.8516 Anomaly AUC:0.6982
[2023-08-28 14:40:46,910][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0104 loss2:0.1255 loss3:0.0033 | AUC:0.8507 Anomaly AUC:0.6904
[2023-08-28 14:41:05,796][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0054 loss2:0.0967 loss3:0.0020 | AUC:0.8363 Anomaly AUC:0.6784
[2023-08-28 14:41:25,221][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0105 loss2:0.1021 loss3:0.0030 | AUC:0.8260 Anomaly AUC:0.6784
[2023-08-28 14:41:25,222][main-autotune.py][line:120][INFO] Training completes in 6m 58s | best AUCAUC:0.8516 Anomaly AUC:0.6982

[2023-08-28 14:41:27,115][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:41:53,941][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3836 loss2:1.0712 loss3:0.1790 | AUC:0.8089 Anomaly AUC:0.6521
[2023-08-28 14:42:14,988][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1734 loss2:0.8488 loss3:0.0409 | AUC:0.8158 Anomaly AUC:0.6589
[2023-08-28 14:42:33,479][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0740 loss2:0.7366 loss3:0.0170 | AUC:0.8074 Anomaly AUC:0.6525
[2023-08-28 14:42:54,833][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0424 loss2:0.6476 loss3:0.0091 | AUC:0.8405 Anomaly AUC:0.6711
[2023-08-28 14:43:17,914][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0283 loss2:0.5690 loss3:0.0079 | AUC:0.8281 Anomaly AUC:0.6903
[2023-08-28 14:43:36,712][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0264 loss2:0.4935 loss3:0.0052 | AUC:0.8507 Anomaly AUC:0.6834
[2023-08-28 14:43:56,268][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0202 loss2:0.4148 loss3:0.0048 | AUC:0.8540 Anomaly AUC:0.6910
[2023-08-28 14:44:18,434][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0196 loss2:0.3328 loss3:0.0042 | AUC:0.8458 Anomaly AUC:0.6852
[2023-08-28 14:44:40,450][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0044 loss2:0.2256 loss3:0.0016 | AUC:0.8433 Anomaly AUC:0.6786
[2023-08-28 14:45:03,151][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0196 loss2:0.2184 loss3:0.0040 | AUC:0.8320 Anomaly AUC:0.6620
[2023-08-28 14:45:22,018][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0215 loss2:0.1863 loss3:0.0046 | AUC:0.8305 Anomaly AUC:0.6720
[2023-08-28 14:45:41,895][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0140 loss2:0.1341 loss3:0.0030 | AUC:0.8366 Anomaly AUC:0.6666
[2023-08-28 14:46:05,407][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0110 loss2:0.1090 loss3:0.0025 | AUC:0.8373 Anomaly AUC:0.6815
[2023-08-28 14:46:29,213][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0141 loss2:0.0810 loss3:0.0027 | AUC:0.8226 Anomaly AUC:0.6603
[2023-08-28 14:46:52,307][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0146 loss2:0.0944 loss3:0.0036 | AUC:0.8331 Anomaly AUC:0.6555
[2023-08-28 14:47:16,026][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.0104 loss2:0.0611 loss3:0.0024 | AUC:0.8242 Anomaly AUC:0.6345
[2023-08-28 14:47:39,726][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0047 loss2:0.0420 loss3:0.0011 | AUC:0.8260 Anomaly AUC:0.6726
[2023-08-28 14:47:58,832][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0180 loss2:0.0749 loss3:0.0036 | AUC:0.8465 Anomaly AUC:0.6759
[2023-08-28 14:48:18,605][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0013 loss2:0.0292 loss3:0.0007 | AUC:0.8478 Anomaly AUC:0.6848
[2023-08-28 14:48:42,142][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0092 loss2:0.0329 loss3:0.0018 | AUC:0.8364 Anomaly AUC:0.6489
[2023-08-28 14:48:42,144][main-autotune.py][line:120][INFO] Training completes in 7m 7s | best AUCAUC:0.8540 Anomaly AUC:0.6910

[2023-08-28 14:48:44,170][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:49:11,356][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3672 loss2:1.0135 loss3:0.2315 | AUC:0.8405 Anomaly AUC:0.6470
[2023-08-28 14:49:32,235][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1571 loss2:0.7791 loss3:0.0562 | AUC:0.8282 Anomaly AUC:0.6598
[2023-08-28 14:49:50,886][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0696 loss2:0.6478 loss3:0.0274 | AUC:0.8187 Anomaly AUC:0.6498
[2023-08-28 14:50:12,830][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0450 loss2:0.5424 loss3:0.0171 | AUC:0.8466 Anomaly AUC:0.6755
[2023-08-28 14:50:35,718][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0326 loss2:0.4549 loss3:0.0131 | AUC:0.8473 Anomaly AUC:0.6743
[2023-08-28 14:50:57,511][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0207 loss2:0.3676 loss3:0.0081 | AUC:0.8351 Anomaly AUC:0.6545
[2023-08-28 14:51:21,231][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0104 loss2:0.2784 loss3:0.0042 | AUC:0.8329 Anomaly AUC:0.6612
[2023-08-28 14:51:40,080][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0015 loss2:0.1922 loss3:0.0014 | AUC:0.8466 Anomaly AUC:0.6841
[2023-08-28 14:51:59,845][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0111 loss2:0.1750 loss3:0.0031 | AUC:0.8280 Anomaly AUC:0.6581
[2023-08-28 14:52:23,114][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0208 loss2:0.1801 loss3:0.0058 | AUC:0.8554 Anomaly AUC:0.6970
[2023-08-28 14:52:42,033][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0114 loss2:0.1247 loss3:0.0029 | AUC:0.8391 Anomaly AUC:0.6965
[2023-08-28 14:53:01,882][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0139 loss2:0.1148 loss3:0.0035 | AUC:0.8533 Anomaly AUC:0.6916
[2023-08-28 14:53:25,388][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0042 loss2:0.0746 loss3:0.0014 | AUC:0.8543 Anomaly AUC:0.6954
[2023-08-28 14:53:48,568][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0051 loss2:0.0604 loss3:0.0017 | AUC:0.8450 Anomaly AUC:0.6732
[2023-08-28 14:54:11,869][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0096 loss2:0.0693 loss3:0.0029 | AUC:0.8507 Anomaly AUC:0.6900
[2023-08-28 14:54:34,816][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0104 loss2:0.0636 loss3:0.0028 | AUC:0.8481 Anomaly AUC:0.6755
[2023-08-28 14:54:57,634][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0095 loss2:0.0602 loss3:0.0026 | AUC:0.8444 Anomaly AUC:0.7103
[2023-08-28 14:55:20,697][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0119 loss2:0.0529 loss3:0.0032 | AUC:0.8124 Anomaly AUC:0.6413
[2023-08-28 14:55:43,936][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0139 loss2:0.0620 loss3:0.0042 | AUC:0.8248 Anomaly AUC:0.6431
[2023-08-28 14:56:06,952][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0107 loss2:0.0454 loss3:0.0027 | AUC:0.8165 Anomaly AUC:0.6845
[2023-08-28 14:56:06,954][main-autotune.py][line:120][INFO] Training completes in 7m 14s | best AUCAUC:0.8554 Anomaly AUC:0.6970

[2023-08-28 14:56:08,749][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 14:56:35,521][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3902 loss2:1.0957 loss3:0.1987 | AUC:0.8307 Anomaly AUC:0.6533
[2023-08-28 14:56:55,783][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.1568 loss2:0.8467 loss3:0.0454 | AUC:0.8399 Anomaly AUC:0.6638
[2023-08-28 14:57:14,312][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0668 loss2:0.7313 loss3:0.0174 | AUC:0.8241 Anomaly AUC:0.6542
[2023-08-28 14:57:36,167][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0463 loss2:0.6594 loss3:0.0121 | AUC:0.8239 Anomaly AUC:0.6591
[2023-08-28 14:57:55,209][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0367 loss2:0.5739 loss3:0.0093 | AUC:0.7952 Anomaly AUC:0.6543
[2023-08-28 14:58:14,845][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0285 loss2:0.4953 loss3:0.0072 | AUC:0.8172 Anomaly AUC:0.6274
[2023-08-28 14:58:37,246][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0179 loss2:0.3952 loss3:0.0046 | AUC:0.8373 Anomaly AUC:0.6395
[2023-08-28 14:58:57,624][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0238 loss2:0.3448 loss3:0.0060 | AUC:0.8478 Anomaly AUC:0.6597
[2023-08-28 14:59:16,369][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0106 loss2:0.2511 loss3:0.0029 | AUC:0.8271 Anomaly AUC:0.6330
[2023-08-28 14:59:39,325][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0005 loss2:0.1430 loss3:0.0010 | AUC:0.8218 Anomaly AUC:0.6264
[2023-08-28 15:00:01,633][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0003 loss2:0.0800 loss3:0.0009 | AUC:0.8279 Anomaly AUC:0.6356
[2023-08-28 15:00:23,746][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0002 loss2:0.0498 loss3:0.0009 | AUC:0.8253 Anomaly AUC:0.6297
[2023-08-28 15:00:45,774][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0001 loss2:0.0343 loss3:0.0008 | AUC:0.8266 Anomaly AUC:0.6314
[2023-08-28 15:01:07,864][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0001 loss2:0.0257 loss3:0.0009 | AUC:0.8255 Anomaly AUC:0.6290
[2023-08-28 15:01:27,886][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0002 loss2:0.0207 loss3:0.0010 | AUC:0.8141 Anomaly AUC:0.6141
[2023-08-28 15:01:46,677][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.0719 loss2:0.2803 loss3:0.0184 | AUC:0.8198 Anomaly AUC:0.6518
[2023-08-28 15:02:08,658][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.0231 loss2:0.1397 loss3:0.0053 | AUC:0.7951 Anomaly AUC:0.6119
[2023-08-28 15:02:30,631][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.0268 loss2:0.1103 loss3:0.0068 | AUC:0.8294 Anomaly AUC:0.6284
[2023-08-28 15:02:52,697][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0115 loss2:0.0576 loss3:0.0031 | AUC:0.7903 Anomaly AUC:0.5887
[2023-08-28 15:03:11,615][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0065 loss2:0.0376 loss3:0.0018 | AUC:0.8275 Anomaly AUC:0.6330
[2023-08-28 15:03:11,616][main-autotune.py][line:120][INFO] Training completes in 6m 55s | best AUCAUC:0.8478 Anomaly AUC:0.6597

[2023-08-28 15:03:13,296][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:03:42,012][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3843 loss2:1.1018 loss3:0.1883 | AUC:0.8049 Anomaly AUC:0.6510
[2023-08-28 15:04:00,427][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.1747 loss2:0.8605 loss3:0.0466 | AUC:0.8179 Anomaly AUC:0.6738
[2023-08-28 15:04:20,873][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0781 loss2:0.7472 loss3:0.0188 | AUC:0.8269 Anomaly AUC:0.6636
[2023-08-28 15:04:39,416][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0572 loss2:0.6815 loss3:0.0135 | AUC:0.8392 Anomaly AUC:0.6552
[2023-08-28 15:05:00,943][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0337 loss2:0.5955 loss3:0.0085 | AUC:0.8432 Anomaly AUC:0.6676
[2023-08-28 15:05:23,773][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0329 loss2:0.5257 loss3:0.0072 | AUC:0.8407 Anomaly AUC:0.6638
[2023-08-28 15:05:46,429][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0305 loss2:0.4583 loss3:0.0076 | AUC:0.8222 Anomaly AUC:0.6472
[2023-08-28 15:06:08,892][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0158 loss2:0.3543 loss3:0.0040 | AUC:0.8328 Anomaly AUC:0.6500
[2023-08-28 15:06:29,078][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0163 loss2:0.2754 loss3:0.0040 | AUC:0.8248 Anomaly AUC:0.6249
[2023-08-28 15:06:47,814][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0085 loss2:0.1935 loss3:0.0027 | AUC:0.8194 Anomaly AUC:0.6384
[2023-08-28 15:07:10,210][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0193 loss2:0.1681 loss3:0.0050 | AUC:0.8465 Anomaly AUC:0.6433
[2023-08-28 15:07:32,461][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0154 loss2:0.1289 loss3:0.0037 | AUC:0.8423 Anomaly AUC:0.6557
[2023-08-28 15:07:51,166][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0093 loss2:0.0875 loss3:0.0027 | AUC:0.8357 Anomaly AUC:0.6204
[2023-08-28 15:08:10,573][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0117 loss2:0.0759 loss3:0.0029 | AUC:0.8338 Anomaly AUC:0.6235
[2023-08-28 15:08:32,661][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0152 loss2:0.0708 loss3:0.0036 | AUC:0.8305 Anomaly AUC:0.6260
[2023-08-28 15:08:54,890][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.0131 loss2:0.0623 loss3:0.0036 | AUC:0.8153 Anomaly AUC:0.6026
[2023-08-28 15:09:17,052][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.0090 loss2:0.0488 loss3:0.0025 | AUC:0.8179 Anomaly AUC:0.6214
[2023-08-28 15:09:39,155][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.0062 loss2:0.0354 loss3:0.0020 | AUC:0.8448 Anomaly AUC:0.6401
[2023-08-28 15:10:01,300][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0159 loss2:0.0502 loss3:0.0042 | AUC:0.8456 Anomaly AUC:0.6390
[2023-08-28 15:10:23,394][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0095 loss2:0.0438 loss3:0.0031 | AUC:0.8389 Anomaly AUC:0.6377
[2023-08-28 15:10:23,396][main-autotune.py][line:120][INFO] Training completes in 7m 2s | best AUCAUC:0.8465 Anomaly AUC:0.6433

[2023-08-28 15:10:25,242][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:10:52,071][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3697 loss2:1.0860 loss3:0.1978 | AUC:0.8265 Anomaly AUC:0.6541
[2023-08-28 15:11:12,902][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1591 loss2:0.8439 loss3:0.0439 | AUC:0.8224 Anomaly AUC:0.6736
[2023-08-28 15:11:31,475][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0693 loss2:0.7418 loss3:0.0182 | AUC:0.8317 Anomaly AUC:0.6684
[2023-08-28 15:11:53,462][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0301 loss2:0.6594 loss3:0.0078 | AUC:0.8619 Anomaly AUC:0.6963
[2023-08-28 15:12:16,070][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0249 loss2:0.5792 loss3:0.0063 | AUC:0.8480 Anomaly AUC:0.6699
[2023-08-28 15:12:36,969][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0187 loss2:0.4905 loss3:0.0051 | AUC:0.8438 Anomaly AUC:0.6716
[2023-08-28 15:12:55,596][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0280 loss2:0.4416 loss3:0.0066 | AUC:0.8552 Anomaly AUC:0.6995
[2023-08-28 15:13:17,197][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0255 loss2:0.3843 loss3:0.0058 | AUC:0.8434 Anomaly AUC:0.6599
[2023-08-28 15:13:37,801][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0083 loss2:0.2795 loss3:0.0024 | AUC:0.8458 Anomaly AUC:0.6808
[2023-08-28 15:13:56,576][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0032 loss2:0.2047 loss3:0.0015 | AUC:0.8430 Anomaly AUC:0.6754
[2023-08-28 15:14:17,795][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0093 loss2:0.1748 loss3:0.0028 | AUC:0.8245 Anomaly AUC:0.6668
[2023-08-28 15:14:39,201][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0058 loss2:0.1343 loss3:0.0022 | AUC:0.8403 Anomaly AUC:0.6686
[2023-08-28 15:15:01,082][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0133 loss2:0.1250 loss3:0.0032 | AUC:0.8351 Anomaly AUC:0.6586
[2023-08-28 15:15:24,615][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0153 loss2:0.1315 loss3:0.0039 | AUC:0.8438 Anomaly AUC:0.6647
[2023-08-28 15:15:45,330][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0083 loss2:0.0841 loss3:0.0022 | AUC:0.8510 Anomaly AUC:0.6837
[2023-08-28 15:16:04,165][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0117 loss2:0.0885 loss3:0.0030 | AUC:0.8444 Anomaly AUC:0.6649
[2023-08-28 15:16:25,319][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0103 loss2:0.0780 loss3:0.0029 | AUC:0.8497 Anomaly AUC:0.6811
[2023-08-28 15:16:48,712][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0063 loss2:0.0627 loss3:0.0022 | AUC:0.8475 Anomaly AUC:0.6792
[2023-08-28 15:17:09,367][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0134 loss2:0.0544 loss3:0.0028 | AUC:0.8338 Anomaly AUC:0.6449
[2023-08-28 15:17:28,144][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0176 loss2:0.0805 loss3:0.0044 | AUC:0.8451 Anomaly AUC:0.6694
[2023-08-28 15:17:28,145][main-autotune.py][line:120][INFO] Training completes in 6m 54s | best AUCAUC:0.8619 Anomaly AUC:0.6963

[2023-08-28 15:17:29,809][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:17:57,058][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3747 loss2:1.0674 loss3:0.2428 | AUC:0.8374 Anomaly AUC:0.6453
[2023-08-28 15:18:18,426][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1519 loss2:0.8294 loss3:0.0528 | AUC:0.8270 Anomaly AUC:0.6629
[2023-08-28 15:18:42,429][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0573 loss2:0.7171 loss3:0.0200 | AUC:0.8367 Anomaly AUC:0.6566
[2023-08-28 15:19:05,747][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0394 loss2:0.6406 loss3:0.0116 | AUC:0.8350 Anomaly AUC:0.6710
[2023-08-28 15:19:24,397][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0213 loss2:0.5562 loss3:0.0082 | AUC:0.8510 Anomaly AUC:0.6990
[2023-08-28 15:19:44,027][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0172 loss2:0.4838 loss3:0.0064 | AUC:0.8306 Anomaly AUC:0.6656
[2023-08-28 15:20:06,040][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0179 loss2:0.4261 loss3:0.0062 | AUC:0.8562 Anomaly AUC:0.6744
[2023-08-28 15:20:28,067][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0127 loss2:0.3622 loss3:0.0045 | AUC:0.8415 Anomaly AUC:0.6656
[2023-08-28 15:20:50,104][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0045 loss2:0.2925 loss3:0.0028 | AUC:0.8415 Anomaly AUC:0.6638
[2023-08-28 15:21:13,346][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0078 loss2:0.2622 loss3:0.0035 | AUC:0.8428 Anomaly AUC:0.6693
[2023-08-28 15:21:32,147][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0120 loss2:0.2393 loss3:0.0043 | AUC:0.8359 Anomaly AUC:0.6740
[2023-08-28 15:21:51,884][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0149 loss2:0.2229 loss3:0.0055 | AUC:0.8510 Anomaly AUC:0.6746
[2023-08-28 15:22:15,591][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0140 loss2:0.1944 loss3:0.0044 | AUC:0.8382 Anomaly AUC:0.6816
[2023-08-28 15:22:36,615][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0079 loss2:0.1698 loss3:0.0034 | AUC:0.8505 Anomaly AUC:0.6780
[2023-08-28 15:22:55,375][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0044 loss2:0.1392 loss3:0.0021 | AUC:0.8500 Anomaly AUC:0.6797
[2023-08-28 15:23:16,596][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0072 loss2:0.1452 loss3:0.0033 | AUC:0.8539 Anomaly AUC:0.6856
[2023-08-28 15:23:40,062][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0077 loss2:0.1271 loss3:0.0027 | AUC:0.8453 Anomaly AUC:0.6819
[2023-08-28 15:24:01,599][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0008 loss2:0.1041 loss3:0.0013 | AUC:0.8612 Anomaly AUC:0.6949
[2023-08-28 15:24:20,761][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0003 loss2:0.0911 loss3:0.0010 | AUC:0.8607 Anomaly AUC:0.6912
[2023-08-28 15:24:40,255][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0003 loss2:0.0836 loss3:0.0011 | AUC:0.8608 Anomaly AUC:0.6904
[2023-08-28 15:24:40,257][main-autotune.py][line:120][INFO] Training completes in 7m 2s | best AUCAUC:0.8612 Anomaly AUC:0.6949

[2023-08-28 15:24:42,288][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:25:09,106][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3785 loss2:1.1115 loss3:0.1973 | AUC:0.8296 Anomaly AUC:0.6319
[2023-08-28 15:25:29,907][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1729 loss2:0.8910 loss3:0.0449 | AUC:0.8412 Anomaly AUC:0.6788
[2023-08-28 15:25:48,483][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0655 loss2:0.7798 loss3:0.0155 | AUC:0.8537 Anomaly AUC:0.6727
[2023-08-28 15:26:09,907][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0456 loss2:0.7231 loss3:0.0111 | AUC:0.8482 Anomaly AUC:0.6722
[2023-08-28 15:26:28,671][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0485 loss2:0.6813 loss3:0.0103 | AUC:0.8424 Anomaly AUC:0.6686
[2023-08-28 15:26:48,249][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0152 loss2:0.5948 loss3:0.0038 | AUC:0.8511 Anomaly AUC:0.6759
[2023-08-28 15:27:10,241][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0126 loss2:0.5172 loss3:0.0026 | AUC:0.8375 Anomaly AUC:0.6657
[2023-08-28 15:27:32,547][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0195 loss2:0.4880 loss3:0.0050 | AUC:0.8298 Anomaly AUC:0.6405
[2023-08-28 15:27:54,101][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0162 loss2:0.4087 loss3:0.0033 | AUC:0.8456 Anomaly AUC:0.6629
[2023-08-28 15:28:17,855][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0167 loss2:0.3433 loss3:0.0035 | AUC:0.8300 Anomaly AUC:0.6458
[2023-08-28 15:28:41,121][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0134 loss2:0.2914 loss3:0.0030 | AUC:0.8453 Anomaly AUC:0.6586
[2023-08-28 15:29:00,039][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0033 loss2:0.2026 loss3:0.0011 | AUC:0.8381 Anomaly AUC:0.6501
[2023-08-28 15:29:21,711][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0007 loss2:0.1371 loss3:0.0007 | AUC:0.8460 Anomaly AUC:0.6613
[2023-08-28 15:29:43,382][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0125 loss2:0.1395 loss3:0.0032 | AUC:0.8307 Anomaly AUC:0.6423
[2023-08-28 15:30:06,983][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0069 loss2:0.1210 loss3:0.0021 | AUC:0.7800 Anomaly AUC:0.5620
[2023-08-28 15:30:30,123][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0330 loss2:0.1831 loss3:0.0068 | AUC:0.8372 Anomaly AUC:0.6317
[2023-08-28 15:30:53,224][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0076 loss2:0.0906 loss3:0.0019 | AUC:0.8344 Anomaly AUC:0.6330
[2023-08-28 15:31:14,911][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0072 loss2:0.0706 loss3:0.0017 | AUC:0.8252 Anomaly AUC:0.6201
[2023-08-28 15:31:36,548][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0152 loss2:0.0822 loss3:0.0036 | AUC:0.8332 Anomaly AUC:0.6130
[2023-08-28 15:31:57,779][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0024 loss2:0.0431 loss3:0.0010 | AUC:0.8296 Anomaly AUC:0.6182
[2023-08-28 15:31:57,781][main-autotune.py][line:120][INFO] Training completes in 7m 7s | best AUCAUC:0.8537 Anomaly AUC:0.6727

[2023-08-28 15:31:59,884][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:32:26,605][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3724 loss2:1.4114 loss3:0.3873 | AUC:0.7996 Anomaly AUC:0.5943
[2023-08-28 15:32:47,220][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.0361 loss2:1.4068 loss3:0.4156 | AUC:0.7930 Anomaly AUC:0.6037
[2023-08-28 15:33:05,786][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0037 loss2:1.3934 loss3:0.3514 | AUC:0.7274 Anomaly AUC:0.5770
[2023-08-28 15:33:26,856][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0015 loss2:1.2914 loss3:0.3111 | AUC:0.7943 Anomaly AUC:0.6125
[2023-08-28 15:33:45,527][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0017 loss2:1.2295 loss3:0.2925 | AUC:0.7594 Anomaly AUC:0.5906
[2023-08-28 15:34:04,993][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0010 loss2:1.1822 loss3:0.2720 | AUC:0.6586 Anomaly AUC:0.5434
[2023-08-28 15:34:28,234][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0608 loss2:1.2057 loss3:0.3220 | AUC:0.6469 Anomaly AUC:0.5087
[2023-08-28 15:34:46,879][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0010 loss2:1.1551 loss3:0.2856 | AUC:0.6173 Anomaly AUC:0.4940
[2023-08-28 15:35:06,415][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0009 loss2:1.1324 loss3:0.2646 | AUC:0.6329 Anomaly AUC:0.5001
[2023-08-28 15:35:26,424][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0007 loss2:1.1098 loss3:0.2521 | AUC:0.6284 Anomaly AUC:0.4926
[2023-08-28 15:35:47,832][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0008 loss2:1.0780 loss3:0.2404 | AUC:0.6392 Anomaly AUC:0.4997
[2023-08-28 15:36:08,339][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0007 loss2:1.0491 loss3:0.2281 | AUC:0.6949 Anomaly AUC:0.5276
[2023-08-28 15:36:27,200][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0007 loss2:1.0271 loss3:0.2117 | AUC:0.6470 Anomaly AUC:0.4908
[2023-08-28 15:36:48,395][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0010 loss2:0.9936 loss3:0.1912 | AUC:0.5912 Anomaly AUC:0.4619
[2023-08-28 15:37:10,944][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0008 loss2:0.9432 loss3:0.1616 | AUC:0.6192 Anomaly AUC:0.4713
[2023-08-28 15:37:34,261][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0010 loss2:0.8965 loss3:0.1322 | AUC:0.6259 Anomaly AUC:0.4714
[2023-08-28 15:37:55,894][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0119 loss2:0.8666 loss3:0.1195 | AUC:0.7912 Anomaly AUC:0.5784
[2023-08-28 15:38:18,652][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0232 loss2:0.9492 loss3:0.2185 | AUC:0.5002 Anomaly AUC:0.4180
[2023-08-28 15:38:41,882][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0012 loss2:0.9257 loss3:0.1344 | AUC:0.5532 Anomaly AUC:0.4270
[2023-08-28 15:39:01,157][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0009 loss2:0.8581 loss3:0.0963 | AUC:0.4766 Anomaly AUC:0.3904
[2023-08-28 15:39:01,158][main-autotune.py][line:120][INFO] Training completes in 6m 53s | best AUCAUC:0.7996 Anomaly AUC:0.5943

[2023-08-28 15:39:02,865][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:39:33,999][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3691 loss2:1.0696 loss3:0.3418 | AUC:0.8274 Anomaly AUC:0.6532
[2023-08-28 15:39:52,326][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1500 loss2:0.8325 loss3:0.2592 | AUC:0.8121 Anomaly AUC:0.6592
[2023-08-28 15:40:12,646][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0580 loss2:0.7065 loss3:0.1836 | AUC:0.8282 Anomaly AUC:0.6464
[2023-08-28 15:40:31,172][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0354 loss2:0.6208 loss3:0.1350 | AUC:0.8132 Anomaly AUC:0.6685
[2023-08-28 15:40:51,727][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0255 loss2:0.5399 loss3:0.1025 | AUC:0.8227 Anomaly AUC:0.6580
[2023-08-28 15:41:13,988][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0246 loss2:0.4619 loss3:0.0852 | AUC:0.8162 Anomaly AUC:0.6432
[2023-08-28 15:41:34,394][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0114 loss2:0.3653 loss3:0.0616 | AUC:0.8500 Anomaly AUC:0.6798
[2023-08-28 15:41:53,217][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0200 loss2:0.3172 loss3:0.0586 | AUC:0.8476 Anomaly AUC:0.6721
[2023-08-28 15:42:14,127][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0144 loss2:0.2534 loss3:0.0506 | AUC:0.8104 Anomaly AUC:0.6382
[2023-08-28 15:42:36,544][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0070 loss2:0.1869 loss3:0.0391 | AUC:0.8274 Anomaly AUC:0.6530
[2023-08-28 15:42:59,007][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0124 loss2:0.1599 loss3:0.0395 | AUC:0.8237 Anomaly AUC:0.6453
[2023-08-28 15:43:17,741][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0093 loss2:0.1224 loss3:0.0329 | AUC:0.8299 Anomaly AUC:0.6501
[2023-08-28 15:43:37,226][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0066 loss2:0.1068 loss3:0.0322 | AUC:0.8035 Anomaly AUC:0.6402
[2023-08-28 15:43:57,523][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0249 loss2:0.1447 loss3:0.0430 | AUC:0.8019 Anomaly AUC:0.6369
[2023-08-28 15:44:16,295][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0115 loss2:0.0904 loss3:0.0321 | AUC:0.8230 Anomaly AUC:0.6470
[2023-08-28 15:44:38,423][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0040 loss2:0.0583 loss3:0.0243 | AUC:0.8026 Anomaly AUC:0.6293
[2023-08-28 15:44:57,189][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0106 loss2:0.0674 loss3:0.0283 | AUC:0.8333 Anomaly AUC:0.6576
[2023-08-28 15:45:16,527][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0074 loss2:0.0535 loss3:0.0291 | AUC:0.8259 Anomaly AUC:0.6372
[2023-08-28 15:45:35,359][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0073 loss2:0.0518 loss3:0.0277 | AUC:0.8195 Anomaly AUC:0.6265
[2023-08-28 15:45:54,782][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0033 loss2:0.0394 loss3:0.0249 | AUC:0.8132 Anomaly AUC:0.6187
[2023-08-28 15:45:54,783][main-autotune.py][line:120][INFO] Training completes in 6m 44s | best AUCAUC:0.8500 Anomaly AUC:0.6798

[2023-08-28 15:45:56,433][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:46:23,121][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3667 loss2:1.0174 loss3:0.2874 | AUC:0.8305 Anomaly AUC:0.6544
[2023-08-28 15:46:43,166][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1402 loss2:0.7700 loss3:0.0807 | AUC:0.8034 Anomaly AUC:0.6729
[2023-08-28 15:47:01,641][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0540 loss2:0.6308 loss3:0.0342 | AUC:0.8300 Anomaly AUC:0.6683
[2023-08-28 15:47:23,322][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0404 loss2:0.5279 loss3:0.0238 | AUC:0.8062 Anomaly AUC:0.6530
[2023-08-28 15:47:42,211][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0280 loss2:0.4289 loss3:0.0184 | AUC:0.8327 Anomaly AUC:0.6779
[2023-08-28 15:48:01,775][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0148 loss2:0.3240 loss3:0.0134 | AUC:0.8299 Anomaly AUC:0.6830
[2023-08-28 15:48:24,390][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0136 loss2:0.2539 loss3:0.0118 | AUC:0.8080 Anomaly AUC:0.6389
[2023-08-28 15:48:47,122][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0196 loss2:0.2097 loss3:0.0121 | AUC:0.8347 Anomaly AUC:0.6580
[2023-08-28 15:49:09,519][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0147 loss2:0.1566 loss3:0.0093 | AUC:0.8352 Anomaly AUC:0.6512
[2023-08-28 15:49:31,820][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0098 loss2:0.1166 loss3:0.0075 | AUC:0.8154 Anomaly AUC:0.6625
[2023-08-28 15:49:53,895][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0035 loss2:0.0793 loss3:0.0034 | AUC:0.8214 Anomaly AUC:0.6442
[2023-08-28 15:50:15,931][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0059 loss2:0.0640 loss3:0.0020 | AUC:0.8222 Anomaly AUC:0.6360
[2023-08-28 15:50:38,027][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0241 loss2:0.1088 loss3:0.0078 | AUC:0.8276 Anomaly AUC:0.6443
[2023-08-28 15:51:00,144][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0059 loss2:0.0526 loss3:0.0023 | AUC:0.8433 Anomaly AUC:0.6773
[2023-08-28 15:51:22,405][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0201 loss2:0.0743 loss3:0.0049 | AUC:0.8186 Anomaly AUC:0.6717
[2023-08-28 15:51:44,454][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.0136 loss2:0.0555 loss3:0.0036 | AUC:0.8373 Anomaly AUC:0.6740
[2023-08-28 15:52:03,306][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0117 loss2:0.0467 loss3:0.0031 | AUC:0.8263 Anomaly AUC:0.6839
[2023-08-28 15:52:22,736][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0030 loss2:0.0250 loss3:0.0014 | AUC:0.8248 Anomaly AUC:0.6691
[2023-08-28 15:52:43,134][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0037 loss2:0.0204 loss3:0.0015 | AUC:0.8341 Anomaly AUC:0.6684
[2023-08-28 15:53:02,000][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0001 loss2:0.0116 loss3:0.0006 | AUC:0.8370 Anomaly AUC:0.6713
[2023-08-28 15:53:02,001][main-autotune.py][line:120][INFO] Training completes in 6m 57s | best AUCAUC:0.8433 Anomaly AUC:0.6773

[2023-08-28 15:53:03,694][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 15:53:31,055][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3597 loss2:1.2595 loss3:0.3534 | AUC:0.7929 Anomaly AUC:0.5965
[2023-08-28 15:53:52,013][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1260 loss2:1.0752 loss3:0.2208 | AUC:0.8063 Anomaly AUC:0.5790
[2023-08-28 15:54:10,522][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0573 loss2:0.9989 loss3:0.1474 | AUC:0.7783 Anomaly AUC:0.5814
[2023-08-28 15:54:31,819][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0302 loss2:0.9360 loss3:0.0949 | AUC:0.8130 Anomaly AUC:0.5946
[2023-08-28 15:54:50,536][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0243 loss2:0.8845 loss3:0.0687 | AUC:0.8154 Anomaly AUC:0.5905
[2023-08-28 15:55:10,142][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0083 loss2:0.8163 loss3:0.0497 | AUC:0.7994 Anomaly AUC:0.5770
[2023-08-28 15:55:31,846][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0173 loss2:0.7834 loss3:0.0463 | AUC:0.8123 Anomaly AUC:0.5826
[2023-08-28 15:55:53,608][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0185 loss2:0.7652 loss3:0.0458 | AUC:0.8172 Anomaly AUC:0.6160
[2023-08-28 15:56:16,959][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0117 loss2:0.7316 loss3:0.0372 | AUC:0.8171 Anomaly AUC:0.5794
[2023-08-28 15:56:39,634][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0044 loss2:0.7010 loss3:0.0314 | AUC:0.8339 Anomaly AUC:0.6270
[2023-08-28 15:57:03,121][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0121 loss2:0.6789 loss3:0.0338 | AUC:0.8201 Anomaly AUC:0.6205
[2023-08-28 15:57:26,555][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0103 loss2:0.6557 loss3:0.0299 | AUC:0.8179 Anomaly AUC:0.6199
[2023-08-28 15:57:49,490][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0114 loss2:0.6430 loss3:0.0304 | AUC:0.8048 Anomaly AUC:0.5907
[2023-08-28 15:58:12,384][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0125 loss2:0.6224 loss3:0.0283 | AUC:0.8143 Anomaly AUC:0.6153
[2023-08-28 15:58:35,409][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0057 loss2:0.5878 loss3:0.0248 | AUC:0.8144 Anomaly AUC:0.6193
[2023-08-28 15:58:58,228][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0036 loss2:0.5413 loss3:0.0199 | AUC:0.8304 Anomaly AUC:0.6157
[2023-08-28 15:59:21,207][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0088 loss2:0.5492 loss3:0.0239 | AUC:0.7939 Anomaly AUC:0.6202
[2023-08-28 15:59:44,224][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0081 loss2:0.5287 loss3:0.0240 | AUC:0.8124 Anomaly AUC:0.6071
[2023-08-28 16:00:04,764][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0087 loss2:0.5133 loss3:0.0230 | AUC:0.8029 Anomaly AUC:0.6037
[2023-08-28 16:00:23,617][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0074 loss2:0.4700 loss3:0.0209 | AUC:0.8023 Anomaly AUC:0.6307
[2023-08-28 16:00:23,618][main-autotune.py][line:120][INFO] Training completes in 7m 11s | best AUCAUC:0.8339 Anomaly AUC:0.6270

[2023-08-28 16:00:25,307][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:00:52,628][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3845 loss2:1.1708 loss3:0.1874 | AUC:0.8274 Anomaly AUC:0.6223
[2023-08-28 16:01:13,669][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1781 loss2:0.9809 loss3:0.0527 | AUC:0.8322 Anomaly AUC:0.6586
[2023-08-28 16:01:32,119][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0838 loss2:0.8480 loss3:0.0211 | AUC:0.8522 Anomaly AUC:0.6827
[2023-08-28 16:01:53,047][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0471 loss2:0.7758 loss3:0.0112 | AUC:0.8561 Anomaly AUC:0.6823
[2023-08-28 16:02:11,778][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0233 loss2:0.7260 loss3:0.0062 | AUC:0.8458 Anomaly AUC:0.6677
[2023-08-28 16:02:31,525][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0283 loss2:0.6972 loss3:0.0066 | AUC:0.8419 Anomaly AUC:0.6637
[2023-08-28 16:02:52,274][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0196 loss2:0.6493 loss3:0.0047 | AUC:0.8394 Anomaly AUC:0.6596
[2023-08-28 16:03:11,023][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0261 loss2:0.6182 loss3:0.0059 | AUC:0.8390 Anomaly AUC:0.6334
[2023-08-28 16:03:32,120][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0163 loss2:0.5621 loss3:0.0037 | AUC:0.8377 Anomaly AUC:0.6350
[2023-08-28 16:03:55,664][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0176 loss2:0.5058 loss3:0.0037 | AUC:0.8523 Anomaly AUC:0.6734
[2023-08-28 16:04:14,859][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0143 loss2:0.4394 loss3:0.0032 | AUC:0.8533 Anomaly AUC:0.6577
[2023-08-28 16:04:34,675][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0138 loss2:0.3965 loss3:0.0032 | AUC:0.8372 Anomaly AUC:0.6311
[2023-08-28 16:04:57,746][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0189 loss2:0.3732 loss3:0.0048 | AUC:0.8357 Anomaly AUC:0.6305
[2023-08-28 16:05:19,348][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0164 loss2:0.3356 loss3:0.0037 | AUC:0.8435 Anomaly AUC:0.6299
[2023-08-28 16:05:42,225][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0094 loss2:0.2580 loss3:0.0023 | AUC:0.8412 Anomaly AUC:0.6357
[2023-08-28 16:06:05,249][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0162 loss2:0.2610 loss3:0.0035 | AUC:0.8514 Anomaly AUC:0.6588
[2023-08-28 16:06:28,009][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0085 loss2:0.1779 loss3:0.0023 | AUC:0.8434 Anomaly AUC:0.6458
[2023-08-28 16:06:50,818][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0024 loss2:0.1152 loss3:0.0012 | AUC:0.8496 Anomaly AUC:0.6554
[2023-08-28 16:07:14,047][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0024 loss2:0.0870 loss3:0.0010 | AUC:0.8504 Anomaly AUC:0.6554
[2023-08-28 16:07:37,080][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0095 loss2:0.0957 loss3:0.0025 | AUC:0.8433 Anomaly AUC:0.6342
[2023-08-28 16:07:37,081][main-autotune.py][line:120][INFO] Training completes in 7m 3s | best AUCAUC:0.8561 Anomaly AUC:0.6823

[2023-08-28 16:07:38,749][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:08:05,629][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3750 loss2:1.0665 loss3:0.2425 | AUC:0.8248 Anomaly AUC:0.6485
[2023-08-28 16:08:27,869][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1628 loss2:0.8373 loss3:0.0564 | AUC:0.8415 Anomaly AUC:0.6713
[2023-08-28 16:08:46,501][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0614 loss2:0.7182 loss3:0.0225 | AUC:0.8514 Anomaly AUC:0.6821
[2023-08-28 16:09:05,962][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0434 loss2:0.6450 loss3:0.0133 | AUC:0.8470 Anomaly AUC:0.7087
[2023-08-28 16:09:26,542][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0288 loss2:0.5633 loss3:0.0092 | AUC:0.8548 Anomaly AUC:0.7032
[2023-08-28 16:09:45,217][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0132 loss2:0.4823 loss3:0.0057 | AUC:0.8464 Anomaly AUC:0.6778
[2023-08-28 16:10:06,093][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0142 loss2:0.4223 loss3:0.0051 | AUC:0.8484 Anomaly AUC:0.6798
[2023-08-28 16:10:28,970][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0104 loss2:0.3530 loss3:0.0039 | AUC:0.8645 Anomaly AUC:0.6923
[2023-08-28 16:10:51,382][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0114 loss2:0.3090 loss3:0.0046 | AUC:0.8477 Anomaly AUC:0.6784
[2023-08-28 16:11:14,067][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0158 loss2:0.2909 loss3:0.0051 | AUC:0.8550 Anomaly AUC:0.6878
[2023-08-28 16:11:36,492][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0148 loss2:0.2500 loss3:0.0050 | AUC:0.8459 Anomaly AUC:0.6751
[2023-08-28 16:11:58,844][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0049 loss2:0.2015 loss3:0.0029 | AUC:0.8470 Anomaly AUC:0.6794
[2023-08-28 16:12:20,823][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0065 loss2:0.1844 loss3:0.0032 | AUC:0.8473 Anomaly AUC:0.6799
[2023-08-28 16:12:43,582][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0041 loss2:0.1544 loss3:0.0024 | AUC:0.8501 Anomaly AUC:0.6793
[2023-08-28 16:13:05,794][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0005 loss2:0.1300 loss3:0.0016 | AUC:0.8510 Anomaly AUC:0.6792
[2023-08-28 16:13:27,989][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0004 loss2:0.1163 loss3:0.0015 | AUC:0.8497 Anomaly AUC:0.6796
[2023-08-28 16:13:50,061][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0003 loss2:0.1063 loss3:0.0014 | AUC:0.8496 Anomaly AUC:0.6775
[2023-08-28 16:14:10,821][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0003 loss2:0.0977 loss3:0.0015 | AUC:0.8505 Anomaly AUC:0.6797
[2023-08-28 16:14:32,146][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0002 loss2:0.0898 loss3:0.0014 | AUC:0.8500 Anomaly AUC:0.6790
[2023-08-28 16:14:54,516][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0178 loss2:0.1427 loss3:0.0064 | AUC:0.8428 Anomaly AUC:0.6742
[2023-08-28 16:14:54,517][main-autotune.py][line:120][INFO] Training completes in 7m 7s | best AUCAUC:0.8645 Anomaly AUC:0.6923

[2023-08-28 16:14:56,190][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:15:23,142][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00010 | loss1:0.3888 loss2:1.0819 loss3:0.2966 | AUC:0.8199 Anomaly AUC:0.6361
[2023-08-28 16:15:43,934][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00010 | loss1:0.1603 loss2:0.8513 loss3:0.0987 | AUC:0.8408 Anomaly AUC:0.6891
[2023-08-28 16:16:02,488][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00010 | loss1:0.0556 loss2:0.7408 loss3:0.0336 | AUC:0.8373 Anomaly AUC:0.6992
[2023-08-28 16:16:23,883][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00010 | loss1:0.0375 loss2:0.6752 loss3:0.0187 | AUC:0.8234 Anomaly AUC:0.6836
[2023-08-28 16:16:42,619][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00010 | loss1:0.0236 loss2:0.6036 loss3:0.0105 | AUC:0.8457 Anomaly AUC:0.6889
[2023-08-28 16:17:02,304][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00010 | loss1:0.0143 loss2:0.5353 loss3:0.0073 | AUC:0.8513 Anomaly AUC:0.6897
[2023-08-28 16:17:24,425][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00010 | loss1:0.0173 loss2:0.4895 loss3:0.0071 | AUC:0.8188 Anomaly AUC:0.6723
[2023-08-28 16:17:46,288][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00010 | loss1:0.0095 loss2:0.4291 loss3:0.0049 | AUC:0.8425 Anomaly AUC:0.7012
[2023-08-28 16:18:08,557][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00010 | loss1:0.0064 loss2:0.3787 loss3:0.0039 | AUC:0.8379 Anomaly AUC:0.6869
[2023-08-28 16:18:29,448][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00010 | loss1:0.0043 loss2:0.3387 loss3:0.0036 | AUC:0.8299 Anomaly AUC:0.6845
[2023-08-28 16:18:48,275][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00010 | loss1:0.0013 loss2:0.2897 loss3:0.0025 | AUC:0.8417 Anomaly AUC:0.6923
[2023-08-28 16:19:08,064][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00010 | loss1:0.0010 loss2:0.2598 loss3:0.0023 | AUC:0.8448 Anomaly AUC:0.6871
[2023-08-28 16:19:31,632][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00010 | loss1:0.0008 loss2:0.2397 loss3:0.0021 | AUC:0.8428 Anomaly AUC:0.6893
[2023-08-28 16:19:55,232][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00010 | loss1:0.0007 loss2:0.2238 loss3:0.0020 | AUC:0.8443 Anomaly AUC:0.6884
[2023-08-28 16:20:16,207][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00010 | loss1:0.0006 loss2:0.2102 loss3:0.0018 | AUC:0.8454 Anomaly AUC:0.6855
[2023-08-28 16:20:35,063][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00010 | loss1:0.0005 loss2:0.2002 loss3:0.0018 | AUC:0.8420 Anomaly AUC:0.6774
[2023-08-28 16:20:56,563][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00010 | loss1:0.0004 loss2:0.1921 loss3:0.0018 | AUC:0.8443 Anomaly AUC:0.6869
[2023-08-28 16:21:20,397][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00010 | loss1:0.0004 loss2:0.1838 loss3:0.0017 | AUC:0.8395 Anomaly AUC:0.6778
[2023-08-28 16:21:41,921][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00010 | loss1:0.0003 loss2:0.1763 loss3:0.0016 | AUC:0.8401 Anomaly AUC:0.6793
[2023-08-28 16:22:05,474][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00010 | loss1:0.0003 loss2:0.1698 loss3:0.0016 | AUC:0.8418 Anomaly AUC:0.6831
[2023-08-28 16:22:05,476][main-autotune.py][line:120][INFO] Training completes in 7m 1s | best AUCAUC:0.8513 Anomaly AUC:0.6897

[2023-08-28 16:22:07,207][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:22:33,841][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3734 loss2:1.0715 loss3:0.2485 | AUC:0.8374 Anomaly AUC:0.6651
[2023-08-28 16:22:56,010][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1490 loss2:0.8325 loss3:0.0606 | AUC:0.8316 Anomaly AUC:0.6866
[2023-08-28 16:23:17,275][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0629 loss2:0.7276 loss3:0.0267 | AUC:0.8570 Anomaly AUC:0.7038
[2023-08-28 16:23:35,920][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0324 loss2:0.6463 loss3:0.0138 | AUC:0.8455 Anomaly AUC:0.6965
[2023-08-28 16:23:57,927][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0273 loss2:0.5764 loss3:0.0100 | AUC:0.8618 Anomaly AUC:0.7038
[2023-08-28 16:24:19,892][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0194 loss2:0.5054 loss3:0.0078 | AUC:0.8478 Anomaly AUC:0.6927
[2023-08-28 16:24:40,894][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0077 loss2:0.4265 loss3:0.0055 | AUC:0.8575 Anomaly AUC:0.7047
[2023-08-28 16:24:59,635][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0170 loss2:0.3825 loss3:0.0063 | AUC:0.8434 Anomaly AUC:0.6908
[2023-08-28 16:25:20,977][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0109 loss2:0.3335 loss3:0.0053 | AUC:0.8488 Anomaly AUC:0.7026
[2023-08-28 16:25:43,977][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0120 loss2:0.2881 loss3:0.0051 | AUC:0.8436 Anomaly AUC:0.6893
[2023-08-28 16:26:02,706][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0056 loss2:0.2369 loss3:0.0037 | AUC:0.8525 Anomaly AUC:0.6942
[2023-08-28 16:26:22,452][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0042 loss2:0.2042 loss3:0.0031 | AUC:0.8348 Anomaly AUC:0.6673
[2023-08-28 16:26:46,466][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0238 loss2:0.2329 loss3:0.0087 | AUC:0.8252 Anomaly AUC:0.6742
[2023-08-28 16:27:09,656][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0121 loss2:0.2085 loss3:0.0060 | AUC:0.8396 Anomaly AUC:0.6783
[2023-08-28 16:27:33,179][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0062 loss2:0.1578 loss3:0.0031 | AUC:0.8495 Anomaly AUC:0.6751
[2023-08-28 16:27:54,657][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0039 loss2:0.1429 loss3:0.0030 | AUC:0.8412 Anomaly AUC:0.6785
[2023-08-28 16:28:18,208][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0020 loss2:0.1210 loss3:0.0022 | AUC:0.8468 Anomaly AUC:0.6817
[2023-08-28 16:28:41,494][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0038 loss2:0.1132 loss3:0.0027 | AUC:0.8427 Anomaly AUC:0.6856
[2023-08-28 16:29:04,642][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0084 loss2:0.1315 loss3:0.0044 | AUC:0.8581 Anomaly AUC:0.6943
[2023-08-28 16:29:26,152][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0144 loss2:0.1236 loss3:0.0051 | AUC:0.8417 Anomaly AUC:0.6868
[2023-08-28 16:29:26,154][main-autotune.py][line:120][INFO] Training completes in 7m 11s | best AUCAUC:0.8618 Anomaly AUC:0.7038

[2023-08-28 16:29:28,035][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:29:54,903][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3777 loss2:1.0303 loss3:0.1973 | AUC:0.8289 Anomaly AUC:0.6525
[2023-08-28 16:30:16,884][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1727 loss2:0.8052 loss3:0.0462 | AUC:0.8369 Anomaly AUC:0.6691
[2023-08-28 16:30:35,408][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0780 loss2:0.6847 loss3:0.0193 | AUC:0.8373 Anomaly AUC:0.6586
[2023-08-28 16:30:56,291][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0419 loss2:0.5895 loss3:0.0111 | AUC:0.8354 Anomaly AUC:0.6832
[2023-08-28 16:31:14,853][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0290 loss2:0.4941 loss3:0.0076 | AUC:0.8449 Anomaly AUC:0.6991
[2023-08-28 16:31:34,320][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0188 loss2:0.4080 loss3:0.0047 | AUC:0.8273 Anomaly AUC:0.6697
[2023-08-28 16:31:57,746][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0178 loss2:0.3433 loss3:0.0044 | AUC:0.8586 Anomaly AUC:0.6956
[2023-08-28 16:32:19,970][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0142 loss2:0.2797 loss3:0.0035 | AUC:0.8563 Anomaly AUC:0.6792
[2023-08-28 16:32:42,440][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0142 loss2:0.2406 loss3:0.0039 | AUC:0.8591 Anomaly AUC:0.6958
[2023-08-28 16:33:04,525][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0194 loss2:0.2186 loss3:0.0040 | AUC:0.8487 Anomaly AUC:0.6657
[2023-08-28 16:33:26,604][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0031 loss2:0.1565 loss3:0.0013 | AUC:0.8424 Anomaly AUC:0.6638
[2023-08-28 16:33:48,481][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0064 loss2:0.1359 loss3:0.0019 | AUC:0.8397 Anomaly AUC:0.6650
[2023-08-28 16:34:10,493][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0109 loss2:0.1403 loss3:0.0029 | AUC:0.8354 Anomaly AUC:0.6738
[2023-08-28 16:34:29,306][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0095 loss2:0.1172 loss3:0.0023 | AUC:0.8394 Anomaly AUC:0.6473
[2023-08-28 16:34:48,716][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0046 loss2:0.0933 loss3:0.0016 | AUC:0.8418 Anomaly AUC:0.6527
[2023-08-28 16:35:10,638][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0005 loss2:0.0708 loss3:0.0006 | AUC:0.8437 Anomaly AUC:0.6546
[2023-08-28 16:35:29,526][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0003 loss2:0.0592 loss3:0.0005 | AUC:0.8415 Anomaly AUC:0.6539
[2023-08-28 16:35:48,756][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0002 loss2:0.0517 loss3:0.0006 | AUC:0.8404 Anomaly AUC:0.6533
[2023-08-28 16:36:10,815][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0002 loss2:0.0459 loss3:0.0006 | AUC:0.8389 Anomaly AUC:0.6518
[2023-08-28 16:36:33,167][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0001 loss2:0.0410 loss3:0.0006 | AUC:0.8371 Anomaly AUC:0.6473
[2023-08-28 16:36:33,169][main-autotune.py][line:120][INFO] Training completes in 6m 57s | best AUCAUC:0.8591 Anomaly AUC:0.6958

[2023-08-28 16:36:34,885][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:37:01,790][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00020 | loss1:0.3699 loss2:1.0319 loss3:0.2815 | AUC:0.8241 Anomaly AUC:0.6550
[2023-08-28 16:37:22,436][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00020 | loss1:0.1352 loss2:0.7797 loss3:0.0910 | AUC:0.8323 Anomaly AUC:0.6887
[2023-08-28 16:37:41,035][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00020 | loss1:0.0532 loss2:0.6564 loss3:0.0358 | AUC:0.8216 Anomaly AUC:0.6751
[2023-08-28 16:38:02,239][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00020 | loss1:0.0247 loss2:0.5479 loss3:0.0191 | AUC:0.8422 Anomaly AUC:0.6735
[2023-08-28 16:38:20,856][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00020 | loss1:0.0254 loss2:0.4680 loss3:0.0135 | AUC:0.8161 Anomaly AUC:0.6948
[2023-08-28 16:38:40,370][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00020 | loss1:0.0233 loss2:0.4143 loss3:0.0087 | AUC:0.8350 Anomaly AUC:0.6875
[2023-08-28 16:39:03,978][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00020 | loss1:0.0087 loss2:0.3369 loss3:0.0048 | AUC:0.8512 Anomaly AUC:0.6881
[2023-08-28 16:39:22,774][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00020 | loss1:0.0013 loss2:0.2665 loss3:0.0024 | AUC:0.8475 Anomaly AUC:0.6880
[2023-08-28 16:39:42,311][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00020 | loss1:0.0008 loss2:0.2239 loss3:0.0024 | AUC:0.8510 Anomaly AUC:0.6873
[2023-08-28 16:40:04,065][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00020 | loss1:0.0007 loss2:0.1932 loss3:0.0027 | AUC:0.8537 Anomaly AUC:0.6879
[2023-08-28 16:40:28,026][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00020 | loss1:0.0006 loss2:0.1682 loss3:0.0026 | AUC:0.8530 Anomaly AUC:0.6841
[2023-08-28 16:40:52,048][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00020 | loss1:0.0005 loss2:0.1522 loss3:0.0024 | AUC:0.8513 Anomaly AUC:0.6817
[2023-08-28 16:41:15,422][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00020 | loss1:0.0004 loss2:0.1395 loss3:0.0023 | AUC:0.8466 Anomaly AUC:0.6748
[2023-08-28 16:41:38,807][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00020 | loss1:0.0004 loss2:0.1281 loss3:0.0024 | AUC:0.8484 Anomaly AUC:0.6738
[2023-08-28 16:41:57,710][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00020 | loss1:0.0964 loss2:0.3315 loss3:0.0265 | AUC:0.8440 Anomaly AUC:0.6745
[2023-08-28 16:42:17,525][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00020 | loss1:0.0137 loss2:0.1824 loss3:0.0066 | AUC:0.8459 Anomaly AUC:0.6816
[2023-08-28 16:42:40,688][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00020 | loss1:0.0088 loss2:0.1375 loss3:0.0043 | AUC:0.8047 Anomaly AUC:0.6682
[2023-08-28 16:43:03,837][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00020 | loss1:0.0016 loss2:0.1128 loss3:0.0027 | AUC:0.8221 Anomaly AUC:0.6772
[2023-08-28 16:43:27,000][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00020 | loss1:0.0006 loss2:0.0974 loss3:0.0018 | AUC:0.8274 Anomaly AUC:0.6750
[2023-08-28 16:43:50,236][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00020 | loss1:0.0004 loss2:0.0888 loss3:0.0016 | AUC:0.8285 Anomaly AUC:0.6734
[2023-08-28 16:43:50,238][main-autotune.py][line:120][INFO] Training completes in 7m 7s | best AUCAUC:0.8537 Anomaly AUC:0.6879

[2023-08-28 16:43:52,102][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:44:18,921][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00040 | loss1:0.3742 loss2:1.0344 loss3:0.1921 | AUC:0.8222 Anomaly AUC:0.6531
[2023-08-28 16:44:39,098][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00040 | loss1:0.1569 loss2:0.8021 loss3:0.0378 | AUC:0.8262 Anomaly AUC:0.6752
[2023-08-28 16:44:57,662][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00040 | loss1:0.0718 loss2:0.6816 loss3:0.0160 | AUC:0.8303 Anomaly AUC:0.6816
[2023-08-28 16:45:20,002][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00040 | loss1:0.0430 loss2:0.5893 loss3:0.0093 | AUC:0.8357 Anomaly AUC:0.6705
[2023-08-28 16:45:43,062][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00040 | loss1:0.0219 loss2:0.4944 loss3:0.0049 | AUC:0.8243 Anomaly AUC:0.6857
[2023-08-28 16:46:06,128][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00040 | loss1:0.0107 loss2:0.3842 loss3:0.0028 | AUC:0.8219 Anomaly AUC:0.6859
[2023-08-28 16:46:28,816][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00040 | loss1:0.0157 loss2:0.3152 loss3:0.0031 | AUC:0.8366 Anomaly AUC:0.6968
[2023-08-28 16:46:51,446][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00040 | loss1:0.0181 loss2:0.2590 loss3:0.0041 | AUC:0.8268 Anomaly AUC:0.6616
[2023-08-28 16:47:14,796][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00040 | loss1:0.0207 loss2:0.2295 loss3:0.0040 | AUC:0.8304 Anomaly AUC:0.6640
[2023-08-28 16:47:37,240][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00040 | loss1:0.0068 loss2:0.1657 loss3:0.0018 | AUC:0.8061 Anomaly AUC:0.6470
[2023-08-28 16:47:59,602][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00040 | loss1:0.0060 loss2:0.1200 loss3:0.0016 | AUC:0.8331 Anomaly AUC:0.6727
[2023-08-28 16:48:20,579][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00040 | loss1:0.0132 loss2:0.1299 loss3:0.0026 | AUC:0.8239 Anomaly AUC:0.6325
[2023-08-28 16:48:39,462][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00040 | loss1:0.0103 loss2:0.0964 loss3:0.0020 | AUC:0.8094 Anomaly AUC:0.6326
[2023-08-28 16:48:59,090][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00040 | loss1:0.0127 loss2:0.0938 loss3:0.0027 | AUC:0.8322 Anomaly AUC:0.6366
[2023-08-28 16:49:19,586][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00040 | loss1:0.0088 loss2:0.0667 loss3:0.0019 | AUC:0.8408 Anomaly AUC:0.6559
[2023-08-28 16:49:40,962][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00040 | loss1:0.0061 loss2:0.0572 loss3:0.0012 | AUC:0.8277 Anomaly AUC:0.6236
[2023-08-28 16:50:01,138][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00040 | loss1:0.0107 loss2:0.0689 loss3:0.0023 | AUC:0.8309 Anomaly AUC:0.6386
[2023-08-28 16:50:19,947][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00040 | loss1:0.0038 loss2:0.0408 loss3:0.0009 | AUC:0.8442 Anomaly AUC:0.6709
[2023-08-28 16:50:40,459][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00040 | loss1:0.0219 loss2:0.0676 loss3:0.0041 | AUC:0.8488 Anomaly AUC:0.6782
[2023-08-28 16:51:02,787][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00040 | loss1:0.0139 loss2:0.0552 loss3:0.0026 | AUC:0.8228 Anomaly AUC:0.6360
[2023-08-28 16:51:02,788][main-autotune.py][line:120][INFO] Training completes in 7m 2s | best AUCAUC:0.8488 Anomaly AUC:0.6782

[2023-08-28 16:51:04,570][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:51:31,450][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00080 | loss1:0.3679 loss2:1.0501 loss3:0.2664 | AUC:0.8328 Anomaly AUC:0.6427
[2023-08-28 16:51:52,233][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00080 | loss1:0.1428 loss2:0.7935 loss3:0.0560 | AUC:0.8203 Anomaly AUC:0.6460
[2023-08-28 16:52:10,701][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00080 | loss1:0.0550 loss2:0.6622 loss3:0.0238 | AUC:0.8473 Anomaly AUC:0.6754
[2023-08-28 16:52:32,025][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00080 | loss1:0.0321 loss2:0.5497 loss3:0.0156 | AUC:0.8117 Anomaly AUC:0.6483
[2023-08-28 16:52:50,626][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00080 | loss1:0.0333 loss2:0.4450 loss3:0.0142 | AUC:0.8392 Anomaly AUC:0.6770
[2023-08-28 16:53:10,263][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00080 | loss1:0.0215 loss2:0.3579 loss3:0.0102 | AUC:0.8297 Anomaly AUC:0.6556
[2023-08-28 16:53:32,114][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00080 | loss1:0.0154 loss2:0.2621 loss3:0.0056 | AUC:0.8626 Anomaly AUC:0.7046
[2023-08-28 16:53:55,581][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00080 | loss1:0.0027 loss2:0.1455 loss3:0.0017 | AUC:0.8557 Anomaly AUC:0.6890
[2023-08-28 16:54:14,295][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00080 | loss1:0.0090 loss2:0.1076 loss3:0.0025 | AUC:0.8455 Anomaly AUC:0.6611
[2023-08-28 16:54:34,063][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00080 | loss1:0.0159 loss2:0.1073 loss3:0.0039 | AUC:0.8280 Anomaly AUC:0.6412
[2023-08-28 16:54:55,506][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00080 | loss1:0.0262 loss2:0.1101 loss3:0.0056 | AUC:0.8073 Anomaly AUC:0.6282
[2023-08-28 16:55:18,304][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00080 | loss1:0.0184 loss2:0.0709 loss3:0.0038 | AUC:0.8218 Anomaly AUC:0.6527
[2023-08-28 16:55:37,203][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00080 | loss1:0.0060 loss2:0.0405 loss3:0.0017 | AUC:0.8328 Anomaly AUC:0.6640
[2023-08-28 16:55:58,666][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00080 | loss1:0.0057 loss2:0.0240 loss3:0.0013 | AUC:0.8371 Anomaly AUC:0.6577
[2023-08-28 16:56:20,197][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00080 | loss1:0.0157 loss2:0.0501 loss3:0.0040 | AUC:0.8157 Anomaly AUC:0.6447
[2023-08-28 16:56:41,912][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00080 | loss1:0.0097 loss2:0.0331 loss3:0.0025 | AUC:0.8436 Anomaly AUC:0.6604
[2023-08-28 16:57:04,997][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00080 | loss1:0.0136 loss2:0.0374 loss3:0.0030 | AUC:0.8214 Anomaly AUC:0.6703
[2023-08-28 16:57:28,222][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00080 | loss1:0.0138 loss2:0.0373 loss3:0.0035 | AUC:0.8295 Anomaly AUC:0.6677
[2023-08-28 16:57:51,131][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00080 | loss1:0.0109 loss2:0.0251 loss3:0.0029 | AUC:0.8319 Anomaly AUC:0.6350
[2023-08-28 16:58:12,797][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00080 | loss1:0.0026 loss2:0.0099 loss3:0.0009 | AUC:0.8177 Anomaly AUC:0.6344
[2023-08-28 16:58:12,799][main-autotune.py][line:120][INFO] Training completes in 6m 60s | best AUCAUC:0.8626 Anomaly AUC:0.7046

[2023-08-28 16:58:14,840][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 16:58:41,693][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00080 | loss1:0.3659 loss2:1.0210 loss3:0.2592 | AUC:0.8191 Anomaly AUC:0.6545
[2023-08-28 16:59:02,255][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00080 | loss1:0.1340 loss2:0.7595 loss3:0.0508 | AUC:0.7901 Anomaly AUC:0.6774
[2023-08-28 16:59:20,817][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00080 | loss1:0.0628 loss2:0.6249 loss3:0.0249 | AUC:0.8088 Anomaly AUC:0.6539
[2023-08-28 16:59:41,937][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00080 | loss1:0.0308 loss2:0.4990 loss3:0.0153 | AUC:0.8249 Anomaly AUC:0.6817
[2023-08-28 17:00:00,706][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00080 | loss1:0.0365 loss2:0.4209 loss3:0.0148 | AUC:0.8101 Anomaly AUC:0.6655
[2023-08-28 17:00:20,166][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00080 | loss1:0.0093 loss2:0.2693 loss3:0.0067 | AUC:0.8462 Anomaly AUC:0.6989
[2023-08-28 17:00:43,412][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00080 | loss1:0.0213 loss2:0.2162 loss3:0.0060 | AUC:0.7907 Anomaly AUC:0.6652
[2023-08-28 17:01:02,180][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00080 | loss1:0.0156 loss2:0.1532 loss3:0.0037 | AUC:0.8092 Anomaly AUC:0.6831
[2023-08-28 17:01:21,835][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00080 | loss1:0.0092 loss2:0.0925 loss3:0.0021 | AUC:0.7924 Anomaly AUC:0.6690
[2023-08-28 17:01:44,590][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00080 | loss1:0.0162 loss2:0.0885 loss3:0.0037 | AUC:0.8359 Anomaly AUC:0.6890
[2023-08-28 17:02:03,324][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00080 | loss1:0.0131 loss2:0.0682 loss3:0.0032 | AUC:0.8151 Anomaly AUC:0.6371
[2023-08-28 17:02:22,955][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00080 | loss1:0.0186 loss2:0.0671 loss3:0.0037 | AUC:0.8459 Anomaly AUC:0.7042
[2023-08-28 17:02:44,028][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00080 | loss1:0.0149 loss2:0.0518 loss3:0.0034 | AUC:0.8243 Anomaly AUC:0.6530
[2023-08-28 17:03:05,243][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00080 | loss1:0.0192 loss2:0.0505 loss3:0.0042 | AUC:0.8027 Anomaly AUC:0.6695
[2023-08-28 17:03:25,703][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00080 | loss1:0.0022 loss2:0.0170 loss3:0.0009 | AUC:0.8314 Anomaly AUC:0.6745
[2023-08-28 17:03:44,514][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00080 | loss1:0.0007 loss2:0.0093 loss3:0.0004 | AUC:0.8270 Anomaly AUC:0.6748
[2023-08-28 17:04:05,710][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00080 | loss1:0.0001 loss2:0.0062 loss3:0.0003 | AUC:0.8269 Anomaly AUC:0.6741
[2023-08-28 17:04:26,249][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00080 | loss1:0.0001 loss2:0.0048 loss3:0.0003 | AUC:0.8273 Anomaly AUC:0.6726
[2023-08-28 17:04:48,719][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00080 | loss1:0.0000 loss2:0.0040 loss3:0.0003 | AUC:0.8265 Anomaly AUC:0.6699
[2023-08-28 17:05:09,497][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00080 | loss1:0.0000 loss2:0.0034 loss3:0.0003 | AUC:0.8255 Anomaly AUC:0.6694
[2023-08-28 17:05:09,498][main-autotune.py][line:120][INFO] Training completes in 6m 46s | best AUCAUC:0.8462 Anomaly AUC:0.6989

[2023-08-28 17:05:11,154][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:05:39,245][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00090 | loss1:0.3351 loss2:1.0286 loss3:0.3634 | AUC:0.8135 Anomaly AUC:0.6565
[2023-08-28 17:06:00,093][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00090 | loss1:0.0281 loss2:0.7172 loss3:0.2954 | AUC:0.8346 Anomaly AUC:0.6899
[2023-08-28 17:06:18,631][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00090 | loss1:0.0085 loss2:0.5321 loss3:0.1356 | AUC:0.8324 Anomaly AUC:0.6784
[2023-08-28 17:06:40,565][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00090 | loss1:0.0112 loss2:0.4001 loss3:0.0806 | AUC:0.8140 Anomaly AUC:0.6643
[2023-08-28 17:07:03,821][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00090 | loss1:0.0064 loss2:0.3172 loss3:0.0645 | AUC:0.8337 Anomaly AUC:0.6685
[2023-08-28 17:07:26,743][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00090 | loss1:0.0039 loss2:0.1780 loss3:0.0396 | AUC:0.8454 Anomaly AUC:0.6761
[2023-08-28 17:07:49,651][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00090 | loss1:0.0039 loss2:0.1518 loss3:0.0505 | AUC:0.8374 Anomaly AUC:0.6932
[2023-08-28 17:08:12,244][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00090 | loss1:0.0013 loss2:0.0771 loss3:0.0245 | AUC:0.8396 Anomaly AUC:0.6734
[2023-08-28 17:08:35,261][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00090 | loss1:0.0003 loss2:0.0412 loss3:0.0129 | AUC:0.8396 Anomaly AUC:0.6676
[2023-08-28 17:08:56,532][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00090 | loss1:0.0001 loss2:0.0258 loss3:0.0086 | AUC:0.8462 Anomaly AUC:0.6779
[2023-08-28 17:09:18,898][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00090 | loss1:0.0001 loss2:0.0181 loss3:0.0059 | AUC:0.8466 Anomaly AUC:0.6738
[2023-08-28 17:09:41,420][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00090 | loss1:0.3226 loss2:0.0170 loss3:0.0067 | AUC:0.7256 Anomaly AUC:0.5425
[2023-08-28 17:10:03,617][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00090 | loss1:1.5541 loss2:0.9664 loss3:0.1406 | AUC:0.7014 Anomaly AUC:0.5010
[2023-08-28 17:10:25,988][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00090 | loss1:0.1036 loss2:0.5692 loss3:0.0240 | AUC:0.7879 Anomaly AUC:0.6018
[2023-08-28 17:10:48,153][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00090 | loss1:0.0414 loss2:0.1958 loss3:0.0219 | AUC:0.8023 Anomaly AUC:0.6124
[2023-08-28 17:11:10,378][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00090 | loss1:0.0118 loss2:0.0946 loss3:0.0312 | AUC:0.8167 Anomaly AUC:0.6236
[2023-08-28 17:11:32,492][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00090 | loss1:0.0050 loss2:0.0433 loss3:0.0138 | AUC:0.8256 Anomaly AUC:0.6282
[2023-08-28 17:11:54,770][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00090 | loss1:0.0060 loss2:0.0456 loss3:0.0281 | AUC:0.8214 Anomaly AUC:0.6301
[2023-08-28 17:12:16,302][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00090 | loss1:0.0054 loss2:0.0392 loss3:0.0184 | AUC:0.8391 Anomaly AUC:0.6753
[2023-08-28 17:12:38,492][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00090 | loss1:0.0028 loss2:0.0219 loss3:0.0134 | AUC:0.8424 Anomaly AUC:0.6637
[2023-08-28 17:12:38,495][main-autotune.py][line:120][INFO] Training completes in 7m 19s | best AUCAUC:0.8466 Anomaly AUC:0.6738

[2023-08-28 17:22:16,168][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:22:42,993][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00060 | loss1:0.3636 loss2:1.1620 loss3:0.3408 | AUC:0.8078 Anomaly AUC:0.6043
[2023-08-28 17:23:04,384][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00060 | loss1:0.0591 loss2:0.8649 loss3:0.4238 | AUC:0.8337 Anomaly AUC:0.6900
[2023-08-28 17:23:28,238][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00060 | loss1:0.0023 loss2:0.6846 loss3:0.2228 | AUC:0.8390 Anomaly AUC:0.7025
[2023-08-28 17:23:46,822][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00060 | loss1:0.0035 loss2:0.5748 loss3:0.2349 | AUC:0.7883 Anomaly AUC:0.6809
[2023-08-28 17:24:06,284][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00060 | loss1:0.0020 loss2:0.4655 loss3:0.2267 | AUC:0.7800 Anomaly AUC:0.6796
[2023-08-28 17:24:28,539][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00060 | loss1:0.0018 loss2:0.3636 loss3:0.2050 | AUC:0.8137 Anomaly AUC:0.6789
[2023-08-28 17:24:49,722][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00060 | loss1:0.0023 loss2:0.2994 loss3:0.2476 | AUC:0.8140 Anomaly AUC:0.6687
[2023-08-28 17:25:08,433][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00060 | loss1:0.0017 loss2:0.2417 loss3:0.2052 | AUC:0.7799 Anomaly AUC:0.6883
[2023-08-28 17:25:30,200][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00060 | loss1:0.0022 loss2:0.2117 loss3:0.2263 | AUC:0.7935 Anomaly AUC:0.6815
[2023-08-28 17:25:52,123][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00060 | loss1:0.0014 loss2:0.1443 loss3:0.1811 | AUC:0.7692 Anomaly AUC:0.6619
[2023-08-28 17:26:13,936][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00060 | loss1:0.0008 loss2:0.1079 loss3:0.1614 | AUC:0.7436 Anomaly AUC:0.6542
[2023-08-28 17:26:37,939][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00060 | loss1:0.0007 loss2:0.0715 loss3:0.1426 | AUC:0.8014 Anomaly AUC:0.6957
[2023-08-28 17:26:59,852][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00060 | loss1:0.0004 loss2:0.0410 loss3:0.1009 | AUC:0.8246 Anomaly AUC:0.6909
[2023-08-28 17:27:21,733][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00060 | loss1:0.0005 loss2:0.0418 loss3:0.1129 | AUC:0.7983 Anomaly AUC:0.6796
[2023-08-28 17:27:43,227][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00060 | loss1:0.0006 loss2:0.0497 loss3:0.1468 | AUC:0.7715 Anomaly AUC:0.6616
[2023-08-28 17:28:04,736][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00060 | loss1:0.0004 loss2:0.0299 loss3:0.1453 | AUC:0.7699 Anomaly AUC:0.6277
[2023-08-28 17:28:26,408][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00060 | loss1:0.9109 loss2:1.0773 loss3:2.2757 | AUC:0.7475 Anomaly AUC:0.5776
[2023-08-28 17:28:49,756][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00060 | loss1:0.3029 loss2:0.9813 loss3:0.2247 | AUC:0.7918 Anomaly AUC:0.6470
[2023-08-28 17:29:10,280][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00060 | loss1:0.0149 loss2:0.7045 loss3:0.4286 | AUC:0.8099 Anomaly AUC:0.6929
[2023-08-28 17:29:31,883][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00060 | loss1:0.0020 loss2:0.5094 loss3:0.2342 | AUC:0.8299 Anomaly AUC:0.7122
[2023-08-28 17:29:31,885][main-autotune.py][line:120][INFO] Training completes in 7m 7s | best AUCAUC:0.8390 Anomaly AUC:0.7025

[2023-08-28 17:29:33,690][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:30:00,990][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3688 loss2:1.0534 loss3:0.3636 | AUC:0.8256 Anomaly AUC:0.6546
[2023-08-28 17:30:21,958][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1115 loss2:0.7955 loss3:0.2872 | AUC:0.8174 Anomaly AUC:0.6743
[2023-08-28 17:30:40,634][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0508 loss2:0.6866 loss3:0.1730 | AUC:0.8379 Anomaly AUC:0.6704
[2023-08-28 17:31:01,966][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0321 loss2:0.5933 loss3:0.0614 | AUC:0.8402 Anomaly AUC:0.6595
[2023-08-28 17:31:20,630][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0213 loss2:0.5049 loss3:0.0351 | AUC:0.8418 Anomaly AUC:0.6635
[2023-08-28 17:31:40,199][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0147 loss2:0.4250 loss3:0.0245 | AUC:0.8361 Anomaly AUC:0.6555
[2023-08-28 17:32:02,576][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0141 loss2:0.3568 loss3:0.0201 | AUC:0.8397 Anomaly AUC:0.6785
[2023-08-28 17:32:22,858][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0132 loss2:0.3054 loss3:0.0172 | AUC:0.8299 Anomaly AUC:0.6749
[2023-08-28 17:32:44,526][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0117 loss2:0.2503 loss3:0.0138 | AUC:0.8399 Anomaly AUC:0.6776
[2023-08-28 17:33:07,981][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0162 loss2:0.2424 loss3:0.0153 | AUC:0.8133 Anomaly AUC:0.6586
[2023-08-28 17:33:29,651][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0036 loss2:0.1768 loss3:0.0107 | AUC:0.8191 Anomaly AUC:0.6608
[2023-08-28 17:33:49,862][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0039 loss2:0.1417 loss3:0.0086 | AUC:0.8318 Anomaly AUC:0.6644
[2023-08-28 17:34:13,034][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0015 loss2:0.1171 loss3:0.0063 | AUC:0.8350 Anomaly AUC:0.6599
[2023-08-28 17:34:34,069][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0004 loss2:0.0961 loss3:0.0032 | AUC:0.8413 Anomaly AUC:0.6733
[2023-08-28 17:34:56,280][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0003 loss2:0.0804 loss3:0.0013 | AUC:0.8380 Anomaly AUC:0.6666
[2023-08-28 17:35:17,312][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0002 loss2:0.0689 loss3:0.0010 | AUC:0.8394 Anomaly AUC:0.6697
[2023-08-28 17:35:41,355][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0002 loss2:0.0601 loss3:0.0009 | AUC:0.8426 Anomaly AUC:0.6711
[2023-08-28 17:36:02,449][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0001 loss2:0.0527 loss3:0.0008 | AUC:0.8420 Anomaly AUC:0.6695
[2023-08-28 17:36:26,064][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0001 loss2:0.0458 loss3:0.0007 | AUC:0.8421 Anomaly AUC:0.6691
[2023-08-28 17:36:44,967][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0001 loss2:0.0405 loss3:0.0007 | AUC:0.8441 Anomaly AUC:0.6720
[2023-08-28 17:36:44,968][main-autotune.py][line:120][INFO] Training completes in 7m 2s | best AUCAUC:0.8441 Anomaly AUC:0.6720

[2023-08-28 17:36:46,648][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:37:17,922][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3681 loss2:1.3188 loss3:0.2484 | AUC:0.8094 Anomaly AUC:0.5975
[2023-08-28 17:37:36,249][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1374 loss2:1.1366 loss3:0.0699 | AUC:0.8325 Anomaly AUC:0.6079
[2023-08-28 17:37:56,620][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0538 loss2:1.0298 loss3:0.0302 | AUC:0.8303 Anomaly AUC:0.6186
[2023-08-28 17:38:15,246][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0410 loss2:0.9864 loss3:0.0190 | AUC:0.8453 Anomaly AUC:0.6378
[2023-08-28 17:38:34,824][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0531 loss2:0.9971 loss3:0.0234 | AUC:0.8452 Anomaly AUC:0.6445
[2023-08-28 17:38:57,748][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0115 loss2:0.9036 loss3:0.0077 | AUC:0.8394 Anomaly AUC:0.6437
[2023-08-28 17:39:16,531][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0107 loss2:0.8740 loss3:0.0064 | AUC:0.8437 Anomaly AUC:0.6513
[2023-08-28 17:39:36,286][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0067 loss2:0.8479 loss3:0.0043 | AUC:0.8458 Anomaly AUC:0.6590
[2023-08-28 17:39:57,462][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0201 loss2:0.8647 loss3:0.0082 | AUC:0.8470 Anomaly AUC:0.6580
[2023-08-28 17:40:19,119][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0155 loss2:0.8432 loss3:0.0061 | AUC:0.8365 Anomaly AUC:0.6354
[2023-08-28 17:40:40,431][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0138 loss2:0.8234 loss3:0.0051 | AUC:0.8545 Anomaly AUC:0.6801
[2023-08-28 17:41:01,785][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0044 loss2:0.7994 loss3:0.0025 | AUC:0.8636 Anomaly AUC:0.7000
[2023-08-28 17:41:22,740][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0047 loss2:0.7907 loss3:0.0026 | AUC:0.8537 Anomaly AUC:0.6809
[2023-08-28 17:41:44,110][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0094 loss2:0.7924 loss3:0.0037 | AUC:0.8453 Anomaly AUC:0.6747
[2023-08-28 17:42:05,303][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0118 loss2:0.7803 loss3:0.0037 | AUC:0.8528 Anomaly AUC:0.6959
[2023-08-28 17:42:26,270][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.0080 loss2:0.7672 loss3:0.0030 | AUC:0.8443 Anomaly AUC:0.6764
[2023-08-28 17:42:46,787][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0079 loss2:0.7571 loss3:0.0026 | AUC:0.8452 Anomaly AUC:0.6648
[2023-08-28 17:43:08,945][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0109 loss2:0.7485 loss3:0.0033 | AUC:0.8417 Anomaly AUC:0.6778
[2023-08-28 17:43:27,707][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0091 loss2:0.6229 loss3:0.0033 | AUC:0.8427 Anomaly AUC:0.6633
[2023-08-28 17:43:46,738][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0046 loss2:0.6953 loss3:0.0025 | AUC:0.8496 Anomaly AUC:0.6742
[2023-08-28 17:43:46,741][main-autotune.py][line:120][INFO] Training completes in 6m 52s | best AUCAUC:0.8636 Anomaly AUC:0.7000

[2023-08-28 17:43:48,814][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:44:15,912][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00070 | loss1:0.3853 loss2:1.0450 loss3:0.1813 | AUC:0.8276 Anomaly AUC:0.6541
[2023-08-28 17:44:37,943][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00070 | loss1:0.1667 loss2:0.8072 loss3:0.0406 | AUC:0.8191 Anomaly AUC:0.6738
[2023-08-28 17:45:01,879][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00070 | loss1:0.0848 loss2:0.6858 loss3:0.0208 | AUC:0.8421 Anomaly AUC:0.6820
[2023-08-28 17:45:25,009][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00070 | loss1:0.0385 loss2:0.5742 loss3:0.0101 | AUC:0.8435 Anomaly AUC:0.6634
[2023-08-28 17:45:43,670][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00070 | loss1:0.0272 loss2:0.4721 loss3:0.0072 | AUC:0.8212 Anomaly AUC:0.6706
[2023-08-28 17:46:04,839][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00070 | loss1:0.0364 loss2:0.3902 loss3:0.0087 | AUC:0.8594 Anomaly AUC:0.6935
[2023-08-28 17:46:23,633][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00070 | loss1:0.0171 loss2:0.2767 loss3:0.0041 | AUC:0.8540 Anomaly AUC:0.6774
[2023-08-28 17:46:43,297][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00070 | loss1:0.0104 loss2:0.1862 loss3:0.0030 | AUC:0.8619 Anomaly AUC:0.6963
[2023-08-28 17:47:05,291][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00070 | loss1:0.0199 loss2:0.1498 loss3:0.0047 | AUC:0.8559 Anomaly AUC:0.6866
[2023-08-28 17:47:28,851][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00070 | loss1:0.0066 loss2:0.0934 loss3:0.0023 | AUC:0.8502 Anomaly AUC:0.6702
[2023-08-28 17:47:47,684][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00070 | loss1:0.0036 loss2:0.0482 loss3:0.0012 | AUC:0.8489 Anomaly AUC:0.6736
[2023-08-28 17:48:07,479][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00070 | loss1:0.0168 loss2:0.0756 loss3:0.0040 | AUC:0.8550 Anomaly AUC:0.6679
[2023-08-28 17:48:26,635][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00070 | loss1:0.0236 loss2:0.0954 loss3:0.0056 | AUC:0.8376 Anomaly AUC:0.6692
[2023-08-28 17:48:46,225][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00070 | loss1:0.0154 loss2:0.0585 loss3:0.0036 | AUC:0.8440 Anomaly AUC:0.6629
[2023-08-28 17:49:05,530][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00070 | loss1:0.0123 loss2:0.0407 loss3:0.0026 | AUC:0.8318 Anomaly AUC:0.6486
[2023-08-28 17:49:25,308][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00070 | loss1:0.0067 loss2:0.0266 loss3:0.0016 | AUC:0.8383 Anomaly AUC:0.6687
[2023-08-28 17:49:48,742][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00070 | loss1:0.0056 loss2:0.0203 loss3:0.0015 | AUC:0.8466 Anomaly AUC:0.6636
[2023-08-28 17:50:10,390][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00070 | loss1:0.0079 loss2:0.0224 loss3:0.0022 | AUC:0.8399 Anomaly AUC:0.6710
[2023-08-28 17:50:32,098][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00070 | loss1:0.0101 loss2:0.0331 loss3:0.0026 | AUC:0.8608 Anomaly AUC:0.6968
[2023-08-28 17:50:55,895][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00070 | loss1:0.0061 loss2:0.0239 loss3:0.0017 | AUC:0.8420 Anomaly AUC:0.6703
[2023-08-28 17:50:55,897][main-autotune.py][line:120][INFO] Training completes in 6m 59s | best AUCAUC:0.8619 Anomaly AUC:0.6963

[2023-08-28 17:50:57,920][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:51:24,689][main-autotune.py][line:110][INFO] [Epoch:1/20]: lr:0.00050 | loss1:0.3619 loss2:1.0335 loss3:0.3455 | AUC:0.8293 Anomaly AUC:0.6677
[2023-08-28 17:51:44,671][main-autotune.py][line:110][INFO] [Epoch:2/20]: lr:0.00050 | loss1:0.1145 loss2:0.7679 loss3:0.1972 | AUC:0.8351 Anomaly AUC:0.6712
[2023-08-28 17:52:03,133][main-autotune.py][line:110][INFO] [Epoch:3/20]: lr:0.00050 | loss1:0.0471 loss2:0.6326 loss3:0.0563 | AUC:0.8533 Anomaly AUC:0.6828
[2023-08-28 17:52:24,570][main-autotune.py][line:110][INFO] [Epoch:4/20]: lr:0.00050 | loss1:0.0283 loss2:0.5194 loss3:0.0296 | AUC:0.8158 Anomaly AUC:0.6593
[2023-08-28 17:52:45,056][main-autotune.py][line:110][INFO] [Epoch:5/20]: lr:0.00050 | loss1:0.0268 loss2:0.4227 loss3:0.0237 | AUC:0.8541 Anomaly AUC:0.6828
[2023-08-28 17:53:03,628][main-autotune.py][line:110][INFO] [Epoch:6/20]: lr:0.00050 | loss1:0.0156 loss2:0.3399 loss3:0.0189 | AUC:0.8534 Anomaly AUC:0.6755
[2023-08-28 17:53:24,300][main-autotune.py][line:110][INFO] [Epoch:7/20]: lr:0.00050 | loss1:0.0215 loss2:0.2729 loss3:0.0169 | AUC:0.8395 Anomaly AUC:0.6859
[2023-08-28 17:53:45,145][main-autotune.py][line:110][INFO] [Epoch:8/20]: lr:0.00050 | loss1:0.0074 loss2:0.2030 loss3:0.0130 | AUC:0.8362 Anomaly AUC:0.6546
[2023-08-28 17:54:07,900][main-autotune.py][line:110][INFO] [Epoch:9/20]: lr:0.00050 | loss1:0.0044 loss2:0.1438 loss3:0.0102 | AUC:0.8431 Anomaly AUC:0.6658
[2023-08-28 17:54:29,770][main-autotune.py][line:110][INFO] [Epoch:10/20]: lr:0.00050 | loss1:0.0006 loss2:0.0984 loss3:0.0071 | AUC:0.8466 Anomaly AUC:0.6669
[2023-08-28 17:54:50,622][main-autotune.py][line:110][INFO] [Epoch:11/20]: lr:0.00050 | loss1:0.0002 loss2:0.0696 loss3:0.0043 | AUC:0.8485 Anomaly AUC:0.6687
[2023-08-28 17:55:09,416][main-autotune.py][line:110][INFO] [Epoch:12/20]: lr:0.00050 | loss1:0.0002 loss2:0.0530 loss3:0.0011 | AUC:0.8479 Anomaly AUC:0.6661
[2023-08-28 17:55:28,867][main-autotune.py][line:110][INFO] [Epoch:13/20]: lr:0.00050 | loss1:0.0001 loss2:0.0414 loss3:0.0007 | AUC:0.8486 Anomaly AUC:0.6693
[2023-08-28 17:55:49,464][main-autotune.py][line:110][INFO] [Epoch:14/20]: lr:0.00050 | loss1:0.0001 loss2:0.0338 loss3:0.0006 | AUC:0.8489 Anomaly AUC:0.6708
[2023-08-28 17:56:08,228][main-autotune.py][line:110][INFO] [Epoch:15/20]: lr:0.00050 | loss1:0.0002 loss2:0.0277 loss3:0.0006 | AUC:0.8519 Anomaly AUC:0.6758
[2023-08-28 17:56:27,549][main-autotune.py][line:110][INFO] [Epoch:16/20]: lr:0.00050 | loss1:0.1842 loss2:0.3816 loss3:0.0338 | AUC:0.8454 Anomaly AUC:0.7093
[2023-08-28 17:56:49,436][main-autotune.py][line:110][INFO] [Epoch:17/20]: lr:0.00050 | loss1:0.0117 loss2:0.1144 loss3:0.0070 | AUC:0.8418 Anomaly AUC:0.7026
[2023-08-28 17:57:08,209][main-autotune.py][line:110][INFO] [Epoch:18/20]: lr:0.00050 | loss1:0.0154 loss2:0.0717 loss3:0.0043 | AUC:0.8498 Anomaly AUC:0.6997
[2023-08-28 17:57:27,509][main-autotune.py][line:110][INFO] [Epoch:19/20]: lr:0.00050 | loss1:0.0086 loss2:0.0490 loss3:0.0028 | AUC:0.8454 Anomaly AUC:0.7023
[2023-08-28 17:57:49,560][main-autotune.py][line:110][INFO] [Epoch:20/20]: lr:0.00050 | loss1:0.0034 loss2:0.0306 loss3:0.0015 | AUC:0.8447 Anomaly AUC:0.6976
[2023-08-28 17:57:49,562][main-autotune.py][line:120][INFO] Training completes in 6m 43s | best AUCAUC:0.8541 Anomaly AUC:0.6828

[2023-08-28 17:57:51,672][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:58:03,855][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 20, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 17:58:03,977][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 17:58:03,978][main.py][line:159][INFO] Training Mode
[2023-08-28 17:58:03,978][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 17:58:03,978][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 17:58:12,054][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 17:58:32,798][main.py][line:105][INFO] [Epoch:1/20]: lr:0.00030 | loss1:0.3789 loss2:1.1780 loss3:0.2148 | AUC:0.8165 Anomaly AUC:0.6045
[2023-08-28 17:58:55,958][main.py][line:105][INFO] [Epoch:2/20]: lr:0.00030 | loss1:0.1669 loss2:0.9576 loss3:0.0586 | AUC:0.8339 Anomaly AUC:0.6661
[2023-08-28 17:59:14,465][main.py][line:105][INFO] [Epoch:3/20]: lr:0.00030 | loss1:0.0713 loss2:0.8343 loss3:0.0206 | AUC:0.8324 Anomaly AUC:0.6610
[2023-08-28 17:59:34,008][main.py][line:105][INFO] [Epoch:4/20]: lr:0.00030 | loss1:0.0418 loss2:0.7795 loss3:0.0112 | AUC:0.8560 Anomaly AUC:0.6929
[2023-08-28 17:59:56,234][main.py][line:105][INFO] [Epoch:5/20]: lr:0.00030 | loss1:0.0314 loss2:0.7412 loss3:0.0083 | AUC:0.8533 Anomaly AUC:0.6833
[2023-08-28 18:00:16,618][main.py][line:105][INFO] [Epoch:6/20]: lr:0.00030 | loss1:0.0245 loss2:0.7049 loss3:0.0064 | AUC:0.8407 Anomaly AUC:0.6765
[2023-08-28 18:00:38,275][main.py][line:105][INFO] [Epoch:7/20]: lr:0.00030 | loss1:0.0189 loss2:0.6704 loss3:0.0053 | AUC:0.8496 Anomaly AUC:0.6708
[2023-08-28 18:01:01,544][main.py][line:105][INFO] [Epoch:8/20]: lr:0.00030 | loss1:0.0191 loss2:0.6380 loss3:0.0053 | AUC:0.8328 Anomaly AUC:0.6459
[2023-08-28 18:01:20,327][main.py][line:105][INFO] [Epoch:9/20]: lr:0.00030 | loss1:0.0102 loss2:0.5792 loss3:0.0029 | AUC:0.8521 Anomaly AUC:0.6782
[2023-08-28 18:01:39,866][main.py][line:105][INFO] [Epoch:10/20]: lr:0.00030 | loss1:0.0160 loss2:0.5448 loss3:0.0039 | AUC:0.8369 Anomaly AUC:0.6263
[2023-08-28 18:02:02,055][main.py][line:105][INFO] [Epoch:11/20]: lr:0.00030 | loss1:0.0157 loss2:0.5047 loss3:0.0045 | AUC:0.8490 Anomaly AUC:0.6597
[2023-08-28 18:02:23,501][main.py][line:105][INFO] [Epoch:12/20]: lr:0.00030 | loss1:0.0111 loss2:0.4436 loss3:0.0033 | AUC:0.8338 Anomaly AUC:0.6497
[2023-08-28 18:02:44,513][main.py][line:105][INFO] [Epoch:13/20]: lr:0.00030 | loss1:0.0133 loss2:0.4141 loss3:0.0041 | AUC:0.8193 Anomaly AUC:0.6381
[2023-08-28 18:03:05,782][main.py][line:105][INFO] [Epoch:14/20]: lr:0.00030 | loss1:0.0062 loss2:0.3371 loss3:0.0023 | AUC:0.8521 Anomaly AUC:0.6741
[2023-08-28 18:03:27,010][main.py][line:105][INFO] [Epoch:15/20]: lr:0.00030 | loss1:0.0235 loss2:0.3647 loss3:0.0083 | AUC:0.8234 Anomaly AUC:0.6182
[2023-08-28 18:03:48,995][main.py][line:105][INFO] [Epoch:16/20]: lr:0.00030 | loss1:0.0132 loss2:0.3108 loss3:0.0039 | AUC:0.8453 Anomaly AUC:0.6535
[2023-08-28 18:04:10,571][main.py][line:105][INFO] [Epoch:17/20]: lr:0.00030 | loss1:0.0077 loss2:0.2537 loss3:0.0027 | AUC:0.8427 Anomaly AUC:0.6527
[2023-08-28 18:04:30,556][main.py][line:105][INFO] [Epoch:18/20]: lr:0.00030 | loss1:0.0007 loss2:0.1745 loss3:0.0009 | AUC:0.8519 Anomaly AUC:0.6686
[2023-08-28 18:04:49,472][main.py][line:105][INFO] [Epoch:19/20]: lr:0.00030 | loss1:0.0003 loss2:0.1325 loss3:0.0010 | AUC:0.8464 Anomaly AUC:0.6599
[2023-08-28 18:05:09,168][main.py][line:105][INFO] [Epoch:20/20]: lr:0.00030 | loss1:0.0002 loss2:0.1005 loss3:0.0009 | AUC:0.8452 Anomaly AUC:0.6562
[2023-08-28 18:05:09,190][main.py][line:113][INFO] Training completes in 6m 57s | best AUCAUC:0.8560 Anomaly AUC:0.6929

[2023-08-28 18:05:54,871][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 18:05:57,203][main-autotune.py][line:128][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 18:05:59,513][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 18:05:59,644][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 18:05:59,645][main.py][line:159][INFO] Training Mode
[2023-08-28 18:05:59,645][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 18:05:59,645][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 5e-05
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0008
    lr: 5e-05
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 18:06:07,836][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 18:06:26,272][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00006 | loss1:0.5015 loss2:1.3441 loss3:0.3848 | AUC:0.8069 Anomaly AUC:0.6039
[2023-08-28 18:06:46,454][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00007 | loss1:0.2288 loss2:1.1303 loss3:0.3428 | AUC:0.7990 Anomaly AUC:0.6456
[2023-08-28 18:07:05,042][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00009 | loss1:0.1038 loss2:0.9735 loss3:0.2400 | AUC:0.8265 Anomaly AUC:0.6590
[2023-08-28 18:07:26,199][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.0603 loss2:0.9046 loss3:0.1503 | AUC:0.8349 Anomaly AUC:0.6570
[2023-08-28 18:07:44,779][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00011 | loss1:0.0408 loss2:0.8633 loss3:0.0753 | AUC:0.8459 Anomaly AUC:0.6639
[2023-08-28 18:08:05,954][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00012 | loss1:0.0511 loss2:0.8511 loss3:0.0399 | AUC:0.8466 Anomaly AUC:0.6879
[2023-08-28 18:08:24,636][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00014 | loss1:0.0244 loss2:0.8247 loss3:0.0224 | AUC:0.8339 Anomaly AUC:0.6884
[2023-08-28 18:08:44,382][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00015 | loss1:0.0277 loss2:0.8028 loss3:0.0181 | AUC:0.8242 Anomaly AUC:0.6805
[2023-08-28 18:09:04,356][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00016 | loss1:0.0198 loss2:0.7701 loss3:0.0120 | AUC:0.8396 Anomaly AUC:0.6598
[2023-08-28 18:09:25,718][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00017 | loss1:0.0167 loss2:0.7405 loss3:0.0086 | AUC:0.8378 Anomaly AUC:0.6862
[2023-08-28 18:09:49,042][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00019 | loss1:0.0131 loss2:0.7003 loss3:0.0068 | AUC:0.8432 Anomaly AUC:0.6846
[2023-08-28 18:10:10,314][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00020 | loss1:0.0303 loss2:0.6895 loss3:0.0113 | AUC:0.8272 Anomaly AUC:0.6499
[2023-08-28 18:10:31,179][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00021 | loss1:0.0202 loss2:0.6568 loss3:0.0084 | AUC:0.8435 Anomaly AUC:0.6837
[2023-08-28 18:10:53,143][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00022 | loss1:0.0167 loss2:0.6167 loss3:0.0076 | AUC:0.8399 Anomaly AUC:0.6786
[2023-08-28 18:11:13,403][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00024 | loss1:0.0223 loss2:0.5817 loss3:0.0093 | AUC:0.8072 Anomaly AUC:0.6507
[2023-08-28 18:11:32,935][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00025 | loss1:0.0146 loss2:0.5423 loss3:0.0064 | AUC:0.8264 Anomaly AUC:0.6854
[2023-08-28 18:11:54,410][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00026 | loss1:0.0156 loss2:0.4979 loss3:0.0057 | AUC:0.8280 Anomaly AUC:0.6696
[2023-08-28 18:12:15,428][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00027 | loss1:0.0084 loss2:0.4531 loss3:0.0046 | AUC:0.8370 Anomaly AUC:0.6642
[2023-08-28 18:12:36,751][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00029 | loss1:0.0271 loss2:0.4542 loss3:0.0106 | AUC:0.8286 Anomaly AUC:0.6606
[2023-08-28 18:12:57,921][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.0120 loss2:0.4129 loss3:0.0073 | AUC:0.8120 Anomaly AUC:0.6859
[2023-08-28 18:13:20,503][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.0165 loss2:0.3930 loss3:0.0070 | AUC:0.8340 Anomaly AUC:0.6632
[2023-08-28 18:13:39,350][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.0268 loss2:0.3820 loss3:0.0105 | AUC:0.8363 Anomaly AUC:0.6663
[2023-08-28 18:13:58,731][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.0155 loss2:0.3253 loss3:0.0057 | AUC:0.8391 Anomaly AUC:0.6712
[2023-08-28 18:14:19,536][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.0125 loss2:0.2950 loss3:0.0048 | AUC:0.8330 Anomaly AUC:0.6739
[2023-08-28 18:14:40,275][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00030 | loss1:0.0118 loss2:0.2486 loss3:0.0055 | AUC:0.8456 Anomaly AUC:0.6792
[2023-08-28 18:15:01,427][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.0120 loss2:0.2081 loss3:0.0039 | AUC:0.8393 Anomaly AUC:0.6505
[2023-08-28 18:15:22,365][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00030 | loss1:0.0256 loss2:0.2752 loss3:0.0088 | AUC:0.8268 Anomaly AUC:0.6625
[2023-08-28 18:15:42,636][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00030 | loss1:0.0186 loss2:0.2287 loss3:0.0055 | AUC:0.8292 Anomaly AUC:0.6574
[2023-08-28 18:16:05,125][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00030 | loss1:0.0084 loss2:0.1657 loss3:0.0030 | AUC:0.8342 Anomaly AUC:0.6562
[2023-08-28 18:16:25,445][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00030 | loss1:0.0095 loss2:0.1353 loss3:0.0032 | AUC:0.8410 Anomaly AUC:0.6704
[2023-08-28 18:16:46,306][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00030 | loss1:0.0133 loss2:0.1474 loss3:0.0043 | AUC:0.8420 Anomaly AUC:0.6786
[2023-08-28 18:17:07,713][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00030 | loss1:0.0074 loss2:0.1128 loss3:0.0024 | AUC:0.8267 Anomaly AUC:0.6449
[2023-08-28 18:17:28,692][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00030 | loss1:0.0030 loss2:0.0801 loss3:0.0015 | AUC:0.8219 Anomaly AUC:0.6440
[2023-08-28 18:17:51,015][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00030 | loss1:0.0189 loss2:0.1353 loss3:0.0058 | AUC:0.8199 Anomaly AUC:0.6339
[2023-08-28 18:18:11,991][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00030 | loss1:0.0142 loss2:0.1333 loss3:0.0039 | AUC:0.8361 Anomaly AUC:0.6502
[2023-08-28 18:18:33,181][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00030 | loss1:0.0023 loss2:0.0599 loss3:0.0012 | AUC:0.8359 Anomaly AUC:0.6587
[2023-08-28 18:18:54,322][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00030 | loss1:0.0004 loss2:0.0438 loss3:0.0008 | AUC:0.8360 Anomaly AUC:0.6633
[2023-08-28 18:19:14,650][main.py][line:105][INFO] [Epoch:38/50]: lr:0.00030 | loss1:0.0001 loss2:0.0331 loss3:0.0007 | AUC:0.8329 Anomaly AUC:0.6656
[2023-08-28 18:19:33,602][main.py][line:105][INFO] [Epoch:39/50]: lr:0.00030 | loss1:0.0001 loss2:0.0273 loss3:0.0007 | AUC:0.8310 Anomaly AUC:0.6670
[2023-08-28 18:19:54,305][main.py][line:105][INFO] [Epoch:40/50]: lr:0.00030 | loss1:0.0001 loss2:0.0238 loss3:0.0007 | AUC:0.8307 Anomaly AUC:0.6642
[2023-08-28 18:20:16,339][main.py][line:105][INFO] [Epoch:41/50]: lr:0.00029 | loss1:0.0001 loss2:0.0205 loss3:0.0007 | AUC:0.8297 Anomaly AUC:0.6693
[2023-08-28 18:20:38,805][main.py][line:105][INFO] [Epoch:42/50]: lr:0.00029 | loss1:0.0001 loss2:0.0184 loss3:0.0007 | AUC:0.8303 Anomaly AUC:0.6693
[2023-08-28 18:21:01,075][main.py][line:105][INFO] [Epoch:43/50]: lr:0.00029 | loss1:0.0001 loss2:0.0162 loss3:0.0008 | AUC:0.8270 Anomaly AUC:0.6682
[2023-08-28 18:21:23,349][main.py][line:105][INFO] [Epoch:44/50]: lr:0.00029 | loss1:0.0001 loss2:0.0142 loss3:0.0008 | AUC:0.8257 Anomaly AUC:0.6665
[2023-08-28 18:21:44,469][main.py][line:105][INFO] [Epoch:45/50]: lr:0.00029 | loss1:0.0000 loss2:0.0128 loss3:0.0008 | AUC:0.8256 Anomaly AUC:0.6678
[2023-08-28 18:22:05,466][main.py][line:105][INFO] [Epoch:46/50]: lr:0.00029 | loss1:0.0000 loss2:0.0122 loss3:0.0008 | AUC:0.8246 Anomaly AUC:0.6673
[2023-08-28 18:22:25,906][main.py][line:105][INFO] [Epoch:47/50]: lr:0.00029 | loss1:0.0000 loss2:0.0108 loss3:0.0008 | AUC:0.8202 Anomaly AUC:0.6660
[2023-08-28 18:22:44,841][main.py][line:105][INFO] [Epoch:48/50]: lr:0.00029 | loss1:0.0000 loss2:0.0114 loss3:0.0009 | AUC:0.8232 Anomaly AUC:0.6675
[2023-08-28 18:23:05,680][main.py][line:105][INFO] [Epoch:49/50]: lr:0.00029 | loss1:0.0000 loss2:0.0092 loss3:0.0008 | AUC:0.8157 Anomaly AUC:0.6623
[2023-08-28 18:23:27,353][main.py][line:105][INFO] [Epoch:50/50]: lr:0.00029 | loss1:0.1169 loss2:0.5183 loss3:0.0704 | AUC:0.8410 Anomaly AUC:0.6517
[2023-08-28 18:23:27,375][main.py][line:113][INFO] Training completes in 17m 20s | best AUCAUC:0.8466 Anomaly AUC:0.6879

[2023-08-28 18:23:49,281][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 18:23:49,410][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 18:23:49,410][main.py][line:159][INFO] Training Mode
[2023-08-28 18:23:49,410][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 18:23:49,410][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0008
    lr: 0.0008
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 18:23:57,473][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 18:24:15,849][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.3789 loss2:1.1780 loss3:0.2148 | AUC:0.8165 Anomaly AUC:0.6045
[2023-08-28 18:24:36,492][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.1663 loss2:0.9576 loss3:0.0588 | AUC:0.8413 Anomaly AUC:0.6545
[2023-08-28 18:24:54,996][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.0772 loss2:0.8370 loss3:0.0229 | AUC:0.8472 Anomaly AUC:0.6841
[2023-08-28 18:25:16,666][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.0424 loss2:0.7764 loss3:0.0119 | AUC:0.8413 Anomaly AUC:0.6841
[2023-08-28 18:25:36,991][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00029 | loss1:0.0305 loss2:0.7395 loss3:0.0085 | AUC:0.8438 Anomaly AUC:0.6653
[2023-08-28 18:25:55,778][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00029 | loss1:0.0244 loss2:0.7015 loss3:0.0066 | AUC:0.8521 Anomaly AUC:0.6832
[2023-08-28 18:26:17,045][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00029 | loss1:0.0165 loss2:0.6629 loss3:0.0047 | AUC:0.8071 Anomaly AUC:0.6282
[2023-08-28 18:26:39,428][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00029 | loss1:0.0169 loss2:0.6294 loss3:0.0049 | AUC:0.8299 Anomaly AUC:0.6476
[2023-08-28 18:27:01,452][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00028 | loss1:0.0116 loss2:0.5827 loss3:0.0034 | AUC:0.8415 Anomaly AUC:0.6615
[2023-08-28 18:27:24,464][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00028 | loss1:0.0102 loss2:0.5275 loss3:0.0030 | AUC:0.8589 Anomaly AUC:0.6789
[2023-08-28 18:27:43,197][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00028 | loss1:0.0242 loss2:0.5207 loss3:0.0060 | AUC:0.8248 Anomaly AUC:0.6328
[2023-08-28 18:28:05,044][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00027 | loss1:0.0091 loss2:0.4512 loss3:0.0026 | AUC:0.8368 Anomaly AUC:0.6518
[2023-08-28 18:28:28,037][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00027 | loss1:0.0052 loss2:0.3910 loss3:0.0019 | AUC:0.8141 Anomaly AUC:0.6293
[2023-08-28 18:28:51,313][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00026 | loss1:0.0138 loss2:0.3741 loss3:0.0039 | AUC:0.8142 Anomaly AUC:0.6376
[2023-08-28 18:29:14,430][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00026 | loss1:0.0033 loss2:0.2914 loss3:0.0016 | AUC:0.8235 Anomaly AUC:0.6292
[2023-08-28 18:29:36,080][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00025 | loss1:0.0090 loss2:0.2723 loss3:0.0030 | AUC:0.8290 Anomaly AUC:0.6179
[2023-08-28 18:29:58,973][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00024 | loss1:0.0064 loss2:0.2341 loss3:0.0024 | AUC:0.8325 Anomaly AUC:0.6476
[2023-08-28 18:30:22,163][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00024 | loss1:0.0046 loss2:0.1956 loss3:0.0018 | AUC:0.8392 Anomaly AUC:0.6492
[2023-08-28 18:30:45,107][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00023 | loss1:0.0156 loss2:0.2247 loss3:0.0046 | AUC:0.8402 Anomaly AUC:0.6430
[2023-08-28 18:31:06,452][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00022 | loss1:0.0071 loss2:0.1790 loss3:0.0025 | AUC:0.8220 Anomaly AUC:0.6281
[2023-08-28 18:31:29,413][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00022 | loss1:0.0037 loss2:0.1382 loss3:0.0014 | AUC:0.8214 Anomaly AUC:0.6294
[2023-08-28 18:31:52,257][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00021 | loss1:0.0005 loss2:0.1046 loss3:0.0009 | AUC:0.8290 Anomaly AUC:0.6420
[2023-08-28 18:32:14,591][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00020 | loss1:0.0049 loss2:0.1057 loss3:0.0017 | AUC:0.8248 Anomaly AUC:0.6177
[2023-08-28 18:32:37,509][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00020 | loss1:0.0036 loss2:0.0949 loss3:0.0017 | AUC:0.8302 Anomaly AUC:0.6409
[2023-08-28 18:32:58,803][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00019 | loss1:0.0027 loss2:0.0797 loss3:0.0014 | AUC:0.8144 Anomaly AUC:0.6248
[2023-08-28 18:33:20,166][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00018 | loss1:0.0039 loss2:0.0760 loss3:0.0019 | AUC:0.8123 Anomaly AUC:0.6383
[2023-08-28 18:33:41,031][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00017 | loss1:0.0005 loss2:0.0591 loss3:0.0010 | AUC:0.8024 Anomaly AUC:0.6386
[2023-08-28 18:33:59,955][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00017 | loss1:0.0001 loss2:0.0481 loss3:0.0008 | AUC:0.7990 Anomaly AUC:0.6339
[2023-08-28 18:34:20,950][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00016 | loss1:0.0001 loss2:0.0431 loss3:0.0008 | AUC:0.7974 Anomaly AUC:0.6337
[2023-08-28 18:34:43,158][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00015 | loss1:0.0001 loss2:0.0385 loss3:0.0008 | AUC:0.7965 Anomaly AUC:0.6299
[2023-08-28 18:35:05,451][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00014 | loss1:0.0001 loss2:0.0351 loss3:0.0008 | AUC:0.7952 Anomaly AUC:0.6293
[2023-08-28 18:35:27,966][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00013 | loss1:0.0001 loss2:0.0320 loss3:0.0008 | AUC:0.7945 Anomaly AUC:0.6276
[2023-08-28 18:35:47,532][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 18:35:47,656][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 18:35:47,656][main.py][line:159][INFO] Training Mode
[2023-08-28 18:35:47,657][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 18:35:47,657][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 18:35:55,933][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 18:36:14,322][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.3789 loss2:1.1780 loss3:0.2148 | AUC:0.8165 Anomaly AUC:0.6045
[2023-08-28 18:36:36,783][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.1669 loss2:0.9576 loss3:0.0586 | AUC:0.8339 Anomaly AUC:0.6661
[2023-08-28 18:37:00,459][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.0713 loss2:0.8343 loss3:0.0206 | AUC:0.8324 Anomaly AUC:0.6610
[2023-08-28 18:37:23,028][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.0418 loss2:0.7795 loss3:0.0112 | AUC:0.8560 Anomaly AUC:0.6929
[2023-08-28 18:37:45,330][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.0314 loss2:0.7412 loss3:0.0083 | AUC:0.8533 Anomaly AUC:0.6833
[2023-08-28 18:38:07,191][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.0245 loss2:0.7049 loss3:0.0064 | AUC:0.8407 Anomaly AUC:0.6765
[2023-08-28 18:38:29,269][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.0189 loss2:0.6704 loss3:0.0053 | AUC:0.8496 Anomaly AUC:0.6708
[2023-08-28 18:38:50,901][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.0191 loss2:0.6380 loss3:0.0053 | AUC:0.8328 Anomaly AUC:0.6459
[2023-08-28 18:39:12,713][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.0102 loss2:0.5792 loss3:0.0029 | AUC:0.8521 Anomaly AUC:0.6782
[2023-08-28 18:39:34,558][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0160 loss2:0.5448 loss3:0.0039 | AUC:0.8369 Anomaly AUC:0.6263
[2023-08-28 18:39:56,393][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.0157 loss2:0.5047 loss3:0.0045 | AUC:0.8490 Anomaly AUC:0.6597
[2023-08-28 18:40:19,987][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.0111 loss2:0.4436 loss3:0.0033 | AUC:0.8338 Anomaly AUC:0.6497
[2023-08-28 18:40:43,804][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.0133 loss2:0.4141 loss3:0.0041 | AUC:0.8193 Anomaly AUC:0.6381
[2023-08-28 18:41:07,196][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.0062 loss2:0.3371 loss3:0.0023 | AUC:0.8521 Anomaly AUC:0.6741
[2023-08-28 18:41:28,655][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.0235 loss2:0.3647 loss3:0.0083 | AUC:0.8234 Anomaly AUC:0.6182
[2023-08-28 18:41:52,274][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.0132 loss2:0.3108 loss3:0.0039 | AUC:0.8453 Anomaly AUC:0.6535
[2023-08-28 18:42:13,675][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.0077 loss2:0.2537 loss3:0.0027 | AUC:0.8427 Anomaly AUC:0.6527
[2023-08-28 18:42:35,949][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.0007 loss2:0.1745 loss3:0.0009 | AUC:0.8519 Anomaly AUC:0.6686
[2023-08-28 18:42:57,062][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.0003 loss2:0.1325 loss3:0.0010 | AUC:0.8464 Anomaly AUC:0.6599
[2023-08-28 18:43:18,960][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.0002 loss2:0.1005 loss3:0.0009 | AUC:0.8452 Anomaly AUC:0.6562
[2023-08-28 18:43:40,306][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.0002 loss2:0.0794 loss3:0.0010 | AUC:0.8473 Anomaly AUC:0.6544
[2023-08-28 18:44:01,656][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.0001 loss2:0.0652 loss3:0.0010 | AUC:0.8479 Anomaly AUC:0.6547
[2023-08-28 18:44:23,186][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.0001 loss2:0.0552 loss3:0.0010 | AUC:0.8452 Anomaly AUC:0.6508
[2023-08-28 18:44:46,254][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.0001 loss2:0.0447 loss3:0.0010 | AUC:0.8443 Anomaly AUC:0.6482
[2023-08-28 18:45:09,215][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00030 | loss1:0.0001 loss2:0.0376 loss3:0.0009 | AUC:0.8430 Anomaly AUC:0.6475
[2023-08-28 18:45:32,109][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.0001 loss2:0.0323 loss3:0.0009 | AUC:0.8416 Anomaly AUC:0.6408
[2023-08-28 18:45:54,889][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00030 | loss1:0.0001 loss2:0.0290 loss3:0.0009 | AUC:0.8372 Anomaly AUC:0.6436
[2023-08-28 18:46:15,579][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00030 | loss1:0.0000 loss2:0.0244 loss3:0.0009 | AUC:0.8390 Anomaly AUC:0.6418
[2023-08-28 18:46:36,839][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00030 | loss1:0.0000 loss2:0.0215 loss3:0.0009 | AUC:0.8263 Anomaly AUC:0.6300
[2023-08-28 18:46:58,059][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00030 | loss1:0.0000 loss2:0.0191 loss3:0.0008 | AUC:0.8268 Anomaly AUC:0.6315
[2023-08-28 18:47:25,216][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 18:47:25,343][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 18:47:25,343][main.py][line:159][INFO] Training Mode
[2023-08-28 18:47:25,344][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 18:47:25,344][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 18:47:33,519][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 18:47:51,900][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.3782 loss2:1.1754 loss3:0.2132 | AUC:0.8149 Anomaly AUC:0.6024
[2023-08-28 18:48:12,687][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.1720 loss2:0.9583 loss3:0.0584 | AUC:0.8053 Anomaly AUC:0.6684
[2023-08-28 18:48:31,322][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.0827 loss2:0.8449 loss3:0.0241 | AUC:0.8284 Anomaly AUC:0.6481
[2023-08-28 18:48:52,776][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.0496 loss2:0.7884 loss3:0.0134 | AUC:0.8305 Anomaly AUC:0.6797
[2023-08-28 18:49:11,469][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.0318 loss2:0.7485 loss3:0.0096 | AUC:0.8334 Anomaly AUC:0.6605
[2023-08-28 18:49:32,919][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.0232 loss2:0.7130 loss3:0.0064 | AUC:0.8480 Anomaly AUC:0.6637
[2023-08-28 18:49:51,548][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.0221 loss2:0.6816 loss3:0.0061 | AUC:0.8019 Anomaly AUC:0.6664
[2023-08-28 18:50:11,111][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.0253 loss2:0.6678 loss3:0.0091 | AUC:0.8280 Anomaly AUC:0.6388
[2023-08-28 18:50:32,846][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.0174 loss2:0.6300 loss3:0.0045 | AUC:0.8363 Anomaly AUC:0.6711
[2023-08-28 18:50:56,329][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0198 loss2:0.5944 loss3:0.0052 | AUC:0.8398 Anomaly AUC:0.6662
[2023-08-28 18:51:18,067][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.0107 loss2:0.5359 loss3:0.0037 | AUC:0.8527 Anomaly AUC:0.6710
[2023-08-28 18:51:41,423][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.0083 loss2:0.4733 loss3:0.0026 | AUC:0.8520 Anomaly AUC:0.6801
[2023-08-28 18:52:02,858][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.0128 loss2:0.4494 loss3:0.0042 | AUC:0.8221 Anomaly AUC:0.6280
[2023-08-28 18:52:24,547][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.0090 loss2:0.3956 loss3:0.0036 | AUC:0.8417 Anomaly AUC:0.6444
[2023-08-28 18:52:47,325][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.0092 loss2:0.3294 loss3:0.0027 | AUC:0.8291 Anomaly AUC:0.6254
[2023-08-28 18:53:10,733][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.0018 loss2:0.2649 loss3:0.0016 | AUC:0.8456 Anomaly AUC:0.6714
[2023-08-28 18:53:31,842][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.0003 loss2:0.1926 loss3:0.0012 | AUC:0.8464 Anomaly AUC:0.6688
[2023-08-28 18:53:53,135][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.0002 loss2:0.1417 loss3:0.0011 | AUC:0.8460 Anomaly AUC:0.6706
[2023-08-28 18:54:15,276][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.0001 loss2:0.1085 loss3:0.0012 | AUC:0.8468 Anomaly AUC:0.6733
[2023-08-28 18:54:36,449][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.0001 loss2:0.0834 loss3:0.0012 | AUC:0.8451 Anomaly AUC:0.6708
[2023-08-28 18:54:56,799][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.0001 loss2:0.0659 loss3:0.0011 | AUC:0.8442 Anomaly AUC:0.6673
[2023-08-28 18:55:17,911][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.0057 loss2:0.0758 loss3:0.0026 | AUC:0.8108 Anomaly AUC:0.6085
[2023-08-28 18:55:38,565][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.0440 loss2:0.3242 loss3:0.0103 | AUC:0.8313 Anomaly AUC:0.6224
[2023-08-28 18:56:01,318][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.0220 loss2:0.1822 loss3:0.0044 | AUC:0.8447 Anomaly AUC:0.6383
[2023-08-28 18:56:23,924][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00030 | loss1:0.0111 loss2:0.1170 loss3:0.0025 | AUC:0.8314 Anomaly AUC:0.6163
[2023-08-28 18:56:46,563][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.0088 loss2:0.0835 loss3:0.0023 | AUC:0.8397 Anomaly AUC:0.6459
[2023-08-28 18:57:07,044][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00030 | loss1:0.0219 loss2:0.1297 loss3:0.0052 | AUC:0.8353 Anomaly AUC:0.6244
[2023-08-28 18:57:26,026][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00030 | loss1:0.0085 loss2:0.0830 loss3:0.0024 | AUC:0.8409 Anomaly AUC:0.6425
[2023-08-28 18:57:48,737][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00030 | loss1:0.0066 loss2:0.0677 loss3:0.0020 | AUC:0.8536 Anomaly AUC:0.6578
[2023-08-28 18:58:11,296][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00030 | loss1:0.0030 loss2:0.0453 loss3:0.0014 | AUC:0.8412 Anomaly AUC:0.6313
[2023-08-28 18:58:33,663][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00030 | loss1:0.0093 loss2:0.0586 loss3:0.0027 | AUC:0.8162 Anomaly AUC:0.5862
[2023-08-28 18:58:54,100][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00030 | loss1:0.0107 loss2:0.0638 loss3:0.0026 | AUC:0.8228 Anomaly AUC:0.5874
[2023-08-28 18:59:13,074][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00030 | loss1:0.0052 loss2:0.0426 loss3:0.0019 | AUC:0.8239 Anomaly AUC:0.5939
[2023-08-28 18:59:34,962][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00030 | loss1:0.0002 loss2:0.0220 loss3:0.0006 | AUC:0.8329 Anomaly AUC:0.6183
[2023-08-28 18:59:57,474][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00030 | loss1:0.0000 loss2:0.0166 loss3:0.0006 | AUC:0.8295 Anomaly AUC:0.6148
[2023-08-28 19:00:17,358][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00030 | loss1:0.0000 loss2:0.0134 loss3:0.0006 | AUC:0.8272 Anomaly AUC:0.6098
[2023-08-28 19:00:36,842][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00030 | loss1:0.0000 loss2:0.0124 loss3:0.0006 | AUC:0.8269 Anomaly AUC:0.6073
[2023-08-28 19:00:49,236][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 19:00:49,351][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 19:00:49,351][main.py][line:159][INFO] Training Mode
[2023-08-28 19:00:49,351][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-08-28 19:00:49,351][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0008
    maximize: False
    weight_decay: 5e-05
)

[2023-08-28 19:00:57,421][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-08-28 19:01:18,525][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.3786 loss2:1.1816 loss3:0.2161 | AUC:0.8117 Anomaly AUC:0.5934
[2023-08-28 19:01:36,913][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.1670 loss2:0.9995 loss3:0.0619 | AUC:0.8416 Anomaly AUC:0.6555
[2023-08-28 19:01:56,431][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.0682 loss2:0.8523 loss3:0.0221 | AUC:0.8457 Anomaly AUC:0.6528
[2023-08-28 19:02:17,227][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.0391 loss2:0.7790 loss3:0.0128 | AUC:0.8526 Anomaly AUC:0.6953
[2023-08-28 19:02:35,980][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.0316 loss2:0.7372 loss3:0.0094 | AUC:0.8526 Anomaly AUC:0.6781
[2023-08-28 19:02:56,981][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.0243 loss2:0.7071 loss3:0.0078 | AUC:0.8581 Anomaly AUC:0.7006
[2023-08-28 19:03:20,127][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.0258 loss2:0.6769 loss3:0.0081 | AUC:0.8500 Anomaly AUC:0.6697
[2023-08-28 19:03:42,999][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.0137 loss2:0.6298 loss3:0.0045 | AUC:0.8584 Anomaly AUC:0.6902
[2023-08-28 19:04:05,468][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.0075 loss2:0.5670 loss3:0.0029 | AUC:0.8496 Anomaly AUC:0.6633
[2023-08-28 19:04:27,692][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0164 loss2:0.5363 loss3:0.0049 | AUC:0.8494 Anomaly AUC:0.6763
[2023-08-28 19:04:49,764][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.0168 loss2:0.5067 loss3:0.0054 | AUC:0.8528 Anomaly AUC:0.6795
[2023-08-28 19:05:10,685][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.0142 loss2:0.4492 loss3:0.0043 | AUC:0.8481 Anomaly AUC:0.6888
[2023-08-28 19:05:32,648][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.0056 loss2:0.3827 loss3:0.0026 | AUC:0.8415 Anomaly AUC:0.7103
[2023-08-28 19:05:54,683][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.0094 loss2:0.3526 loss3:0.0035 | AUC:0.8302 Anomaly AUC:0.6779
[2023-08-28 19:06:17,111][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.0112 loss2:0.3031 loss3:0.0037 | AUC:0.8630 Anomaly AUC:0.7008
[2023-08-28 19:06:39,002][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.0098 loss2:0.2714 loss3:0.0032 | AUC:0.8566 Anomaly AUC:0.6826
[2023-08-28 19:07:01,099][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.0053 loss2:0.2153 loss3:0.0024 | AUC:0.8566 Anomaly AUC:0.6817
[2023-08-28 19:07:22,984][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.0180 loss2:0.2469 loss3:0.0058 | AUC:0.8553 Anomaly AUC:0.6817
[2023-08-28 19:07:45,247][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.0073 loss2:0.1811 loss3:0.0024 | AUC:0.8694 Anomaly AUC:0.7097
[2023-08-28 19:08:07,374][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.0134 loss2:0.1833 loss3:0.0038 | AUC:0.8414 Anomaly AUC:0.6581
[2023-08-28 19:08:29,208][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.0117 loss2:0.1720 loss3:0.0037 | AUC:0.8241 Anomaly AUC:0.6342
[2023-08-28 19:08:50,939][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.0019 loss2:0.1022 loss3:0.0013 | AUC:0.8465 Anomaly AUC:0.6621
[2023-08-28 19:09:12,677][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.0005 loss2:0.0755 loss3:0.0010 | AUC:0.8522 Anomaly AUC:0.6708
[2023-08-28 19:09:34,375][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.0001 loss2:0.0583 loss3:0.0009 | AUC:0.8539 Anomaly AUC:0.6743
[2023-08-28 19:09:53,272][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00030 | loss1:0.0001 loss2:0.0474 loss3:0.0009 | AUC:0.8552 Anomaly AUC:0.6753
[2023-08-28 19:10:12,605][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.0001 loss2:0.0396 loss3:0.0010 | AUC:0.8541 Anomaly AUC:0.6720
[2023-08-28 19:10:31,577][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00030 | loss1:0.0001 loss2:0.0340 loss3:0.0010 | AUC:0.8526 Anomaly AUC:0.6680
[2023-08-28 19:10:50,483][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00030 | loss1:0.0001 loss2:0.0291 loss3:0.0010 | AUC:0.8512 Anomaly AUC:0.6642
[2023-08-28 19:11:12,129][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00030 | loss1:0.0001 loss2:0.0257 loss3:0.0009 | AUC:0.8500 Anomaly AUC:0.6609
[2023-08-28 19:11:31,238][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00030 | loss1:0.0001 loss2:0.0227 loss3:0.0010 | AUC:0.8482 Anomaly AUC:0.6569
[2023-08-28 19:11:50,509][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00030 | loss1:0.0000 loss2:0.0202 loss3:0.0009 | AUC:0.8461 Anomaly AUC:0.6516
[2023-08-28 19:12:09,606][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00030 | loss1:0.0000 loss2:0.0180 loss3:0.0010 | AUC:0.8432 Anomaly AUC:0.6468
[2023-08-28 19:12:28,739][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00030 | loss1:0.0000 loss2:0.0158 loss3:0.0009 | AUC:0.8427 Anomaly AUC:0.6467
[2023-08-28 19:12:47,624][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00030 | loss1:0.0000 loss2:0.0144 loss3:0.0009 | AUC:0.8384 Anomaly AUC:0.6431
[2023-08-28 19:13:07,053][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00030 | loss1:0.0000 loss2:0.0138 loss3:0.0009 | AUC:0.8263 Anomaly AUC:0.6380
[2023-08-28 19:13:28,455][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00030 | loss1:0.0001 loss2:0.0068 loss3:0.0008 | AUC:0.8113 Anomaly AUC:0.6051
[2023-08-28 19:13:49,980][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00030 | loss1:0.0704 loss2:0.3301 loss3:0.0191 | AUC:0.8296 Anomaly AUC:0.5926
[2023-08-28 19:14:08,997][main.py][line:105][INFO] [Epoch:38/50]: lr:0.00030 | loss1:0.0445 loss2:0.3116 loss3:0.0089 | AUC:0.8242 Anomaly AUC:0.6103
[2023-08-28 19:14:28,268][main.py][line:105][INFO] [Epoch:39/50]: lr:0.00030 | loss1:0.0138 loss2:0.1241 loss3:0.0030 | AUC:0.8326 Anomaly AUC:0.6311
[2023-08-28 19:14:47,326][main.py][line:105][INFO] [Epoch:40/50]: lr:0.00030 | loss1:0.0063 loss2:0.0647 loss3:0.0017 | AUC:0.8329 Anomaly AUC:0.6392
[2023-08-28 19:15:06,360][main.py][line:105][INFO] [Epoch:41/50]: lr:0.00030 | loss1:0.0114 loss2:0.0673 loss3:0.0025 | AUC:0.8231 Anomaly AUC:0.6005
[2023-08-28 19:15:25,395][main.py][line:105][INFO] [Epoch:42/50]: lr:0.00030 | loss1:0.0057 loss2:0.0393 loss3:0.0016 | AUC:0.8240 Anomaly AUC:0.6191
[2023-08-28 19:15:44,616][main.py][line:105][INFO] [Epoch:43/50]: lr:0.00030 | loss1:0.0034 loss2:0.0267 loss3:0.0013 | AUC:0.8333 Anomaly AUC:0.6255
[2023-08-28 19:16:06,097][main.py][line:105][INFO] [Epoch:44/50]: lr:0.00030 | loss1:0.0025 loss2:0.0234 loss3:0.0011 | AUC:0.8184 Anomaly AUC:0.6187
[2023-08-28 19:16:25,012][main.py][line:105][INFO] [Epoch:45/50]: lr:0.00030 | loss1:0.0071 loss2:0.0334 loss3:0.0020 | AUC:0.8322 Anomaly AUC:0.6177
[2023-08-28 19:16:44,232][main.py][line:105][INFO] [Epoch:46/50]: lr:0.00030 | loss1:0.0131 loss2:0.0569 loss3:0.0029 | AUC:0.8091 Anomaly AUC:0.5970
[2023-08-28 19:17:03,227][main.py][line:105][INFO] [Epoch:47/50]: lr:0.00030 | loss1:0.0067 loss2:0.0335 loss3:0.0019 | AUC:0.8200 Anomaly AUC:0.6122
[2023-08-28 19:17:22,295][main.py][line:105][INFO] [Epoch:48/50]: lr:0.00030 | loss1:0.0056 loss2:0.0291 loss3:0.0018 | AUC:0.8392 Anomaly AUC:0.6356
[2023-08-28 19:17:43,800][main.py][line:105][INFO] [Epoch:49/50]: lr:0.00030 | loss1:0.0067 loss2:0.0305 loss3:0.0019 | AUC:0.8259 Anomaly AUC:0.5984
[2023-08-28 19:18:02,848][main.py][line:105][INFO] [Epoch:50/50]: lr:0.00030 | loss1:0.0107 loss2:0.0375 loss3:0.0027 | AUC:0.8337 Anomaly AUC:0.6011
[2023-08-28 19:18:02,871][main.py][line:113][INFO] Training completes in 17m 5s | best AUCAUC:0.8694 Anomaly AUC:0.7097

[2023-08-28 19:22:25,039][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-08-28 19:22:25,166][main.py][line:156][INFO] total params:7.5707M
[2023-08-28 19:22:25,166][main.py][line:165][INFO] Test Mode
[2023-08-28 19:22:25,166][main.py][line:36][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-08-28 19:22:33,153][infer.py][line:47][INFO] offline AUC:0.8703 AP:0.3618 FAR:0.0356 | Complete in 0m 8s

[2023-09-08 14:35:26,830][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 14:35:26,959][main.py][line:156][INFO] total params:7.5707M
[2023-09-08 14:35:26,959][main.py][line:159][INFO] Training Mode
[2023-09-08 14:35:26,959][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 14:35:26,959][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 14:35:35,050][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-09-08 14:35:53,352][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.3872 loss2:1.0113 loss3:0.1092 | AUC:0.8354 Anomaly AUC:0.6713
[2023-09-08 14:36:11,435][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1242 loss2:0.7115 loss3:0.1127 | AUC:0.8321 Anomaly AUC:0.6583
[2023-09-08 14:36:29,763][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0397 loss2:0.5424 loss3:0.1135 | AUC:0.8483 Anomaly AUC:0.6743
[2023-09-08 14:36:48,358][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00050 | loss1:0.0209 loss2:0.4035 loss3:0.0714 | AUC:0.8215 Anomaly AUC:0.6614
[2023-09-08 14:37:07,107][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00050 | loss1:0.0278 loss2:0.3108 loss3:0.0159 | AUC:0.8428 Anomaly AUC:0.6896
[2023-09-08 14:37:25,936][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00050 | loss1:0.0169 loss2:0.2307 loss3:0.0091 | AUC:0.8309 Anomaly AUC:0.6638
[2023-09-08 14:37:44,703][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00050 | loss1:0.0182 loss2:0.1758 loss3:0.0027 | AUC:0.8365 Anomaly AUC:0.6666
[2023-09-08 14:38:03,574][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00050 | loss1:0.0122 loss2:0.1319 loss3:0.0011 | AUC:0.8466 Anomaly AUC:0.6725
[2023-09-08 14:38:22,528][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00050 | loss1:0.0061 loss2:0.0945 loss3:0.0007 | AUC:0.8549 Anomaly AUC:0.6781
[2023-09-08 14:38:41,630][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00050 | loss1:0.0182 loss2:0.1012 loss3:0.0015 | AUC:0.8395 Anomaly AUC:0.6528
[2023-09-08 14:39:00,409][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00050 | loss1:0.0184 loss2:0.0926 loss3:0.0025 | AUC:0.8433 Anomaly AUC:0.6666
[2023-09-08 14:39:19,199][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00050 | loss1:0.0136 loss2:0.0715 loss3:0.0042 | AUC:0.7761 Anomaly AUC:0.6565
[2023-09-08 14:39:38,056][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00050 | loss1:0.0076 loss2:0.0493 loss3:0.0011 | AUC:0.8250 Anomaly AUC:0.6467
[2023-09-08 14:39:56,879][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00050 | loss1:0.0067 loss2:0.0433 loss3:0.0009 | AUC:0.8402 Anomaly AUC:0.6591
[2023-09-08 14:40:15,820][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00050 | loss1:0.0145 loss2:0.0482 loss3:0.0020 | AUC:0.8213 Anomaly AUC:0.6272
[2023-09-08 14:40:34,720][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00050 | loss1:0.0083 loss2:0.0368 loss3:0.0012 | AUC:0.8241 Anomaly AUC:0.6497
[2023-09-08 14:40:53,664][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00050 | loss1:0.0089 loss2:0.0340 loss3:0.0012 | AUC:0.8065 Anomaly AUC:0.6465
[2023-09-08 14:41:12,636][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00050 | loss1:0.0061 loss2:0.0367 loss3:0.0023 | AUC:0.8474 Anomaly AUC:0.6831
[2023-09-08 14:41:31,675][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00050 | loss1:0.0042 loss2:0.0191 loss3:0.0012 | AUC:0.8111 Anomaly AUC:0.6497
[2023-09-08 14:41:50,599][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00050 | loss1:0.0094 loss2:0.0300 loss3:0.0020 | AUC:0.8237 Anomaly AUC:0.6400
[2023-09-08 14:41:56,887][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 14:41:57,001][main.py][line:156][INFO] total params:7.5707M
[2023-09-08 14:41:57,001][main.py][line:159][INFO] Training Mode
[2023-09-08 14:41:57,001][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 14:41:57,001][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 14:42:05,015][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-09-08 14:42:23,594][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.3998 loss2:1.0214 loss3:0.2141 | AUC:0.8299 Anomaly AUC:0.6727
[2023-09-08 14:42:41,996][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1430 loss2:0.7303 loss3:0.0442 | AUC:0.8212 Anomaly AUC:0.6807
[2023-09-08 14:43:00,767][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0503 loss2:0.5691 loss3:0.0178 | AUC:0.8280 Anomaly AUC:0.6812
[2023-09-08 14:43:19,350][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00050 | loss1:0.0245 loss2:0.4460 loss3:0.0103 | AUC:0.8157 Anomaly AUC:0.6451
[2023-09-08 14:43:38,021][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00050 | loss1:0.0239 loss2:0.3525 loss3:0.0063 | AUC:0.8082 Anomaly AUC:0.6667
[2023-09-08 14:43:56,670][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00050 | loss1:0.0131 loss2:0.2513 loss3:0.0032 | AUC:0.8007 Anomaly AUC:0.6415
[2023-09-08 14:44:15,441][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00050 | loss1:0.0161 loss2:0.1944 loss3:0.0031 | AUC:0.8237 Anomaly AUC:0.6700
[2023-09-08 14:44:34,249][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00050 | loss1:0.0184 loss2:0.1677 loss3:0.0038 | AUC:0.8289 Anomaly AUC:0.6561
[2023-09-08 14:44:53,065][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00050 | loss1:0.0061 loss2:0.1133 loss3:0.0016 | AUC:0.8375 Anomaly AUC:0.6628
[2023-09-08 14:45:11,990][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00050 | loss1:0.0168 loss2:0.1125 loss3:0.0034 | AUC:0.8546 Anomaly AUC:0.6989
[2023-09-08 14:45:30,710][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00050 | loss1:0.0050 loss2:0.0797 loss3:0.0016 | AUC:0.8473 Anomaly AUC:0.6817
[2023-09-08 14:45:49,624][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00050 | loss1:0.0005 loss2:0.0467 loss3:0.0004 | AUC:0.8441 Anomaly AUC:0.6778
[2023-09-08 14:46:08,405][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00050 | loss1:0.0143 loss2:0.0605 loss3:0.0028 | AUC:0.8230 Anomaly AUC:0.6443
[2023-09-08 14:46:27,261][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00050 | loss1:0.0136 loss2:0.0687 loss3:0.0028 | AUC:0.8027 Anomaly AUC:0.6410
[2023-09-08 14:46:46,195][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00050 | loss1:0.0131 loss2:0.0523 loss3:0.0025 | AUC:0.8186 Anomaly AUC:0.6517
[2023-09-08 14:47:05,125][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00050 | loss1:0.0148 loss2:0.0500 loss3:0.0029 | AUC:0.8348 Anomaly AUC:0.6565
[2023-09-08 14:47:24,017][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00050 | loss1:0.0048 loss2:0.0325 loss3:0.0012 | AUC:0.8461 Anomaly AUC:0.6821
[2023-09-08 14:47:42,802][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00050 | loss1:0.0152 loss2:0.0409 loss3:0.0027 | AUC:0.8438 Anomaly AUC:0.6671
[2023-09-08 14:48:01,693][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00050 | loss1:0.0054 loss2:0.0242 loss3:0.0011 | AUC:0.8396 Anomaly AUC:0.6805
[2023-09-08 14:48:20,596][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00050 | loss1:0.0060 loss2:0.0236 loss3:0.0011 | AUC:0.8203 Anomaly AUC:0.6609
[2023-09-08 14:48:39,629][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00050 | loss1:0.0026 loss2:0.0166 loss3:0.0007 | AUC:0.8285 Anomaly AUC:0.6760
[2023-09-08 14:48:58,582][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00050 | loss1:0.0119 loss2:0.0294 loss3:0.0020 | AUC:0.8214 Anomaly AUC:0.6488
[2023-09-08 14:49:17,476][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00050 | loss1:0.0097 loss2:0.0275 loss3:0.0019 | AUC:0.8149 Anomaly AUC:0.6421
[2023-09-08 14:49:36,391][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00050 | loss1:0.0006 loss2:0.0121 loss3:0.0004 | AUC:0.8178 Anomaly AUC:0.6422
[2023-09-08 14:49:55,441][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00050 | loss1:0.0004 loss2:0.0070 loss3:0.0003 | AUC:0.8105 Anomaly AUC:0.6407
[2023-09-08 14:50:14,403][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00050 | loss1:0.0007 loss2:0.0070 loss3:0.0003 | AUC:0.8317 Anomaly AUC:0.6616
[2023-09-08 14:50:33,403][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00050 | loss1:0.0001 loss2:0.0049 loss3:0.0003 | AUC:0.8289 Anomaly AUC:0.6589
[2023-09-08 14:50:52,285][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00050 | loss1:0.0001 loss2:0.0041 loss3:0.0003 | AUC:0.8259 Anomaly AUC:0.6565
[2023-09-08 14:51:11,248][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00050 | loss1:0.0001 loss2:0.0040 loss3:0.0003 | AUC:0.8252 Anomaly AUC:0.6573
[2023-09-08 14:51:30,157][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00050 | loss1:0.0001 loss2:0.0036 loss3:0.0004 | AUC:0.8221 Anomaly AUC:0.6574
[2023-09-08 14:51:49,089][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00050 | loss1:0.0001 loss2:0.0033 loss3:0.0004 | AUC:0.8201 Anomaly AUC:0.6577
[2023-09-08 14:52:08,020][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00050 | loss1:0.0001 loss2:0.0031 loss3:0.0004 | AUC:0.8200 Anomaly AUC:0.6596
[2023-09-08 14:52:26,976][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00050 | loss1:0.0001 loss2:0.0029 loss3:0.0004 | AUC:0.8196 Anomaly AUC:0.6588
[2023-09-08 14:52:45,968][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00050 | loss1:0.0001 loss2:0.0027 loss3:0.0004 | AUC:0.8196 Anomaly AUC:0.6608
[2023-09-08 14:53:05,080][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00050 | loss1:0.0001 loss2:0.0027 loss3:0.0004 | AUC:0.8183 Anomaly AUC:0.6653
[2023-09-08 14:53:24,111][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00050 | loss1:0.0001 loss2:0.0023 loss3:0.0004 | AUC:0.8163 Anomaly AUC:0.6611
[2023-09-08 14:53:43,062][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00050 | loss1:0.0001 loss2:0.0023 loss3:0.0004 | AUC:0.8079 Anomaly AUC:0.6621
[2023-09-08 14:54:02,103][main.py][line:105][INFO] [Epoch:38/50]: lr:0.00050 | loss1:0.0001 loss2:0.0022 loss3:0.0004 | AUC:0.8004 Anomaly AUC:0.6625
[2023-09-08 14:54:21,256][main.py][line:105][INFO] [Epoch:39/50]: lr:0.00050 | loss1:0.0858 loss2:0.1371 loss3:0.0189 | AUC:0.8334 Anomaly AUC:0.6514
[2023-09-08 14:54:40,405][main.py][line:105][INFO] [Epoch:40/50]: lr:0.00050 | loss1:0.0177 loss2:0.0382 loss3:0.0038 | AUC:0.8388 Anomaly AUC:0.6707
[2023-09-08 14:54:59,427][main.py][line:105][INFO] [Epoch:41/50]: lr:0.00050 | loss1:0.0046 loss2:0.0127 loss3:0.0011 | AUC:0.8073 Anomaly AUC:0.6467
[2023-09-08 14:55:18,407][main.py][line:105][INFO] [Epoch:42/50]: lr:0.00050 | loss1:0.0004 loss2:0.0062 loss3:0.0004 | AUC:0.8112 Anomaly AUC:0.6531
[2023-09-08 14:55:37,427][main.py][line:105][INFO] [Epoch:43/50]: lr:0.00050 | loss1:0.0002 loss2:0.0059 loss3:0.0004 | AUC:0.8127 Anomaly AUC:0.6450
[2023-09-08 14:55:56,522][main.py][line:105][INFO] [Epoch:44/50]: lr:0.00050 | loss1:0.0001 loss2:0.0026 loss3:0.0003 | AUC:0.8094 Anomaly AUC:0.6457
[2023-09-08 14:56:15,718][main.py][line:105][INFO] [Epoch:45/50]: lr:0.00050 | loss1:0.0001 loss2:0.0036 loss3:0.0003 | AUC:0.8066 Anomaly AUC:0.6372
[2023-09-08 14:56:35,056][main.py][line:105][INFO] [Epoch:46/50]: lr:0.00050 | loss1:0.0190 loss2:0.0331 loss3:0.0037 | AUC:0.8311 Anomaly AUC:0.6572
[2023-09-08 14:56:54,204][main.py][line:105][INFO] [Epoch:47/50]: lr:0.00050 | loss1:0.0101 loss2:0.0168 loss3:0.0020 | AUC:0.8293 Anomaly AUC:0.6343
[2023-09-08 14:57:13,267][main.py][line:105][INFO] [Epoch:48/50]: lr:0.00050 | loss1:0.0081 loss2:0.0163 loss3:0.0019 | AUC:0.8257 Anomaly AUC:0.6378
[2023-09-08 14:57:32,304][main.py][line:105][INFO] [Epoch:49/50]: lr:0.00050 | loss1:0.0033 loss2:0.0111 loss3:0.0011 | AUC:0.8184 Anomaly AUC:0.6358
[2023-09-08 14:57:51,344][main.py][line:105][INFO] [Epoch:50/50]: lr:0.00050 | loss1:0.0002 loss2:0.0033 loss3:0.0004 | AUC:0.8215 Anomaly AUC:0.6507
[2023-09-08 14:57:51,367][main.py][line:113][INFO] Training completes in 15m 46s | best AUCAUC:0.8546 Anomaly AUC:0.6989

[2023-09-08 15:14:09,648][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 15:14:09,770][main.py][line:156][INFO] total params:7.5707M
[2023-09-08 15:14:09,770][main.py][line:159][INFO] Training Mode
[2023-09-08 15:14:09,771][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 15:14:09,771][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 15:14:17,926][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-09-08 15:14:36,222][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.3878 loss2:1.0115 loss3:0.2050 | AUC:0.8310 Anomaly AUC:0.6631
[2023-09-08 15:14:54,271][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1445 loss2:0.7358 loss3:0.0420 | AUC:0.8413 Anomaly AUC:0.7023
[2023-09-08 15:15:12,497][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0538 loss2:0.5809 loss3:0.0168 | AUC:0.8429 Anomaly AUC:0.6733
[2023-09-08 15:15:31,089][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00050 | loss1:0.0300 loss2:0.4636 loss3:0.0099 | AUC:0.8487 Anomaly AUC:0.6711
[2023-09-08 15:15:49,662][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00050 | loss1:0.0133 loss2:0.3292 loss3:0.0033 | AUC:0.8328 Anomaly AUC:0.6580
[2023-09-08 15:16:08,359][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00050 | loss1:0.0067 loss2:0.2296 loss3:0.0020 | AUC:0.8432 Anomaly AUC:0.6676
[2023-09-08 15:16:27,059][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00050 | loss1:0.0008 loss2:0.1484 loss3:0.0007 | AUC:0.8449 Anomaly AUC:0.6736
[2023-09-08 15:16:45,923][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00050 | loss1:0.0005 loss2:0.1050 loss3:0.0006 | AUC:0.8427 Anomaly AUC:0.6711
[2023-09-08 15:17:04,673][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00050 | loss1:0.0004 loss2:0.0810 loss3:0.0005 | AUC:0.8409 Anomaly AUC:0.6708
[2023-09-08 15:17:23,664][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00050 | loss1:0.0003 loss2:0.0641 loss3:0.0005 | AUC:0.8414 Anomaly AUC:0.6750
[2023-09-08 15:17:42,436][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00050 | loss1:0.0003 loss2:0.0510 loss3:0.0005 | AUC:0.8430 Anomaly AUC:0.6773
[2023-09-08 15:18:01,269][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00050 | loss1:0.0002 loss2:0.0422 loss3:0.0005 | AUC:0.8400 Anomaly AUC:0.6727
[2023-09-08 15:18:20,175][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00050 | loss1:0.0002 loss2:0.0350 loss3:0.0005 | AUC:0.8394 Anomaly AUC:0.6666
[2023-09-08 15:18:39,054][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00050 | loss1:0.0001 loss2:0.0294 loss3:0.0005 | AUC:0.8380 Anomaly AUC:0.6682
[2023-09-08 15:18:58,022][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00050 | loss1:0.0908 loss2:0.0580 loss3:0.0050 | AUC:0.6854 Anomaly AUC:0.6476
[2023-09-08 15:19:16,884][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00050 | loss1:0.1155 loss2:0.3685 loss3:0.0219 | AUC:0.8221 Anomaly AUC:0.6696
[2023-09-08 15:19:35,825][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00050 | loss1:0.0135 loss2:0.0856 loss3:0.0026 | AUC:0.8365 Anomaly AUC:0.6720
[2023-09-08 15:20:18,503][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 15:20:18,615][main.py][line:156][INFO] total params:7.5707M
[2023-09-08 15:20:18,615][main.py][line:159][INFO] Training Mode
[2023-09-08 15:20:18,616][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 15:20:18,616][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 15:20:26,774][main.py][line:81][INFO] Random initialize AUCAUC:0.5390 Anomaly AUC:0.54581
[2023-09-08 15:20:45,118][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.3998 loss2:1.0214 loss3:0.2141 | AUC:0.8299 Anomaly AUC:0.6727
[2023-09-08 15:21:03,342][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1430 loss2:0.7303 loss3:0.0442 | AUC:0.8212 Anomaly AUC:0.6807
[2023-09-08 15:21:21,926][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0503 loss2:0.5691 loss3:0.0178 | AUC:0.8280 Anomaly AUC:0.6812
[2023-09-08 15:21:40,527][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00050 | loss1:0.0245 loss2:0.4460 loss3:0.0103 | AUC:0.8157 Anomaly AUC:0.6451
[2023-09-08 15:21:59,307][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00050 | loss1:0.0239 loss2:0.3525 loss3:0.0063 | AUC:0.8082 Anomaly AUC:0.6667
[2023-09-08 15:22:18,137][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00050 | loss1:0.0131 loss2:0.2513 loss3:0.0032 | AUC:0.8007 Anomaly AUC:0.6415
[2023-09-08 15:22:37,046][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00050 | loss1:0.0161 loss2:0.1944 loss3:0.0031 | AUC:0.8237 Anomaly AUC:0.6700
[2023-09-08 15:22:55,868][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00050 | loss1:0.0184 loss2:0.1677 loss3:0.0038 | AUC:0.8289 Anomaly AUC:0.6561
[2023-09-08 15:23:14,800][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00050 | loss1:0.0061 loss2:0.1133 loss3:0.0016 | AUC:0.8375 Anomaly AUC:0.6628
[2023-09-08 15:23:33,770][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00050 | loss1:0.0168 loss2:0.1125 loss3:0.0034 | AUC:0.8546 Anomaly AUC:0.6989
[2023-09-08 15:23:52,613][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00050 | loss1:0.0050 loss2:0.0797 loss3:0.0016 | AUC:0.8473 Anomaly AUC:0.6817
[2023-09-08 15:24:11,464][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00050 | loss1:0.0005 loss2:0.0467 loss3:0.0004 | AUC:0.8441 Anomaly AUC:0.6778
[2023-09-08 15:24:30,450][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00050 | loss1:0.0143 loss2:0.0605 loss3:0.0028 | AUC:0.8230 Anomaly AUC:0.6443
[2023-09-08 15:24:49,416][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00050 | loss1:0.0136 loss2:0.0687 loss3:0.0028 | AUC:0.8027 Anomaly AUC:0.6410
[2023-09-08 15:25:08,505][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00050 | loss1:0.0131 loss2:0.0523 loss3:0.0025 | AUC:0.8186 Anomaly AUC:0.6517
[2023-09-08 15:25:27,437][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00050 | loss1:0.0148 loss2:0.0500 loss3:0.0029 | AUC:0.8348 Anomaly AUC:0.6565
[2023-09-08 15:25:46,468][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00050 | loss1:0.0048 loss2:0.0325 loss3:0.0012 | AUC:0.8461 Anomaly AUC:0.6821
[2023-09-08 15:26:05,470][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00050 | loss1:0.0152 loss2:0.0409 loss3:0.0027 | AUC:0.8438 Anomaly AUC:0.6671
[2023-09-08 15:26:24,485][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00050 | loss1:0.0054 loss2:0.0242 loss3:0.0011 | AUC:0.8396 Anomaly AUC:0.6805
[2023-09-08 15:26:43,397][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00050 | loss1:0.0060 loss2:0.0236 loss3:0.0011 | AUC:0.8203 Anomaly AUC:0.6609
[2023-09-08 15:27:02,298][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00050 | loss1:0.0026 loss2:0.0166 loss3:0.0007 | AUC:0.8285 Anomaly AUC:0.6760
[2023-09-08 15:27:21,263][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00050 | loss1:0.0119 loss2:0.0294 loss3:0.0020 | AUC:0.8214 Anomaly AUC:0.6488
[2023-09-08 15:27:40,249][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00050 | loss1:0.0097 loss2:0.0275 loss3:0.0019 | AUC:0.8149 Anomaly AUC:0.6421
[2023-09-08 15:27:59,128][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00050 | loss1:0.0006 loss2:0.0121 loss3:0.0004 | AUC:0.8178 Anomaly AUC:0.6422
[2023-09-08 15:28:18,078][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00050 | loss1:0.0004 loss2:0.0070 loss3:0.0003 | AUC:0.8105 Anomaly AUC:0.6407
[2023-09-08 15:28:36,932][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00050 | loss1:0.0007 loss2:0.0070 loss3:0.0003 | AUC:0.8317 Anomaly AUC:0.6616
[2023-09-08 15:28:55,875][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00050 | loss1:0.0001 loss2:0.0049 loss3:0.0003 | AUC:0.8289 Anomaly AUC:0.6589
[2023-09-08 15:29:14,892][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00050 | loss1:0.0001 loss2:0.0041 loss3:0.0003 | AUC:0.8259 Anomaly AUC:0.6565
[2023-09-08 15:29:33,910][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00050 | loss1:0.0001 loss2:0.0040 loss3:0.0003 | AUC:0.8252 Anomaly AUC:0.6573
[2023-09-08 15:29:52,892][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00050 | loss1:0.0001 loss2:0.0036 loss3:0.0004 | AUC:0.8221 Anomaly AUC:0.6574
[2023-09-08 15:30:06,225][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 15:30:06,346][main.py][line:156][INFO] total params:7.0246M
[2023-09-08 15:30:06,346][main.py][line:159][INFO] Training Mode
[2023-09-08 15:30:06,346][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 15:30:06,346][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 15:30:11,826][main.py][line:81][INFO] Random initialize AUCAUC:0.5187 Anomaly AUC:0.49901
[2023-09-08 15:30:26,201][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.3793 loss2:1.0117 loss3:0.2033 | AUC:0.8363 Anomaly AUC:0.6691
[2023-09-08 15:30:40,334][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1325 loss2:0.7132 loss3:0.0420 | AUC:0.8318 Anomaly AUC:0.6638
[2023-09-08 15:30:54,501][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0536 loss2:0.5687 loss3:0.0205 | AUC:0.8262 Anomaly AUC:0.6577
[2023-09-08 15:31:08,806][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00050 | loss1:0.0331 loss2:0.4636 loss3:0.0155 | AUC:0.8346 Anomaly AUC:0.6624
[2023-09-08 15:31:23,316][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00050 | loss1:0.0146 loss2:0.3453 loss3:0.0110 | AUC:0.8344 Anomaly AUC:0.6518
[2023-09-08 15:31:37,924][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00050 | loss1:0.0100 loss2:0.2437 loss3:0.0093 | AUC:0.8387 Anomaly AUC:0.6601
[2023-09-08 15:31:52,486][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00050 | loss1:0.0126 loss2:0.1837 loss3:0.0081 | AUC:0.8287 Anomaly AUC:0.6414
[2023-09-08 15:32:07,173][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00050 | loss1:0.0170 loss2:0.1681 loss3:0.0084 | AUC:0.8402 Anomaly AUC:0.6415
[2023-09-08 15:32:21,833][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00050 | loss1:0.0104 loss2:0.1125 loss3:0.0048 | AUC:0.8308 Anomaly AUC:0.6375
[2023-09-08 15:32:36,639][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00050 | loss1:0.0077 loss2:0.0827 loss3:0.0015 | AUC:0.8406 Anomaly AUC:0.6350
[2023-09-08 15:32:51,316][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00050 | loss1:0.0215 loss2:0.0968 loss3:0.0040 | AUC:0.8434 Anomaly AUC:0.6469
[2023-09-08 15:33:06,051][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00050 | loss1:0.0111 loss2:0.0681 loss3:0.0019 | AUC:0.8517 Anomaly AUC:0.6757
[2023-09-08 15:33:20,709][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00050 | loss1:0.0049 loss2:0.0457 loss3:0.0010 | AUC:0.8551 Anomaly AUC:0.6806
[2023-09-08 15:33:35,441][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00050 | loss1:0.0022 loss2:0.0314 loss3:0.0006 | AUC:0.8492 Anomaly AUC:0.6859
[2023-09-08 15:33:50,007][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00050 | loss1:0.0145 loss2:0.0522 loss3:0.0028 | AUC:0.8413 Anomaly AUC:0.6652
[2023-09-08 15:34:04,579][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00050 | loss1:0.0229 loss2:0.0655 loss3:0.0032 | AUC:0.8395 Anomaly AUC:0.6470
[2023-09-08 15:34:19,253][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00050 | loss1:0.0043 loss2:0.0266 loss3:0.0010 | AUC:0.8449 Anomaly AUC:0.6560
[2023-09-08 15:34:33,890][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00050 | loss1:0.0009 loss2:0.0173 loss3:0.0003 | AUC:0.8426 Anomaly AUC:0.6549
[2023-09-08 15:34:48,647][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00050 | loss1:0.0006 loss2:0.0126 loss3:0.0002 | AUC:0.8461 Anomaly AUC:0.6539
[2023-09-08 15:35:03,389][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00050 | loss1:0.0001 loss2:0.0103 loss3:0.0002 | AUC:0.8464 Anomaly AUC:0.6536
[2023-09-08 15:35:18,820][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 15:35:18,933][main.py][line:156][INFO] total params:7.0092M
[2023-09-08 15:35:18,934][main.py][line:159][INFO] Training Mode
[2023-09-08 15:35:18,934][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 15:35:18,934][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 15:35:24,362][main.py][line:81][INFO] Random initialize AUCAUC:0.6123 Anomaly AUC:0.51706
[2023-09-08 15:35:38,634][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.3433 loss2:1.0771 loss3:0.3081 | AUC:0.8319 Anomaly AUC:0.6614
[2023-09-08 15:35:52,783][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.0977 loss2:0.8106 loss3:0.1800 | AUC:0.8404 Anomaly AUC:0.6848
[2023-09-08 15:36:06,918][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.0503 loss2:0.7131 loss3:0.0909 | AUC:0.8567 Anomaly AUC:0.6791
[2023-09-08 15:36:21,060][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.0377 loss2:0.6306 loss3:0.0429 | AUC:0.8445 Anomaly AUC:0.6774
[2023-09-08 15:36:35,462][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0146 loss2:0.5511 loss3:0.0246 | AUC:0.8457 Anomaly AUC:0.6885
[2023-09-08 15:36:49,910][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0194 loss2:0.5020 loss3:0.0203 | AUC:0.8498 Anomaly AUC:0.6910
[2023-09-08 15:37:04,402][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0046 loss2:0.4395 loss3:0.0146 | AUC:0.8519 Anomaly AUC:0.6905
[2023-09-08 15:37:19,001][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0102 loss2:0.3972 loss3:0.0136 | AUC:0.8522 Anomaly AUC:0.6989
[2023-09-08 15:37:33,459][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0084 loss2:0.3666 loss3:0.0127 | AUC:0.8496 Anomaly AUC:0.6852
[2023-09-08 15:37:48,154][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0020 loss2:0.3240 loss3:0.0104 | AUC:0.8528 Anomaly AUC:0.6931
[2023-09-08 15:38:02,771][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0016 loss2:0.2953 loss3:0.0096 | AUC:0.8487 Anomaly AUC:0.6909
[2023-09-08 15:38:17,393][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0305 loss2:0.3138 loss3:0.0127 | AUC:0.8504 Anomaly AUC:0.6896
[2023-09-08 15:38:32,110][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0099 loss2:0.2822 loss3:0.0103 | AUC:0.8487 Anomaly AUC:0.6826
[2023-09-08 15:38:46,774][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0046 loss2:0.2561 loss3:0.0095 | AUC:0.8498 Anomaly AUC:0.6731
[2023-09-08 15:39:01,425][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0046 loss2:0.2437 loss3:0.0094 | AUC:0.8450 Anomaly AUC:0.6783
[2023-09-08 15:39:16,077][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0173 loss2:0.2535 loss3:0.0104 | AUC:0.8427 Anomaly AUC:0.6790
[2023-09-08 15:39:30,572][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0030 loss2:0.2209 loss3:0.0080 | AUC:0.8375 Anomaly AUC:0.6671
[2023-09-08 15:39:45,219][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0181 loss2:0.2281 loss3:0.0092 | AUC:0.8434 Anomaly AUC:0.6812
[2023-09-08 15:39:59,737][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0033 loss2:0.2033 loss3:0.0074 | AUC:0.8476 Anomaly AUC:0.6842
[2023-09-08 15:40:14,203][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0009 loss2:0.1869 loss3:0.0060 | AUC:0.8487 Anomaly AUC:0.6815
[2023-09-08 15:40:28,773][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0007 loss2:0.1783 loss3:0.0051 | AUC:0.8482 Anomaly AUC:0.6823
[2023-09-08 15:40:43,440][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0006 loss2:0.1712 loss3:0.0042 | AUC:0.8483 Anomaly AUC:0.6815
[2023-09-08 15:40:57,994][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0005 loss2:0.1647 loss3:0.0032 | AUC:0.8472 Anomaly AUC:0.6800
[2023-09-08 15:41:12,722][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0005 loss2:0.1574 loss3:0.0020 | AUC:0.8471 Anomaly AUC:0.6807
[2023-09-08 15:41:27,274][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0004 loss2:0.1517 loss3:0.0007 | AUC:0.8466 Anomaly AUC:0.6798
[2023-09-08 15:41:41,826][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0004 loss2:0.1469 loss3:0.0002 | AUC:0.8451 Anomaly AUC:0.6759
[2023-09-08 15:41:56,531][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0004 loss2:0.1409 loss3:0.0002 | AUC:0.8426 Anomaly AUC:0.6652
[2023-09-08 15:42:11,251][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0438 loss2:0.2052 loss3:0.0084 | AUC:0.8403 Anomaly AUC:0.6666
[2023-09-08 15:42:25,968][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0032 loss2:0.1457 loss3:0.0017 | AUC:0.8480 Anomaly AUC:0.6788
[2023-09-08 15:42:40,678][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0011 loss2:0.1342 loss3:0.0012 | AUC:0.8504 Anomaly AUC:0.6793
[2023-09-08 15:42:55,374][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0005 loss2:0.1253 loss3:0.0006 | AUC:0.8510 Anomaly AUC:0.6800
[2023-09-08 15:43:10,110][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.0004 loss2:0.1198 loss3:0.0004 | AUC:0.8499 Anomaly AUC:0.6785
[2023-09-08 15:43:24,851][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.0004 loss2:0.1144 loss3:0.0003 | AUC:0.8498 Anomaly AUC:0.6784
[2023-09-08 15:43:39,493][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.0003 loss2:0.1102 loss3:0.0003 | AUC:0.8495 Anomaly AUC:0.6774
[2023-09-08 15:43:54,218][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.0003 loss2:0.1057 loss3:0.0002 | AUC:0.8495 Anomaly AUC:0.6778
[2023-09-08 15:44:09,006][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.0003 loss2:0.1022 loss3:0.0002 | AUC:0.8501 Anomaly AUC:0.6787
[2023-09-08 15:44:23,707][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00010 | loss1:0.0003 loss2:0.0987 loss3:0.0002 | AUC:0.8495 Anomaly AUC:0.6769
[2023-09-08 15:44:29,055][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 15:44:29,160][main.py][line:156][INFO] total params:7.0041M
[2023-09-08 15:44:29,160][main.py][line:159][INFO] Training Mode
[2023-09-08 15:44:29,161][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 15:44:29,161][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 15:44:34,551][main.py][line:81][INFO] Random initialize AUCAUC:0.5407 Anomaly AUC:0.52595
[2023-09-08 15:44:48,653][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.2909 loss2:1.1736 loss3:0.3429 | AUC:0.7941 Anomaly AUC:0.6692
[2023-09-08 15:45:02,618][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.0308 loss2:0.8104 loss3:0.2489 | AUC:0.8030 Anomaly AUC:0.6690
[2023-09-08 15:45:16,507][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.0208 loss2:0.7136 loss3:0.1849 | AUC:0.7886 Anomaly AUC:0.6664
[2023-09-08 15:45:30,458][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.0332 loss2:0.6898 loss3:0.1489 | AUC:0.8202 Anomaly AUC:0.6713
[2023-09-08 15:45:44,625][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0174 loss2:0.5971 loss3:0.1069 | AUC:0.8087 Anomaly AUC:0.6600
[2023-09-08 15:45:58,922][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0126 loss2:0.5455 loss3:0.0832 | AUC:0.8221 Anomaly AUC:0.6601
[2023-09-08 15:46:13,142][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0113 loss2:0.4894 loss3:0.0637 | AUC:0.8158 Anomaly AUC:0.6709
[2023-09-08 15:46:27,391][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0113 loss2:0.4601 loss3:0.0577 | AUC:0.8295 Anomaly AUC:0.6620
[2023-09-08 15:46:41,646][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0872 loss2:0.5445 loss3:0.0654 | AUC:0.8059 Anomaly AUC:0.6339
[2023-09-08 15:46:56,085][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0096 loss2:0.5137 loss3:0.0621 | AUC:0.8340 Anomaly AUC:0.6706
[2023-09-08 15:47:10,409][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0077 loss2:0.4029 loss3:0.0368 | AUC:0.8359 Anomaly AUC:0.6734
[2023-09-08 15:47:24,709][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0092 loss2:0.3724 loss3:0.0319 | AUC:0.7997 Anomaly AUC:0.6591
[2023-09-08 15:47:39,016][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0090 loss2:0.3782 loss3:0.0412 | AUC:0.8342 Anomaly AUC:0.6755
[2023-09-08 15:47:53,310][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0048 loss2:0.3146 loss3:0.0242 | AUC:0.8389 Anomaly AUC:0.6801
[2023-09-08 15:48:07,686][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0044 loss2:0.2935 loss3:0.0200 | AUC:0.8462 Anomaly AUC:0.6776
[2023-09-08 15:48:21,973][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0045 loss2:0.2805 loss3:0.0190 | AUC:0.8480 Anomaly AUC:0.6789
[2023-09-08 15:48:36,301][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0036 loss2:0.2655 loss3:0.0165 | AUC:0.8481 Anomaly AUC:0.6838
[2023-09-08 15:48:50,584][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0042 loss2:0.2521 loss3:0.0164 | AUC:0.8448 Anomaly AUC:0.6788
[2023-09-08 15:49:05,028][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0034 loss2:0.2408 loss3:0.0149 | AUC:0.8507 Anomaly AUC:0.6764
[2023-09-08 15:49:19,336][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0502 loss2:0.5049 loss3:0.1010 | AUC:0.8372 Anomaly AUC:0.6710
[2023-09-08 15:49:33,659][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0029 loss2:0.2601 loss3:0.0207 | AUC:0.8417 Anomaly AUC:0.6840
[2023-09-08 15:49:48,014][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0023 loss2:0.2262 loss3:0.0159 | AUC:0.8459 Anomaly AUC:0.6825
[2023-09-08 15:50:02,326][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0022 loss2:0.2119 loss3:0.0143 | AUC:0.8450 Anomaly AUC:0.6819
[2023-09-08 15:50:16,681][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0040 loss2:0.2223 loss3:0.0166 | AUC:0.8484 Anomaly AUC:0.6833
[2023-09-08 15:50:31,028][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0017 loss2:0.1918 loss3:0.0129 | AUC:0.8437 Anomaly AUC:0.6823
[2023-09-08 15:50:45,373][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0058 loss2:0.2258 loss3:0.0182 | AUC:0.8413 Anomaly AUC:0.6724
[2023-09-08 15:50:59,716][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0018 loss2:0.1849 loss3:0.0135 | AUC:0.8476 Anomaly AUC:0.6853
[2023-09-08 15:51:14,130][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0010 loss2:0.1672 loss3:0.0114 | AUC:0.8475 Anomaly AUC:0.6799
[2023-09-08 15:51:28,540][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0011 loss2:0.1618 loss3:0.0111 | AUC:0.8445 Anomaly AUC:0.6795
[2023-09-08 15:51:42,943][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0098 loss2:0.2491 loss3:0.0226 | AUC:0.8413 Anomaly AUC:0.6709
[2023-09-08 15:51:59,362][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 15:51:59,477][main.py][line:156][INFO] total params:7.5298M
[2023-09-08 15:51:59,477][main.py][line:159][INFO] Training Mode
[2023-09-08 15:51:59,477][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 15:51:59,477][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 15:52:07,530][main.py][line:81][INFO] Random initialize AUCAUC:0.4610 Anomaly AUC:0.46533
[2023-09-08 15:52:25,979][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.2978 loss2:1.1717 loss3:0.3430 | AUC:0.8182 Anomaly AUC:0.6871
[2023-09-08 15:52:44,266][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.0312 loss2:0.8290 loss3:0.2466 | AUC:0.8244 Anomaly AUC:0.6860
[2023-09-08 15:53:02,736][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.0215 loss2:0.7369 loss3:0.1862 | AUC:0.8095 Anomaly AUC:0.6715
[2023-09-08 15:53:21,328][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.0208 loss2:0.6554 loss3:0.1305 | AUC:0.8259 Anomaly AUC:0.6799
[2023-09-08 15:53:40,073][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0149 loss2:0.5787 loss3:0.0904 | AUC:0.8359 Anomaly AUC:0.6744
[2023-09-08 15:53:58,682][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0156 loss2:0.5306 loss3:0.0749 | AUC:0.8264 Anomaly AUC:0.6754
[2023-09-08 15:54:17,520][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0106 loss2:0.4738 loss3:0.0589 | AUC:0.8250 Anomaly AUC:0.6673
[2023-09-08 15:54:36,226][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0093 loss2:0.4420 loss3:0.0471 | AUC:0.8284 Anomaly AUC:0.6534
[2023-09-08 15:54:54,951][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0257 loss2:0.5522 loss3:0.0872 | AUC:0.8230 Anomaly AUC:0.6603
[2023-09-08 15:55:13,791][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0058 loss2:0.4035 loss3:0.0405 | AUC:0.8336 Anomaly AUC:0.6699
[2023-09-08 15:55:32,630][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0047 loss2:0.3515 loss3:0.0293 | AUC:0.8313 Anomaly AUC:0.6690
[2023-09-08 15:55:51,461][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0041 loss2:0.3245 loss3:0.0249 | AUC:0.8462 Anomaly AUC:0.6772
[2023-09-08 15:56:10,282][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0034 loss2:0.2981 loss3:0.0197 | AUC:0.8431 Anomaly AUC:0.6752
[2023-09-08 15:56:29,121][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0027 loss2:0.2828 loss3:0.0177 | AUC:0.8437 Anomaly AUC:0.6708
[2023-09-08 15:56:47,911][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0068 loss2:0.2951 loss3:0.0226 | AUC:0.8431 Anomaly AUC:0.6636
[2023-09-08 15:57:06,790][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0030 loss2:0.2661 loss3:0.0190 | AUC:0.8422 Anomaly AUC:0.6778
[2023-09-08 15:57:25,763][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0016 loss2:0.2389 loss3:0.0152 | AUC:0.8538 Anomaly AUC:0.6814
[2023-09-08 15:57:44,495][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0013 loss2:0.2215 loss3:0.0126 | AUC:0.8491 Anomaly AUC:0.6687
[2023-09-08 15:58:03,297][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0037 loss2:0.2335 loss3:0.0162 | AUC:0.8459 Anomaly AUC:0.6602
[2023-09-08 15:58:22,200][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0016 loss2:0.2150 loss3:0.0145 | AUC:0.8514 Anomaly AUC:0.6787
[2023-09-08 15:58:40,959][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0381 loss2:0.3959 loss3:0.0581 | AUC:0.8151 Anomaly AUC:0.6793
[2023-09-08 15:58:59,778][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0031 loss2:0.2903 loss3:0.0236 | AUC:0.8624 Anomaly AUC:0.7001
[2023-09-08 15:59:18,537][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0017 loss2:0.2098 loss3:0.0150 | AUC:0.8619 Anomaly AUC:0.6956
[2023-09-08 15:59:37,311][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0016 loss2:0.1899 loss3:0.0134 | AUC:0.8603 Anomaly AUC:0.6929
[2023-09-08 15:59:56,122][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0009 loss2:0.1778 loss3:0.0119 | AUC:0.8611 Anomaly AUC:0.6897
[2023-09-08 16:00:15,011][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0008 loss2:0.1681 loss3:0.0113 | AUC:0.8583 Anomaly AUC:0.6880
[2023-09-08 16:00:33,894][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0011 loss2:0.1636 loss3:0.0116 | AUC:0.8556 Anomaly AUC:0.6813
[2023-09-08 16:00:52,757][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0007 loss2:0.1561 loss3:0.0109 | AUC:0.8610 Anomaly AUC:0.6917
[2023-09-08 16:01:11,626][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0005 loss2:0.1483 loss3:0.0103 | AUC:0.8586 Anomaly AUC:0.6865
[2023-09-08 16:01:30,485][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0005 loss2:0.1431 loss3:0.0101 | AUC:0.8581 Anomaly AUC:0.6852
[2023-09-08 16:01:49,285][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0004 loss2:0.1372 loss3:0.0099 | AUC:0.8591 Anomaly AUC:0.6868
[2023-09-08 16:02:08,159][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.0004 loss2:0.1320 loss3:0.0096 | AUC:0.8593 Anomaly AUC:0.6868
[2023-09-08 16:02:27,002][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.0093 loss2:0.2964 loss3:0.0457 | AUC:0.8045 Anomaly AUC:0.6809
[2023-09-08 16:02:45,843][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.0043 loss2:0.2000 loss3:0.0242 | AUC:0.8449 Anomaly AUC:0.6815
[2023-09-08 16:03:04,819][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.0010 loss2:0.1338 loss3:0.0126 | AUC:0.8505 Anomaly AUC:0.6858
[2023-09-08 16:03:23,764][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.0005 loss2:0.1211 loss3:0.0106 | AUC:0.8498 Anomaly AUC:0.6838
[2023-09-08 16:03:42,788][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00010 | loss1:0.0006 loss2:0.1164 loss3:0.0101 | AUC:0.8374 Anomaly AUC:0.6599
[2023-09-08 16:04:01,634][main.py][line:105][INFO] [Epoch:38/50]: lr:0.00010 | loss1:0.0050 loss2:0.1926 loss3:0.0232 | AUC:0.8486 Anomaly AUC:0.6861
[2023-09-08 16:04:20,478][main.py][line:105][INFO] [Epoch:39/50]: lr:0.00010 | loss1:0.0003 loss2:0.1105 loss3:0.0105 | AUC:0.8572 Anomaly AUC:0.6949
[2023-09-08 16:04:31,841][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 16:04:31,961][main.py][line:156][INFO] total params:7.5298M
[2023-09-08 16:04:31,961][main.py][line:159][INFO] Training Mode
[2023-09-08 16:04:31,962][main.py][line:77][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 16:04:31,962][main.py][line:78][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 16:04:40,049][main.py][line:81][INFO] Random initialize AUCAUC:0.4652 Anomaly AUC:0.46786
[2023-09-08 16:04:58,420][main.py][line:105][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.3002 loss2:1.1699 loss3:0.3419 | AUC:0.8189 Anomaly AUC:0.6837
[2023-09-08 16:05:16,567][main.py][line:105][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.0327 loss2:0.8230 loss3:0.2394 | AUC:0.8244 Anomaly AUC:0.6883
[2023-09-08 16:05:34,903][main.py][line:105][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.0227 loss2:0.7298 loss3:0.1689 | AUC:0.8127 Anomaly AUC:0.6634
[2023-09-08 16:05:53,328][main.py][line:105][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.0198 loss2:0.6505 loss3:0.1184 | AUC:0.8301 Anomaly AUC:0.6878
[2023-09-08 16:06:11,826][main.py][line:105][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0150 loss2:0.5802 loss3:0.0959 | AUC:0.8313 Anomaly AUC:0.6800
[2023-09-08 16:06:30,456][main.py][line:105][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0135 loss2:0.5214 loss3:0.0754 | AUC:0.8356 Anomaly AUC:0.6952
[2023-09-08 16:06:49,084][main.py][line:105][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0101 loss2:0.4898 loss3:0.0715 | AUC:0.8501 Anomaly AUC:0.6966
[2023-09-08 16:07:07,801][main.py][line:105][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0078 loss2:0.4211 loss3:0.0467 | AUC:0.8518 Anomaly AUC:0.6911
[2023-09-08 16:07:26,431][main.py][line:105][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0081 loss2:0.4016 loss3:0.0428 | AUC:0.8433 Anomaly AUC:0.6870
[2023-09-08 16:07:45,309][main.py][line:105][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0061 loss2:0.3656 loss3:0.0341 | AUC:0.8558 Anomaly AUC:0.6900
[2023-09-08 16:08:03,998][main.py][line:105][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0037 loss2:0.3229 loss3:0.0248 | AUC:0.8562 Anomaly AUC:0.6898
[2023-09-08 16:08:22,833][main.py][line:105][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0039 loss2:0.3013 loss3:0.0209 | AUC:0.8611 Anomaly AUC:0.6966
[2023-09-08 16:08:41,498][main.py][line:105][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0060 loss2:0.2964 loss3:0.0238 | AUC:0.8562 Anomaly AUC:0.6869
[2023-09-08 16:09:00,257][main.py][line:105][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0035 loss2:0.2780 loss3:0.0202 | AUC:0.8594 Anomaly AUC:0.6995
[2023-09-08 16:09:18,994][main.py][line:105][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0040 loss2:0.2627 loss3:0.0190 | AUC:0.8546 Anomaly AUC:0.6874
[2023-09-08 16:09:37,836][main.py][line:105][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0011 loss2:0.2279 loss3:0.0133 | AUC:0.8593 Anomaly AUC:0.6889
[2023-09-08 16:09:56,492][main.py][line:105][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0021 loss2:0.2197 loss3:0.0127 | AUC:0.8454 Anomaly AUC:0.6723
[2023-09-08 16:10:15,270][main.py][line:105][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.1022 loss2:0.6460 loss3:0.0992 | AUC:0.8356 Anomaly AUC:0.6760
[2023-09-08 16:10:34,015][main.py][line:105][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0027 loss2:0.2853 loss3:0.0220 | AUC:0.8571 Anomaly AUC:0.6913
[2023-09-08 16:10:52,759][main.py][line:105][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0020 loss2:0.2330 loss3:0.0153 | AUC:0.8613 Anomaly AUC:0.6931
[2023-09-08 16:11:11,572][main.py][line:105][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0014 loss2:0.2132 loss3:0.0132 | AUC:0.8612 Anomaly AUC:0.6890
[2023-09-08 16:11:30,384][main.py][line:105][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0013 loss2:0.2031 loss3:0.0123 | AUC:0.8620 Anomaly AUC:0.6952
[2023-09-08 16:11:49,162][main.py][line:105][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0010 loss2:0.1915 loss3:0.0116 | AUC:0.8621 Anomaly AUC:0.6935
[2023-09-08 16:12:07,942][main.py][line:105][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0009 loss2:0.1837 loss3:0.0111 | AUC:0.8641 Anomaly AUC:0.6955
[2023-09-08 16:12:26,659][main.py][line:105][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0008 loss2:0.1769 loss3:0.0107 | AUC:0.8635 Anomaly AUC:0.6941
[2023-09-08 16:12:45,486][main.py][line:105][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0007 loss2:0.1701 loss3:0.0105 | AUC:0.8652 Anomaly AUC:0.6953
[2023-09-08 16:13:04,452][main.py][line:105][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0040 loss2:0.1912 loss3:0.0148 | AUC:0.8490 Anomaly AUC:0.6727
[2023-09-08 16:13:23,283][main.py][line:105][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0018 loss2:0.1762 loss3:0.0135 | AUC:0.8567 Anomaly AUC:0.6927
[2023-09-08 16:13:42,175][main.py][line:105][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0019 loss2:0.1599 loss3:0.0116 | AUC:0.8510 Anomaly AUC:0.6856
[2023-09-08 16:14:00,976][main.py][line:105][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0047 loss2:0.1820 loss3:0.0159 | AUC:0.8545 Anomaly AUC:0.6925
[2023-09-08 16:14:19,829][main.py][line:105][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0013 loss2:0.1507 loss3:0.0119 | AUC:0.8610 Anomaly AUC:0.6992
[2023-09-08 16:14:38,787][main.py][line:105][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.0023 loss2:0.1458 loss3:0.0124 | AUC:0.8556 Anomaly AUC:0.6899
[2023-09-08 16:14:57,716][main.py][line:105][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.0015 loss2:0.1550 loss3:0.0133 | AUC:0.8623 Anomaly AUC:0.6943
[2023-09-08 16:15:16,661][main.py][line:105][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.0026 loss2:0.1435 loss3:0.0138 | AUC:0.8500 Anomaly AUC:0.6875
[2023-09-08 16:15:35,527][main.py][line:105][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.0196 loss2:0.2770 loss3:0.0361 | AUC:0.8306 Anomaly AUC:0.7041
[2023-09-08 16:15:54,372][main.py][line:105][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.0027 loss2:0.2223 loss3:0.0206 | AUC:0.8564 Anomaly AUC:0.6950
[2023-09-08 16:16:13,159][main.py][line:105][INFO] [Epoch:37/50]: lr:0.00010 | loss1:0.0007 loss2:0.1316 loss3:0.0119 | AUC:0.8568 Anomaly AUC:0.6892
[2023-09-08 16:16:32,018][main.py][line:105][INFO] [Epoch:38/50]: lr:0.00010 | loss1:0.0007 loss2:0.1189 loss3:0.0108 | AUC:0.8544 Anomaly AUC:0.6899
[2023-09-08 16:16:50,930][main.py][line:105][INFO] [Epoch:39/50]: lr:0.00010 | loss1:0.0004 loss2:0.1125 loss3:0.0104 | AUC:0.8585 Anomaly AUC:0.6906
[2023-09-08 16:17:09,827][main.py][line:105][INFO] [Epoch:40/50]: lr:0.00010 | loss1:0.0004 loss2:0.1058 loss3:0.0099 | AUC:0.8579 Anomaly AUC:0.6879
[2023-09-08 16:17:28,759][main.py][line:105][INFO] [Epoch:41/50]: lr:0.00010 | loss1:0.0006 loss2:0.1026 loss3:0.0099 | AUC:0.8545 Anomaly AUC:0.6800
[2023-09-08 16:17:47,653][main.py][line:105][INFO] [Epoch:42/50]: lr:0.00010 | loss1:0.0017 loss2:0.1115 loss3:0.0124 | AUC:0.8618 Anomaly AUC:0.6920
[2023-09-08 16:18:06,590][main.py][line:105][INFO] [Epoch:43/50]: lr:0.00010 | loss1:0.0003 loss2:0.0943 loss3:0.0100 | AUC:0.8643 Anomaly AUC:0.6922
[2023-09-08 16:18:25,459][main.py][line:105][INFO] [Epoch:44/50]: lr:0.00010 | loss1:0.0003 loss2:0.0891 loss3:0.0095 | AUC:0.8643 Anomaly AUC:0.6930
[2023-09-08 16:18:44,437][main.py][line:105][INFO] [Epoch:45/50]: lr:0.00010 | loss1:0.0191 loss2:0.1359 loss3:0.0229 | AUC:0.8125 Anomaly AUC:0.6921
[2023-09-08 16:19:03,609][main.py][line:105][INFO] [Epoch:46/50]: lr:0.00010 | loss1:0.0023 loss2:0.1306 loss3:0.0205 | AUC:0.8595 Anomaly AUC:0.7033
[2023-09-08 16:19:22,568][main.py][line:105][INFO] [Epoch:47/50]: lr:0.00010 | loss1:0.0004 loss2:0.0857 loss3:0.0111 | AUC:0.8640 Anomaly AUC:0.6997
[2023-09-08 16:19:41,508][main.py][line:105][INFO] [Epoch:48/50]: lr:0.00010 | loss1:0.0004 loss2:0.0798 loss3:0.0104 | AUC:0.8687 Anomaly AUC:0.7055
[2023-09-08 16:20:00,320][main.py][line:105][INFO] [Epoch:49/50]: lr:0.00010 | loss1:0.0127 loss2:0.1729 loss3:0.0277 | AUC:0.8594 Anomaly AUC:0.7009
[2023-09-08 16:20:19,220][main.py][line:105][INFO] [Epoch:50/50]: lr:0.00010 | loss1:0.0008 loss2:0.0821 loss3:0.0113 | AUC:0.8575 Anomaly AUC:0.6984
[2023-09-08 16:20:19,243][main.py][line:113][INFO] Training completes in 15m 39s | best AUCAUC:0.8687 Anomaly AUC:0.7055

[2023-09-08 16:20:33,635][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 16:20:33,762][main.py][line:156][INFO] total params:7.5298M
[2023-09-08 16:20:33,762][main.py][line:165][INFO] Test Mode
[2023-09-08 16:20:33,762][main.py][line:36][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-09-08 16:20:41,721][infer.py][line:47][INFO] offline AUC:0.8701 AP:0.2813 FAR:0.0278 | Complete in 0m 8s

[2023-09-08 16:21:08,543][main.py][line:120][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 16:21:08,667][main.py][line:156][INFO] total params:7.5195M
[2023-09-08 16:21:08,667][main.py][line:165][INFO] Test Mode
[2023-09-08 16:21:08,667][main.py][line:36][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-09-08 16:21:08,678][main.py][line:46][INFO] self_attention.DR_DMU.Nmemory.memory_block size mismatch: load torch.Size([30, 512]) given torch.Size([10, 512])
[2023-09-08 16:30:37,897][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 10, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 16:30:41,011][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 16:30:41,011][main.py][line:168][INFO] Training Mode
[2023-09-08 16:30:41,012][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 16:30:41,012][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 16:30:49,170][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 16:31:07,364][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3580 loss2:1.1621 loss3:0.3261 | AUC:0.8121 Anomaly AUC:0.6739
[2023-09-08 16:31:25,360][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0455 loss2:0.8325 loss3:0.2229 | AUC:0.8152 Anomaly AUC:0.6726
[2023-09-08 16:31:43,557][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0271 loss2:0.7438 loss3:0.1565 | AUC:0.8008 Anomaly AUC:0.6755
[2023-09-08 16:32:02,242][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0222 loss2:0.6590 loss3:0.1010 | AUC:0.8269 Anomaly AUC:0.6845
[2023-09-08 16:32:20,967][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0199 loss2:0.6125 loss3:0.0788 | AUC:0.8229 Anomaly AUC:0.6792
[2023-09-08 16:32:39,624][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0143 loss2:0.5575 loss3:0.0639 | AUC:0.8356 Anomaly AUC:0.6819
[2023-09-08 16:32:58,363][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0091 loss2:0.4882 loss3:0.0399 | AUC:0.8364 Anomaly AUC:0.6749
[2023-09-08 16:33:17,204][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0086 loss2:0.4448 loss3:0.0312 | AUC:0.8307 Anomaly AUC:0.6732
[2023-09-08 16:33:36,164][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0066 loss2:0.4008 loss3:0.0271 | AUC:0.8400 Anomaly AUC:0.6796
[2023-09-08 16:33:54,863][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0086 loss2:0.3931 loss3:0.0285 | AUC:0.8338 Anomaly AUC:0.6748
[2023-09-08 16:34:13,710][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0041 loss2:0.3282 loss3:0.0188 | AUC:0.8422 Anomaly AUC:0.6731
[2023-09-08 16:34:32,429][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0038 loss2:0.3039 loss3:0.0175 | AUC:0.8372 Anomaly AUC:0.6760
[2023-09-08 16:34:51,279][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0501 loss2:0.5177 loss3:0.0557 | AUC:0.8222 Anomaly AUC:0.6677
[2023-09-08 16:35:10,106][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0063 loss2:0.3703 loss3:0.0300 | AUC:0.8411 Anomaly AUC:0.6721
[2023-09-08 16:35:28,890][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0030 loss2:0.2882 loss3:0.0166 | AUC:0.8457 Anomaly AUC:0.6786
[2023-09-08 16:35:47,714][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0025 loss2:0.2614 loss3:0.0139 | AUC:0.8428 Anomaly AUC:0.6765
[2023-09-08 16:36:06,396][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0032 loss2:0.2480 loss3:0.0140 | AUC:0.8435 Anomaly AUC:0.6753
[2023-09-08 16:36:25,245][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0021 loss2:0.2301 loss3:0.0127 | AUC:0.8493 Anomaly AUC:0.6742
[2023-09-08 16:36:44,033][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0012 loss2:0.2165 loss3:0.0115 | AUC:0.8487 Anomaly AUC:0.6760
[2023-09-08 16:37:02,846][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0969 loss2:0.4701 loss3:0.0650 | AUC:0.8247 Anomaly AUC:0.6523
[2023-09-08 16:37:21,713][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0068 loss2:0.5549 loss3:0.0701 | AUC:0.8330 Anomaly AUC:0.6703
[2023-09-08 16:37:40,538][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0035 loss2:0.3117 loss3:0.0236 | AUC:0.8418 Anomaly AUC:0.6758
[2023-09-08 16:37:59,484][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0030 loss2:0.2557 loss3:0.0160 | AUC:0.8432 Anomaly AUC:0.6795
[2023-09-08 16:38:18,306][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0021 loss2:0.2328 loss3:0.0133 | AUC:0.8446 Anomaly AUC:0.6775
[2023-09-08 16:38:37,106][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0017 loss2:0.2173 loss3:0.0120 | AUC:0.8467 Anomaly AUC:0.6806
[2023-09-08 16:38:55,943][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0016 loss2:0.2067 loss3:0.0113 | AUC:0.8458 Anomaly AUC:0.6787
[2023-09-08 16:39:14,776][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0016 loss2:0.1992 loss3:0.0111 | AUC:0.8473 Anomaly AUC:0.6782
[2023-09-08 16:39:33,772][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0071 loss2:0.2170 loss3:0.0147 | AUC:0.8554 Anomaly AUC:0.6924
[2023-09-08 16:39:52,592][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0041 loss2:0.2075 loss3:0.0160 | AUC:0.8491 Anomaly AUC:0.6887
[2023-09-08 16:40:11,567][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0010 loss2:0.1804 loss3:0.0117 | AUC:0.8499 Anomaly AUC:0.6812
[2023-09-08 16:40:30,419][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0009 loss2:0.1682 loss3:0.0105 | AUC:0.8484 Anomaly AUC:0.6779
[2023-09-08 16:40:49,269][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0009 loss2:0.1630 loss3:0.0102 | AUC:0.8489 Anomaly AUC:0.6791
[2023-09-08 16:41:08,096][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0008 loss2:0.1557 loss3:0.0101 | AUC:0.8475 Anomaly AUC:0.6762
[2023-09-08 16:41:26,946][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0007 loss2:0.1503 loss3:0.0098 | AUC:0.8473 Anomaly AUC:0.6769
[2023-09-08 16:41:45,849][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0180 loss2:0.2840 loss3:0.0281 | AUC:0.8443 Anomaly AUC:0.6868
[2023-09-08 16:42:04,706][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0018 loss2:0.1618 loss3:0.0136 | AUC:0.8480 Anomaly AUC:0.6850
[2023-09-08 16:42:23,584][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0017 loss2:0.1470 loss3:0.0117 | AUC:0.8515 Anomaly AUC:0.6891
[2023-09-08 16:42:42,399][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0009 loss2:0.1358 loss3:0.0105 | AUC:0.8481 Anomaly AUC:0.6757
[2023-09-08 16:43:01,265][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0007 loss2:0.1291 loss3:0.0101 | AUC:0.8512 Anomaly AUC:0.6816
[2023-09-08 16:43:20,205][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0005 loss2:0.1227 loss3:0.0098 | AUC:0.8493 Anomaly AUC:0.6790
[2023-09-08 16:43:39,138][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0008 loss2:0.1191 loss3:0.0098 | AUC:0.8464 Anomaly AUC:0.6797
[2023-09-08 16:43:58,143][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0034 loss2:0.1457 loss3:0.0162 | AUC:0.8392 Anomaly AUC:0.6730
[2023-09-08 16:44:16,995][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0004 loss2:0.1129 loss3:0.0102 | AUC:0.8413 Anomaly AUC:0.6683
[2023-09-08 16:44:35,947][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0005 loss2:0.1062 loss3:0.0097 | AUC:0.8417 Anomaly AUC:0.6682
[2023-09-08 16:44:55,136][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0004 loss2:0.1015 loss3:0.0094 | AUC:0.8435 Anomaly AUC:0.6707
[2023-09-08 16:45:14,402][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0003 loss2:0.0973 loss3:0.0092 | AUC:0.8454 Anomaly AUC:0.6723
[2023-09-08 16:45:33,323][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0003 loss2:0.0936 loss3:0.0090 | AUC:0.8452 Anomaly AUC:0.6732
[2023-09-08 16:45:52,170][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0003 loss2:0.0900 loss3:0.0088 | AUC:0.8446 Anomaly AUC:0.6726
[2023-09-08 16:46:11,100][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0003 loss2:0.0868 loss3:0.0087 | AUC:0.8463 Anomaly AUC:0.6771
[2023-09-08 16:50:33,829][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 20, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 16:50:36,752][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 16:50:36,752][main.py][line:168][INFO] Training Mode
[2023-09-08 16:50:36,753][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 16:50:36,753][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 16:50:44,946][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 16:51:29,321][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 20, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 16:51:32,078][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 16:51:32,078][main.py][line:168][INFO] Training Mode
[2023-09-08 16:51:32,078][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 16:51:32,078][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 16:51:40,082][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 16:51:58,378][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3580 loss2:1.1621 loss3:0.3261 | AUC:0.8121 Anomaly AUC:0.6739
[2023-09-08 16:52:16,381][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0455 loss2:0.8325 loss3:0.2229 | AUC:0.8152 Anomaly AUC:0.6726
[2023-09-08 16:52:34,500][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0271 loss2:0.7438 loss3:0.1565 | AUC:0.8008 Anomaly AUC:0.6755
[2023-09-08 16:52:52,950][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0222 loss2:0.6590 loss3:0.1010 | AUC:0.8269 Anomaly AUC:0.6845
[2023-09-08 16:53:11,408][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0199 loss2:0.6125 loss3:0.0788 | AUC:0.8229 Anomaly AUC:0.6792
[2023-09-08 16:53:30,027][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0143 loss2:0.5575 loss3:0.0639 | AUC:0.8356 Anomaly AUC:0.6819
[2023-09-08 16:53:48,732][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0091 loss2:0.4882 loss3:0.0399 | AUC:0.8364 Anomaly AUC:0.6749
[2023-09-08 16:54:07,397][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0086 loss2:0.4448 loss3:0.0312 | AUC:0.8307 Anomaly AUC:0.6732
[2023-09-08 16:54:26,159][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0066 loss2:0.4008 loss3:0.0271 | AUC:0.8400 Anomaly AUC:0.6796
[2023-09-08 16:54:44,782][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0086 loss2:0.3931 loss3:0.0285 | AUC:0.8338 Anomaly AUC:0.6748
[2023-09-08 16:55:03,384][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0041 loss2:0.3282 loss3:0.0188 | AUC:0.8422 Anomaly AUC:0.6731
[2023-09-08 16:55:22,170][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0038 loss2:0.3039 loss3:0.0175 | AUC:0.8372 Anomaly AUC:0.6760
[2023-09-08 16:55:40,860][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0501 loss2:0.5177 loss3:0.0557 | AUC:0.8222 Anomaly AUC:0.6677
[2023-09-08 16:55:59,635][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0063 loss2:0.3703 loss3:0.0300 | AUC:0.8411 Anomaly AUC:0.6721
[2023-09-08 16:56:18,432][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0030 loss2:0.2882 loss3:0.0166 | AUC:0.8457 Anomaly AUC:0.6786
[2023-09-08 16:56:37,069][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0025 loss2:0.2614 loss3:0.0139 | AUC:0.8428 Anomaly AUC:0.6765
[2023-09-08 16:56:55,847][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0032 loss2:0.2480 loss3:0.0140 | AUC:0.8435 Anomaly AUC:0.6753
[2023-09-08 16:57:14,671][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0021 loss2:0.2301 loss3:0.0127 | AUC:0.8493 Anomaly AUC:0.6742
[2023-09-08 16:57:33,420][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0012 loss2:0.2165 loss3:0.0115 | AUC:0.8487 Anomaly AUC:0.6760
[2023-09-08 16:57:52,156][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0969 loss2:0.4701 loss3:0.0650 | AUC:0.8247 Anomaly AUC:0.6523
[2023-09-08 16:58:10,860][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0068 loss2:0.5549 loss3:0.0701 | AUC:0.8330 Anomaly AUC:0.6703
[2023-09-08 16:58:29,576][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0035 loss2:0.3117 loss3:0.0236 | AUC:0.8418 Anomaly AUC:0.6758
[2023-09-08 16:58:48,382][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0030 loss2:0.2557 loss3:0.0160 | AUC:0.8432 Anomaly AUC:0.6795
[2023-09-08 16:59:07,162][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0021 loss2:0.2328 loss3:0.0133 | AUC:0.8446 Anomaly AUC:0.6775
[2023-09-08 16:59:25,976][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0017 loss2:0.2173 loss3:0.0120 | AUC:0.8467 Anomaly AUC:0.6806
[2023-09-08 16:59:44,803][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0016 loss2:0.2067 loss3:0.0113 | AUC:0.8458 Anomaly AUC:0.6787
[2023-09-08 17:00:03,550][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0016 loss2:0.1992 loss3:0.0111 | AUC:0.8473 Anomaly AUC:0.6782
[2023-09-08 17:00:22,385][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0071 loss2:0.2170 loss3:0.0147 | AUC:0.8554 Anomaly AUC:0.6924
[2023-09-08 17:00:41,194][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0041 loss2:0.2075 loss3:0.0160 | AUC:0.8491 Anomaly AUC:0.6887
[2023-09-08 17:01:00,052][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0010 loss2:0.1804 loss3:0.0117 | AUC:0.8499 Anomaly AUC:0.6812
[2023-09-08 17:01:18,872][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0009 loss2:0.1682 loss3:0.0105 | AUC:0.8484 Anomaly AUC:0.6779
[2023-09-08 17:01:37,649][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0009 loss2:0.1630 loss3:0.0102 | AUC:0.8489 Anomaly AUC:0.6791
[2023-09-08 17:01:56,415][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0008 loss2:0.1557 loss3:0.0101 | AUC:0.8475 Anomaly AUC:0.6762
[2023-09-08 17:02:15,251][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0007 loss2:0.1503 loss3:0.0098 | AUC:0.8473 Anomaly AUC:0.6769
[2023-09-08 17:02:33,974][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0180 loss2:0.2840 loss3:0.0281 | AUC:0.8443 Anomaly AUC:0.6868
[2023-09-08 17:02:52,736][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0018 loss2:0.1618 loss3:0.0136 | AUC:0.8480 Anomaly AUC:0.6850
[2023-09-08 17:03:11,567][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0017 loss2:0.1470 loss3:0.0117 | AUC:0.8515 Anomaly AUC:0.6891
[2023-09-08 17:03:30,271][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0009 loss2:0.1358 loss3:0.0105 | AUC:0.8481 Anomaly AUC:0.6757
[2023-09-08 17:03:49,091][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0007 loss2:0.1291 loss3:0.0101 | AUC:0.8512 Anomaly AUC:0.6816
[2023-09-08 17:04:07,897][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0005 loss2:0.1227 loss3:0.0098 | AUC:0.8493 Anomaly AUC:0.6790
[2023-09-08 17:04:26,852][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0008 loss2:0.1191 loss3:0.0098 | AUC:0.8464 Anomaly AUC:0.6797
[2023-09-08 17:04:45,662][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0034 loss2:0.1457 loss3:0.0162 | AUC:0.8392 Anomaly AUC:0.6730
[2023-09-08 17:05:04,525][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0004 loss2:0.1129 loss3:0.0102 | AUC:0.8413 Anomaly AUC:0.6683
[2023-09-08 17:05:23,374][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0005 loss2:0.1062 loss3:0.0097 | AUC:0.8417 Anomaly AUC:0.6682
[2023-09-08 17:05:42,249][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0004 loss2:0.1015 loss3:0.0094 | AUC:0.8435 Anomaly AUC:0.6707
[2023-09-08 17:06:01,208][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0003 loss2:0.0973 loss3:0.0092 | AUC:0.8454 Anomaly AUC:0.6723
[2023-09-08 17:06:20,078][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0003 loss2:0.0936 loss3:0.0090 | AUC:0.8452 Anomaly AUC:0.6732
[2023-09-08 17:06:38,873][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0003 loss2:0.0900 loss3:0.0088 | AUC:0.8446 Anomaly AUC:0.6726
[2023-09-08 17:06:57,779][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0003 loss2:0.0868 loss3:0.0087 | AUC:0.8463 Anomaly AUC:0.6771
[2023-09-08 17:20:39,828][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 0, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 17:20:42,662][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 17:20:42,662][main.py][line:168][INFO] Training Mode
[2023-09-08 17:20:42,663][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 17:20:42,663][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 17:20:50,721][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 17:21:09,001][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3580 loss2:1.1621 loss3:0.3261 | AUC:0.8121 Anomaly AUC:0.6739
[2023-09-08 17:21:26,957][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0455 loss2:0.8325 loss3:0.2229 | AUC:0.8152 Anomaly AUC:0.6726
[2023-09-08 17:21:45,077][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0271 loss2:0.7438 loss3:0.1565 | AUC:0.8008 Anomaly AUC:0.6755
[2023-09-08 17:22:03,587][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0222 loss2:0.6590 loss3:0.1010 | AUC:0.8269 Anomaly AUC:0.6845
[2023-09-08 17:22:22,109][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0199 loss2:0.6125 loss3:0.0788 | AUC:0.8229 Anomaly AUC:0.6792
[2023-09-08 17:22:40,701][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0143 loss2:0.5575 loss3:0.0639 | AUC:0.8356 Anomaly AUC:0.6819
[2023-09-08 17:22:59,368][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0091 loss2:0.4882 loss3:0.0399 | AUC:0.8364 Anomaly AUC:0.6749
[2023-09-08 17:23:18,077][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0086 loss2:0.4448 loss3:0.0312 | AUC:0.8307 Anomaly AUC:0.6732
[2023-09-08 17:23:36,926][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0066 loss2:0.4008 loss3:0.0271 | AUC:0.8400 Anomaly AUC:0.6796
[2023-09-08 17:23:55,599][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0086 loss2:0.3931 loss3:0.0285 | AUC:0.8338 Anomaly AUC:0.6748
[2023-09-08 17:24:14,367][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0041 loss2:0.3282 loss3:0.0188 | AUC:0.8422 Anomaly AUC:0.6731
[2023-09-08 17:24:33,064][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0038 loss2:0.3039 loss3:0.0175 | AUC:0.8372 Anomaly AUC:0.6760
[2023-09-08 17:24:51,895][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0501 loss2:0.5177 loss3:0.0557 | AUC:0.8222 Anomaly AUC:0.6677
[2023-09-08 17:25:10,587][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0063 loss2:0.3703 loss3:0.0300 | AUC:0.8411 Anomaly AUC:0.6721
[2023-09-08 17:25:29,395][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0030 loss2:0.2882 loss3:0.0166 | AUC:0.8457 Anomaly AUC:0.6786
[2023-09-08 17:25:48,138][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0025 loss2:0.2614 loss3:0.0139 | AUC:0.8428 Anomaly AUC:0.6765
[2023-09-08 17:26:06,943][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0032 loss2:0.2480 loss3:0.0140 | AUC:0.8435 Anomaly AUC:0.6753
[2023-09-08 17:26:25,740][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0021 loss2:0.2301 loss3:0.0127 | AUC:0.8493 Anomaly AUC:0.6742
[2023-09-08 17:26:44,490][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0012 loss2:0.2165 loss3:0.0115 | AUC:0.8487 Anomaly AUC:0.6760
[2023-09-08 17:27:03,281][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0969 loss2:0.4701 loss3:0.0650 | AUC:0.8247 Anomaly AUC:0.6523
[2023-09-08 17:27:21,979][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0068 loss2:0.5549 loss3:0.0701 | AUC:0.8330 Anomaly AUC:0.6703
[2023-09-08 17:27:40,794][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0035 loss2:0.3117 loss3:0.0236 | AUC:0.8418 Anomaly AUC:0.6758
[2023-09-08 17:27:59,586][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0030 loss2:0.2557 loss3:0.0160 | AUC:0.8432 Anomaly AUC:0.6795
[2023-09-08 17:28:18,399][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0021 loss2:0.2328 loss3:0.0133 | AUC:0.8446 Anomaly AUC:0.6775
[2023-09-08 17:28:37,158][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0017 loss2:0.2173 loss3:0.0120 | AUC:0.8467 Anomaly AUC:0.6806
[2023-09-08 17:28:55,963][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0016 loss2:0.2067 loss3:0.0113 | AUC:0.8458 Anomaly AUC:0.6787
[2023-09-08 17:29:14,824][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0016 loss2:0.1992 loss3:0.0111 | AUC:0.8473 Anomaly AUC:0.6782
[2023-09-08 17:29:33,741][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0071 loss2:0.2170 loss3:0.0147 | AUC:0.8554 Anomaly AUC:0.6924
[2023-09-08 17:29:52,398][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0041 loss2:0.2075 loss3:0.0160 | AUC:0.8491 Anomaly AUC:0.6887
[2023-09-08 17:30:11,343][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0010 loss2:0.1804 loss3:0.0117 | AUC:0.8499 Anomaly AUC:0.6812
[2023-09-08 17:30:30,117][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0009 loss2:0.1682 loss3:0.0105 | AUC:0.8484 Anomaly AUC:0.6779
[2023-09-08 17:30:48,871][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0009 loss2:0.1630 loss3:0.0102 | AUC:0.8489 Anomaly AUC:0.6791
[2023-09-08 17:31:07,719][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0008 loss2:0.1557 loss3:0.0101 | AUC:0.8475 Anomaly AUC:0.6762
[2023-09-08 17:31:26,599][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0007 loss2:0.1503 loss3:0.0098 | AUC:0.8473 Anomaly AUC:0.6769
[2023-09-08 17:31:45,510][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0180 loss2:0.2840 loss3:0.0281 | AUC:0.8443 Anomaly AUC:0.6868
[2023-09-08 17:32:04,371][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0018 loss2:0.1618 loss3:0.0136 | AUC:0.8480 Anomaly AUC:0.6850
[2023-09-08 17:32:23,270][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0017 loss2:0.1470 loss3:0.0117 | AUC:0.8515 Anomaly AUC:0.6891
[2023-09-08 17:32:42,101][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0009 loss2:0.1358 loss3:0.0105 | AUC:0.8481 Anomaly AUC:0.6757
[2023-09-08 17:33:00,970][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0007 loss2:0.1291 loss3:0.0101 | AUC:0.8512 Anomaly AUC:0.6816
[2023-09-08 17:33:19,817][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0005 loss2:0.1227 loss3:0.0098 | AUC:0.8493 Anomaly AUC:0.6790
[2023-09-08 17:33:38,833][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0008 loss2:0.1191 loss3:0.0098 | AUC:0.8464 Anomaly AUC:0.6797
[2023-09-08 17:33:57,759][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0034 loss2:0.1457 loss3:0.0162 | AUC:0.8392 Anomaly AUC:0.6730
[2023-09-08 17:34:16,594][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0004 loss2:0.1129 loss3:0.0102 | AUC:0.8413 Anomaly AUC:0.6683
[2023-09-08 17:34:35,422][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0005 loss2:0.1062 loss3:0.0097 | AUC:0.8417 Anomaly AUC:0.6682
[2023-09-08 17:34:54,314][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0004 loss2:0.1015 loss3:0.0094 | AUC:0.8435 Anomaly AUC:0.6707
[2023-09-08 17:35:13,257][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0003 loss2:0.0973 loss3:0.0092 | AUC:0.8454 Anomaly AUC:0.6723
[2023-09-08 17:35:32,202][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0003 loss2:0.0936 loss3:0.0090 | AUC:0.8452 Anomaly AUC:0.6732
[2023-09-08 17:35:51,044][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0003 loss2:0.0900 loss3:0.0088 | AUC:0.8446 Anomaly AUC:0.6726
[2023-09-08 17:36:10,105][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0003 loss2:0.0868 loss3:0.0087 | AUC:0.8463 Anomaly AUC:0.6771
[2023-09-08 17:36:28,601][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.1105 loss2:0.1589 loss3:0.0743 | AUC:0.8261 Anomaly AUC:0.6889
[2023-09-08 17:36:46,834][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0029 loss2:0.0000 loss3:0.0206 | AUC:0.8133 Anomaly AUC:0.6768
[2023-09-08 17:37:05,185][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0057 loss2:0.1759 loss3:0.0201 | AUC:0.8455 Anomaly AUC:0.6843
[2023-09-08 17:37:24,135][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0013 loss2:0.1506 loss3:0.0121 | AUC:0.8571 Anomaly AUC:0.6986
[2023-09-08 17:37:42,968][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0009 loss2:0.1074 loss3:0.0098 | AUC:0.8513 Anomaly AUC:0.6974
[2023-09-08 17:38:01,700][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0019 loss2:0.1172 loss3:0.0110 | AUC:0.8458 Anomaly AUC:0.6801
[2023-09-08 17:38:20,542][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0006 loss2:0.0939 loss3:0.0094 | AUC:0.8500 Anomaly AUC:0.6835
[2023-09-08 17:38:39,370][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0005 loss2:0.0865 loss3:0.0089 | AUC:0.8508 Anomaly AUC:0.6814
[2023-09-08 17:38:58,300][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0005 loss2:0.0823 loss3:0.0087 | AUC:0.8507 Anomaly AUC:0.6829
[2023-09-08 17:39:17,177][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0004 loss2:0.0781 loss3:0.0086 | AUC:0.8507 Anomaly AUC:0.6837
[2023-09-08 17:39:36,213][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0033 loss2:0.0995 loss3:0.0119 | AUC:0.8493 Anomaly AUC:0.6886
[2023-09-08 17:39:55,072][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0005 loss2:0.0793 loss3:0.0096 | AUC:0.8521 Anomaly AUC:0.6896
[2023-09-08 17:40:14,087][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0004 loss2:0.0698 loss3:0.0086 | AUC:0.8496 Anomaly AUC:0.6825
[2023-09-08 17:40:33,002][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0003 loss2:0.0659 loss3:0.0084 | AUC:0.8524 Anomaly AUC:0.6865
[2023-09-08 17:40:51,917][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0003 loss2:0.0623 loss3:0.0082 | AUC:0.8519 Anomaly AUC:0.6865
[2023-09-08 17:41:10,889][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0003 loss2:0.0602 loss3:0.0081 | AUC:0.8515 Anomaly AUC:0.6835
[2023-09-08 17:41:29,793][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0003 loss2:0.0572 loss3:0.0079 | AUC:0.8515 Anomaly AUC:0.6849
[2023-09-08 17:41:48,803][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0002 loss2:0.0550 loss3:0.0078 | AUC:0.8522 Anomaly AUC:0.6857
[2023-09-08 17:42:07,735][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0052 loss2:0.0921 loss3:0.0142 | AUC:0.8455 Anomaly AUC:0.6972
[2023-09-08 17:42:26,612][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0013 loss2:0.0660 loss3:0.0116 | AUC:0.8451 Anomaly AUC:0.6863
[2023-09-08 17:42:45,580][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0003 loss2:0.0540 loss3:0.0086 | AUC:0.8534 Anomaly AUC:0.6874
[2023-09-08 17:43:04,535][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0003 loss2:0.0476 loss3:0.0079 | AUC:0.8536 Anomaly AUC:0.6857
[2023-09-08 17:43:23,460][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0007 loss2:0.0580 loss3:0.0093 | AUC:0.8520 Anomaly AUC:0.6866
[2023-09-08 17:43:42,356][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0002 loss2:0.0450 loss3:0.0079 | AUC:0.8548 Anomaly AUC:0.6918
[2023-09-08 17:44:01,205][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0002 loss2:0.0407 loss3:0.0074 | AUC:0.8537 Anomaly AUC:0.6831
[2023-09-08 17:44:20,150][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0002 loss2:0.0389 loss3:0.0072 | AUC:0.8537 Anomaly AUC:0.6845
[2023-09-08 17:44:39,049][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0002 loss2:0.0367 loss3:0.0069 | AUC:0.8530 Anomaly AUC:0.6814
[2023-09-08 17:44:58,001][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0001 loss2:0.0351 loss3:0.0066 | AUC:0.8512 Anomaly AUC:0.6803
[2023-09-08 17:45:16,958][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0162 loss2:0.1175 loss3:0.0269 | AUC:0.8062 Anomaly AUC:0.6919
[2023-09-08 17:45:35,955][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0043 loss2:0.1114 loss3:0.0243 | AUC:0.8369 Anomaly AUC:0.6748
[2023-09-08 17:45:54,922][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0008 loss2:0.0392 loss3:0.0098 | AUC:0.8423 Anomaly AUC:0.6750
[2023-09-08 17:46:13,906][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0015 loss2:0.0416 loss3:0.0101 | AUC:0.8362 Anomaly AUC:0.6739
[2023-09-08 17:46:32,857][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0012 loss2:0.0384 loss3:0.0095 | AUC:0.8450 Anomaly AUC:0.6766
[2023-09-08 17:46:51,712][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0004 loss2:0.0296 loss3:0.0076 | AUC:0.8450 Anomaly AUC:0.6762
[2023-09-08 17:47:10,674][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0002 loss2:0.0266 loss3:0.0067 | AUC:0.8465 Anomaly AUC:0.6768
[2023-09-08 17:47:29,792][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0002 loss2:0.0256 loss3:0.0065 | AUC:0.8438 Anomaly AUC:0.6723
[2023-09-08 17:47:48,889][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0001 loss2:0.0242 loss3:0.0061 | AUC:0.8442 Anomaly AUC:0.6721
[2023-09-08 17:48:08,032][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0001 loss2:0.0225 loss3:0.0059 | AUC:0.8452 Anomaly AUC:0.6739
[2023-09-08 17:48:37,840][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 17:48:40,655][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 17:48:40,656][main.py][line:168][INFO] Training Mode
[2023-09-08 17:48:40,656][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 17:48:40,656][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 17:48:48,759][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 17:49:09,529][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3262 loss2:1.1322 loss3:0.3181 | AUC:0.7969 Anomaly AUC:0.6682
[2023-09-08 17:49:30,094][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0478 loss2:0.8238 loss3:0.2107 | AUC:0.8239 Anomaly AUC:0.6698
[2023-09-08 17:49:50,878][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0265 loss2:0.7094 loss3:0.1155 | AUC:0.8168 Anomaly AUC:0.6588
[2023-09-08 17:50:11,762][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0207 loss2:0.6232 loss3:0.0649 | AUC:0.8281 Anomaly AUC:0.6657
[2023-09-08 17:50:32,780][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0148 loss2:0.5602 loss3:0.0434 | AUC:0.8361 Anomaly AUC:0.6723
[2023-09-08 17:50:53,889][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0103 loss2:0.4951 loss3:0.0321 | AUC:0.8478 Anomaly AUC:0.6779
[2023-09-08 17:51:14,908][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0073 loss2:0.4433 loss3:0.0232 | AUC:0.8478 Anomaly AUC:0.6770
[2023-09-08 17:51:36,061][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0066 loss2:0.3938 loss3:0.0203 | AUC:0.8434 Anomaly AUC:0.6826
[2023-09-08 17:51:57,344][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0048 loss2:0.3519 loss3:0.0168 | AUC:0.8444 Anomaly AUC:0.6747
[2023-09-08 17:52:18,512][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0033 loss2:0.3134 loss3:0.0143 | AUC:0.8440 Anomaly AUC:0.6595
[2023-09-08 17:52:39,636][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0050 loss2:0.2965 loss3:0.0134 | AUC:0.8448 Anomaly AUC:0.6653
[2023-09-08 17:53:00,796][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0077 loss2:0.2847 loss3:0.0145 | AUC:0.8470 Anomaly AUC:0.6712
[2023-09-08 17:53:22,041][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0020 loss2:0.2539 loss3:0.0118 | AUC:0.8449 Anomaly AUC:0.6627
[2023-09-08 17:53:43,309][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0023 loss2:0.2459 loss3:0.0116 | AUC:0.8439 Anomaly AUC:0.6615
[2023-09-08 17:54:04,500][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0031 loss2:0.2294 loss3:0.0115 | AUC:0.8455 Anomaly AUC:0.6785
[2023-09-08 17:54:25,666][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0042 loss2:0.2258 loss3:0.0114 | AUC:0.8456 Anomaly AUC:0.6720
[2023-09-08 17:54:46,859][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0050 loss2:0.2167 loss3:0.0117 | AUC:0.8476 Anomaly AUC:0.6743
[2023-09-08 17:55:08,212][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0027 loss2:0.2078 loss3:0.0108 | AUC:0.8414 Anomaly AUC:0.6620
[2023-09-08 17:55:29,573][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0059 loss2:0.2103 loss3:0.0116 | AUC:0.8524 Anomaly AUC:0.6825
[2023-09-08 17:55:50,794][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0009 loss2:0.1877 loss3:0.0100 | AUC:0.8567 Anomaly AUC:0.6792
[2023-09-08 17:56:12,018][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0014 loss2:0.1838 loss3:0.0103 | AUC:0.8514 Anomaly AUC:0.6872
[2023-09-08 17:56:33,375][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0121 loss2:0.1878 loss3:0.0125 | AUC:0.8534 Anomaly AUC:0.6844
[2023-09-08 17:56:54,771][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0072 loss2:0.1879 loss3:0.0121 | AUC:0.8601 Anomaly AUC:0.6943
[2023-09-08 17:57:16,023][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0055 loss2:0.1806 loss3:0.0118 | AUC:0.8448 Anomaly AUC:0.6685
[2023-09-08 17:57:37,172][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0022 loss2:0.1630 loss3:0.0102 | AUC:0.8446 Anomaly AUC:0.6754
[2023-09-08 17:57:58,438][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0003 loss2:0.1523 loss3:0.0093 | AUC:0.8518 Anomaly AUC:0.6807
[2023-09-08 17:58:19,666][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0003 loss2:0.1459 loss3:0.0088 | AUC:0.8512 Anomaly AUC:0.6804
[2023-09-08 17:58:40,919][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0002 loss2:0.1390 loss3:0.0085 | AUC:0.8484 Anomaly AUC:0.6791
[2023-09-08 17:59:02,375][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0002 loss2:0.1350 loss3:0.0083 | AUC:0.8513 Anomaly AUC:0.6839
[2023-09-08 17:59:23,581][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0018 loss2:0.1375 loss3:0.0083 | AUC:0.8529 Anomaly AUC:0.6872
[2023-09-08 17:59:44,808][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0123 loss2:0.1631 loss3:0.0112 | AUC:0.8529 Anomaly AUC:0.6673
[2023-09-08 18:00:06,105][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0117 loss2:0.1533 loss3:0.0110 | AUC:0.8428 Anomaly AUC:0.6642
[2023-09-08 18:00:27,471][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0081 loss2:0.1385 loss3:0.0103 | AUC:0.8375 Anomaly AUC:0.6740
[2023-09-08 18:00:48,667][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0048 loss2:0.1313 loss3:0.0101 | AUC:0.8442 Anomaly AUC:0.6690
[2023-09-08 18:01:09,882][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0032 loss2:0.1210 loss3:0.0087 | AUC:0.8380 Anomaly AUC:0.6640
[2023-09-08 18:01:31,175][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0009 loss2:0.1125 loss3:0.0077 | AUC:0.8479 Anomaly AUC:0.6656
[2023-09-08 18:01:52,553][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0002 loss2:0.1052 loss3:0.0069 | AUC:0.8506 Anomaly AUC:0.6705
[2023-09-08 18:02:13,783][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0002 loss2:0.1009 loss3:0.0063 | AUC:0.8483 Anomaly AUC:0.6675
[2023-09-08 18:02:35,064][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0002 loss2:0.0970 loss3:0.0057 | AUC:0.8386 Anomaly AUC:0.6493
[2023-09-08 18:02:56,416][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0159 loss2:0.1161 loss3:0.0081 | AUC:0.8433 Anomaly AUC:0.6607
[2023-09-08 18:03:17,865][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0081 loss2:0.1034 loss3:0.0065 | AUC:0.8424 Anomaly AUC:0.6782
[2023-09-08 18:03:39,316][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0105 loss2:0.1121 loss3:0.0074 | AUC:0.8353 Anomaly AUC:0.6806
[2023-09-08 18:04:00,657][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0171 loss2:0.1054 loss3:0.0076 | AUC:0.8258 Anomaly AUC:0.6641
[2023-09-08 18:04:22,010][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0057 loss2:0.0952 loss3:0.0057 | AUC:0.8404 Anomaly AUC:0.6658
[2023-09-08 18:04:43,396][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0040 loss2:0.0888 loss3:0.0047 | AUC:0.8523 Anomaly AUC:0.6955
[2023-09-08 18:05:04,893][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0089 loss2:0.0897 loss3:0.0051 | AUC:0.8472 Anomaly AUC:0.6852
[2023-09-08 18:05:26,283][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0026 loss2:0.0796 loss3:0.0030 | AUC:0.8510 Anomaly AUC:0.6807
[2023-09-08 18:05:47,532][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0023 loss2:0.0726 loss3:0.0016 | AUC:0.8421 Anomaly AUC:0.6714
[2023-09-08 18:06:08,899][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0001 loss2:0.0678 loss3:0.0003 | AUC:0.8429 Anomaly AUC:0.6719
[2023-09-08 18:06:30,282][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0001 loss2:0.0645 loss3:0.0002 | AUC:0.8309 Anomaly AUC:0.6396
[2023-09-08 18:06:51,720][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0030 loss2:0.0657 loss3:0.0007 | AUC:0.8486 Anomaly AUC:0.6773
[2023-09-08 18:07:13,020][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0068 loss2:0.0718 loss3:0.0017 | AUC:0.8433 Anomaly AUC:0.6598
[2023-09-08 18:07:34,393][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0068 loss2:0.0715 loss3:0.0015 | AUC:0.8440 Anomaly AUC:0.6762
[2023-09-08 18:07:55,725][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0037 loss2:0.0641 loss3:0.0010 | AUC:0.8238 Anomaly AUC:0.6546
[2023-09-08 18:08:17,125][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0088 loss2:0.0675 loss3:0.0020 | AUC:0.8178 Anomaly AUC:0.6452
[2023-09-08 18:08:38,446][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0015 loss2:0.0567 loss3:0.0011 | AUC:0.8415 Anomaly AUC:0.6774
[2023-09-08 18:08:59,843][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0015 loss2:0.0508 loss3:0.0005 | AUC:0.8415 Anomaly AUC:0.6819
[2023-09-08 18:09:21,159][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0079 loss2:0.0559 loss3:0.0014 | AUC:0.8085 Anomaly AUC:0.6454
[2023-09-08 18:09:42,558][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0040 loss2:0.0524 loss3:0.0014 | AUC:0.8235 Anomaly AUC:0.6584
[2023-09-08 18:10:03,827][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0004 loss2:0.0453 loss3:0.0004 | AUC:0.8190 Anomaly AUC:0.6448
[2023-09-08 18:10:25,212][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0001 loss2:0.0414 loss3:0.0002 | AUC:0.8225 Anomaly AUC:0.6473
[2023-09-08 18:10:46,591][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0002 loss2:0.0399 loss3:0.0002 | AUC:0.8338 Anomaly AUC:0.6503
[2023-09-08 18:11:07,940][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0034 loss2:0.0429 loss3:0.0011 | AUC:0.8289 Anomaly AUC:0.6601
[2023-09-08 18:11:29,427][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0073 loss2:0.0533 loss3:0.0019 | AUC:0.8409 Anomaly AUC:0.6762
[2023-09-08 18:11:50,905][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0021 loss2:0.0383 loss3:0.0007 | AUC:0.8277 Anomaly AUC:0.6706
[2023-09-08 18:12:12,287][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0039 loss2:0.0391 loss3:0.0009 | AUC:0.8288 Anomaly AUC:0.6672
[2023-09-08 18:12:33,677][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0019 loss2:0.0360 loss3:0.0008 | AUC:0.8207 Anomaly AUC:0.6682
[2023-09-08 18:12:55,133][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0018 loss2:0.0346 loss3:0.0007 | AUC:0.8297 Anomaly AUC:0.6755
[2023-09-08 18:13:16,518][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0001 loss2:0.0296 loss3:0.0003 | AUC:0.8351 Anomaly AUC:0.6748
[2023-09-08 18:13:37,970][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0001 loss2:0.0283 loss3:0.0003 | AUC:0.8450 Anomaly AUC:0.6665
[2023-09-08 18:13:59,340][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0084 loss2:0.0400 loss3:0.0019 | AUC:0.8169 Anomaly AUC:0.6609
[2023-09-08 18:14:20,697][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0052 loss2:0.0372 loss3:0.0017 | AUC:0.8429 Anomaly AUC:0.6698
[2023-09-08 18:14:42,164][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0038 loss2:0.0305 loss3:0.0008 | AUC:0.8261 Anomaly AUC:0.6677
[2023-09-08 18:15:03,551][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0031 loss2:0.0284 loss3:0.0012 | AUC:0.8311 Anomaly AUC:0.6880
[2023-09-08 18:15:24,911][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0006 loss2:0.0249 loss3:0.0005 | AUC:0.8285 Anomaly AUC:0.6704
[2023-09-08 18:15:46,335][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0001 loss2:0.0216 loss3:0.0002 | AUC:0.8353 Anomaly AUC:0.6732
[2023-09-08 18:16:07,762][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0001 loss2:0.0206 loss3:0.0002 | AUC:0.8392 Anomaly AUC:0.6736
[2023-09-08 18:16:29,138][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0001 loss2:0.0197 loss3:0.0002 | AUC:0.8418 Anomaly AUC:0.6744
[2023-09-08 18:16:50,495][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0001 loss2:0.0184 loss3:0.0002 | AUC:0.8415 Anomaly AUC:0.6737
[2023-09-08 18:17:12,080][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0001 loss2:0.0176 loss3:0.0002 | AUC:0.8419 Anomaly AUC:0.6715
[2023-09-08 18:17:33,538][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0001 loss2:0.0168 loss3:0.0002 | AUC:0.8418 Anomaly AUC:0.6699
[2023-09-08 18:17:55,016][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0001 loss2:0.0161 loss3:0.0002 | AUC:0.8428 Anomaly AUC:0.6710
[2023-09-08 18:18:16,518][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0001 loss2:0.0155 loss3:0.0002 | AUC:0.8404 Anomaly AUC:0.6696
[2023-09-08 18:18:37,948][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0001 loss2:0.0145 loss3:0.0002 | AUC:0.8418 Anomaly AUC:0.6692
[2023-09-08 18:18:59,368][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0001 loss2:0.0142 loss3:0.0002 | AUC:0.8405 Anomaly AUC:0.6690
[2023-09-08 18:19:20,795][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0001 loss2:0.0136 loss3:0.0002 | AUC:0.8415 Anomaly AUC:0.6677
[2023-09-08 18:19:42,174][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0001 loss2:0.0125 loss3:0.0002 | AUC:0.8437 Anomaly AUC:0.6690
[2023-09-08 18:20:03,511][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0001 loss2:0.0120 loss3:0.0002 | AUC:0.8417 Anomaly AUC:0.6686
[2023-09-08 18:20:25,030][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0205 loss2:0.0513 loss3:0.0044 | AUC:0.8321 Anomaly AUC:0.6760
[2023-09-08 18:20:46,410][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0130 loss2:0.0336 loss3:0.0030 | AUC:0.8333 Anomaly AUC:0.6756
[2023-09-08 18:21:07,760][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0097 loss2:0.0276 loss3:0.0021 | AUC:0.8320 Anomaly AUC:0.6645
[2023-09-08 18:21:29,119][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0027 loss2:0.0146 loss3:0.0008 | AUC:0.8154 Anomaly AUC:0.6737
[2023-09-08 18:21:50,397][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.0033 loss2:0.0149 loss3:0.0010 | AUC:0.8219 Anomaly AUC:0.6747
[2023-09-08 18:22:11,725][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0065 loss2:0.0187 loss3:0.0013 | AUC:0.8362 Anomaly AUC:0.6821
[2023-09-08 18:22:33,092][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0001 loss2:0.0109 loss3:0.0004 | AUC:0.8387 Anomaly AUC:0.6645
[2023-09-08 18:22:54,416][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0002 loss2:0.0090 loss3:0.0003 | AUC:0.8416 Anomaly AUC:0.6650
[2023-09-08 18:23:15,708][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0003 loss2:0.0083 loss3:0.0002 | AUC:0.8440 Anomaly AUC:0.6686
[2023-09-08 18:23:37,148][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0024 loss2:0.0103 loss3:0.0006 | AUC:0.8324 Anomaly AUC:0.6656
[2023-09-08 18:23:58,626][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0002 loss2:0.0077 loss3:0.0004 | AUC:0.8292 Anomaly AUC:0.6548
[2023-09-08 18:24:20,079][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0001 loss2:0.0070 loss3:0.0003 | AUC:0.8310 Anomaly AUC:0.6567
[2023-09-08 18:24:20,103][main.py][line:116][INFO] Training completes in 35m 31s | best AUCAUC:0.8601 Anomaly AUC:0.6943

[2023-09-08 18:27:31,209][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 18:27:34,078][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 18:27:34,079][main.py][line:168][INFO] Training Mode
[2023-09-08 18:27:34,079][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 18:27:34,079][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 18:27:42,104][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 18:28:00,494][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3561 loss2:1.1609 loss3:0.3260 | AUC:0.8097 Anomaly AUC:0.6761
[2023-09-08 18:28:18,528][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0456 loss2:0.8332 loss3:0.2223 | AUC:0.8185 Anomaly AUC:0.6773
[2023-09-08 18:28:36,772][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0263 loss2:0.7389 loss3:0.1530 | AUC:0.8138 Anomaly AUC:0.6741
[2023-09-08 18:28:55,395][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0255 loss2:0.6757 loss3:0.1059 | AUC:0.8116 Anomaly AUC:0.6731
[2023-09-08 18:29:13,968][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0200 loss2:0.6253 loss3:0.0797 | AUC:0.8245 Anomaly AUC:0.6716
[2023-09-08 18:29:32,608][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0109 loss2:0.5411 loss3:0.0501 | AUC:0.8335 Anomaly AUC:0.6742
[2023-09-08 18:29:51,289][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0577 loss2:0.6224 loss3:0.0706 | AUC:0.8163 Anomaly AUC:0.6734
[2023-09-08 18:30:10,007][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0082 loss2:0.4869 loss3:0.0398 | AUC:0.8261 Anomaly AUC:0.6733
[2023-09-08 18:30:28,875][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0077 loss2:0.4412 loss3:0.0309 | AUC:0.8261 Anomaly AUC:0.6699
[2023-09-08 18:30:47,676][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0064 loss2:0.4033 loss3:0.0257 | AUC:0.8287 Anomaly AUC:0.6662
[2023-09-08 18:31:06,581][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0068 loss2:0.3808 loss3:0.0243 | AUC:0.8360 Anomaly AUC:0.6798
[2023-09-08 18:31:25,412][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0052 loss2:0.3458 loss3:0.0204 | AUC:0.8404 Anomaly AUC:0.6748
[2023-09-08 18:31:44,207][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0058 loss2:0.3205 loss3:0.0177 | AUC:0.8437 Anomaly AUC:0.6793
[2023-09-08 18:32:03,051][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0034 loss2:0.3049 loss3:0.0179 | AUC:0.8381 Anomaly AUC:0.6680
[2023-09-08 18:32:22,023][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0031 loss2:0.2748 loss3:0.0148 | AUC:0.8446 Anomaly AUC:0.6801
[2023-09-08 18:32:40,758][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0025 loss2:0.2588 loss3:0.0138 | AUC:0.8440 Anomaly AUC:0.6767
[2023-09-08 18:32:59,558][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0822 loss2:0.4998 loss3:0.0692 | AUC:0.7905 Anomaly AUC:0.6538
[2023-09-08 18:33:18,372][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0055 loss2:0.4282 loss3:0.0352 | AUC:0.8379 Anomaly AUC:0.6802
[2023-09-08 18:33:37,162][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0036 loss2:0.2923 loss3:0.0188 | AUC:0.8443 Anomaly AUC:0.6807
[2023-09-08 18:33:56,063][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0027 loss2:0.2553 loss3:0.0147 | AUC:0.8496 Anomaly AUC:0.6850
[2023-09-08 18:34:14,815][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0018 loss2:0.2331 loss3:0.0127 | AUC:0.8486 Anomaly AUC:0.6798
[2023-09-08 18:34:33,641][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0064 loss2:0.2532 loss3:0.0151 | AUC:0.8410 Anomaly AUC:0.6704
[2023-09-08 18:34:52,572][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0016 loss2:0.2212 loss3:0.0130 | AUC:0.8495 Anomaly AUC:0.6811
[2023-09-08 18:35:11,321][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0011 loss2:0.2001 loss3:0.0114 | AUC:0.8458 Anomaly AUC:0.6739
[2023-09-08 18:35:30,213][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0025 loss2:0.1969 loss3:0.0124 | AUC:0.8519 Anomaly AUC:0.6799
[2023-09-08 18:35:48,995][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0016 loss2:0.1863 loss3:0.0115 | AUC:0.8479 Anomaly AUC:0.6754
[2023-09-08 18:36:07,863][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0046 loss2:0.1968 loss3:0.0139 | AUC:0.8285 Anomaly AUC:0.6554
[2023-09-08 18:36:26,647][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0024 loss2:0.1912 loss3:0.0140 | AUC:0.8563 Anomaly AUC:0.6919
[2023-09-08 18:36:45,531][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0009 loss2:0.1653 loss3:0.0108 | AUC:0.8526 Anomaly AUC:0.6833
[2023-09-08 18:37:04,393][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0007 loss2:0.1572 loss3:0.0104 | AUC:0.8585 Anomaly AUC:0.6891
[2023-09-08 18:37:23,299][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0006 loss2:0.1498 loss3:0.0100 | AUC:0.8590 Anomaly AUC:0.6901
[2023-09-08 18:37:42,101][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0005 loss2:0.1450 loss3:0.0099 | AUC:0.8570 Anomaly AUC:0.6874
[2023-09-08 18:38:00,991][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0451 loss2:0.4641 loss3:0.0566 | AUC:0.8098 Anomaly AUC:0.6611
[2023-09-08 18:38:19,936][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0030 loss2:0.2316 loss3:0.0182 | AUC:0.8452 Anomaly AUC:0.6770
[2023-09-08 18:38:38,866][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0012 loss2:0.1568 loss3:0.0119 | AUC:0.8426 Anomaly AUC:0.6696
[2023-09-08 18:38:57,819][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0008 loss2:0.1419 loss3:0.0106 | AUC:0.8482 Anomaly AUC:0.6748
[2023-09-08 18:39:16,614][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0007 loss2:0.1342 loss3:0.0103 | AUC:0.8432 Anomaly AUC:0.6640
[2023-09-08 18:39:35,570][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0006 loss2:0.1293 loss3:0.0100 | AUC:0.8481 Anomaly AUC:0.6748
[2023-09-08 18:39:54,502][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0006 loss2:0.1223 loss3:0.0098 | AUC:0.8460 Anomaly AUC:0.6705
[2023-09-08 18:40:13,387][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0103 loss2:0.2003 loss3:0.0223 | AUC:0.8380 Anomaly AUC:0.6655
[2023-09-08 18:40:32,321][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0007 loss2:0.1213 loss3:0.0113 | AUC:0.8475 Anomaly AUC:0.6711
[2023-09-08 18:40:51,186][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0005 loss2:0.1099 loss3:0.0101 | AUC:0.8463 Anomaly AUC:0.6702
[2023-09-08 18:41:10,207][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0051 loss2:0.1434 loss3:0.0152 | AUC:0.8433 Anomaly AUC:0.6814
[2023-09-08 18:41:29,049][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0007 loss2:0.1073 loss3:0.0113 | AUC:0.8479 Anomaly AUC:0.6796
[2023-09-08 18:41:47,999][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0004 loss2:0.0987 loss3:0.0100 | AUC:0.8473 Anomaly AUC:0.6758
[2023-09-08 18:42:07,136][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0017 loss2:0.0971 loss3:0.0107 | AUC:0.8464 Anomaly AUC:0.6774
[2023-09-08 18:42:26,046][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0004 loss2:0.0906 loss3:0.0096 | AUC:0.8432 Anomaly AUC:0.6756
[2023-09-08 18:42:44,996][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0004 loss2:0.0866 loss3:0.0094 | AUC:0.8458 Anomaly AUC:0.6761
[2023-09-08 18:43:03,926][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0003 loss2:0.0825 loss3:0.0092 | AUC:0.8456 Anomaly AUC:0.6775
[2023-09-08 18:43:22,869][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0003 loss2:0.0788 loss3:0.0090 | AUC:0.8442 Anomaly AUC:0.6731
[2023-09-08 18:43:41,940][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0003 loss2:0.0754 loss3:0.0089 | AUC:0.8450 Anomaly AUC:0.6770
[2023-09-08 18:44:00,877][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0002 loss2:0.0731 loss3:0.0088 | AUC:0.8450 Anomaly AUC:0.6769
[2023-09-08 18:44:19,836][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0002 loss2:0.0693 loss3:0.0086 | AUC:0.8446 Anomaly AUC:0.6763
[2023-09-08 18:44:38,863][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0119 loss2:0.1497 loss3:0.0186 | AUC:0.8347 Anomaly AUC:0.6564
[2023-09-08 18:44:57,855][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0020 loss2:0.1106 loss3:0.0156 | AUC:0.8450 Anomaly AUC:0.6687
[2023-09-08 18:45:16,785][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0007 loss2:0.0719 loss3:0.0106 | AUC:0.8426 Anomaly AUC:0.6636
[2023-09-08 18:45:35,736][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0002 loss2:0.0614 loss3:0.0091 | AUC:0.8438 Anomaly AUC:0.6633
[2023-09-08 18:45:54,639][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0039 loss2:0.0828 loss3:0.0142 | AUC:0.8446 Anomaly AUC:0.6677
[2023-09-08 18:46:13,656][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0006 loss2:0.0623 loss3:0.0103 | AUC:0.8440 Anomaly AUC:0.6671
[2023-09-08 18:46:32,586][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0003 loss2:0.0543 loss3:0.0090 | AUC:0.8431 Anomaly AUC:0.6606
[2023-09-08 18:46:51,589][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0002 loss2:0.0506 loss3:0.0086 | AUC:0.8420 Anomaly AUC:0.6612
[2023-09-08 18:47:10,579][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0082 loss2:0.1408 loss3:0.0283 | AUC:0.8411 Anomaly AUC:0.6722
[2023-09-08 18:47:51,514][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 18:47:54,260][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 18:47:54,261][main.py][line:168][INFO] Training Mode
[2023-09-08 18:47:54,261][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 18:47:54,261][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 18:48:02,237][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 18:48:20,461][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3561 loss2:1.1609 loss3:0.3260 | AUC:0.8097 Anomaly AUC:0.6761
[2023-09-08 18:48:38,428][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0456 loss2:0.8332 loss3:0.2223 | AUC:0.8185 Anomaly AUC:0.6773
[2023-09-08 18:48:56,694][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0263 loss2:0.7389 loss3:0.1530 | AUC:0.8138 Anomaly AUC:0.6741
[2023-09-08 18:49:15,142][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0255 loss2:0.6757 loss3:0.1059 | AUC:0.8116 Anomaly AUC:0.6731
[2023-09-08 18:49:33,731][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0200 loss2:0.6253 loss3:0.0797 | AUC:0.8245 Anomaly AUC:0.6716
[2023-09-08 18:49:52,204][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0109 loss2:0.5411 loss3:0.0501 | AUC:0.8335 Anomaly AUC:0.6742
[2023-09-08 18:50:10,788][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0577 loss2:0.6224 loss3:0.0706 | AUC:0.8163 Anomaly AUC:0.6734
[2023-09-08 18:50:29,480][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0082 loss2:0.4869 loss3:0.0398 | AUC:0.8261 Anomaly AUC:0.6733
[2023-09-08 18:50:48,250][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0077 loss2:0.4412 loss3:0.0309 | AUC:0.8261 Anomaly AUC:0.6699
[2023-09-08 18:51:06,871][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0064 loss2:0.4033 loss3:0.0257 | AUC:0.8287 Anomaly AUC:0.6662
[2023-09-08 18:51:25,629][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0068 loss2:0.3808 loss3:0.0243 | AUC:0.8360 Anomaly AUC:0.6798
[2023-09-08 18:51:44,301][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0052 loss2:0.3458 loss3:0.0204 | AUC:0.8404 Anomaly AUC:0.6748
[2023-09-08 18:52:02,916][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0058 loss2:0.3205 loss3:0.0177 | AUC:0.8437 Anomaly AUC:0.6793
[2023-09-08 18:52:21,665][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0034 loss2:0.3049 loss3:0.0179 | AUC:0.8381 Anomaly AUC:0.6680
[2023-09-08 18:52:40,378][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0031 loss2:0.2748 loss3:0.0148 | AUC:0.8446 Anomaly AUC:0.6801
[2023-09-08 18:52:59,138][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0025 loss2:0.2588 loss3:0.0138 | AUC:0.8440 Anomaly AUC:0.6767
[2023-09-08 18:53:17,925][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0822 loss2:0.4998 loss3:0.0692 | AUC:0.7905 Anomaly AUC:0.6538
[2023-09-08 18:53:36,720][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0055 loss2:0.4282 loss3:0.0352 | AUC:0.8379 Anomaly AUC:0.6802
[2023-09-08 18:53:55,528][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0036 loss2:0.2923 loss3:0.0188 | AUC:0.8443 Anomaly AUC:0.6807
[2023-09-08 18:54:14,312][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0027 loss2:0.2553 loss3:0.0147 | AUC:0.8496 Anomaly AUC:0.6850
[2023-09-08 18:54:33,018][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0018 loss2:0.2331 loss3:0.0127 | AUC:0.8486 Anomaly AUC:0.6798
[2023-09-08 18:54:51,816][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0064 loss2:0.2532 loss3:0.0151 | AUC:0.8410 Anomaly AUC:0.6704
[2023-09-08 18:55:10,624][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0016 loss2:0.2212 loss3:0.0130 | AUC:0.8495 Anomaly AUC:0.6811
[2023-09-08 18:55:40,226][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 18:55:42,929][main.py][line:165][INFO] total params:7.0450M
[2023-09-08 18:55:42,929][main.py][line:168][INFO] Training Mode
[2023-09-08 18:55:42,930][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 18:55:42,930][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 18:55:48,412][main.py][line:82][INFO] Random initialize AUCAUC:0.6061 Anomaly AUC:0.57717
[2023-09-08 18:56:02,673][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.2837 loss2:1.1899 loss3:0.3571 | AUC:0.8008 Anomaly AUC:0.6638
[2023-09-08 18:56:16,608][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0305 loss2:0.8369 loss3:0.2740 | AUC:0.7914 Anomaly AUC:0.6633
[2023-09-08 18:56:30,551][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0164 loss2:0.7428 loss3:0.2297 | AUC:0.8100 Anomaly AUC:0.6597
[2023-09-08 18:56:44,650][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0189 loss2:0.6583 loss3:0.1776 | AUC:0.8157 Anomaly AUC:0.6677
[2023-09-08 18:56:58,968][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0148 loss2:0.5898 loss3:0.1372 | AUC:0.8111 Anomaly AUC:0.6621
[2023-09-08 18:57:13,402][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0120 loss2:0.5341 loss3:0.1129 | AUC:0.8160 Anomaly AUC:0.6692
[2023-09-08 18:57:27,887][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0080 loss2:0.4760 loss3:0.0860 | AUC:0.8221 Anomaly AUC:0.6699
[2023-09-08 18:57:42,450][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0074 loss2:0.4278 loss3:0.0711 | AUC:0.8258 Anomaly AUC:0.6703
[2023-09-08 18:57:57,080][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0068 loss2:0.3931 loss3:0.0574 | AUC:0.8264 Anomaly AUC:0.6803
[2023-09-08 18:58:11,469][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0082 loss2:0.3844 loss3:0.0683 | AUC:0.8286 Anomaly AUC:0.6702
[2023-09-08 18:58:25,869][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0052 loss2:0.3376 loss3:0.0464 | AUC:0.8309 Anomaly AUC:0.6710
[2023-09-08 18:58:40,385][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0042 loss2:0.3078 loss3:0.0347 | AUC:0.8255 Anomaly AUC:0.6626
[2023-09-08 18:58:54,860][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0029 loss2:0.2817 loss3:0.0262 | AUC:0.8344 Anomaly AUC:0.6837
[2023-09-08 18:59:09,290][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0050 loss2:0.2901 loss3:0.0308 | AUC:0.8355 Anomaly AUC:0.6757
[2023-09-08 18:59:23,813][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0031 loss2:0.2679 loss3:0.0262 | AUC:0.8411 Anomaly AUC:0.6698
[2023-09-08 18:59:38,307][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0017 loss2:0.2367 loss3:0.0173 | AUC:0.8509 Anomaly AUC:0.6848
[2023-09-08 18:59:52,895][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0019 loss2:0.2314 loss3:0.0164 | AUC:0.8444 Anomaly AUC:0.6751
[2023-09-08 19:00:07,358][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0033 loss2:0.2353 loss3:0.0184 | AUC:0.8371 Anomaly AUC:0.6634
[2023-09-08 19:00:21,731][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.1846 loss2:0.4444 loss3:0.0963 | AUC:0.8166 Anomaly AUC:0.6716
[2023-09-08 19:00:36,198][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0110 loss2:0.6571 loss3:0.0723 | AUC:0.8036 Anomaly AUC:0.6635
[2023-09-08 19:00:50,632][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0048 loss2:0.4074 loss3:0.0395 | AUC:0.8193 Anomaly AUC:0.6699
[2023-09-08 19:01:05,176][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0060 loss2:0.3049 loss3:0.0322 | AUC:0.8276 Anomaly AUC:0.6683
[2023-09-08 19:01:19,652][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0031 loss2:0.2547 loss3:0.0235 | AUC:0.8447 Anomaly AUC:0.6780
[2023-09-08 19:01:34,068][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0015 loss2:0.2284 loss3:0.0158 | AUC:0.8466 Anomaly AUC:0.6817
[2023-09-08 19:01:48,582][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0013 loss2:0.2136 loss3:0.0129 | AUC:0.8458 Anomaly AUC:0.6800
[2023-09-08 19:02:03,075][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0016 loss2:0.2055 loss3:0.0120 | AUC:0.8391 Anomaly AUC:0.6703
[2023-09-08 19:02:17,527][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0054 loss2:0.2311 loss3:0.0198 | AUC:0.8426 Anomaly AUC:0.6762
[2023-09-08 19:02:31,995][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0012 loss2:0.1952 loss3:0.0121 | AUC:0.8562 Anomaly AUC:0.6945
[2023-09-08 19:02:46,490][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0010 loss2:0.1839 loss3:0.0097 | AUC:0.8490 Anomaly AUC:0.6818
[2023-09-08 19:03:00,975][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0007 loss2:0.1754 loss3:0.0082 | AUC:0.8458 Anomaly AUC:0.6758
[2023-09-08 19:03:15,474][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0503 loss2:0.3453 loss3:0.0642 | AUC:0.8176 Anomaly AUC:0.6629
[2023-09-08 19:03:30,115][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0051 loss2:0.2901 loss3:0.0350 | AUC:0.8301 Anomaly AUC:0.6656
[2023-09-08 19:03:44,645][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0022 loss2:0.1847 loss3:0.0157 | AUC:0.8363 Anomaly AUC:0.6673
[2023-09-08 19:03:59,120][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0028 loss2:0.1741 loss3:0.0127 | AUC:0.8282 Anomaly AUC:0.6597
[2023-09-08 19:04:13,649][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0025 loss2:0.1732 loss3:0.0122 | AUC:0.8380 Anomaly AUC:0.6675
[2023-09-08 19:04:28,153][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0012 loss2:0.1583 loss3:0.0082 | AUC:0.8383 Anomaly AUC:0.6683
[2023-09-08 19:04:42,722][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0008 loss2:0.1470 loss3:0.0058 | AUC:0.8374 Anomaly AUC:0.6667
[2023-09-08 19:04:57,280][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0011 loss2:0.1440 loss3:0.0052 | AUC:0.8343 Anomaly AUC:0.6640
[2023-09-08 19:05:11,808][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0027 loss2:0.1556 loss3:0.0070 | AUC:0.8369 Anomaly AUC:0.6660
[2023-09-08 19:05:26,344][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0009 loss2:0.1361 loss3:0.0046 | AUC:0.8402 Anomaly AUC:0.6665
[2023-09-08 19:05:40,881][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0005 loss2:0.1277 loss3:0.0024 | AUC:0.8391 Anomaly AUC:0.6653
[2023-09-08 19:05:55,427][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0197 loss2:0.2794 loss3:0.0349 | AUC:0.8305 Anomaly AUC:0.6530
[2023-09-08 19:06:09,946][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0013 loss2:0.1413 loss3:0.0072 | AUC:0.8394 Anomaly AUC:0.6566
[2023-09-08 19:06:24,475][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0011 loss2:0.1278 loss3:0.0047 | AUC:0.8365 Anomaly AUC:0.6555
[2023-09-08 19:06:39,031][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0009 loss2:0.1212 loss3:0.0039 | AUC:0.8408 Anomaly AUC:0.6617
[2023-09-08 19:06:53,646][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0101 loss2:0.1644 loss3:0.0117 | AUC:0.8317 Anomaly AUC:0.6653
[2023-09-08 19:07:08,222][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0015 loss2:0.1352 loss3:0.0081 | AUC:0.8416 Anomaly AUC:0.6632
[2023-09-08 19:07:22,777][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0013 loss2:0.1114 loss3:0.0047 | AUC:0.8383 Anomaly AUC:0.6646
[2023-09-08 19:07:37,322][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0004 loss2:0.1002 loss3:0.0020 | AUC:0.8431 Anomaly AUC:0.6692
[2023-09-08 19:07:51,903][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0003 loss2:0.0957 loss3:0.0016 | AUC:0.8409 Anomaly AUC:0.6679
[2023-09-08 19:08:06,474][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0004 loss2:0.0909 loss3:0.0014 | AUC:0.8395 Anomaly AUC:0.6650
[2023-09-08 19:08:21,014][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0003 loss2:0.0868 loss3:0.0013 | AUC:0.8405 Anomaly AUC:0.6637
[2023-09-08 19:08:41,736][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 19:08:44,434][main.py][line:165][INFO] total params:7.0450M
[2023-09-08 19:08:44,434][main.py][line:168][INFO] Training Mode
[2023-09-08 19:08:44,434][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 19:08:44,435][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 19:08:49,843][main.py][line:82][INFO] Random initialize AUCAUC:0.6061 Anomaly AUC:0.57717
[2023-09-08 19:09:04,020][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.2538 loss2:1.3731 loss3:0.3813 | AUC:0.7852 Anomaly AUC:0.5808
[2023-09-08 19:09:17,889][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0173 loss2:1.1980 loss3:0.2868 | AUC:0.7732 Anomaly AUC:0.6507
[2023-09-08 19:09:31,889][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0119 loss2:1.0135 loss3:0.2194 | AUC:0.7969 Anomaly AUC:0.6528
[2023-09-08 19:09:45,968][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0126 loss2:0.9563 loss3:0.1613 | AUC:0.7977 Anomaly AUC:0.6549
[2023-09-08 19:10:00,274][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0129 loss2:0.9179 loss3:0.1089 | AUC:0.7456 Anomaly AUC:0.6181
[2023-09-08 19:10:14,662][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0106 loss2:0.9171 loss3:0.0835 | AUC:0.8110 Anomaly AUC:0.6684
[2023-09-08 19:10:29,099][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0074 loss2:0.8753 loss3:0.0572 | AUC:0.7831 Anomaly AUC:0.6340
[2023-09-08 19:10:43,582][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0049 loss2:0.8449 loss3:0.0409 | AUC:0.8161 Anomaly AUC:0.6588
[2023-09-08 19:10:58,136][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0024 loss2:0.8141 loss3:0.0275 | AUC:0.8250 Anomaly AUC:0.6619
[2023-09-08 19:11:12,772][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0073 loss2:0.8225 loss3:0.0401 | AUC:0.8130 Anomaly AUC:0.6618
[2023-09-08 19:11:27,358][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0023 loss2:0.7833 loss3:0.0245 | AUC:0.8339 Anomaly AUC:0.6633
[2023-09-08 19:11:41,871][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0030 loss2:0.7585 loss3:0.0239 | AUC:0.8223 Anomaly AUC:0.6439
[2023-09-08 19:11:56,452][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0027 loss2:0.7335 loss3:0.0209 | AUC:0.8299 Anomaly AUC:0.6365
[2023-09-08 19:12:10,983][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0030 loss2:0.7068 loss3:0.0178 | AUC:0.8196 Anomaly AUC:0.6301
[2023-09-08 19:12:25,563][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0324 loss2:0.8600 loss3:0.0832 | AUC:0.8114 Anomaly AUC:0.6314
[2023-09-08 19:12:40,086][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0027 loss2:0.7500 loss3:0.0212 | AUC:0.8268 Anomaly AUC:0.6219
[2023-09-08 19:12:54,665][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0026 loss2:0.7118 loss3:0.0226 | AUC:0.8080 Anomaly AUC:0.5923
[2023-09-08 19:13:09,183][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0011 loss2:0.6714 loss3:0.0112 | AUC:0.8273 Anomaly AUC:0.6146
[2023-09-08 19:13:23,773][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0011 loss2:0.6454 loss3:0.0107 | AUC:0.8342 Anomaly AUC:0.6291
[2023-09-08 19:13:38,302][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0007 loss2:0.6208 loss3:0.0073 | AUC:0.8324 Anomaly AUC:0.6199
[2023-09-08 19:13:52,872][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0023 loss2:0.6062 loss3:0.0086 | AUC:0.8435 Anomaly AUC:0.6523
[2023-09-08 19:14:07,403][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0009 loss2:0.5811 loss3:0.0075 | AUC:0.8378 Anomaly AUC:0.6307
[2023-09-08 19:14:21,995][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0006 loss2:0.5514 loss3:0.0054 | AUC:0.8350 Anomaly AUC:0.6217
[2023-09-08 19:14:36,538][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0008 loss2:0.5287 loss3:0.0052 | AUC:0.8150 Anomaly AUC:0.5883
[2023-09-08 19:14:51,141][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0007 loss2:0.5008 loss3:0.0041 | AUC:0.8393 Anomaly AUC:0.6342
[2023-09-08 19:15:05,710][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0004 loss2:0.4679 loss3:0.0026 | AUC:0.8386 Anomaly AUC:0.6337
[2023-09-08 19:15:20,333][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0004 loss2:0.4393 loss3:0.0014 | AUC:0.8436 Anomaly AUC:0.6428
[2023-09-08 19:15:34,873][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0914 loss2:0.5966 loss3:0.0409 | AUC:0.8163 Anomaly AUC:0.6148
[2023-09-08 19:15:49,541][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0216 loss2:0.8298 loss3:0.0366 | AUC:0.8016 Anomaly AUC:0.5576
[2023-09-08 19:16:04,166][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0040 loss2:0.6397 loss3:0.0060 | AUC:0.8126 Anomaly AUC:0.5728
[2023-09-08 19:16:18,780][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0006 loss2:0.5521 loss3:0.0014 | AUC:0.8075 Anomaly AUC:0.5637
[2023-09-08 19:16:33,335][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0006 loss2:0.5041 loss3:0.0008 | AUC:0.8120 Anomaly AUC:0.5722
[2023-09-08 19:16:47,979][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0004 loss2:0.4654 loss3:0.0005 | AUC:0.8205 Anomaly AUC:0.5871
[2023-09-08 19:17:02,558][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0004 loss2:0.4362 loss3:0.0005 | AUC:0.8172 Anomaly AUC:0.5818
[2023-09-08 19:17:17,199][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0004 loss2:0.4122 loss3:0.0004 | AUC:0.8181 Anomaly AUC:0.5873
[2023-09-08 19:17:31,836][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0004 loss2:0.3855 loss3:0.0004 | AUC:0.8211 Anomaly AUC:0.5912
[2023-09-08 19:17:46,516][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0003 loss2:0.3593 loss3:0.0003 | AUC:0.8243 Anomaly AUC:0.5940
[2023-09-08 19:18:01,162][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0003 loss2:0.3357 loss3:0.0003 | AUC:0.8223 Anomaly AUC:0.5921
[2023-09-08 19:18:18,331][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 19:18:21,040][main.py][line:165][INFO] total params:7.0041M
[2023-09-08 19:18:21,040][main.py][line:168][INFO] Training Mode
[2023-09-08 19:18:21,041][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 19:18:21,041][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 19:18:26,541][main.py][line:82][INFO] Random initialize AUCAUC:0.5367 Anomaly AUC:0.52559
[2023-09-08 19:18:40,756][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.2882 loss2:1.1712 loss3:0.3429 | AUC:0.7846 Anomaly AUC:0.6633
[2023-09-08 19:18:54,686][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0317 loss2:0.8114 loss3:0.2438 | AUC:0.8035 Anomaly AUC:0.6632
[2023-09-08 19:19:08,634][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0226 loss2:0.7181 loss3:0.1737 | AUC:0.8036 Anomaly AUC:0.6658
[2023-09-08 19:19:22,670][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0466 loss2:0.7293 loss3:0.1565 | AUC:0.8066 Anomaly AUC:0.6679
[2023-09-08 19:19:36,943][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0140 loss2:0.6150 loss3:0.1133 | AUC:0.7989 Anomaly AUC:0.6651
[2023-09-08 19:19:51,252][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0121 loss2:0.5675 loss3:0.0988 | AUC:0.8054 Anomaly AUC:0.6756
[2023-09-08 19:20:05,694][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0104 loss2:0.5183 loss3:0.0850 | AUC:0.8275 Anomaly AUC:0.6743
[2023-09-08 19:20:20,002][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0096 loss2:0.4717 loss3:0.0715 | AUC:0.8349 Anomaly AUC:0.6772
[2023-09-08 19:20:34,349][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0092 loss2:0.4306 loss3:0.0606 | AUC:0.8257 Anomaly AUC:0.6633
[2023-09-08 19:20:48,740][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0104 loss2:0.4095 loss3:0.0565 | AUC:0.8240 Anomaly AUC:0.6703
[2023-09-08 19:21:03,101][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0072 loss2:0.3681 loss3:0.0471 | AUC:0.8255 Anomaly AUC:0.6641
[2023-09-08 19:21:17,571][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0107 loss2:0.4357 loss3:0.0642 | AUC:0.8360 Anomaly AUC:0.6776
[2023-09-08 19:21:31,926][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0043 loss2:0.3176 loss3:0.0332 | AUC:0.8429 Anomaly AUC:0.6769
[2023-09-08 19:21:46,345][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0040 loss2:0.2895 loss3:0.0265 | AUC:0.8457 Anomaly AUC:0.6863
[2023-09-08 19:22:00,775][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0036 loss2:0.2728 loss3:0.0226 | AUC:0.8478 Anomaly AUC:0.6753
[2023-09-08 19:22:15,227][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.1033 loss2:0.5843 loss3:0.1181 | AUC:0.8076 Anomaly AUC:0.6635
[2023-09-08 19:22:29,645][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0053 loss2:0.4508 loss3:0.0466 | AUC:0.8402 Anomaly AUC:0.6745
[2023-09-08 19:22:44,142][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0047 loss2:0.3027 loss3:0.0291 | AUC:0.8473 Anomaly AUC:0.6836
[2023-09-08 19:22:58,547][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0031 loss2:0.2647 loss3:0.0220 | AUC:0.8497 Anomaly AUC:0.6838
[2023-09-08 19:23:12,918][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0030 loss2:0.2484 loss3:0.0197 | AUC:0.8447 Anomaly AUC:0.6784
[2023-09-08 19:23:27,383][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0024 loss2:0.2343 loss3:0.0175 | AUC:0.8512 Anomaly AUC:0.6813
[2023-09-08 19:23:41,731][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0047 loss2:0.2297 loss3:0.0182 | AUC:0.8339 Anomaly AUC:0.6720
[2023-09-08 19:23:56,198][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0062 loss2:0.2433 loss3:0.0241 | AUC:0.8544 Anomaly AUC:0.6910
[2023-09-08 19:24:10,611][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0019 loss2:0.2046 loss3:0.0160 | AUC:0.8507 Anomaly AUC:0.6858
[2023-09-08 19:24:25,023][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0027 loss2:0.1978 loss3:0.0159 | AUC:0.8496 Anomaly AUC:0.6824
[2023-09-08 19:24:39,455][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0014 loss2:0.1879 loss3:0.0142 | AUC:0.8521 Anomaly AUC:0.6853
[2023-09-08 19:24:53,869][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0011 loss2:0.1765 loss3:0.0128 | AUC:0.8507 Anomaly AUC:0.6848
[2023-09-08 19:25:08,251][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0010 loss2:0.1696 loss3:0.0123 | AUC:0.8517 Anomaly AUC:0.6839
[2023-09-08 19:25:22,728][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0009 loss2:0.1631 loss3:0.0119 | AUC:0.8491 Anomaly AUC:0.6797
[2023-09-08 19:25:37,209][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0096 loss2:0.2472 loss3:0.0278 | AUC:0.8507 Anomaly AUC:0.6918
[2023-09-08 19:25:51,747][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0017 loss2:0.1666 loss3:0.0149 | AUC:0.8557 Anomaly AUC:0.6894
[2023-09-08 19:26:06,191][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0072 loss2:0.1960 loss3:0.0214 | AUC:0.8409 Anomaly AUC:0.6883
[2023-09-08 19:26:20,685][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0048 loss2:0.1853 loss3:0.0246 | AUC:0.8483 Anomaly AUC:0.6860
[2023-09-08 19:26:35,146][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0009 loss2:0.1418 loss3:0.0134 | AUC:0.8561 Anomaly AUC:0.6902
[2023-09-08 19:26:49,616][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0008 loss2:0.1341 loss3:0.0122 | AUC:0.8532 Anomaly AUC:0.6867
[2023-09-08 19:27:04,098][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0006 loss2:0.1268 loss3:0.0114 | AUC:0.8553 Anomaly AUC:0.6891
[2023-09-08 19:27:18,607][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0005 loss2:0.1200 loss3:0.0110 | AUC:0.8540 Anomaly AUC:0.6814
[2023-09-08 19:27:33,059][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0221 loss2:0.2783 loss3:0.0529 | AUC:0.8094 Anomaly AUC:0.6691
[2023-09-08 19:27:47,595][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0028 loss2:0.2007 loss3:0.0280 | AUC:0.8406 Anomaly AUC:0.6815
[2023-09-08 19:28:02,078][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0017 loss2:0.1315 loss3:0.0153 | AUC:0.8446 Anomaly AUC:0.6787
[2023-09-08 19:28:16,573][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0012 loss2:0.1165 loss3:0.0133 | AUC:0.8441 Anomaly AUC:0.6800
[2023-09-08 19:28:31,032][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0044 loss2:0.1215 loss3:0.0152 | AUC:0.7870 Anomaly AUC:0.6314
[2023-09-08 19:28:45,588][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0029 loss2:0.1463 loss3:0.0230 | AUC:0.8463 Anomaly AUC:0.6742
[2023-09-08 19:29:00,038][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0022 loss2:0.1131 loss3:0.0151 | AUC:0.8516 Anomaly AUC:0.6873
[2023-09-08 19:29:14,590][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0008 loss2:0.0959 loss3:0.0120 | AUC:0.8550 Anomaly AUC:0.6837
[2023-09-08 19:29:29,145][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0006 loss2:0.0903 loss3:0.0114 | AUC:0.8510 Anomaly AUC:0.6809
[2023-09-08 19:29:43,672][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0005 loss2:0.0847 loss3:0.0107 | AUC:0.8543 Anomaly AUC:0.6869
[2023-09-08 19:29:58,124][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0049 loss2:0.1207 loss3:0.0156 | AUC:0.8301 Anomaly AUC:0.6596
[2023-09-08 19:30:12,599][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0051 loss2:0.1335 loss3:0.0238 | AUC:0.8525 Anomaly AUC:0.6811
[2023-09-08 19:30:27,075][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0005 loss2:0.0793 loss3:0.0117 | AUC:0.8526 Anomaly AUC:0.6802
[2023-09-08 19:30:41,572][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0005 loss2:0.0738 loss3:0.0110 | AUC:0.8546 Anomaly AUC:0.6822
[2023-09-08 19:30:56,132][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0003 loss2:0.0700 loss3:0.0105 | AUC:0.8561 Anomaly AUC:0.6832
[2023-09-08 19:31:10,638][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0003 loss2:0.0661 loss3:0.0101 | AUC:0.8559 Anomaly AUC:0.6859
[2023-09-08 19:31:25,184][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0003 loss2:0.0640 loss3:0.0101 | AUC:0.8558 Anomaly AUC:0.6832
[2023-09-08 19:31:39,731][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0003 loss2:0.0607 loss3:0.0098 | AUC:0.8542 Anomaly AUC:0.6864
[2023-09-08 19:31:54,215][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0925 loss2:0.3003 loss3:0.0708 | AUC:0.7985 Anomaly AUC:0.6847
[2023-09-08 19:32:08,758][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0041 loss2:0.1966 loss3:0.0299 | AUC:0.8423 Anomaly AUC:0.6768
[2023-09-08 19:32:23,311][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0017 loss2:0.0781 loss3:0.0149 | AUC:0.8439 Anomaly AUC:0.6803
[2023-09-08 19:32:37,859][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0006 loss2:0.0609 loss3:0.0120 | AUC:0.8453 Anomaly AUC:0.6750
[2023-09-08 19:32:52,404][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0015 loss2:0.0660 loss3:0.0134 | AUC:0.8486 Anomaly AUC:0.6792
[2023-09-08 19:33:06,980][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0006 loss2:0.0535 loss3:0.0111 | AUC:0.8493 Anomaly AUC:0.6786
[2023-09-08 19:33:21,521][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0044 loss2:0.0751 loss3:0.0161 | AUC:0.8470 Anomaly AUC:0.6803
[2023-09-08 19:33:36,078][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0062 loss2:0.0997 loss3:0.0206 | AUC:0.8462 Anomaly AUC:0.6799
[2023-09-08 19:33:50,579][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0004 loss2:0.0487 loss3:0.0117 | AUC:0.8521 Anomaly AUC:0.6798
[2023-09-08 19:34:05,139][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0007 loss2:0.0452 loss3:0.0113 | AUC:0.8497 Anomaly AUC:0.6828
[2023-09-08 19:34:19,672][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0003 loss2:0.0412 loss3:0.0101 | AUC:0.8528 Anomaly AUC:0.6803
[2023-09-08 19:34:34,153][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0005 loss2:0.0422 loss3:0.0104 | AUC:0.8454 Anomaly AUC:0.6753
[2023-09-08 19:34:48,695][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0017 loss2:0.0528 loss3:0.0134 | AUC:0.8401 Anomaly AUC:0.6734
[2023-09-08 19:35:03,210][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0006 loss2:0.0469 loss3:0.0126 | AUC:0.8478 Anomaly AUC:0.6864
[2023-09-08 19:35:17,784][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0002 loss2:0.0352 loss3:0.0099 | AUC:0.8519 Anomaly AUC:0.6829
[2023-09-08 19:35:32,338][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0003 loss2:0.0327 loss3:0.0097 | AUC:0.8521 Anomaly AUC:0.6857
[2023-09-08 19:35:46,956][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0002 loss2:0.0310 loss3:0.0093 | AUC:0.8511 Anomaly AUC:0.6826
[2023-09-08 19:36:01,462][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0002 loss2:0.0289 loss3:0.0091 | AUC:0.8525 Anomaly AUC:0.6824
[2023-09-08 19:36:15,966][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0019 loss2:0.0438 loss3:0.0106 | AUC:0.8427 Anomaly AUC:0.6717
[2023-09-08 19:36:30,447][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0090 loss2:0.1122 loss3:0.0254 | AUC:0.8383 Anomaly AUC:0.6816
[2023-09-08 19:36:45,041][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0011 loss2:0.0417 loss3:0.0146 | AUC:0.8472 Anomaly AUC:0.6809
[2023-09-08 19:36:59,568][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0010 loss2:0.0308 loss3:0.0108 | AUC:0.8345 Anomaly AUC:0.6829
[2023-09-08 19:37:14,160][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0003 loss2:0.0254 loss3:0.0101 | AUC:0.8544 Anomaly AUC:0.6954
[2023-09-08 19:37:28,680][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0002 loss2:0.0354 loss3:0.0095 | AUC:0.8558 Anomaly AUC:0.6893
[2023-09-08 19:37:43,245][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0004 loss2:0.0244 loss3:0.0093 | AUC:0.8460 Anomaly AUC:0.6854
[2023-09-08 19:37:57,775][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0027 loss2:0.0340 loss3:0.0133 | AUC:0.8479 Anomaly AUC:0.6884
[2023-09-08 19:38:12,368][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0002 loss2:0.0225 loss3:0.0091 | AUC:0.8529 Anomaly AUC:0.6925
[2023-09-08 19:38:26,869][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0006 loss2:0.0325 loss3:0.0100 | AUC:0.8473 Anomaly AUC:0.6799
[2023-09-08 19:38:41,376][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0003 loss2:0.0182 loss3:0.0087 | AUC:0.8477 Anomaly AUC:0.6783
[2023-09-08 19:38:55,947][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0001 loss2:0.0165 loss3:0.0081 | AUC:0.8495 Anomaly AUC:0.6800
[2023-09-08 19:39:10,503][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0001 loss2:0.0155 loss3:0.0078 | AUC:0.8471 Anomaly AUC:0.6767
[2023-09-08 19:39:25,063][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0001 loss2:0.0147 loss3:0.0075 | AUC:0.8474 Anomaly AUC:0.6761
[2023-09-08 19:39:39,546][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0266 loss2:0.0892 loss3:0.0237 | AUC:0.8140 Anomaly AUC:0.6475
[2023-09-08 19:39:54,129][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0090 loss2:0.2000 loss3:0.0449 | AUC:0.8367 Anomaly AUC:0.6625
[2023-09-08 19:40:08,675][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0018 loss2:0.0311 loss3:0.0145 | AUC:0.8432 Anomaly AUC:0.6746
[2023-09-08 19:40:23,182][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0021 loss2:0.0347 loss3:0.0181 | AUC:0.8473 Anomaly AUC:0.6863
[2023-09-08 19:40:37,672][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0048 loss2:0.0620 loss3:0.0242 | AUC:0.8443 Anomaly AUC:0.6829
[2023-09-08 19:40:52,223][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.0008 loss2:0.0215 loss3:0.0116 | AUC:0.8476 Anomaly AUC:0.6715
[2023-09-08 19:41:06,737][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0002 loss2:0.0138 loss3:0.0084 | AUC:0.8506 Anomaly AUC:0.6750
[2023-09-08 19:41:21,236][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0018 loss2:0.0190 loss3:0.0106 | AUC:0.8446 Anomaly AUC:0.6767
[2023-09-08 19:41:35,759][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0016 loss2:0.0192 loss3:0.0107 | AUC:0.8513 Anomaly AUC:0.6845
[2023-09-08 19:41:50,271][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0003 loss2:0.0149 loss3:0.0095 | AUC:0.8521 Anomaly AUC:0.6842
[2023-09-08 19:42:04,835][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0001 loss2:0.0103 loss3:0.0076 | AUC:0.8540 Anomaly AUC:0.6839
[2023-09-08 19:42:19,417][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0001 loss2:0.0095 loss3:0.0072 | AUC:0.8547 Anomaly AUC:0.6839
[2023-09-08 19:42:33,941][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0003 loss2:0.0090 loss3:0.0071 | AUC:0.8523 Anomaly AUC:0.6843
[2023-09-08 19:42:33,963][main.py][line:116][INFO] Training completes in 24m 7s | best AUCAUC:0.8561 Anomaly AUC:0.6832

[2023-09-08 19:46:09,791][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 20, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 19:46:12,523][main.py][line:165][INFO] total params:7.0092M
[2023-09-08 19:46:12,524][main.py][line:168][INFO] Training Mode
[2023-09-08 19:46:12,524][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 19:46:12,524][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 19:46:17,993][main.py][line:82][INFO] Random initialize AUCAUC:0.4547 Anomaly AUC:0.50867
[2023-09-08 19:46:32,236][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3141 loss2:1.1729 loss3:0.3407 | AUC:0.8027 Anomaly AUC:0.6632
[2023-09-08 19:46:46,219][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0383 loss2:0.8388 loss3:0.2508 | AUC:0.7913 Anomaly AUC:0.6674
[2023-09-08 19:47:00,165][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0220 loss2:0.7371 loss3:0.1907 | AUC:0.8041 Anomaly AUC:0.6621
[2023-09-08 19:47:14,153][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0219 loss2:0.6520 loss3:0.1353 | AUC:0.8119 Anomaly AUC:0.6677
[2023-09-08 19:47:28,438][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0156 loss2:0.5796 loss3:0.0995 | AUC:0.8276 Anomaly AUC:0.6672
[2023-09-08 19:47:42,793][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0128 loss2:0.5223 loss3:0.0767 | AUC:0.8373 Anomaly AUC:0.6683
[2023-09-08 19:47:57,243][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0106 loss2:0.4686 loss3:0.0625 | AUC:0.8374 Anomaly AUC:0.6737
[2023-09-08 19:48:11,723][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0146 loss2:0.4505 loss3:0.0575 | AUC:0.7921 Anomaly AUC:0.6749
[2023-09-08 19:48:26,317][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0053 loss2:0.4033 loss3:0.0457 | AUC:0.8319 Anomaly AUC:0.6698
[2023-09-08 19:48:40,857][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0044 loss2:0.3480 loss3:0.0299 | AUC:0.8361 Anomaly AUC:0.6698
[2023-09-08 19:48:55,377][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0121 loss2:0.4212 loss3:0.0521 | AUC:0.8252 Anomaly AUC:0.6603
[2023-09-08 19:49:09,963][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0049 loss2:0.3330 loss3:0.0301 | AUC:0.8366 Anomaly AUC:0.6607
[2023-09-08 19:49:24,591][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0048 loss2:0.3157 loss3:0.0274 | AUC:0.8359 Anomaly AUC:0.6719
[2023-09-08 19:49:39,112][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0026 loss2:0.2729 loss3:0.0193 | AUC:0.8404 Anomaly AUC:0.6711
[2023-09-08 19:49:53,714][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0022 loss2:0.2562 loss3:0.0167 | AUC:0.8406 Anomaly AUC:0.6705
[2023-09-08 19:50:08,330][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0017 loss2:0.2409 loss3:0.0141 | AUC:0.8361 Anomaly AUC:0.6667
[2023-09-08 19:50:22,809][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0081 loss2:0.2852 loss3:0.0265 | AUC:0.8336 Anomaly AUC:0.6627
[2023-09-08 19:50:37,224][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0017 loss2:0.2284 loss3:0.0163 | AUC:0.8363 Anomaly AUC:0.6630
[2023-09-08 19:50:51,795][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0014 loss2:0.2130 loss3:0.0134 | AUC:0.8405 Anomaly AUC:0.6700
[2023-09-08 19:51:06,313][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.1298 loss2:0.3996 loss3:0.0934 | AUC:0.7134 Anomaly AUC:0.5683
[2023-09-08 19:51:20,868][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0094 loss2:0.6174 loss3:0.0787 | AUC:0.8167 Anomaly AUC:0.6667
[2023-09-08 19:51:35,456][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0048 loss2:0.3455 loss3:0.0341 | AUC:0.8361 Anomaly AUC:0.6782
[2023-09-08 19:51:50,077][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0032 loss2:0.2799 loss3:0.0220 | AUC:0.8379 Anomaly AUC:0.6761
[2023-09-08 19:52:04,690][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0023 loss2:0.2501 loss3:0.0169 | AUC:0.8385 Anomaly AUC:0.6739
[2023-09-08 19:52:19,291][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0018 loss2:0.2346 loss3:0.0142 | AUC:0.8383 Anomaly AUC:0.6697
[2023-09-08 19:52:33,909][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0019 loss2:0.2252 loss3:0.0129 | AUC:0.8363 Anomaly AUC:0.6686
[2023-09-08 19:52:48,559][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0014 loss2:0.2129 loss3:0.0117 | AUC:0.8337 Anomaly AUC:0.6608
[2023-09-08 19:53:03,166][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0086 loss2:0.2811 loss3:0.0282 | AUC:0.8345 Anomaly AUC:0.6635
[2023-09-08 19:53:17,759][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0019 loss2:0.2104 loss3:0.0139 | AUC:0.8361 Anomaly AUC:0.6685
[2023-09-08 19:53:32,430][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0012 loss2:0.1950 loss3:0.0112 | AUC:0.8348 Anomaly AUC:0.6613
[2023-09-08 19:53:47,086][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0013 loss2:0.1935 loss3:0.0109 | AUC:0.8380 Anomaly AUC:0.6668
[2023-09-08 19:54:01,759][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0010 loss2:0.1788 loss3:0.0101 | AUC:0.8330 Anomaly AUC:0.6649
[2023-09-08 19:54:16,370][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0008 loss2:0.1694 loss3:0.0093 | AUC:0.8333 Anomaly AUC:0.6634
[2023-09-08 19:54:31,003][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0167 loss2:0.4058 loss3:0.0448 | AUC:0.8326 Anomaly AUC:0.6675
[2023-09-08 19:54:45,645][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0041 loss2:0.2108 loss3:0.0220 | AUC:0.8339 Anomaly AUC:0.6660
[2023-09-08 19:55:00,307][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0018 loss2:0.1800 loss3:0.0143 | AUC:0.8351 Anomaly AUC:0.6601
[2023-09-08 19:55:14,988][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0052 loss2:0.2111 loss3:0.0221 | AUC:0.8313 Anomaly AUC:0.6627
[2023-09-08 19:55:29,624][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0015 loss2:0.1598 loss3:0.0123 | AUC:0.8348 Anomaly AUC:0.6662
[2023-09-08 19:56:33,945][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 20, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 19:56:36,826][main.py][line:165][INFO] total params:7.5349M
[2023-09-08 19:56:36,826][main.py][line:168][INFO] Training Mode
[2023-09-08 19:56:36,827][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 19:56:36,827][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 19:56:44,938][main.py][line:82][INFO] Random initialize AUCAUC:0.6086 Anomaly AUC:0.60989
[2023-09-08 19:57:03,141][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5450 loss2:1.2442 loss3:0.2747 | AUC:0.7911 Anomaly AUC:0.6417
[2023-09-08 19:57:21,198][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2978 loss2:0.9230 loss3:0.0732 | AUC:0.8174 Anomaly AUC:0.6572
[2023-09-08 19:57:39,535][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2086 loss2:0.7948 loss3:0.0432 | AUC:0.8281 Anomaly AUC:0.6719
[2023-09-08 19:57:57,924][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1382 loss2:0.7038 loss3:0.0291 | AUC:0.8350 Anomaly AUC:0.6632
[2023-09-08 19:58:16,611][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0883 loss2:0.6191 loss3:0.0209 | AUC:0.8098 Anomaly AUC:0.6667
[2023-09-08 19:58:35,239][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0710 loss2:0.5402 loss3:0.0167 | AUC:0.8275 Anomaly AUC:0.6663
[2023-09-08 19:58:53,849][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0354 loss2:0.4481 loss3:0.0098 | AUC:0.8277 Anomaly AUC:0.6618
[2023-09-08 19:59:12,618][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0279 loss2:0.3596 loss3:0.0067 | AUC:0.8118 Anomaly AUC:0.6322
[2023-09-08 19:59:31,386][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0168 loss2:0.2751 loss3:0.0039 | AUC:0.8102 Anomaly AUC:0.6553
[2023-09-08 19:59:50,090][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0228 loss2:0.2239 loss3:0.0044 | AUC:0.8350 Anomaly AUC:0.6470
[2023-09-08 20:00:08,757][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0107 loss2:0.1370 loss3:0.0020 | AUC:0.8340 Anomaly AUC:0.6435
[2023-09-08 20:00:27,454][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0225 loss2:0.1312 loss3:0.0044 | AUC:0.8346 Anomaly AUC:0.6499
[2023-09-08 20:00:46,227][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0168 loss2:0.0834 loss3:0.0029 | AUC:0.8433 Anomaly AUC:0.6621
[2023-09-08 20:01:04,956][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0081 loss2:0.0616 loss3:0.0018 | AUC:0.8420 Anomaly AUC:0.6574
[2023-09-08 20:01:23,695][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0114 loss2:0.0497 loss3:0.0019 | AUC:0.8318 Anomaly AUC:0.6544
[2023-09-08 20:01:42,599][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0005 loss2:0.0233 loss3:0.0004 | AUC:0.8546 Anomaly AUC:0.6734
[2023-09-08 20:02:01,319][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0002 loss2:0.0158 loss3:0.0003 | AUC:0.8497 Anomaly AUC:0.6672
[2023-09-08 20:02:20,174][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0002 loss2:0.0125 loss3:0.0002 | AUC:0.8474 Anomaly AUC:0.6593
[2023-09-08 20:02:38,964][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0002 loss2:0.0108 loss3:0.0003 | AUC:0.8470 Anomaly AUC:0.6621
[2023-09-08 20:02:57,901][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0001 loss2:0.0096 loss3:0.0003 | AUC:0.8464 Anomaly AUC:0.6606
[2023-09-08 20:03:16,689][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0001 loss2:0.0076 loss3:0.0003 | AUC:0.8500 Anomaly AUC:0.6683
[2023-09-08 20:03:35,514][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0001 loss2:0.0070 loss3:0.0003 | AUC:0.8482 Anomaly AUC:0.6633
[2023-09-08 20:03:54,320][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0001 loss2:0.0060 loss3:0.0003 | AUC:0.8488 Anomaly AUC:0.6653
[2023-09-08 20:04:13,068][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0001 loss2:0.0052 loss3:0.0003 | AUC:0.8503 Anomaly AUC:0.6686
[2023-09-08 20:04:31,953][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0001 loss2:0.0047 loss3:0.0003 | AUC:0.8502 Anomaly AUC:0.6685
[2023-09-08 20:04:50,772][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0001 loss2:0.0045 loss3:0.0003 | AUC:0.8513 Anomaly AUC:0.6854
[2023-09-08 20:05:09,732][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0001 loss2:0.0042 loss3:0.0003 | AUC:0.8455 Anomaly AUC:0.6596
[2023-09-08 20:05:28,499][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0001 loss2:0.0037 loss3:0.0003 | AUC:0.8517 Anomaly AUC:0.6782
[2023-09-08 20:05:47,498][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0001 loss2:0.0035 loss3:0.0003 | AUC:0.8478 Anomaly AUC:0.6693
[2023-09-08 20:06:06,300][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0001 loss2:0.0071 loss3:0.0004 | AUC:0.8073 Anomaly AUC:0.6596
[2023-09-08 20:06:25,093][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0920 loss2:0.2114 loss3:0.0176 | AUC:0.8439 Anomaly AUC:0.6695
[2023-09-08 20:06:43,994][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0168 loss2:0.0562 loss3:0.0033 | AUC:0.8168 Anomaly AUC:0.6596
[2023-09-08 20:07:02,757][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0154 loss2:0.0337 loss3:0.0029 | AUC:0.8238 Anomaly AUC:0.6646
[2023-09-08 20:07:21,609][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0109 loss2:0.0244 loss3:0.0022 | AUC:0.8233 Anomaly AUC:0.6726
[2023-09-08 20:07:40,499][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0096 loss2:0.0225 loss3:0.0018 | AUC:0.8442 Anomaly AUC:0.6686
[2023-09-08 20:07:59,322][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0097 loss2:0.0170 loss3:0.0019 | AUC:0.8320 Anomaly AUC:0.6647
[2023-09-08 20:08:18,155][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0031 loss2:0.0110 loss3:0.0009 | AUC:0.8358 Anomaly AUC:0.6806
[2023-09-08 20:08:37,046][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0021 loss2:0.0122 loss3:0.0007 | AUC:0.8285 Anomaly AUC:0.6719
[2023-09-08 20:08:55,863][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0089 loss2:0.0136 loss3:0.0019 | AUC:0.8279 Anomaly AUC:0.6783
[2023-09-08 20:09:14,655][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0085 loss2:0.0169 loss3:0.0019 | AUC:0.8306 Anomaly AUC:0.6564
[2023-09-08 20:09:33,503][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0164 loss2:0.0305 loss3:0.0028 | AUC:0.7788 Anomaly AUC:0.6641
[2023-09-08 20:10:09,907][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 20:10:12,748][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 20:10:12,748][main.py][line:168][INFO] Training Mode
[2023-09-08 20:10:12,749][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 20:10:12,749][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 20:10:20,816][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-08 20:10:39,053][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5273 loss2:1.2215 loss3:0.2657 | AUC:0.8208 Anomaly AUC:0.6607
[2023-09-08 20:10:57,090][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2955 loss2:0.8976 loss3:0.0725 | AUC:0.8298 Anomaly AUC:0.6711
[2023-09-08 20:11:15,737][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2125 loss2:0.7922 loss3:0.0425 | AUC:0.8048 Anomaly AUC:0.6619
[2023-09-08 20:11:34,361][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1763 loss2:0.7313 loss3:0.0345 | AUC:0.8353 Anomaly AUC:0.6802
[2023-09-08 20:11:53,035][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0987 loss2:0.6299 loss3:0.0188 | AUC:0.8331 Anomaly AUC:0.6586
[2023-09-08 20:12:11,851][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0780 loss2:0.5650 loss3:0.0140 | AUC:0.8296 Anomaly AUC:0.6864
[2023-09-08 20:12:30,691][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0369 loss2:0.4620 loss3:0.0066 | AUC:0.8414 Anomaly AUC:0.6826
[2023-09-08 20:12:49,469][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0246 loss2:0.3866 loss3:0.0045 | AUC:0.8420 Anomaly AUC:0.6866
[2023-09-08 20:13:08,235][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0302 loss2:0.3160 loss3:0.0048 | AUC:0.8300 Anomaly AUC:0.6739
[2023-09-08 20:13:27,014][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0195 loss2:0.2438 loss3:0.0035 | AUC:0.8170 Anomaly AUC:0.6526
[2023-09-08 20:13:45,782][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0192 loss2:0.1786 loss3:0.0033 | AUC:0.8202 Anomaly AUC:0.6681
[2023-09-08 20:14:04,596][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0171 loss2:0.1304 loss3:0.0032 | AUC:0.8278 Anomaly AUC:0.6721
[2023-09-08 20:14:23,434][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0054 loss2:0.0754 loss3:0.0014 | AUC:0.8342 Anomaly AUC:0.6473
[2023-09-08 20:14:42,261][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0100 loss2:0.0628 loss3:0.0020 | AUC:0.8378 Anomaly AUC:0.6651
[2023-09-08 20:15:01,088][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0142 loss2:0.0679 loss3:0.0028 | AUC:0.8141 Anomaly AUC:0.6272
[2023-09-08 20:15:20,055][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0139 loss2:0.0570 loss3:0.0026 | AUC:0.8005 Anomaly AUC:0.6490
[2023-09-08 20:15:38,846][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0085 loss2:0.0399 loss3:0.0017 | AUC:0.8210 Anomaly AUC:0.6487
[2023-09-08 20:15:57,627][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0015 loss2:0.0192 loss3:0.0007 | AUC:0.8221 Anomaly AUC:0.6310
[2023-09-08 20:16:16,433][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0103 loss2:0.0267 loss3:0.0017 | AUC:0.8277 Anomaly AUC:0.6700
[2023-09-08 20:16:35,244][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0220 loss2:0.0514 loss3:0.0035 | AUC:0.8197 Anomaly AUC:0.6845
[2023-09-08 20:16:54,057][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0115 loss2:0.0331 loss3:0.0020 | AUC:0.8043 Anomaly AUC:0.6544
[2023-09-08 20:17:12,934][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0011 loss2:0.0128 loss3:0.0005 | AUC:0.8222 Anomaly AUC:0.6466
[2023-09-08 20:17:31,768][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0068 loss2:0.0178 loss3:0.0012 | AUC:0.8231 Anomaly AUC:0.6636
[2023-09-08 20:17:50,710][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0083 loss2:0.0200 loss3:0.0017 | AUC:0.8253 Anomaly AUC:0.6275
[2023-09-08 20:18:09,541][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0011 loss2:0.0139 loss3:0.0006 | AUC:0.8545 Anomaly AUC:0.6852
[2023-09-08 20:18:28,317][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0004 loss2:0.0076 loss3:0.0003 | AUC:0.8440 Anomaly AUC:0.6632
[2023-09-08 20:18:47,091][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0001 loss2:0.0045 loss3:0.0003 | AUC:0.8386 Anomaly AUC:0.6692
[2023-09-08 20:19:05,369][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0002 loss2:0.0000 loss3:0.0003 | AUC:0.8292 Anomaly AUC:0.6488
[2023-09-08 20:19:23,578][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8304 Anomaly AUC:0.6504
[2023-09-08 20:19:41,723][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8318 Anomaly AUC:0.6450
[2023-09-08 20:19:59,962][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8325 Anomaly AUC:0.6427
[2023-09-08 20:20:18,096][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8329 Anomaly AUC:0.6401
[2023-09-08 20:20:29,378][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 20:20:32,133][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 20:20:32,134][main.py][line:168][INFO] Training Mode
[2023-09-08 20:20:32,134][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 20:20:32,134][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 20:20:40,301][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-08 20:20:58,442][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5273 loss2:1.2215 loss3:0.2657 | AUC:0.8208 Anomaly AUC:0.6607
[2023-09-08 20:21:16,644][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2955 loss2:0.8976 loss3:0.0725 | AUC:0.8298 Anomaly AUC:0.6711
[2023-09-08 20:21:35,076][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2125 loss2:0.7922 loss3:0.0425 | AUC:0.8048 Anomaly AUC:0.6619
[2023-09-08 20:21:53,606][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1763 loss2:0.7313 loss3:0.0345 | AUC:0.8353 Anomaly AUC:0.6802
[2023-09-08 20:22:12,141][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0987 loss2:0.6299 loss3:0.0188 | AUC:0.8331 Anomaly AUC:0.6586
[2023-09-08 20:22:30,815][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0780 loss2:0.5650 loss3:0.0140 | AUC:0.8296 Anomaly AUC:0.6864
[2023-09-08 20:22:49,498][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0369 loss2:0.4620 loss3:0.0066 | AUC:0.8414 Anomaly AUC:0.6826
[2023-09-08 20:23:08,223][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0246 loss2:0.3866 loss3:0.0045 | AUC:0.8420 Anomaly AUC:0.6866
[2023-09-08 20:23:26,954][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0302 loss2:0.3160 loss3:0.0048 | AUC:0.8300 Anomaly AUC:0.6739
[2023-09-08 20:23:45,679][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0195 loss2:0.2438 loss3:0.0035 | AUC:0.8170 Anomaly AUC:0.6526
[2023-09-08 20:24:04,551][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0192 loss2:0.1786 loss3:0.0033 | AUC:0.8202 Anomaly AUC:0.6681
[2023-09-08 20:24:23,462][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0171 loss2:0.1304 loss3:0.0032 | AUC:0.8278 Anomaly AUC:0.6721
[2023-09-08 20:24:42,196][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0054 loss2:0.0754 loss3:0.0014 | AUC:0.8342 Anomaly AUC:0.6473
[2023-09-08 20:25:00,945][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0100 loss2:0.0628 loss3:0.0020 | AUC:0.8378 Anomaly AUC:0.6651
[2023-09-08 20:25:19,711][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0142 loss2:0.0679 loss3:0.0028 | AUC:0.8141 Anomaly AUC:0.6272
[2023-09-08 20:25:38,530][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0139 loss2:0.0570 loss3:0.0026 | AUC:0.8005 Anomaly AUC:0.6490
[2023-09-08 20:25:57,381][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0085 loss2:0.0399 loss3:0.0017 | AUC:0.8210 Anomaly AUC:0.6487
[2023-09-08 20:26:16,183][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0015 loss2:0.0192 loss3:0.0007 | AUC:0.8221 Anomaly AUC:0.6310
[2023-09-08 20:26:34,977][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0103 loss2:0.0267 loss3:0.0017 | AUC:0.8277 Anomaly AUC:0.6700
[2023-09-08 20:26:53,834][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0220 loss2:0.0514 loss3:0.0035 | AUC:0.8197 Anomaly AUC:0.6845
[2023-09-08 20:27:12,708][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0115 loss2:0.0331 loss3:0.0020 | AUC:0.8043 Anomaly AUC:0.6544
[2023-09-08 20:27:32,891][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 20:27:35,621][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 20:27:35,621][main.py][line:168][INFO] Training Mode
[2023-09-08 20:27:35,622][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 20:27:35,622][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 20:27:43,682][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-08 20:28:01,949][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.3961 loss2:1.1420 loss3:0.3711 | AUC:0.7735 Anomaly AUC:0.6706
[2023-09-08 20:28:20,110][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0150 loss2:0.7484 loss3:0.2829 | AUC:0.7619 Anomaly AUC:0.6699
[2023-09-08 20:28:38,540][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0078 loss2:0.6094 loss3:0.2113 | AUC:0.8009 Anomaly AUC:0.6693
[2023-09-08 20:28:56,977][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0103 loss2:0.5578 loss3:0.1770 | AUC:0.7929 Anomaly AUC:0.6622
[2023-09-08 20:29:15,579][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0054 loss2:0.4393 loss3:0.1274 | AUC:0.7973 Anomaly AUC:0.6697
[2023-09-08 20:29:34,237][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0033 loss2:0.3517 loss3:0.0995 | AUC:0.8228 Anomaly AUC:0.6750
[2023-09-08 20:29:52,847][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0064 loss2:0.2917 loss3:0.0872 | AUC:0.8030 Anomaly AUC:0.6580
[2023-09-08 20:30:11,559][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0039 loss2:0.2192 loss3:0.0687 | AUC:0.8157 Anomaly AUC:0.6538
[2023-09-08 20:30:30,479][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0022 loss2:0.1515 loss3:0.0494 | AUC:0.8241 Anomaly AUC:0.6680
[2023-09-08 20:30:49,151][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0024 loss2:0.1116 loss3:0.0393 | AUC:0.8145 Anomaly AUC:0.6625
[2023-09-08 20:31:07,863][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0074 loss2:0.1034 loss3:0.0484 | AUC:0.7815 Anomaly AUC:0.6730
[2023-09-08 20:31:26,795][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0040 loss2:0.0828 loss3:0.0450 | AUC:0.8217 Anomaly AUC:0.6668
[2023-09-08 20:31:45,535][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0016 loss2:0.0510 loss3:0.0276 | AUC:0.8132 Anomaly AUC:0.6617
[2023-09-08 20:32:04,437][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0016 loss2:0.0472 loss3:0.0287 | AUC:0.8205 Anomaly AUC:0.6585
[2023-09-08 20:32:23,304][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0004 loss2:0.0306 loss3:0.0191 | AUC:0.8308 Anomaly AUC:0.6686
[2023-09-08 20:32:42,068][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0063 loss2:0.0584 loss3:0.0316 | AUC:0.7132 Anomaly AUC:0.6007
[2023-09-08 20:33:00,876][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0023 loss2:0.0502 loss3:0.0427 | AUC:0.8320 Anomaly AUC:0.6805
[2023-09-08 20:33:17,929][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 20:33:20,734][main.py][line:165][INFO] total params:17.0166M
[2023-09-08 20:33:20,735][main.py][line:168][INFO] Training Mode
[2023-09-08 20:33:20,735][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 20:33:20,735][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 20:33:28,488][main.py][line:82][INFO] Random initialize AUCAUC:0.5283 Anomaly AUC:0.51616
[2023-09-08 20:33:50,341][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0580 loss2:1.0715 loss3:0.1326 | AUC:0.7202 Anomaly AUC:0.6563
[2023-09-08 20:34:11,881][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0068 loss2:0.8126 loss3:0.0576 | AUC:0.7708 Anomaly AUC:0.6662
[2023-09-08 20:34:33,788][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0033 loss2:0.7263 loss3:0.0474 | AUC:0.7314 Anomaly AUC:0.6634
[2023-09-08 20:34:55,812][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0026 loss2:0.6533 loss3:0.0401 | AUC:0.7380 Anomaly AUC:0.6664
[2023-09-08 20:35:17,853][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0026 loss2:0.5435 loss3:0.0340 | AUC:0.7277 Anomaly AUC:0.6522
[2023-09-08 20:35:40,038][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0026 loss2:0.4348 loss3:0.0326 | AUC:0.7893 Anomaly AUC:0.6759
[2023-09-08 20:36:02,174][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0041 loss2:0.3720 loss3:0.0381 | AUC:0.7293 Anomaly AUC:0.6778
[2023-09-08 20:36:24,421][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0024 loss2:0.3002 loss3:0.0320 | AUC:0.7415 Anomaly AUC:0.6627
[2023-09-08 20:36:46,707][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0013 loss2:0.2201 loss3:0.0219 | AUC:0.7344 Anomaly AUC:0.6602
[2023-09-08 20:37:08,913][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0012 loss2:0.1722 loss3:0.0207 | AUC:0.7552 Anomaly AUC:0.6524
[2023-09-08 20:37:31,183][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0013 loss2:0.1384 loss3:0.0188 | AUC:0.7451 Anomaly AUC:0.6437
[2023-09-08 20:37:53,450][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0007 loss2:0.0993 loss3:0.0163 | AUC:0.7379 Anomaly AUC:0.6276
[2023-09-08 20:38:15,761][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0011 loss2:0.0887 loss3:0.0178 | AUC:0.7642 Anomaly AUC:0.6525
[2023-09-08 20:38:38,153][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0011 loss2:0.0710 loss3:0.0176 | AUC:0.7689 Anomaly AUC:0.6543
[2023-09-08 20:39:00,405][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0010 loss2:0.0752 loss3:0.0165 | AUC:0.7650 Anomaly AUC:0.6555
[2023-09-08 20:39:22,688][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0008 loss2:0.0568 loss3:0.0161 | AUC:0.7810 Anomaly AUC:0.6737
[2023-09-08 20:39:45,091][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0006 loss2:0.0379 loss3:0.0146 | AUC:0.7674 Anomaly AUC:0.6539
[2023-09-08 20:40:07,444][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0004 loss2:0.0305 loss3:0.0130 | AUC:0.7635 Anomaly AUC:0.6572
[2023-09-08 20:40:29,683][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0005 loss2:0.0263 loss3:0.0134 | AUC:0.7634 Anomaly AUC:0.6477
[2023-09-08 20:40:51,984][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0003 loss2:0.0185 loss3:0.0120 | AUC:0.7691 Anomaly AUC:0.6544
[2023-09-08 20:41:14,319][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0031 loss2:0.0467 loss3:0.0184 | AUC:0.7741 Anomaly AUC:0.6619
[2023-09-08 20:41:36,677][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0016 loss2:0.0415 loss3:0.0211 | AUC:0.7053 Anomaly AUC:0.6439
[2023-09-08 20:41:59,012][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0013 loss2:0.0351 loss3:0.0195 | AUC:0.6557 Anomaly AUC:0.6560
[2023-09-08 20:42:21,315][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0047 loss2:0.0611 loss3:0.0337 | AUC:0.7483 Anomaly AUC:0.6892
[2023-09-08 20:42:43,611][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0008 loss2:0.0165 loss3:0.0164 | AUC:0.7842 Anomaly AUC:0.6923
[2023-09-08 20:43:06,044][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0003 loss2:0.0087 loss3:0.0132 | AUC:0.7443 Anomaly AUC:0.6694
[2023-09-08 20:43:28,540][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0002 loss2:0.0067 loss3:0.0119 | AUC:0.7817 Anomaly AUC:0.6759
[2023-09-08 20:43:51,058][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0002 loss2:0.0059 loss3:0.0113 | AUC:0.7719 Anomaly AUC:0.6658
[2023-09-08 20:44:13,423][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0002 loss2:0.0045 loss3:0.0110 | AUC:0.7707 Anomaly AUC:0.6662
[2023-09-08 20:44:35,711][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0002 loss2:0.0041 loss3:0.0109 | AUC:0.7626 Anomaly AUC:0.6593
[2023-09-08 20:44:58,029][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0004 loss2:0.0071 loss3:0.0119 | AUC:0.7739 Anomaly AUC:0.6666
[2023-09-08 20:45:20,407][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0011 loss2:0.0502 loss3:0.0202 | AUC:0.7666 Anomaly AUC:0.6652
[2023-09-08 20:45:42,619][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0038 loss2:0.0416 loss3:0.0252 | AUC:0.7427 Anomaly AUC:0.6667
[2023-09-08 20:46:05,008][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0006 loss2:0.0171 loss3:0.0174 | AUC:0.7287 Anomaly AUC:0.6694
[2023-09-08 20:46:27,457][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0002 loss2:0.0054 loss3:0.0130 | AUC:0.7321 Anomaly AUC:0.6512
[2023-09-08 20:46:49,684][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0003 loss2:0.0044 loss3:0.0127 | AUC:0.7281 Anomaly AUC:0.6416
[2023-09-08 20:47:12,057][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0056 loss2:0.0302 loss3:0.0218 | AUC:0.7441 Anomaly AUC:0.6491
[2023-09-08 20:47:34,538][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0007 loss2:0.0224 loss3:0.0178 | AUC:0.7423 Anomaly AUC:0.6630
[2023-09-08 20:47:56,878][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0006 loss2:0.0156 loss3:0.0164 | AUC:0.7471 Anomaly AUC:0.6532
[2023-09-08 20:48:19,255][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0004 loss2:0.0140 loss3:0.0151 | AUC:0.7091 Anomaly AUC:0.6602
[2023-09-08 20:48:41,721][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0004 loss2:0.0134 loss3:0.0149 | AUC:0.6988 Anomaly AUC:0.6614
[2023-09-08 20:49:04,144][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00050 | loss1:0.0012 loss2:0.0064 loss3:0.0130 | AUC:0.7375 Anomaly AUC:0.6765
[2023-09-08 20:49:26,522][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00050 | loss1:0.0003 loss2:0.0030 loss3:0.0130 | AUC:0.7078 Anomaly AUC:0.6642
[2023-09-08 20:49:48,899][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00050 | loss1:0.0001 loss2:0.0017 loss3:0.0111 | AUC:0.7023 Anomaly AUC:0.6590
[2023-09-08 20:50:11,285][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00050 | loss1:0.0001 loss2:0.0020 loss3:0.0110 | AUC:0.6777 Anomaly AUC:0.6521
[2023-09-08 20:50:33,788][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00050 | loss1:0.0004 loss2:0.0044 loss3:0.0121 | AUC:0.6660 Anomaly AUC:0.6362
[2023-09-08 20:50:56,368][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00050 | loss1:0.0006 loss2:0.0304 loss3:0.0187 | AUC:0.7358 Anomaly AUC:0.6363
[2023-09-08 20:51:18,708][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00050 | loss1:0.0008 loss2:0.0283 loss3:0.0190 | AUC:0.7071 Anomaly AUC:0.6471
[2023-09-08 20:51:41,099][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00050 | loss1:0.0003 loss2:0.0124 loss3:0.0147 | AUC:0.7391 Anomaly AUC:0.6377
[2023-09-08 20:52:03,592][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00050 | loss1:0.0002 loss2:0.0122 loss3:0.0139 | AUC:0.7014 Anomaly AUC:0.6370
[2023-09-08 20:52:26,105][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00050 | loss1:0.0004 loss2:0.0154 loss3:0.0154 | AUC:0.7456 Anomaly AUC:0.6433
[2023-09-08 20:52:48,682][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00050 | loss1:0.0002 loss2:0.0077 loss3:0.0127 | AUC:0.7604 Anomaly AUC:0.6641
[2023-09-08 20:53:11,070][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00050 | loss1:0.0002 loss2:0.0055 loss3:0.0127 | AUC:0.7430 Anomaly AUC:0.6422
[2023-09-08 20:53:33,626][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00050 | loss1:0.0005 loss2:0.0065 loss3:0.0133 | AUC:0.7415 Anomaly AUC:0.6594
[2023-09-08 20:53:56,136][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00050 | loss1:0.0003 loss2:0.0112 loss3:0.0140 | AUC:0.7520 Anomaly AUC:0.6575
[2023-09-08 20:54:18,696][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00050 | loss1:0.0002 loss2:0.0134 loss3:0.0140 | AUC:0.7320 Anomaly AUC:0.6575
[2023-09-08 20:54:41,093][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00050 | loss1:0.0007 loss2:0.0110 loss3:0.0152 | AUC:0.7659 Anomaly AUC:0.6707
[2023-09-08 20:55:03,621][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00050 | loss1:0.0003 loss2:0.0126 loss3:0.0186 | AUC:0.7482 Anomaly AUC:0.6588
[2023-09-08 20:55:26,172][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00050 | loss1:0.0001 loss2:0.0059 loss3:0.0133 | AUC:0.7383 Anomaly AUC:0.6645
[2023-09-08 20:55:48,579][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00050 | loss1:0.0005 loss2:0.0122 loss3:0.0152 | AUC:0.7098 Anomaly AUC:0.6471
[2023-09-08 20:56:10,928][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00050 | loss1:0.0008 loss2:0.0147 loss3:0.0180 | AUC:0.7148 Anomaly AUC:0.6820
[2023-09-08 20:56:33,480][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00050 | loss1:0.0002 loss2:0.0206 loss3:0.0163 | AUC:0.7511 Anomaly AUC:0.6588
[2023-09-08 20:56:55,988][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00050 | loss1:0.0002 loss2:0.0091 loss3:0.0133 | AUC:0.7228 Anomaly AUC:0.6504
[2023-09-08 20:57:18,403][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00050 | loss1:0.0001 loss2:0.0040 loss3:0.0125 | AUC:0.7385 Anomaly AUC:0.6585
[2023-09-08 20:57:41,216][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00050 | loss1:0.0003 loss2:0.0044 loss3:0.0128 | AUC:0.7225 Anomaly AUC:0.6689
[2023-09-08 20:58:37,597][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 20:58:40,416][main.py][line:165][INFO] total params:17.0166M
[2023-09-08 20:58:40,416][main.py][line:168][INFO] Training Mode
[2023-09-08 20:58:40,417][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 20:58:40,417][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 20:58:47,876][main.py][line:82][INFO] Random initialize AUCAUC:0.5615 Anomaly AUC:0.52366
[2023-09-08 20:59:09,469][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0624 loss2:1.0443 loss3:0.1426 | AUC:0.7357 Anomaly AUC:0.6533
[2023-09-08 20:59:30,898][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0167 loss2:0.8428 loss3:0.0909 | AUC:0.7497 Anomaly AUC:0.6611
[2023-09-08 20:59:52,552][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0043 loss2:0.7664 loss3:0.0612 | AUC:0.7743 Anomaly AUC:0.6601
[2023-09-08 21:00:14,327][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0036 loss2:0.7124 loss3:0.0532 | AUC:0.7585 Anomaly AUC:0.6476
[2023-09-08 21:00:36,124][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0024 loss2:0.6546 loss3:0.0472 | AUC:0.7631 Anomaly AUC:0.6589
[2023-09-08 21:00:58,021][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0025 loss2:0.5845 loss3:0.0414 | AUC:0.7552 Anomaly AUC:0.6402
[2023-09-08 21:01:19,971][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0023 loss2:0.5124 loss3:0.0386 | AUC:0.7537 Anomaly AUC:0.6360
[2023-09-08 21:01:41,801][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0024 loss2:0.4330 loss3:0.0365 | AUC:0.7618 Anomaly AUC:0.6321
[2023-09-08 21:02:03,719][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0024 loss2:0.3520 loss3:0.0327 | AUC:0.7478 Anomaly AUC:0.6316
[2023-09-08 21:02:25,620][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0023 loss2:0.2835 loss3:0.0316 | AUC:0.7179 Anomaly AUC:0.6179
[2023-09-08 21:02:47,494][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0017 loss2:0.2369 loss3:0.0302 | AUC:0.7577 Anomaly AUC:0.6416
[2023-09-08 21:03:09,499][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0015 loss2:0.1815 loss3:0.0288 | AUC:0.7728 Anomaly AUC:0.6446
[2023-09-08 21:03:31,538][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0011 loss2:0.1305 loss3:0.0254 | AUC:0.7698 Anomaly AUC:0.6463
[2023-09-08 21:03:53,664][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0020 loss2:0.1103 loss3:0.0243 | AUC:0.7268 Anomaly AUC:0.6480
[2023-09-08 21:04:15,722][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0012 loss2:0.0951 loss3:0.0235 | AUC:0.7518 Anomaly AUC:0.6396
[2023-09-08 21:04:37,712][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0011 loss2:0.0659 loss3:0.0203 | AUC:0.7565 Anomaly AUC:0.6309
[2023-09-08 21:04:59,751][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0010 loss2:0.0568 loss3:0.0188 | AUC:0.7341 Anomaly AUC:0.6174
[2023-09-08 21:05:21,839][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0010 loss2:0.0576 loss3:0.0202 | AUC:0.7767 Anomaly AUC:0.6656
[2023-09-08 21:05:43,775][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0008 loss2:0.0396 loss3:0.0171 | AUC:0.7419 Anomaly AUC:0.6347
[2023-09-08 21:06:05,659][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0007 loss2:0.0300 loss3:0.0174 | AUC:0.7759 Anomaly AUC:0.6505
[2023-09-08 21:06:27,727][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0009 loss2:0.0411 loss3:0.0178 | AUC:0.7783 Anomaly AUC:0.6380
[2023-09-08 21:06:49,836][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0028 loss2:0.0493 loss3:0.0268 | AUC:0.7325 Anomaly AUC:0.6413
[2023-09-08 21:07:11,861][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0006 loss2:0.0246 loss3:0.0167 | AUC:0.7263 Anomaly AUC:0.6456
[2023-09-08 21:07:33,877][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0006 loss2:0.0268 loss3:0.0146 | AUC:0.7146 Anomaly AUC:0.6498
[2023-09-08 21:07:55,945][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0006 loss2:0.0229 loss3:0.0156 | AUC:0.7704 Anomaly AUC:0.6522
[2023-09-08 21:08:17,898][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0008 loss2:0.0225 loss3:0.0150 | AUC:0.7419 Anomaly AUC:0.6398
[2023-09-08 21:08:39,972][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0008 loss2:0.0324 loss3:0.0167 | AUC:0.7696 Anomaly AUC:0.6429
[2023-09-08 21:09:02,249][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0008 loss2:0.0274 loss3:0.0178 | AUC:0.7424 Anomaly AUC:0.6362
[2023-09-08 21:09:24,261][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0005 loss2:0.0165 loss3:0.0147 | AUC:0.7618 Anomaly AUC:0.6432
[2023-09-08 21:09:46,314][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0033 loss2:0.0323 loss3:0.0270 | AUC:0.7365 Anomaly AUC:0.6545
[2023-09-08 21:10:08,307][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0012 loss2:0.0307 loss3:0.0236 | AUC:0.7089 Anomaly AUC:0.6618
[2023-09-08 21:10:33,835][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 21:10:36,590][main.py][line:165][INFO] total params:7.5247M
[2023-09-08 21:10:36,590][main.py][line:168][INFO] Training Mode
[2023-09-08 21:10:36,591][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 21:10:36,591][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 21:11:22,435][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 21:11:25,218][main.py][line:165][INFO] total params:7.5247M
[2023-09-08 21:11:25,218][main.py][line:168][INFO] Training Mode
[2023-09-08 21:11:25,218][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 21:11:25,219][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 21:12:28,036][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 10, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 21:12:30,791][main.py][line:165][INFO] total params:7.5247M
[2023-09-08 21:12:30,791][main.py][line:168][INFO] Training Mode
[2023-09-08 21:12:30,791][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 21:12:30,792][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 21:12:39,005][main.py][line:82][INFO] Random initialize AUCAUC:0.4433 Anomaly AUC:0.54786
[2023-09-08 21:12:57,412][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5615 loss2:1.2079 loss3:0.2455 | AUC:0.7968 Anomaly AUC:0.5882
[2023-09-08 21:13:15,551][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2868 loss2:0.9217 loss3:0.0672 | AUC:0.7977 Anomaly AUC:0.5915
[2023-09-08 21:13:34,028][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2188 loss2:0.8124 loss3:0.0386 | AUC:0.8113 Anomaly AUC:0.5970
[2023-09-08 21:13:52,711][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1726 loss2:0.7183 loss3:0.0287 | AUC:0.8013 Anomaly AUC:0.5803
[2023-09-08 21:14:11,446][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.1267 loss2:0.6461 loss3:0.0231 | AUC:0.7901 Anomaly AUC:0.5734
[2023-09-08 21:14:30,303][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0803 loss2:0.5565 loss3:0.0154 | AUC:0.8072 Anomaly AUC:0.5509
[2023-09-08 21:14:49,012][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0503 loss2:0.4699 loss3:0.0102 | AUC:0.8017 Anomaly AUC:0.5496
[2023-09-08 21:15:07,815][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0380 loss2:0.3844 loss3:0.0066 | AUC:0.7932 Anomaly AUC:0.5316
[2023-09-08 21:15:26,712][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0330 loss2:0.3080 loss3:0.0053 | AUC:0.7716 Anomaly AUC:0.5247
[2023-09-08 21:15:45,567][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0165 loss2:0.2256 loss3:0.0033 | AUC:0.8059 Anomaly AUC:0.5563
[2023-09-08 21:16:04,435][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0204 loss2:0.1736 loss3:0.0036 | AUC:0.7806 Anomaly AUC:0.5205
[2023-09-08 21:16:23,285][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0175 loss2:0.1366 loss3:0.0030 | AUC:0.7850 Anomaly AUC:0.5250
[2023-09-08 21:16:42,164][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0079 loss2:0.0820 loss3:0.0018 | AUC:0.7767 Anomaly AUC:0.5314
[2023-09-08 21:17:01,129][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0078 loss2:0.0606 loss3:0.0016 | AUC:0.7991 Anomaly AUC:0.5593
[2023-09-08 21:17:20,089][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0151 loss2:0.0627 loss3:0.0028 | AUC:0.7636 Anomaly AUC:0.5518
[2023-09-08 21:17:38,990][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0160 loss2:0.0601 loss3:0.0029 | AUC:0.7552 Anomaly AUC:0.5150
[2023-09-08 21:17:57,866][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0078 loss2:0.0354 loss3:0.0015 | AUC:0.7824 Anomaly AUC:0.5357
[2023-09-08 21:18:16,797][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0136 loss2:0.0420 loss3:0.0023 | AUC:0.7475 Anomaly AUC:0.5117
[2023-09-08 21:18:35,747][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0084 loss2:0.0280 loss3:0.0015 | AUC:0.7242 Anomaly AUC:0.5216
[2023-09-08 21:18:54,697][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0102 loss2:0.0321 loss3:0.0019 | AUC:0.7210 Anomaly AUC:0.4950
[2023-09-08 21:19:13,530][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0037 loss2:0.0183 loss3:0.0009 | AUC:0.7273 Anomaly AUC:0.5428
[2023-09-08 21:19:32,445][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0075 loss2:0.0278 loss3:0.0014 | AUC:0.7664 Anomaly AUC:0.5462
[2023-09-08 21:19:51,390][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0115 loss2:0.0298 loss3:0.0020 | AUC:0.7724 Anomaly AUC:0.5559
[2023-09-08 21:20:10,334][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0053 loss2:0.0217 loss3:0.0011 | AUC:0.7748 Anomaly AUC:0.5504
[2023-09-08 21:20:29,286][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0105 loss2:0.0261 loss3:0.0019 | AUC:0.7450 Anomaly AUC:0.5167
[2023-09-08 21:20:48,227][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0063 loss2:0.0199 loss3:0.0012 | AUC:0.7457 Anomaly AUC:0.5239
[2023-09-08 21:21:07,159][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0066 loss2:0.0161 loss3:0.0013 | AUC:0.7713 Anomaly AUC:0.5428
[2023-09-08 21:21:26,159][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0087 loss2:0.0199 loss3:0.0015 | AUC:0.7507 Anomaly AUC:0.5203
[2023-09-08 21:21:45,056][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0094 loss2:0.0177 loss3:0.0014 | AUC:0.7529 Anomaly AUC:0.4958
[2023-09-08 21:22:04,025][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0133 loss2:0.0267 loss3:0.0024 | AUC:0.7773 Anomaly AUC:0.5679
[2023-09-08 21:22:22,913][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0088 loss2:0.0192 loss3:0.0016 | AUC:0.7113 Anomaly AUC:0.5236
[2023-09-08 21:22:41,813][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0055 loss2:0.0146 loss3:0.0011 | AUC:0.7139 Anomaly AUC:0.5048
[2023-09-08 21:23:00,670][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0021 loss2:0.0060 loss3:0.0006 | AUC:0.7075 Anomaly AUC:0.5275
[2023-09-08 21:23:19,645][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0027 loss2:0.0049 loss3:0.0006 | AUC:0.7153 Anomaly AUC:0.4906
[2023-09-08 21:23:38,626][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0002 loss2:0.0024 loss3:0.0003 | AUC:0.7362 Anomaly AUC:0.5053
[2023-09-08 21:23:57,569][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0000 loss2:0.0020 loss3:0.0002 | AUC:0.7508 Anomaly AUC:0.5107
[2023-09-08 21:24:16,477][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0000 loss2:0.0018 loss3:0.0002 | AUC:0.7689 Anomaly AUC:0.5223
[2023-09-08 21:24:35,486][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0000 loss2:0.0017 loss3:0.0002 | AUC:0.7758 Anomaly AUC:0.5270
[2023-09-08 21:24:54,608][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0000 loss2:0.0015 loss3:0.0002 | AUC:0.7845 Anomaly AUC:0.5382
[2023-09-08 21:25:13,648][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0000 loss2:0.0017 loss3:0.0002 | AUC:0.7887 Anomaly AUC:0.5441
[2023-09-08 21:25:32,682][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0000 loss2:0.0016 loss3:0.0002 | AUC:0.7937 Anomaly AUC:0.5505
[2023-09-08 21:25:51,816][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00050 | loss1:0.0000 loss2:0.0016 loss3:0.0002 | AUC:0.7966 Anomaly AUC:0.5575
[2023-09-08 21:26:10,833][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00050 | loss1:0.0000 loss2:0.0014 loss3:0.0002 | AUC:0.8012 Anomaly AUC:0.5649
[2023-09-08 21:26:29,842][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00050 | loss1:0.0000 loss2:0.0015 loss3:0.0002 | AUC:0.8034 Anomaly AUC:0.5659
[2023-09-08 21:26:48,833][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00050 | loss1:0.0000 loss2:0.0014 loss3:0.0002 | AUC:0.8049 Anomaly AUC:0.5618
[2023-09-08 21:27:07,916][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00050 | loss1:0.0000 loss2:0.0015 loss3:0.0002 | AUC:0.8072 Anomaly AUC:0.5638
[2023-09-08 21:27:26,976][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00050 | loss1:0.0000 loss2:0.0013 loss3:0.0002 | AUC:0.8078 Anomaly AUC:0.5644
[2023-09-08 21:27:46,135][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00050 | loss1:0.0000 loss2:0.0013 loss3:0.0002 | AUC:0.8069 Anomaly AUC:0.5615
[2023-09-08 21:28:05,296][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00050 | loss1:0.0000 loss2:0.0013 loss3:0.0002 | AUC:0.8110 Anomaly AUC:0.5661
[2023-09-08 21:28:24,346][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00050 | loss1:0.0000 loss2:0.0012 loss3:0.0002 | AUC:0.8116 Anomaly AUC:0.5658
[2023-09-08 21:28:43,465][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00050 | loss1:0.0000 loss2:0.0015 loss3:0.0003 | AUC:0.8129 Anomaly AUC:0.5711
[2023-09-08 21:29:02,537][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00050 | loss1:0.0449 loss2:0.1110 loss3:0.0081 | AUC:0.7526 Anomaly AUC:0.5289
[2023-09-08 21:29:21,760][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00050 | loss1:0.0294 loss2:0.0470 loss3:0.0046 | AUC:0.7681 Anomaly AUC:0.5581
[2023-09-08 21:29:40,916][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00050 | loss1:0.0111 loss2:0.0201 loss3:0.0019 | AUC:0.8130 Anomaly AUC:0.5686
[2023-09-08 21:29:59,900][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00050 | loss1:0.0079 loss2:0.0127 loss3:0.0013 | AUC:0.7636 Anomaly AUC:0.5255
[2023-09-08 21:30:18,923][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00050 | loss1:0.0140 loss2:0.0143 loss3:0.0022 | AUC:0.7996 Anomaly AUC:0.5733
[2023-09-08 21:30:37,901][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00050 | loss1:0.0032 loss2:0.0067 loss3:0.0007 | AUC:0.7857 Anomaly AUC:0.5413
[2023-09-08 21:30:56,948][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00050 | loss1:0.0026 loss2:0.0039 loss3:0.0005 | AUC:0.7839 Anomaly AUC:0.5491
[2023-09-08 21:31:15,910][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00050 | loss1:0.0010 loss2:0.0019 loss3:0.0004 | AUC:0.7935 Anomaly AUC:0.5602
[2023-09-08 21:31:34,875][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00050 | loss1:0.0010 loss2:0.0029 loss3:0.0004 | AUC:0.7986 Anomaly AUC:0.5818
[2023-09-08 21:31:54,022][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00050 | loss1:0.0126 loss2:0.0141 loss3:0.0020 | AUC:0.7853 Anomaly AUC:0.5453
[2023-09-08 21:32:13,082][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00050 | loss1:0.0065 loss2:0.0200 loss3:0.0015 | AUC:0.7529 Anomaly AUC:0.5227
[2023-09-08 21:32:32,104][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00050 | loss1:0.0037 loss2:0.0087 loss3:0.0008 | AUC:0.7937 Anomaly AUC:0.5664
[2023-09-08 21:32:51,022][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00050 | loss1:0.0008 loss2:0.0037 loss3:0.0003 | AUC:0.7964 Anomaly AUC:0.5644
[2023-09-08 21:33:10,362][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00050 | loss1:0.0000 loss2:0.0018 loss3:0.0002 | AUC:0.8003 Anomaly AUC:0.5691
[2023-09-08 21:33:29,474][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00050 | loss1:0.0000 loss2:0.0011 loss3:0.0002 | AUC:0.8043 Anomaly AUC:0.5775
[2023-09-08 21:33:48,560][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00050 | loss1:0.0000 loss2:0.0011 loss3:0.0002 | AUC:0.8058 Anomaly AUC:0.5802
[2023-09-08 21:34:07,636][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00050 | loss1:0.0000 loss2:0.0010 loss3:0.0002 | AUC:0.8058 Anomaly AUC:0.5828
[2023-09-08 21:34:26,665][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00050 | loss1:0.0000 loss2:0.0010 loss3:0.0002 | AUC:0.8026 Anomaly AUC:0.5790
[2023-09-08 21:34:45,733][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00050 | loss1:0.0000 loss2:0.0009 loss3:0.0002 | AUC:0.7997 Anomaly AUC:0.5729
[2023-09-08 21:35:04,896][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00050 | loss1:0.0000 loss2:0.0009 loss3:0.0002 | AUC:0.7970 Anomaly AUC:0.5701
[2023-09-08 21:35:24,077][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00050 | loss1:0.0000 loss2:0.0011 loss3:0.0002 | AUC:0.7885 Anomaly AUC:0.5702
[2023-09-08 21:35:43,044][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00050 | loss1:0.0000 loss2:0.0010 loss3:0.0002 | AUC:0.7822 Anomaly AUC:0.5705
[2023-09-08 21:36:20,441][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 20, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 21:36:23,485][main.py][line:165][INFO] total params:7.5349M
[2023-09-08 21:36:23,485][main.py][line:168][INFO] Training Mode
[2023-09-08 21:36:23,486][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 21:36:23,486][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 21:36:31,789][main.py][line:82][INFO] Random initialize AUCAUC:0.6086 Anomaly AUC:0.60989
[2023-09-08 21:36:50,147][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5169 loss2:1.2753 loss3:0.3613 | AUC:0.8294 Anomaly AUC:0.6350
[2023-09-08 21:37:08,253][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2677 loss2:0.9382 loss3:0.2428 | AUC:0.8360 Anomaly AUC:0.6620
[2023-09-08 21:37:26,869][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1559 loss2:0.8212 loss3:0.1661 | AUC:0.8388 Anomaly AUC:0.6692
[2023-09-08 21:37:45,391][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0850 loss2:0.7455 loss3:0.1071 | AUC:0.8461 Anomaly AUC:0.6629
[2023-09-08 21:38:04,031][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0643 loss2:0.6950 loss3:0.0695 | AUC:0.8453 Anomaly AUC:0.6720
[2023-09-08 21:38:22,744][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0341 loss2:0.6373 loss3:0.0434 | AUC:0.8496 Anomaly AUC:0.6742
[2023-09-08 21:38:41,411][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0381 loss2:0.6010 loss3:0.0337 | AUC:0.8434 Anomaly AUC:0.6838
[2023-09-08 21:39:00,127][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0134 loss2:0.5511 loss3:0.0235 | AUC:0.8499 Anomaly AUC:0.6724
[2023-09-08 21:39:18,925][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0063 loss2:0.5001 loss3:0.0180 | AUC:0.8497 Anomaly AUC:0.6666
[2023-09-08 21:39:37,743][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0032 loss2:0.4539 loss3:0.0144 | AUC:0.8562 Anomaly AUC:0.6796
[2023-09-08 21:39:56,571][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0027 loss2:0.4152 loss3:0.0127 | AUC:0.8527 Anomaly AUC:0.6746
[2023-09-08 21:40:15,399][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0022 loss2:0.3768 loss3:0.0114 | AUC:0.8538 Anomaly AUC:0.6750
[2023-09-08 21:40:34,188][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0332 loss2:0.3860 loss3:0.0157 | AUC:0.8505 Anomaly AUC:0.6643
[2023-09-08 21:40:52,962][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0377 loss2:0.3987 loss3:0.0166 | AUC:0.8541 Anomaly AUC:0.6683
[2023-09-08 21:41:11,844][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0028 loss2:0.3101 loss3:0.0103 | AUC:0.8564 Anomaly AUC:0.6670
[2023-09-08 21:41:30,552][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0015 loss2:0.2786 loss3:0.0088 | AUC:0.8553 Anomaly AUC:0.6629
[2023-09-08 21:41:49,539][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0012 loss2:0.2550 loss3:0.0079 | AUC:0.8565 Anomaly AUC:0.6656
[2023-09-08 21:42:08,293][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0010 loss2:0.2362 loss3:0.0071 | AUC:0.8547 Anomaly AUC:0.6619
[2023-09-08 21:42:27,193][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0009 loss2:0.2196 loss3:0.0061 | AUC:0.8568 Anomaly AUC:0.6699
[2023-09-08 21:42:46,073][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0008 loss2:0.2032 loss3:0.0052 | AUC:0.8558 Anomaly AUC:0.6635
[2023-09-08 21:43:05,010][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0008 loss2:0.1901 loss3:0.0041 | AUC:0.8575 Anomaly AUC:0.6661
[2023-09-08 21:43:23,839][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0009 loss2:0.1802 loss3:0.0029 | AUC:0.8565 Anomaly AUC:0.6649
[2023-09-08 21:43:42,695][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0010 loss2:0.1674 loss3:0.0014 | AUC:0.8493 Anomaly AUC:0.6449
[2023-09-08 21:44:01,544][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0698 loss2:0.2879 loss3:0.0135 | AUC:0.8553 Anomaly AUC:0.6804
[2023-09-08 21:44:20,298][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0093 loss2:0.1836 loss3:0.0034 | AUC:0.8589 Anomaly AUC:0.6715
[2023-09-08 21:44:39,077][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0011 loss2:0.1504 loss3:0.0013 | AUC:0.8529 Anomaly AUC:0.6598
[2023-09-08 21:44:58,042][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0008 loss2:0.1405 loss3:0.0010 | AUC:0.8529 Anomaly AUC:0.6621
[2023-09-08 21:45:16,895][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0009 loss2:0.1325 loss3:0.0009 | AUC:0.8490 Anomaly AUC:0.6527
[2023-09-08 21:45:35,795][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0006 loss2:0.1251 loss3:0.0008 | AUC:0.8502 Anomaly AUC:0.6572
[2023-09-08 21:45:54,724][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0005 loss2:0.1197 loss3:0.0007 | AUC:0.8491 Anomaly AUC:0.6541
[2023-09-08 21:46:13,674][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0004 loss2:0.1136 loss3:0.0007 | AUC:0.8449 Anomaly AUC:0.6437
[2023-09-08 21:46:32,571][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0004 loss2:0.1078 loss3:0.0007 | AUC:0.8435 Anomaly AUC:0.6404
[2023-09-08 21:46:51,477][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0004 loss2:0.1041 loss3:0.0007 | AUC:0.8442 Anomaly AUC:0.6452
[2023-09-08 21:47:10,399][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0734 loss2:0.2668 loss3:0.0148 | AUC:0.8365 Anomaly AUC:0.6368
[2023-09-08 21:47:29,348][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0053 loss2:0.1340 loss3:0.0023 | AUC:0.8450 Anomaly AUC:0.6482
[2023-09-08 21:47:50,347][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 21:47:53,147][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 21:47:53,147][main.py][line:168][INFO] Training Mode
[2023-09-08 21:47:53,147][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 21:47:53,148][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 21:48:01,207][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-08 21:48:19,499][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4374 loss2:1.1496 loss3:0.3402 | AUC:0.8219 Anomaly AUC:0.6583
[2023-09-08 21:48:37,810][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1801 loss2:0.8474 loss3:0.2034 | AUC:0.8387 Anomaly AUC:0.6840
[2023-09-08 21:48:56,440][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0788 loss2:0.7539 loss3:0.1038 | AUC:0.8408 Anomaly AUC:0.6751
[2023-09-08 21:49:15,007][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0392 loss2:0.6852 loss3:0.0481 | AUC:0.8430 Anomaly AUC:0.6660
[2023-09-08 21:49:33,692][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0323 loss2:0.6325 loss3:0.0285 | AUC:0.8380 Anomaly AUC:0.6804
[2023-09-08 21:49:52,421][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0134 loss2:0.5665 loss3:0.0188 | AUC:0.8472 Anomaly AUC:0.6919
[2023-09-08 21:50:11,247][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0067 loss2:0.5143 loss3:0.0143 | AUC:0.8504 Anomaly AUC:0.6878
[2023-09-08 21:50:30,126][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0032 loss2:0.4610 loss3:0.0110 | AUC:0.8522 Anomaly AUC:0.6929
[2023-09-08 21:50:49,100][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0021 loss2:0.4126 loss3:0.0086 | AUC:0.8575 Anomaly AUC:0.7036
[2023-09-08 21:51:07,902][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0019 loss2:0.3726 loss3:0.0062 | AUC:0.8525 Anomaly AUC:0.6970
[2023-09-08 21:51:26,656][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0025 loss2:0.3387 loss3:0.0039 | AUC:0.8514 Anomaly AUC:0.6938
[2023-09-08 21:51:45,442][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0604 loss2:0.3826 loss3:0.0119 | AUC:0.8473 Anomaly AUC:0.6722
[2023-09-08 21:52:04,292][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0066 loss2:0.3137 loss3:0.0043 | AUC:0.8536 Anomaly AUC:0.6915
[2023-09-08 21:52:23,266][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0015 loss2:0.2795 loss3:0.0026 | AUC:0.8506 Anomaly AUC:0.6858
[2023-09-08 21:52:42,135][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0010 loss2:0.2579 loss3:0.0021 | AUC:0.8522 Anomaly AUC:0.6924
[2023-09-08 21:53:01,005][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0009 loss2:0.2398 loss3:0.0018 | AUC:0.8465 Anomaly AUC:0.6881
[2023-09-08 21:53:19,840][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0009 loss2:0.2237 loss3:0.0019 | AUC:0.8491 Anomaly AUC:0.6820
[2023-09-08 21:53:38,610][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0008 loss2:0.2077 loss3:0.0017 | AUC:0.8407 Anomaly AUC:0.6805
[2023-09-08 21:53:57,484][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0012 loss2:0.1967 loss3:0.0020 | AUC:0.8501 Anomaly AUC:0.6868
[2023-09-08 21:54:16,265][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0355 loss2:0.2288 loss3:0.0064 | AUC:0.8480 Anomaly AUC:0.6948
[2023-09-08 21:54:35,183][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0168 loss2:0.2142 loss3:0.0046 | AUC:0.8579 Anomaly AUC:0.6983
[2023-09-08 21:54:54,175][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0018 loss2:0.1790 loss3:0.0022 | AUC:0.8597 Anomaly AUC:0.7000
[2023-09-08 21:55:13,066][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0012 loss2:0.1658 loss3:0.0018 | AUC:0.8503 Anomaly AUC:0.6883
[2023-09-08 21:55:31,993][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0026 loss2:0.1609 loss3:0.0023 | AUC:0.8556 Anomaly AUC:0.6946
[2023-09-08 21:55:50,934][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0007 loss2:0.1496 loss3:0.0016 | AUC:0.8538 Anomaly AUC:0.6894
[2023-09-08 21:56:09,943][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0006 loss2:0.1421 loss3:0.0014 | AUC:0.8569 Anomaly AUC:0.6965
[2023-09-08 21:56:28,877][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0023 loss2:0.1396 loss3:0.0017 | AUC:0.8512 Anomaly AUC:0.6870
[2023-09-08 21:56:47,668][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0013 loss2:0.1326 loss3:0.0018 | AUC:0.8521 Anomaly AUC:0.6917
[2023-09-08 21:57:06,589][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0171 loss2:0.1508 loss3:0.0037 | AUC:0.8629 Anomaly AUC:0.6990
[2023-09-08 21:57:25,536][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0068 loss2:0.1363 loss3:0.0029 | AUC:0.8504 Anomaly AUC:0.6771
[2023-09-08 21:57:44,478][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0026 loss2:0.1205 loss3:0.0021 | AUC:0.8542 Anomaly AUC:0.6851
[2023-09-08 21:58:03,288][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0004 loss2:0.1123 loss3:0.0013 | AUC:0.8583 Anomaly AUC:0.6896
[2023-09-08 21:58:22,254][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0003 loss2:0.1055 loss3:0.0011 | AUC:0.8547 Anomaly AUC:0.6849
[2023-09-08 21:58:41,163][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0003 loss2:0.1018 loss3:0.0009 | AUC:0.8560 Anomaly AUC:0.6872
[2023-09-08 21:59:00,173][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0003 loss2:0.0972 loss3:0.0008 | AUC:0.8526 Anomaly AUC:0.6839
[2023-09-08 21:59:19,144][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0003 loss2:0.0930 loss3:0.0007 | AUC:0.8541 Anomaly AUC:0.6867
[2023-09-08 21:59:38,017][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0003 loss2:0.0896 loss3:0.0007 | AUC:0.8566 Anomaly AUC:0.6902
[2023-09-08 21:59:56,917][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0002 loss2:0.0863 loss3:0.0006 | AUC:0.8547 Anomaly AUC:0.6888
[2023-09-08 22:00:15,837][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0002 loss2:0.0825 loss3:0.0006 | AUC:0.8574 Anomaly AUC:0.6918
[2023-09-08 22:00:34,878][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0002 loss2:0.0792 loss3:0.0006 | AUC:0.8530 Anomaly AUC:0.6846
[2023-09-08 22:00:53,815][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0002 loss2:0.0765 loss3:0.0007 | AUC:0.8524 Anomaly AUC:0.6887
[2023-09-08 22:01:12,721][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0378 loss2:0.1324 loss3:0.0076 | AUC:0.8238 Anomaly AUC:0.6668
[2023-09-08 22:01:31,743][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0116 loss2:0.1019 loss3:0.0039 | AUC:0.8448 Anomaly AUC:0.6859
[2023-09-08 22:01:50,701][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0030 loss2:0.0755 loss3:0.0017 | AUC:0.8426 Anomaly AUC:0.6844
[2023-09-08 22:02:09,668][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0005 loss2:0.0678 loss3:0.0008 | AUC:0.8442 Anomaly AUC:0.6849
[2023-09-08 22:02:28,796][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0003 loss2:0.0640 loss3:0.0007 | AUC:0.8449 Anomaly AUC:0.6864
[2023-09-08 22:02:47,837][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0003 loss2:0.0606 loss3:0.0006 | AUC:0.8445 Anomaly AUC:0.6848
[2023-09-08 22:03:06,810][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0002 loss2:0.0588 loss3:0.0005 | AUC:0.8449 Anomaly AUC:0.6842
[2023-09-08 22:03:25,823][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0002 loss2:0.0555 loss3:0.0005 | AUC:0.8454 Anomaly AUC:0.6851
[2023-09-08 22:03:44,898][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0002 loss2:0.0526 loss3:0.0005 | AUC:0.8460 Anomaly AUC:0.6852
[2023-09-08 22:04:03,987][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0002 loss2:0.0511 loss3:0.0005 | AUC:0.8463 Anomaly AUC:0.6849
[2023-09-08 22:04:22,966][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0002 loss2:0.0487 loss3:0.0005 | AUC:0.8469 Anomaly AUC:0.6856
[2023-09-08 22:04:41,926][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0002 loss2:0.0469 loss3:0.0005 | AUC:0.8470 Anomaly AUC:0.6858
[2023-09-08 22:05:00,873][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0001 loss2:0.0452 loss3:0.0005 | AUC:0.8476 Anomaly AUC:0.6863
[2023-09-08 22:05:19,883][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0001 loss2:0.0427 loss3:0.0004 | AUC:0.8472 Anomaly AUC:0.6855
[2023-09-08 22:05:38,889][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0001 loss2:0.0415 loss3:0.0004 | AUC:0.8477 Anomaly AUC:0.6859
[2023-09-08 22:05:57,978][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0001 loss2:0.0395 loss3:0.0004 | AUC:0.8481 Anomaly AUC:0.6854
[2023-09-08 22:06:17,046][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0001 loss2:0.0380 loss3:0.0004 | AUC:0.8481 Anomaly AUC:0.6856
[2023-09-08 22:06:36,187][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0001 loss2:0.0363 loss3:0.0004 | AUC:0.8481 Anomaly AUC:0.6845
[2023-09-08 22:06:55,239][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0001 loss2:0.0351 loss3:0.0004 | AUC:0.8496 Anomaly AUC:0.6872
[2023-09-08 22:07:14,330][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0001 loss2:0.0333 loss3:0.0004 | AUC:0.8500 Anomaly AUC:0.6878
[2023-09-08 22:07:33,397][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0001 loss2:0.0320 loss3:0.0004 | AUC:0.8497 Anomaly AUC:0.6885
[2023-09-08 22:07:52,483][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0001 loss2:0.0308 loss3:0.0004 | AUC:0.8463 Anomaly AUC:0.6814
[2023-09-08 22:08:11,478][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0001 loss2:0.0290 loss3:0.0004 | AUC:0.8474 Anomaly AUC:0.6847
[2023-09-08 22:08:30,444][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0001 loss2:0.0282 loss3:0.0005 | AUC:0.8491 Anomaly AUC:0.6860
[2023-09-08 22:09:21,436][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 22:09:24,221][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 22:09:24,221][main.py][line:174][INFO] Test Mode
[2023-09-08 22:09:24,221][main.py][line:37][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-09-08 22:09:32,172][infer.py][line:47][INFO] offline AUC:0.8613 AP:0.3052 FAR:0.0156 | Complete in 0m 8s

[2023-09-08 22:10:47,986][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 22:10:50,710][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 22:10:50,710][main.py][line:168][INFO] Training Mode
[2023-09-08 22:10:50,710][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)

[2023-09-08 22:10:50,711][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-08 22:10:58,797][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-08 22:11:17,078][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4374 loss2:1.1496 loss3:0.3402 | AUC:0.8219 Anomaly AUC:0.6583
[2023-09-08 22:11:35,200][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1790 loss2:0.8475 loss3:0.2032 | AUC:0.8436 Anomaly AUC:0.6864
[2023-09-08 22:11:53,413][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0842 loss2:0.7565 loss3:0.1042 | AUC:0.8460 Anomaly AUC:0.6831
[2023-09-08 22:12:11,971][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0399 loss2:0.6855 loss3:0.0485 | AUC:0.8587 Anomaly AUC:0.6962
[2023-09-08 22:12:30,528][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0148 loss2:0.6215 loss3:0.0261 | AUC:0.8524 Anomaly AUC:0.6937
[2023-09-08 22:12:49,262][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0100 loss2:0.5590 loss3:0.0178 | AUC:0.8458 Anomaly AUC:0.6755
[2023-09-08 22:13:07,911][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0159 loss2:0.5170 loss3:0.0152 | AUC:0.8415 Anomaly AUC:0.6765
[2023-09-08 22:13:26,631][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0140 loss2:0.4753 loss3:0.0136 | AUC:0.8468 Anomaly AUC:0.6826
[2023-09-08 22:13:45,346][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00009 | loss1:0.0104 loss2:0.4341 loss3:0.0113 | AUC:0.8509 Anomaly AUC:0.6931
[2023-09-08 22:14:04,106][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00009 | loss1:0.0027 loss2:0.3886 loss3:0.0077 | AUC:0.8513 Anomaly AUC:0.6933
[2023-09-08 22:14:22,847][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00009 | loss1:0.0064 loss2:0.3586 loss3:0.0062 | AUC:0.8455 Anomaly AUC:0.6762
[2023-09-08 22:14:41,755][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00009 | loss1:0.0070 loss2:0.3400 loss3:0.0046 | AUC:0.8511 Anomaly AUC:0.6916
[2023-09-08 22:15:00,658][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00009 | loss1:0.0017 loss2:0.3031 loss3:0.0025 | AUC:0.8508 Anomaly AUC:0.6883
[2023-09-08 22:15:19,497][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00009 | loss1:0.0012 loss2:0.2812 loss3:0.0019 | AUC:0.8512 Anomaly AUC:0.6891
[2023-09-08 22:15:38,275][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00009 | loss1:0.0008 loss2:0.2617 loss3:0.0018 | AUC:0.8510 Anomaly AUC:0.6914
[2023-09-08 22:15:57,145][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00008 | loss1:0.0009 loss2:0.2453 loss3:0.0017 | AUC:0.8509 Anomaly AUC:0.6916
[2023-09-08 22:16:16,018][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00008 | loss1:0.0010 loss2:0.2317 loss3:0.0020 | AUC:0.8414 Anomaly AUC:0.6816
[2023-09-08 22:16:34,957][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00008 | loss1:0.0007 loss2:0.2155 loss3:0.0016 | AUC:0.8435 Anomaly AUC:0.6786
[2023-09-08 22:16:53,823][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00008 | loss1:0.0006 loss2:0.2032 loss3:0.0015 | AUC:0.8470 Anomaly AUC:0.6808
[2023-09-08 22:17:12,659][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00008 | loss1:0.0415 loss2:0.2334 loss3:0.0067 | AUC:0.8521 Anomaly AUC:0.7027
[2023-09-08 22:17:31,460][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00007 | loss1:0.0253 loss2:0.2366 loss3:0.0065 | AUC:0.8503 Anomaly AUC:0.6948
[2023-09-08 22:17:50,296][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00007 | loss1:0.0025 loss2:0.1909 loss3:0.0026 | AUC:0.8472 Anomaly AUC:0.6932
[2023-09-08 22:18:09,068][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00007 | loss1:0.0010 loss2:0.1794 loss3:0.0020 | AUC:0.8491 Anomaly AUC:0.6958
[2023-09-08 22:18:27,818][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00007 | loss1:0.0008 loss2:0.1715 loss3:0.0016 | AUC:0.8492 Anomaly AUC:0.6964
[2023-09-08 22:18:46,720][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00006 | loss1:0.0007 loss2:0.1647 loss3:0.0015 | AUC:0.8491 Anomaly AUC:0.6908
[2023-09-08 22:19:05,569][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00006 | loss1:0.0006 loss2:0.1593 loss3:0.0014 | AUC:0.8501 Anomaly AUC:0.6929
[2023-09-08 22:19:24,455][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00006 | loss1:0.0005 loss2:0.1544 loss3:0.0013 | AUC:0.8496 Anomaly AUC:0.6926
[2023-09-08 22:19:43,386][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00006 | loss1:0.0005 loss2:0.1490 loss3:0.0012 | AUC:0.8499 Anomaly AUC:0.6933
[2023-09-08 22:20:02,298][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00005 | loss1:0.0005 loss2:0.1450 loss3:0.0011 | AUC:0.8500 Anomaly AUC:0.6949
[2023-09-08 22:20:21,199][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00005 | loss1:0.0004 loss2:0.1418 loss3:0.0011 | AUC:0.8506 Anomaly AUC:0.6953
[2023-09-08 22:20:40,075][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00005 | loss1:0.0004 loss2:0.1384 loss3:0.0011 | AUC:0.8491 Anomaly AUC:0.6992
[2023-09-08 22:20:58,950][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00004 | loss1:0.0010 loss2:0.1379 loss3:0.0013 | AUC:0.8520 Anomaly AUC:0.6992
[2023-09-08 22:21:17,853][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00004 | loss1:0.0006 loss2:0.1338 loss3:0.0012 | AUC:0.8464 Anomaly AUC:0.6875
[2023-09-08 22:21:36,802][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00004 | loss1:0.0004 loss2:0.1308 loss3:0.0010 | AUC:0.8502 Anomaly AUC:0.6936
[2023-09-08 22:21:55,616][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00004 | loss1:0.0004 loss2:0.1274 loss3:0.0009 | AUC:0.8507 Anomaly AUC:0.6942
[2023-09-08 22:22:14,645][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00003 | loss1:0.0003 loss2:0.1250 loss3:0.0009 | AUC:0.8508 Anomaly AUC:0.6935
[2023-09-08 22:22:33,590][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00003 | loss1:0.0003 loss2:0.1233 loss3:0.0009 | AUC:0.8512 Anomaly AUC:0.6922
[2023-09-08 22:22:52,581][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00003 | loss1:0.0003 loss2:0.1219 loss3:0.0009 | AUC:0.8520 Anomaly AUC:0.6931
[2023-09-08 22:23:11,486][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00003 | loss1:0.0003 loss2:0.1197 loss3:0.0008 | AUC:0.8521 Anomaly AUC:0.6920
[2023-09-08 22:23:30,356][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00003 | loss1:0.0003 loss2:0.1180 loss3:0.0008 | AUC:0.8521 Anomaly AUC:0.6922
[2023-09-08 22:23:49,208][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00002 | loss1:0.0003 loss2:0.1170 loss3:0.0008 | AUC:0.8530 Anomaly AUC:0.6926
[2023-09-08 22:24:08,095][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00002 | loss1:0.0003 loss2:0.1148 loss3:0.0008 | AUC:0.8528 Anomaly AUC:0.6927
[2023-09-08 22:24:27,063][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00002 | loss1:0.0003 loss2:0.1142 loss3:0.0008 | AUC:0.8531 Anomaly AUC:0.6918
[2023-09-08 22:24:46,090][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00002 | loss1:0.0003 loss2:0.1130 loss3:0.0007 | AUC:0.8519 Anomaly AUC:0.6921
[2023-09-08 22:25:05,195][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00001 | loss1:0.0003 loss2:0.1118 loss3:0.0008 | AUC:0.8517 Anomaly AUC:0.6931
[2023-09-08 22:25:24,327][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00001 | loss1:0.0003 loss2:0.1111 loss3:0.0007 | AUC:0.8532 Anomaly AUC:0.6941
[2023-09-08 22:25:43,270][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00001 | loss1:0.0002 loss2:0.1100 loss3:0.0007 | AUC:0.8533 Anomaly AUC:0.6935
[2023-09-08 22:26:02,311][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00001 | loss1:0.0003 loss2:0.1108 loss3:0.0007 | AUC:0.8518 Anomaly AUC:0.6918
[2023-09-08 22:26:21,168][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00001 | loss1:0.0002 loss2:0.1088 loss3:0.0007 | AUC:0.8529 Anomaly AUC:0.6937
[2023-09-08 22:26:40,135][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00001 | loss1:0.0002 loss2:0.1076 loss3:0.0007 | AUC:0.8534 Anomaly AUC:0.6949
[2023-09-08 22:26:59,143][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00001 | loss1:0.0002 loss2:0.1080 loss3:0.0007 | AUC:0.8529 Anomaly AUC:0.6942
[2023-09-08 22:27:18,080][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00000 | loss1:0.0002 loss2:0.1073 loss3:0.0007 | AUC:0.8534 Anomaly AUC:0.6949
[2023-09-08 22:27:36,942][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00000 | loss1:0.0002 loss2:0.1073 loss3:0.0007 | AUC:0.8534 Anomaly AUC:0.6950
[2023-09-08 22:27:56,033][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00000 | loss1:0.0002 loss2:0.1077 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6947
[2023-09-08 22:28:15,050][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00000 | loss1:0.0002 loss2:0.1065 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6944
[2023-09-08 22:28:33,965][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6945
[2023-09-08 22:28:52,920][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6941
[2023-09-08 22:29:11,840][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00000 | loss1:0.0002 loss2:0.1069 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:29:30,839][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00000 | loss1:0.0002 loss2:0.1063 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:29:49,740][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00000 | loss1:0.0002 loss2:0.1067 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:30:08,725][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00000 | loss1:0.0002 loss2:0.1067 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:30:27,631][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00000 | loss1:0.0002 loss2:0.1065 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:30:46,648][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00000 | loss1:0.0002 loss2:0.1071 loss3:0.0007 | AUC:0.8528 Anomaly AUC:0.6940
[2023-09-08 22:31:05,749][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00000 | loss1:0.0002 loss2:0.1064 loss3:0.0007 | AUC:0.8529 Anomaly AUC:0.6940
[2023-09-08 22:31:24,721][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6941
[2023-09-08 22:31:43,661][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00000 | loss1:0.0002 loss2:0.1064 loss3:0.0007 | AUC:0.8531 Anomaly AUC:0.6947
[2023-09-08 22:32:02,799][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00000 | loss1:0.0002 loss2:0.1068 loss3:0.0007 | AUC:0.8533 Anomaly AUC:0.6945
[2023-09-08 22:32:21,846][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0006 | AUC:0.8525 Anomaly AUC:0.6933
[2023-09-08 22:32:40,855][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00001 | loss1:0.0002 loss2:0.1060 loss3:0.0007 | AUC:0.8523 Anomaly AUC:0.6932
[2023-09-08 22:32:59,941][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00001 | loss1:0.0002 loss2:0.1061 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6939
[2023-09-08 22:33:18,955][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00001 | loss1:0.0002 loss2:0.1049 loss3:0.0007 | AUC:0.8513 Anomaly AUC:0.6918
[2023-09-08 22:33:38,010][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00001 | loss1:0.0002 loss2:0.1049 loss3:0.0007 | AUC:0.8511 Anomaly AUC:0.6912
[2023-09-08 22:33:56,968][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00001 | loss1:0.0002 loss2:0.1046 loss3:0.0007 | AUC:0.8508 Anomaly AUC:0.6912
[2023-09-08 22:34:15,944][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00001 | loss1:0.0002 loss2:0.1045 loss3:0.0007 | AUC:0.8420 Anomaly AUC:0.6810
[2023-09-08 22:34:35,114][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00001 | loss1:0.0002 loss2:0.1042 loss3:0.0007 | AUC:0.8477 Anomaly AUC:0.6875
[2023-09-08 22:34:54,140][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00002 | loss1:0.0012 loss2:0.1040 loss3:0.0008 | AUC:0.8393 Anomaly AUC:0.6859
[2023-09-08 22:35:13,177][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00002 | loss1:0.0033 loss2:0.1069 loss3:0.0015 | AUC:0.8485 Anomaly AUC:0.6949
[2023-09-08 22:35:32,328][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00002 | loss1:0.0009 loss2:0.1043 loss3:0.0011 | AUC:0.8437 Anomaly AUC:0.6878
[2023-09-08 22:35:51,417][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00002 | loss1:0.0003 loss2:0.1024 loss3:0.0009 | AUC:0.8446 Anomaly AUC:0.6877
[2023-09-08 22:36:10,408][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00002 | loss1:0.0002 loss2:0.1008 loss3:0.0008 | AUC:0.8433 Anomaly AUC:0.6889
[2023-09-08 22:36:29,490][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00003 | loss1:0.0002 loss2:0.0989 loss3:0.0007 | AUC:0.8483 Anomaly AUC:0.6918
[2023-09-08 22:36:48,638][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00003 | loss1:0.0002 loss2:0.0978 loss3:0.0007 | AUC:0.8494 Anomaly AUC:0.6939
[2023-09-08 22:37:07,707][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00003 | loss1:0.0008 loss2:0.0969 loss3:0.0008 | AUC:0.8448 Anomaly AUC:0.6881
[2023-09-08 22:37:26,603][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00003 | loss1:0.0118 loss2:0.1118 loss3:0.0031 | AUC:0.8404 Anomaly AUC:0.6791
[2023-09-08 22:37:45,742][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00004 | loss1:0.0016 loss2:0.0977 loss3:0.0014 | AUC:0.8441 Anomaly AUC:0.6877
[2023-09-08 22:38:04,813][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00004 | loss1:0.0015 loss2:0.0952 loss3:0.0013 | AUC:0.8378 Anomaly AUC:0.6815
[2023-09-08 22:38:23,928][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00004 | loss1:0.0007 loss2:0.0936 loss3:0.0012 | AUC:0.8310 Anomaly AUC:0.6670
[2023-09-08 22:38:43,035][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00004 | loss1:0.0004 loss2:0.0915 loss3:0.0011 | AUC:0.8457 Anomaly AUC:0.6833
[2023-09-08 22:39:02,136][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00005 | loss1:0.0003 loss2:0.0888 loss3:0.0009 | AUC:0.8424 Anomaly AUC:0.6805
[2023-09-08 22:39:21,247][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00005 | loss1:0.0002 loss2:0.0872 loss3:0.0008 | AUC:0.8440 Anomaly AUC:0.6805
[2023-09-08 22:39:40,459][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00005 | loss1:0.0002 loss2:0.0854 loss3:0.0007 | AUC:0.8432 Anomaly AUC:0.6769
[2023-09-08 22:39:59,470][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00006 | loss1:0.0002 loss2:0.0831 loss3:0.0007 | AUC:0.8440 Anomaly AUC:0.6791
[2023-09-08 22:40:18,548][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00006 | loss1:0.0001 loss2:0.0815 loss3:0.0007 | AUC:0.8424 Anomaly AUC:0.6777
[2023-09-08 22:40:37,776][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00006 | loss1:0.0001 loss2:0.0801 loss3:0.0007 | AUC:0.8425 Anomaly AUC:0.6764
[2023-09-08 22:40:57,069][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00006 | loss1:0.0001 loss2:0.0775 loss3:0.0006 | AUC:0.8450 Anomaly AUC:0.6809
[2023-09-08 22:41:16,246][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00007 | loss1:0.0400 loss2:0.1193 loss3:0.0063 | AUC:0.8221 Anomaly AUC:0.6701
[2023-09-08 22:41:35,425][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00007 | loss1:0.0137 loss2:0.1000 loss3:0.0041 | AUC:0.8448 Anomaly AUC:0.6889
[2023-09-08 22:41:54,473][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00007 | loss1:0.0006 loss2:0.0755 loss3:0.0014 | AUC:0.8448 Anomaly AUC:0.6865
[2023-09-08 22:42:13,626][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00007 | loss1:0.0003 loss2:0.0710 loss3:0.0010 | AUC:0.8451 Anomaly AUC:0.6879
[2023-09-08 22:42:32,658][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00007 | loss1:0.0008 loss2:0.0691 loss3:0.0009 | AUC:0.8404 Anomaly AUC:0.6825
[2023-09-08 22:42:32,683][main.py][line:116][INFO] Training completes in 31m 34s | best AUCAUC:0.8587 Anomaly AUC:0.6962

[2023-09-08 22:55:31,582][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-08 22:55:34,333][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 22:55:34,333][main.py][line:174][INFO] Test Mode
[2023-09-08 22:55:34,333][main.py][line:37][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-09-08 22:55:42,316][infer.py][line:47][INFO] offline AUC:0.8571 AP:0.3149 FAR:0.0203 | Complete in 0m 8s

[2023-09-09 12:41:28,702][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:41:31,515][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:41:31,516][main.py][line:174][INFO] Test Mode
[2023-09-09 12:41:31,516][main.py][line:37][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-09-09 12:42:18,026][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:42:20,740][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:42:20,741][main.py][line:168][INFO] Training Mode
[2023-09-09 12:42:20,741][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:42:20,741][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:42:53,735][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:42:56,469][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:42:56,469][main.py][line:168][INFO] Training Mode
[2023-09-09 12:42:56,470][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:42:56,470][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:43:04,653][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 12:46:11,434][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:46:14,127][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:46:14,128][main.py][line:168][INFO] Training Mode
[2023-09-09 12:46:14,128][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:46:14,128][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:48:18,957][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:48:21,687][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:48:21,687][main.py][line:168][INFO] Training Mode
[2023-09-09 12:48:21,687][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:48:21,687][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:49:51,022][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:49:53,736][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:49:53,736][main.py][line:168][INFO] Training Mode
[2023-09-09 12:49:53,737][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:49:53,737][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:50:30,926][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:50:33,665][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:50:33,665][main.py][line:168][INFO] Training Mode
[2023-09-09 12:50:33,666][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:50:33,666][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:51:35,668][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:51:38,387][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:51:38,387][main.py][line:168][INFO] Training Mode
[2023-09-09 12:51:38,387][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:51:38,387][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:51:50,303][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:51:53,036][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:51:53,036][main.py][line:168][INFO] Training Mode
[2023-09-09 12:51:53,037][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:51:53,037][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:53:14,557][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:53:17,274][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:53:17,274][main.py][line:168][INFO] Training Mode
[2023-09-09 12:53:17,274][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:53:17,275][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:54:16,263][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:54:18,956][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:54:18,956][main.py][line:168][INFO] Training Mode
[2023-09-09 12:54:18,956][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:54:18,957][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:54:26,954][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 12:55:58,691][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 12:56:01,383][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 12:56:01,383][main.py][line:168][INFO] Training Mode
[2023-09-09 12:56:01,383][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 12:56:01,383][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 12:56:09,573][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:11:59,935][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:12:02,815][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:12:02,815][main.py][line:168][INFO] Training Mode
[2023-09-09 13:12:02,816][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:12:02,816][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:12:10,890][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:12:28,396][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.8970 loss2:1.3775 loss3:0.3818 | AUC:0.8008 Anomaly AUC:0.5946
[2023-09-09 13:12:45,711][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.5022 loss2:1.2988 loss3:0.3720 | AUC:0.8139 Anomaly AUC:0.6162
[2023-09-09 13:13:03,230][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.4076 loss2:1.2008 loss3:0.3543 | AUC:0.8207 Anomaly AUC:0.6437
[2023-09-09 13:13:20,904][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.3496 loss2:1.0600 loss3:0.3249 | AUC:0.7967 Anomaly AUC:0.5919
[2023-09-09 13:13:38,558][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.2993 loss2:0.9288 loss3:0.2833 | AUC:0.8043 Anomaly AUC:0.5750
[2023-09-09 13:13:56,237][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.2391 loss2:0.8405 loss3:0.2302 | AUC:0.8104 Anomaly AUC:0.5884
[2023-09-09 13:14:13,873][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.1879 loss2:0.7821 loss3:0.1767 | AUC:0.7881 Anomaly AUC:0.5626
[2023-09-09 13:14:31,639][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.1693 loss2:0.7479 loss3:0.1288 | AUC:0.7853 Anomaly AUC:0.5500
[2023-09-09 13:14:49,347][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.1395 loss2:0.7057 loss3:0.0891 | AUC:0.7927 Anomaly AUC:0.5456
[2023-09-09 13:15:07,043][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.1251 loss2:0.6752 loss3:0.0624 | AUC:0.7906 Anomaly AUC:0.5572
[2023-09-09 13:15:24,842][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.1131 loss2:0.6380 loss3:0.0436 | AUC:0.7950 Anomaly AUC:0.5578
[2023-09-09 13:15:42,493][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.1046 loss2:0.6023 loss3:0.0301 | AUC:0.7992 Anomaly AUC:0.5542
[2023-09-09 13:16:00,181][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0999 loss2:0.5697 loss3:0.0226 | AUC:0.8026 Anomaly AUC:0.5533
[2023-09-09 13:16:17,796][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0941 loss2:0.5383 loss3:0.0174 | AUC:0.8057 Anomaly AUC:0.5656
[2023-09-09 13:16:35,491][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00009 | loss1:0.0933 loss2:0.5108 loss3:0.0146 | AUC:0.8106 Anomaly AUC:0.5700
[2023-09-09 13:16:53,151][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00009 | loss1:0.0897 loss2:0.4804 loss3:0.0120 | AUC:0.8091 Anomaly AUC:0.5644
[2023-09-09 13:17:11,020][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00009 | loss1:0.1235 loss2:0.4856 loss3:0.0179 | AUC:0.7418 Anomaly AUC:0.5499
[2023-09-09 13:17:40,339][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:17:43,033][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:17:43,033][main.py][line:168][INFO] Training Mode
[2023-09-09 13:17:43,033][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:17:43,034][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:17:51,162][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:18:08,642][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.1735 loss2:1.3341 loss3:0.3602 | AUC:0.2667 Anomaly AUC:0.4634
[2023-09-09 13:18:26,188][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0757 loss2:1.0199 loss3:0.2128 | AUC:0.2667 Anomaly AUC:0.4986
[2023-09-09 13:18:43,702][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0631 loss2:0.8327 loss3:0.0925 | AUC:0.2362 Anomaly AUC:0.4730
[2023-09-09 13:19:01,287][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0595 loss2:0.7018 loss3:0.0384 | AUC:0.2340 Anomaly AUC:0.4742
[2023-09-09 13:19:19,022][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0572 loss2:0.5739 loss3:0.0180 | AUC:0.2436 Anomaly AUC:0.5173
[2023-09-09 13:19:36,776][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0561 loss2:0.4534 loss3:0.0109 | AUC:0.2770 Anomaly AUC:0.5058
[2023-09-09 13:19:48,315][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:19:51,010][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:19:51,011][main.py][line:168][INFO] Training Mode
[2023-09-09 13:19:51,011][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:19:51,011][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:19:59,013][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:20:16,512][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0070 loss2:0.8904 loss3:0.1400 | AUC:0.6717 Anomaly AUC:0.6542
[2023-09-09 13:20:33,966][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0015 loss2:0.5649 loss3:0.0286 | AUC:0.8309 Anomaly AUC:0.6677
[2023-09-09 13:20:51,595][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0006 loss2:0.3935 loss3:0.0160 | AUC:0.6373 Anomaly AUC:0.6302
[2023-09-09 13:21:09,194][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0004 loss2:0.2722 loss3:0.0082 | AUC:0.8298 Anomaly AUC:0.6533
[2023-09-09 13:21:26,908][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0002 loss2:0.1953 loss3:0.0028 | AUC:0.8245 Anomaly AUC:0.6558
[2023-09-09 13:21:44,554][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0002 loss2:0.1498 loss3:0.0017 | AUC:0.8336 Anomaly AUC:0.6548
[2023-09-09 13:22:02,209][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0002 loss2:0.1389 loss3:0.0028 | AUC:0.8344 Anomaly AUC:0.6563
[2023-09-09 13:22:19,891][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0003 loss2:0.1255 loss3:0.0031 | AUC:0.8299 Anomaly AUC:0.6538
[2023-09-09 13:22:37,670][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0002 loss2:0.0945 loss3:0.0019 | AUC:0.8342 Anomaly AUC:0.6553
[2023-09-09 13:22:55,460][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0001 loss2:0.0658 loss3:0.0006 | AUC:0.8354 Anomaly AUC:0.6577
[2023-09-09 13:23:13,156][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0001 loss2:0.0633 loss3:0.0019 | AUC:0.8294 Anomaly AUC:0.6420
[2023-09-09 13:23:30,823][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0002 loss2:0.0597 loss3:0.0019 | AUC:0.8470 Anomaly AUC:0.6638
[2023-09-09 13:23:48,492][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0002 loss2:0.0706 loss3:0.0033 | AUC:0.8339 Anomaly AUC:0.6584
[2023-09-09 13:24:06,085][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0006 loss2:0.0971 loss3:0.0084 | AUC:0.8202 Anomaly AUC:0.6533
[2023-09-09 13:24:23,807][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0001 loss2:0.0506 loss3:0.0028 | AUC:0.8272 Anomaly AUC:0.6519
[2023-09-09 13:24:41,570][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0001 loss2:0.0349 loss3:0.0011 | AUC:0.8348 Anomaly AUC:0.6484
[2023-09-09 13:24:59,346][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0001 loss2:0.0281 loss3:0.0013 | AUC:0.8224 Anomaly AUC:0.6451
[2023-09-09 13:25:17,232][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0000 loss2:0.0218 loss3:0.0009 | AUC:0.8082 Anomaly AUC:0.6339
[2023-09-09 13:25:34,892][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00046 | loss1:0.0004 loss2:0.0552 loss3:0.0074 | AUC:0.7810 Anomaly AUC:0.5984
[2023-09-09 13:25:52,833][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00045 | loss1:0.0002 loss2:0.0317 loss3:0.0030 | AUC:0.7115 Anomaly AUC:0.6221
[2023-09-09 13:26:10,501][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00045 | loss1:0.0001 loss2:0.0179 loss3:0.0011 | AUC:0.6550 Anomaly AUC:0.6117
[2023-09-09 13:26:28,202][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00044 | loss1:0.0001 loss2:0.0114 loss3:0.0003 | AUC:0.6454 Anomaly AUC:0.6053
[2023-09-09 13:26:45,544][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:26:48,237][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:26:48,238][main.py][line:168][INFO] Training Mode
[2023-09-09 13:26:48,238][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:26:48,238][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:26:56,285][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:27:13,781][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.7033 loss2:1.3637 loss3:0.3816 | AUC:0.8138 Anomaly AUC:0.6006
[2023-09-09 13:27:31,129][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.4346 loss2:1.2466 loss3:0.3590 | AUC:0.8197 Anomaly AUC:0.6231
[2023-09-09 13:27:48,716][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.4043 loss2:1.0682 loss3:0.3059 | AUC:0.8296 Anomaly AUC:0.6433
[2023-09-09 13:28:06,342][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.3078 loss2:0.9267 loss3:0.2407 | AUC:0.8385 Anomaly AUC:0.6455
[2023-09-09 13:28:24,047][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.2001 loss2:0.8303 loss3:0.1743 | AUC:0.8440 Anomaly AUC:0.6524
[2023-09-09 13:28:41,697][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.1407 loss2:0.7715 loss3:0.1235 | AUC:0.8354 Anomaly AUC:0.6392
[2023-09-09 13:28:59,354][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0881 loss2:0.7154 loss3:0.0819 | AUC:0.8299 Anomaly AUC:0.6384
[2023-09-09 13:29:16,997][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0767 loss2:0.6711 loss3:0.0559 | AUC:0.8226 Anomaly AUC:0.6700
[2023-09-09 13:29:34,730][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0551 loss2:0.6222 loss3:0.0379 | AUC:0.8410 Anomaly AUC:0.6744
[2023-09-09 13:29:52,446][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0448 loss2:0.5770 loss3:0.0268 | AUC:0.8329 Anomaly AUC:0.6680
[2023-09-09 13:30:10,086][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0422 loss2:0.5350 loss3:0.0204 | AUC:0.8389 Anomaly AUC:0.6657
[2023-09-09 13:30:27,769][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0412 loss2:0.4971 loss3:0.0163 | AUC:0.8400 Anomaly AUC:0.6693
[2023-09-09 13:30:45,709][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0374 loss2:0.4570 loss3:0.0128 | AUC:0.8453 Anomaly AUC:0.6773
[2023-09-09 13:31:03,353][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0369 loss2:0.4198 loss3:0.0100 | AUC:0.8394 Anomaly AUC:0.6676
[2023-09-09 13:31:21,032][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00009 | loss1:0.0339 loss2:0.3855 loss3:0.0079 | AUC:0.8427 Anomaly AUC:0.6699
[2023-09-09 13:31:38,710][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00009 | loss1:0.0315 loss2:0.3539 loss3:0.0065 | AUC:0.8493 Anomaly AUC:0.6745
[2023-09-09 13:31:56,324][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00009 | loss1:0.0290 loss2:0.3273 loss3:0.0056 | AUC:0.8427 Anomaly AUC:0.6664
[2023-09-09 13:32:13,990][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00009 | loss1:0.0724 loss2:0.3466 loss3:0.0158 | AUC:0.8392 Anomaly AUC:0.6447
[2023-09-09 13:32:31,648][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00009 | loss1:0.0966 loss2:0.3712 loss3:0.0175 | AUC:0.8326 Anomaly AUC:0.6394
[2023-09-09 13:32:49,549][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00009 | loss1:0.0316 loss2:0.2926 loss3:0.0072 | AUC:0.8430 Anomaly AUC:0.6538
[2023-09-09 13:33:07,238][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00009 | loss1:0.0259 loss2:0.2663 loss3:0.0054 | AUC:0.8525 Anomaly AUC:0.6631
[2023-09-09 13:33:24,987][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00009 | loss1:0.0234 loss2:0.2485 loss3:0.0043 | AUC:0.8544 Anomaly AUC:0.6676
[2023-09-09 13:33:42,730][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00009 | loss1:0.0216 loss2:0.2325 loss3:0.0037 | AUC:0.8558 Anomaly AUC:0.6694
[2023-09-09 13:34:00,359][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00009 | loss1:0.0202 loss2:0.2204 loss3:0.0033 | AUC:0.8543 Anomaly AUC:0.6648
[2023-09-09 13:34:17,970][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00009 | loss1:0.0188 loss2:0.2082 loss3:0.0030 | AUC:0.8549 Anomaly AUC:0.6647
[2023-09-09 13:34:35,596][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00008 | loss1:0.0175 loss2:0.1980 loss3:0.0027 | AUC:0.8563 Anomaly AUC:0.6677
[2023-09-09 13:34:53,339][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00008 | loss1:0.0167 loss2:0.1880 loss3:0.0025 | AUC:0.8563 Anomaly AUC:0.6682
[2023-09-09 13:35:10,994][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00008 | loss1:0.0157 loss2:0.1786 loss3:0.0023 | AUC:0.8571 Anomaly AUC:0.6667
[2023-09-09 13:35:28,701][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00008 | loss1:0.0147 loss2:0.1708 loss3:0.0021 | AUC:0.8564 Anomaly AUC:0.6675
[2023-09-09 13:35:46,381][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00008 | loss1:0.0139 loss2:0.1636 loss3:0.0019 | AUC:0.8567 Anomaly AUC:0.6657
[2023-09-09 13:36:04,064][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00008 | loss1:0.0127 loss2:0.1569 loss3:0.0018 | AUC:0.8560 Anomaly AUC:0.6660
[2023-09-09 13:36:21,888][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00008 | loss1:0.0125 loss2:0.1517 loss3:0.0017 | AUC:0.8570 Anomaly AUC:0.6688
[2023-09-09 13:36:39,509][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00008 | loss1:0.0115 loss2:0.1441 loss3:0.0016 | AUC:0.8566 Anomaly AUC:0.6681
[2023-09-09 13:36:57,254][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00007 | loss1:0.0112 loss2:0.1402 loss3:0.0016 | AUC:0.8581 Anomaly AUC:0.6715
[2023-09-09 13:37:14,939][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00007 | loss1:0.0108 loss2:0.1343 loss3:0.0015 | AUC:0.8554 Anomaly AUC:0.6669
[2023-09-09 13:37:32,794][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00007 | loss1:0.0105 loss2:0.1291 loss3:0.0014 | AUC:0.8570 Anomaly AUC:0.6701
[2023-09-09 13:37:50,589][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00007 | loss1:0.0101 loss2:0.1254 loss3:0.0014 | AUC:0.8553 Anomaly AUC:0.6679
[2023-09-09 13:38:08,334][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00007 | loss1:0.0101 loss2:0.1216 loss3:0.0013 | AUC:0.8554 Anomaly AUC:0.6699
[2023-09-09 13:38:26,104][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00007 | loss1:0.5119 loss2:0.9194 loss3:0.3733 | AUC:0.8120 Anomaly AUC:0.6391
[2023-09-09 13:38:43,784][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00007 | loss1:0.2438 loss2:0.8395 loss3:0.1446 | AUC:0.8244 Anomaly AUC:0.6465
[2023-09-09 13:39:01,533][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00006 | loss1:0.1425 loss2:0.7199 loss3:0.0948 | AUC:0.8281 Anomaly AUC:0.6483
[2023-09-09 13:39:19,329][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00006 | loss1:0.0885 loss2:0.6373 loss3:0.0696 | AUC:0.8367 Anomaly AUC:0.6658
[2023-09-09 13:39:37,244][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00006 | loss1:0.0634 loss2:0.5747 loss3:0.0526 | AUC:0.8393 Anomaly AUC:0.6660
[2023-09-09 13:39:54,908][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00006 | loss1:0.0510 loss2:0.5173 loss3:0.0411 | AUC:0.8416 Anomaly AUC:0.6660
[2023-09-09 13:40:12,757][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00006 | loss1:0.0409 loss2:0.4684 loss3:0.0330 | AUC:0.8442 Anomaly AUC:0.6716
[2023-09-09 13:40:30,534][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00006 | loss1:0.0380 loss2:0.4254 loss3:0.0281 | AUC:0.8437 Anomaly AUC:0.6684
[2023-09-09 13:40:48,406][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00005 | loss1:0.0345 loss2:0.3870 loss3:0.0242 | AUC:0.8453 Anomaly AUC:0.6703
[2023-09-09 13:41:06,129][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00005 | loss1:0.0307 loss2:0.3571 loss3:0.0213 | AUC:0.8449 Anomaly AUC:0.6685
[2023-09-09 13:41:23,881][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00005 | loss1:0.0293 loss2:0.3268 loss3:0.0194 | AUC:0.8483 Anomaly AUC:0.6734
[2023-09-09 13:41:41,727][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00005 | loss1:0.0269 loss2:0.3028 loss3:0.0175 | AUC:0.8457 Anomaly AUC:0.6687
[2023-09-09 13:41:59,525][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00005 | loss1:0.0259 loss2:0.2843 loss3:0.0161 | AUC:0.8471 Anomaly AUC:0.6712
[2023-09-09 13:42:18,279][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:42:21,023][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:42:21,023][main.py][line:168][INFO] Training Mode
[2023-09-09 13:42:21,024][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:42:21,024][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:42:29,057][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:42:46,629][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3654 loss2:1.1552 loss3:0.3401 | AUC:0.7761 Anomaly AUC:0.6183
[2023-09-09 13:43:04,037][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2157 loss2:0.8709 loss3:0.1945 | AUC:0.7867 Anomaly AUC:0.5966
[2023-09-09 13:43:21,543][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1248 loss2:0.7741 loss3:0.0932 | AUC:0.7995 Anomaly AUC:0.5982
[2023-09-09 13:43:39,101][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0817 loss2:0.7122 loss3:0.0458 | AUC:0.8303 Anomaly AUC:0.6516
[2023-09-09 13:43:56,713][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0326 loss2:0.6363 loss3:0.0253 | AUC:0.8451 Anomaly AUC:0.6698
[2023-09-09 13:44:14,318][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0341 loss2:0.5836 loss3:0.0190 | AUC:0.8251 Anomaly AUC:0.6350
[2023-09-09 13:44:32,008][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0223 loss2:0.5317 loss3:0.0141 | AUC:0.8467 Anomaly AUC:0.6559
[2023-09-09 13:44:49,655][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0119 loss2:0.4714 loss3:0.0098 | AUC:0.8451 Anomaly AUC:0.6576
[2023-09-09 13:45:07,245][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0091 loss2:0.4197 loss3:0.0071 | AUC:0.8468 Anomaly AUC:0.6642
[2023-09-09 13:45:24,893][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0079 loss2:0.3811 loss3:0.0045 | AUC:0.8412 Anomaly AUC:0.6560
[2023-09-09 13:45:42,604][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0066 loss2:0.3426 loss3:0.0022 | AUC:0.8424 Anomaly AUC:0.6549
[2023-09-09 13:46:00,335][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0065 loss2:0.3125 loss3:0.0017 | AUC:0.8416 Anomaly AUC:0.6519
[2023-09-09 13:46:17,937][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0063 loss2:0.2851 loss3:0.0016 | AUC:0.8335 Anomaly AUC:0.6460
[2023-09-09 13:46:35,587][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0060 loss2:0.2640 loss3:0.0015 | AUC:0.8317 Anomaly AUC:0.6380
[2023-09-09 13:46:53,148][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0054 loss2:0.2450 loss3:0.0014 | AUC:0.8237 Anomaly AUC:0.6348
[2023-09-09 13:47:10,859][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0051 loss2:0.2311 loss3:0.0016 | AUC:0.8145 Anomaly AUC:0.6284
[2023-09-09 13:47:28,629][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0230 loss2:0.2323 loss3:0.0045 | AUC:0.8284 Anomaly AUC:0.6492
[2023-09-09 13:47:46,356][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0642 loss2:0.2972 loss3:0.0131 | AUC:0.8151 Anomaly AUC:0.6064
[2023-09-09 13:48:04,027][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0111 loss2:0.2194 loss3:0.0029 | AUC:0.8362 Anomaly AUC:0.6447
[2023-09-09 13:48:21,753][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0036 loss2:0.1916 loss3:0.0014 | AUC:0.8348 Anomaly AUC:0.6494
[2023-09-09 13:48:39,439][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0029 loss2:0.1798 loss3:0.0012 | AUC:0.8336 Anomaly AUC:0.6450
[2023-09-09 13:48:57,149][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0025 loss2:0.1710 loss3:0.0011 | AUC:0.8299 Anomaly AUC:0.6414
[2023-09-09 13:49:14,756][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0023 loss2:0.1627 loss3:0.0010 | AUC:0.8280 Anomaly AUC:0.6431
[2023-09-09 13:49:32,439][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0019 loss2:0.1552 loss3:0.0009 | AUC:0.8232 Anomaly AUC:0.6351
[2023-09-09 13:49:50,168][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0018 loss2:0.1487 loss3:0.0009 | AUC:0.8239 Anomaly AUC:0.6422
[2023-09-09 13:50:07,872][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0015 loss2:0.1420 loss3:0.0008 | AUC:0.8234 Anomaly AUC:0.6384
[2023-09-09 13:50:25,649][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0014 loss2:0.1363 loss3:0.0008 | AUC:0.8228 Anomaly AUC:0.6349
[2023-09-09 13:50:43,478][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0013 loss2:0.1299 loss3:0.0008 | AUC:0.8195 Anomaly AUC:0.6341
[2023-09-09 13:51:01,092][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0011 loss2:0.1251 loss3:0.0007 | AUC:0.8185 Anomaly AUC:0.6322
[2023-09-09 13:51:18,775][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0010 loss2:0.1199 loss3:0.0007 | AUC:0.8216 Anomaly AUC:0.6382
[2023-09-09 13:51:36,448][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0010 loss2:0.1155 loss3:0.0007 | AUC:0.8207 Anomaly AUC:0.6393
[2023-09-09 13:51:54,251][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0009 loss2:0.1117 loss3:0.0007 | AUC:0.8178 Anomaly AUC:0.6338
[2023-09-09 13:52:11,911][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0008 loss2:0.1054 loss3:0.0007 | AUC:0.8160 Anomaly AUC:0.6269
[2023-09-09 13:52:29,657][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0008 loss2:0.1027 loss3:0.0006 | AUC:0.8207 Anomaly AUC:0.6340
[2023-09-09 13:52:47,280][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0006 loss2:0.0979 loss3:0.0006 | AUC:0.8191 Anomaly AUC:0.6304
[2023-09-09 13:53:05,055][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0007 loss2:0.0938 loss3:0.0006 | AUC:0.8165 Anomaly AUC:0.6242
[2023-09-09 13:53:22,718][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0006 loss2:0.0909 loss3:0.0006 | AUC:0.8123 Anomaly AUC:0.6246
[2023-09-09 13:53:40,359][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0005 loss2:0.0871 loss3:0.0005 | AUC:0.8140 Anomaly AUC:0.6244
[2023-09-09 13:53:58,056][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0005 loss2:0.0833 loss3:0.0005 | AUC:0.8160 Anomaly AUC:0.6256
[2023-09-09 13:54:15,814][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0005 loss2:0.0803 loss3:0.0005 | AUC:0.8046 Anomaly AUC:0.6180
[2023-09-09 13:54:33,498][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0005 loss2:0.0787 loss3:0.0007 | AUC:0.8122 Anomaly AUC:0.6237
[2023-09-09 13:54:51,307][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0006 loss2:0.0758 loss3:0.0007 | AUC:0.8153 Anomaly AUC:0.6300
[2023-09-09 13:55:09,241][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0004 loss2:0.0719 loss3:0.0006 | AUC:0.8174 Anomaly AUC:0.6271
[2023-09-09 13:55:26,920][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0003 loss2:0.0681 loss3:0.0005 | AUC:0.8171 Anomaly AUC:0.6262
[2023-09-09 13:55:44,705][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0003 loss2:0.0657 loss3:0.0005 | AUC:0.8116 Anomaly AUC:0.6217
[2023-09-09 13:56:02,520][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0003 loss2:0.0631 loss3:0.0005 | AUC:0.8141 Anomaly AUC:0.6241
[2023-09-09 13:56:17,996][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:56:20,674][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:56:20,674][main.py][line:168][INFO] Training Mode
[2023-09-09 13:56:20,675][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:56:20,675][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:56:28,728][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:56:48,624][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 13:56:51,349][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 13:56:51,349][main.py][line:168][INFO] Training Mode
[2023-09-09 13:56:51,350][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 13:56:51,350][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 13:56:59,344][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 13:57:17,778][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4349 loss2:1.1467 loss3:0.3419 | AUC:0.8093 Anomaly AUC:0.6481
[2023-09-09 13:57:35,835][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1786 loss2:0.8462 loss3:0.2046 | AUC:0.8261 Anomaly AUC:0.6898
[2023-09-09 13:57:54,451][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0732 loss2:0.7514 loss3:0.1039 | AUC:0.8298 Anomaly AUC:0.6661
[2023-09-09 13:58:13,067][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0391 loss2:0.6865 loss3:0.0475 | AUC:0.8449 Anomaly AUC:0.6880
[2023-09-09 13:58:31,677][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0193 loss2:0.6301 loss3:0.0275 | AUC:0.8419 Anomaly AUC:0.6792
[2023-09-09 13:58:50,436][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0269 loss2:0.5821 loss3:0.0205 | AUC:0.8352 Anomaly AUC:0.6688
[2023-09-09 13:59:09,289][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0098 loss2:0.5277 loss3:0.0150 | AUC:0.8418 Anomaly AUC:0.6704
[2023-09-09 13:59:28,328][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0076 loss2:0.4815 loss3:0.0121 | AUC:0.8279 Anomaly AUC:0.6621
[2023-09-09 13:59:47,357][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0024 loss2:0.4334 loss3:0.0093 | AUC:0.8410 Anomaly AUC:0.6761
[2023-09-09 14:00:06,248][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0018 loss2:0.3934 loss3:0.0071 | AUC:0.8407 Anomaly AUC:0.6786
[2023-09-09 14:00:25,185][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0036 loss2:0.3608 loss3:0.0051 | AUC:0.8414 Anomaly AUC:0.6770
[2023-09-09 14:00:44,033][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0019 loss2:0.3325 loss3:0.0027 | AUC:0.8428 Anomaly AUC:0.6754
[2023-09-09 14:01:02,980][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0098 loss2:0.3154 loss3:0.0035 | AUC:0.8301 Anomaly AUC:0.6615
[2023-09-09 14:01:21,859][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0304 loss2:0.3308 loss3:0.0064 | AUC:0.8462 Anomaly AUC:0.6733
[2023-09-09 14:01:40,785][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0075 loss2:0.2926 loss3:0.0040 | AUC:0.8496 Anomaly AUC:0.6799
[2023-09-09 14:01:59,800][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0013 loss2:0.2549 loss3:0.0024 | AUC:0.8525 Anomaly AUC:0.6855
[2023-09-09 14:02:18,684][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0007 loss2:0.2354 loss3:0.0021 | AUC:0.8514 Anomaly AUC:0.6844
[2023-09-09 14:02:37,647][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0007 loss2:0.2193 loss3:0.0019 | AUC:0.8490 Anomaly AUC:0.6803
[2023-09-09 14:02:56,664][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0006 loss2:0.2049 loss3:0.0018 | AUC:0.8532 Anomaly AUC:0.6856
[2023-09-09 14:03:15,568][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0005 loss2:0.1917 loss3:0.0017 | AUC:0.8517 Anomaly AUC:0.6825
[2023-09-09 14:03:34,517][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0005 loss2:0.1819 loss3:0.0016 | AUC:0.8492 Anomaly AUC:0.6813
[2023-09-09 14:03:53,453][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0005 loss2:0.1721 loss3:0.0015 | AUC:0.8518 Anomaly AUC:0.6863
[2023-09-09 14:04:12,394][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0004 loss2:0.1632 loss3:0.0013 | AUC:0.8525 Anomaly AUC:0.6856
[2023-09-09 14:04:31,338][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0004 loss2:0.1553 loss3:0.0012 | AUC:0.8521 Anomaly AUC:0.6871
[2023-09-09 14:04:50,347][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0003 loss2:0.1481 loss3:0.0012 | AUC:0.8541 Anomaly AUC:0.6893
[2023-09-09 14:05:09,328][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0003 loss2:0.1414 loss3:0.0011 | AUC:0.8539 Anomaly AUC:0.6888
[2023-09-09 14:05:28,335][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0003 loss2:0.1362 loss3:0.0010 | AUC:0.8547 Anomaly AUC:0.6875
[2023-09-09 14:05:47,303][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0468 loss2:0.2022 loss3:0.0108 | AUC:0.8425 Anomaly AUC:0.6805
[2023-09-09 14:06:06,306][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0020 loss2:0.1369 loss3:0.0023 | AUC:0.8427 Anomaly AUC:0.6802
[2023-09-09 14:06:25,250][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0005 loss2:0.1242 loss3:0.0014 | AUC:0.8475 Anomaly AUC:0.6836
[2023-09-09 14:06:44,286][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0004 loss2:0.1176 loss3:0.0012 | AUC:0.8503 Anomaly AUC:0.6863
[2023-09-09 14:07:03,264][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0004 loss2:0.1132 loss3:0.0011 | AUC:0.8492 Anomaly AUC:0.6852
[2023-09-09 14:07:22,359][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0003 loss2:0.1069 loss3:0.0010 | AUC:0.8505 Anomaly AUC:0.6879
[2023-09-09 14:07:41,416][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0003 loss2:0.1035 loss3:0.0009 | AUC:0.8522 Anomaly AUC:0.6908
[2023-09-09 14:08:00,377][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0003 loss2:0.0990 loss3:0.0009 | AUC:0.8515 Anomaly AUC:0.6883
[2023-09-09 14:08:19,362][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0002 loss2:0.0946 loss3:0.0008 | AUC:0.8510 Anomaly AUC:0.6878
[2023-09-09 14:08:38,328][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0002 loss2:0.0912 loss3:0.0007 | AUC:0.8518 Anomaly AUC:0.6893
[2023-09-09 14:08:57,382][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0002 loss2:0.0879 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6918
[2023-09-09 14:09:16,420][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0002 loss2:0.0839 loss3:0.0007 | AUC:0.8508 Anomaly AUC:0.6916
[2023-09-09 14:09:35,461][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0002 loss2:0.0808 loss3:0.0006 | AUC:0.8489 Anomaly AUC:0.6849
[2023-09-09 14:09:54,633][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0525 loss2:0.1380 loss3:0.0088 | AUC:0.8399 Anomaly AUC:0.6794
[2023-09-09 14:10:13,640][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0178 loss2:0.1184 loss3:0.0053 | AUC:0.8483 Anomaly AUC:0.6928
[2023-09-09 14:10:32,649][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0020 loss2:0.0801 loss3:0.0019 | AUC:0.8529 Anomaly AUC:0.6968
[2023-09-09 14:10:51,739][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0005 loss2:0.0730 loss3:0.0012 | AUC:0.8534 Anomaly AUC:0.6978
[2023-09-09 14:11:10,806][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0004 loss2:0.0687 loss3:0.0010 | AUC:0.8514 Anomaly AUC:0.6966
[2023-09-09 14:11:30,000][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0003 loss2:0.0656 loss3:0.0008 | AUC:0.8520 Anomaly AUC:0.6953
[2023-09-09 14:11:49,191][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0003 loss2:0.0627 loss3:0.0008 | AUC:0.8531 Anomaly AUC:0.6934
[2023-09-09 14:12:08,381][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0003 loss2:0.0606 loss3:0.0007 | AUC:0.8541 Anomaly AUC:0.6942
[2023-09-09 14:12:27,445][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0002 loss2:0.0572 loss3:0.0006 | AUC:0.8533 Anomaly AUC:0.6941
[2023-09-09 14:12:46,787][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0002 loss2:0.0542 loss3:0.0006 | AUC:0.8528 Anomaly AUC:0.6928
[2023-09-09 14:13:05,981][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0002 loss2:0.0526 loss3:0.0006 | AUC:0.8533 Anomaly AUC:0.6936
[2023-09-09 14:13:25,094][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0002 loss2:0.0501 loss3:0.0005 | AUC:0.8541 Anomaly AUC:0.6945
[2023-09-09 14:13:44,234][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0002 loss2:0.0483 loss3:0.0005 | AUC:0.8541 Anomaly AUC:0.6943
[2023-09-09 14:14:03,430][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0002 loss2:0.0466 loss3:0.0005 | AUC:0.8530 Anomaly AUC:0.6921
[2023-09-09 14:14:22,494][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0001 loss2:0.0440 loss3:0.0005 | AUC:0.8523 Anomaly AUC:0.6913
[2023-09-09 14:14:41,653][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0001 loss2:0.0427 loss3:0.0005 | AUC:0.8535 Anomaly AUC:0.6932
[2023-09-09 14:15:00,802][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0001 loss2:0.0407 loss3:0.0005 | AUC:0.8531 Anomaly AUC:0.6917
[2023-09-09 14:15:19,952][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0001 loss2:0.0391 loss3:0.0005 | AUC:0.8541 Anomaly AUC:0.6929
[2023-09-09 14:15:39,038][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0001 loss2:0.0373 loss3:0.0005 | AUC:0.8542 Anomaly AUC:0.6931
[2023-09-09 14:15:58,125][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0001 loss2:0.0362 loss3:0.0005 | AUC:0.8536 Anomaly AUC:0.6920
[2023-09-09 14:16:17,157][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0001 loss2:0.0343 loss3:0.0005 | AUC:0.8537 Anomaly AUC:0.6930
[2023-09-09 14:16:36,219][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0001 loss2:0.0329 loss3:0.0005 | AUC:0.8535 Anomaly AUC:0.6930
[2023-09-09 14:16:55,493][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0001 loss2:0.0317 loss3:0.0005 | AUC:0.8531 Anomaly AUC:0.6908
[2023-09-09 14:17:14,667][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0001 loss2:0.0299 loss3:0.0005 | AUC:0.8538 Anomaly AUC:0.6910
[2023-09-09 14:17:41,654][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 14:17:44,312][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 14:17:44,313][main.py][line:168][INFO] Training Mode
[2023-09-09 14:17:44,313][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 14:17:44,313][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 14:17:52,371][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 14:18:10,771][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4513 loss2:1.1467 loss3:0.3419 | AUC:0.8093 Anomaly AUC:0.6481
[2023-09-09 14:18:29,042][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1860 loss2:0.8462 loss3:0.2046 | AUC:0.8261 Anomaly AUC:0.6898
[2023-09-09 14:18:47,648][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0759 loss2:0.7514 loss3:0.1039 | AUC:0.8298 Anomaly AUC:0.6661
[2023-09-09 14:19:06,258][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0405 loss2:0.6865 loss3:0.0475 | AUC:0.8449 Anomaly AUC:0.6880
[2023-09-09 14:19:25,101][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0201 loss2:0.6301 loss3:0.0275 | AUC:0.8419 Anomaly AUC:0.6792
[2023-09-09 14:19:43,822][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0276 loss2:0.5821 loss3:0.0205 | AUC:0.8352 Anomaly AUC:0.6688
[2023-09-09 14:20:02,626][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0102 loss2:0.5277 loss3:0.0150 | AUC:0.8418 Anomaly AUC:0.6704
[2023-09-09 14:20:21,528][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0080 loss2:0.4815 loss3:0.0121 | AUC:0.8279 Anomaly AUC:0.6621
[2023-09-09 14:20:40,505][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0027 loss2:0.4334 loss3:0.0093 | AUC:0.8410 Anomaly AUC:0.6761
[2023-09-09 14:20:59,466][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0020 loss2:0.3934 loss3:0.0071 | AUC:0.8407 Anomaly AUC:0.6786
[2023-09-09 14:21:18,287][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0039 loss2:0.3608 loss3:0.0051 | AUC:0.8414 Anomaly AUC:0.6770
[2023-09-09 14:21:37,197][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0021 loss2:0.3325 loss3:0.0027 | AUC:0.8428 Anomaly AUC:0.6754
[2023-09-09 14:21:56,177][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0101 loss2:0.3154 loss3:0.0035 | AUC:0.8301 Anomaly AUC:0.6615
[2023-09-09 14:22:15,605][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0310 loss2:0.3308 loss3:0.0064 | AUC:0.8462 Anomaly AUC:0.6733
[2023-09-09 14:27:21,801][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 14:27:24,514][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 14:27:24,515][main.py][line:168][INFO] Training Mode
[2023-09-09 14:27:24,515][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 14:27:24,515][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 14:27:32,565][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 14:27:51,061][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4523 loss2:1.1476 loss3:0.2664 | AUC:0.8081 Anomaly AUC:0.6499
[2023-09-09 14:28:09,221][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1908 loss2:0.8474 loss3:0.1376 | AUC:0.8139 Anomaly AUC:0.6760
[2023-09-09 14:28:27,698][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0768 loss2:0.7486 loss3:0.0629 | AUC:0.8248 Anomaly AUC:0.6739
[2023-09-09 14:28:46,349][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0366 loss2:0.6794 loss3:0.0307 | AUC:0.8376 Anomaly AUC:0.6799
[2023-09-09 14:29:05,050][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0262 loss2:0.6256 loss3:0.0205 | AUC:0.8414 Anomaly AUC:0.6791
[2023-09-09 14:29:23,799][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0105 loss2:0.5629 loss3:0.0149 | AUC:0.8395 Anomaly AUC:0.6763
[2023-09-09 14:29:42,756][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0083 loss2:0.5136 loss3:0.0117 | AUC:0.8383 Anomaly AUC:0.6768
[2023-09-09 14:30:01,789][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0046 loss2:0.4616 loss3:0.0088 | AUC:0.8381 Anomaly AUC:0.6731
[2023-09-09 14:30:20,684][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0210 loss2:0.4350 loss3:0.0083 | AUC:0.8330 Anomaly AUC:0.6648
[2023-09-09 14:30:39,591][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0181 loss2:0.4095 loss3:0.0054 | AUC:0.8339 Anomaly AUC:0.6784
[2023-09-09 14:30:58,564][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0026 loss2:0.3506 loss3:0.0033 | AUC:0.8404 Anomaly AUC:0.6839
[2023-09-09 14:31:17,540][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0048 loss2:0.3280 loss3:0.0037 | AUC:0.8325 Anomaly AUC:0.6700
[2023-09-09 14:31:36,418][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0024 loss2:0.2959 loss3:0.0032 | AUC:0.8366 Anomaly AUC:0.6765
[2023-09-09 14:31:55,382][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0013 loss2:0.2705 loss3:0.0029 | AUC:0.8389 Anomaly AUC:0.6820
[2023-09-09 14:32:14,426][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0011 loss2:0.2496 loss3:0.0028 | AUC:0.8392 Anomaly AUC:0.6823
[2023-09-09 14:32:33,360][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0010 loss2:0.2319 loss3:0.0027 | AUC:0.8396 Anomaly AUC:0.6844
[2023-09-09 14:32:52,290][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0008 loss2:0.2155 loss3:0.0024 | AUC:0.8356 Anomaly AUC:0.6797
[2023-09-09 14:33:11,246][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0008 loss2:0.2014 loss3:0.0023 | AUC:0.8317 Anomaly AUC:0.6786
[2023-09-09 14:33:30,204][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0291 loss2:0.2246 loss3:0.0068 | AUC:0.8249 Anomaly AUC:0.6595
[2023-09-09 14:33:49,097][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0140 loss2:0.2063 loss3:0.0051 | AUC:0.8230 Anomaly AUC:0.6541
[2023-09-09 14:34:08,042][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0047 loss2:0.1852 loss3:0.0038 | AUC:0.8352 Anomaly AUC:0.6763
[2023-09-09 14:34:27,005][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0015 loss2:0.1705 loss3:0.0030 | AUC:0.8305 Anomaly AUC:0.6717
[2023-09-09 14:34:45,971][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0036 loss2:0.1673 loss3:0.0034 | AUC:0.8234 Anomaly AUC:0.6775
[2023-09-09 14:35:04,946][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0128 loss2:0.1728 loss3:0.0046 | AUC:0.8359 Anomaly AUC:0.6862
[2023-09-09 14:35:24,119][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0061 loss2:0.1578 loss3:0.0038 | AUC:0.8216 Anomaly AUC:0.6647
[2023-09-09 14:35:43,138][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0023 loss2:0.1457 loss3:0.0026 | AUC:0.8312 Anomaly AUC:0.6688
[2023-09-09 14:36:02,145][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0005 loss2:0.1353 loss3:0.0021 | AUC:0.8383 Anomaly AUC:0.6764
[2023-09-09 14:36:21,133][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0004 loss2:0.1281 loss3:0.0019 | AUC:0.8386 Anomaly AUC:0.6776
[2023-09-09 14:36:40,108][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0004 loss2:0.1230 loss3:0.0017 | AUC:0.8408 Anomaly AUC:0.6790
[2023-09-09 14:36:59,155][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0004 loss2:0.1182 loss3:0.0016 | AUC:0.8410 Anomaly AUC:0.6794
[2023-09-09 14:37:18,129][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0003 loss2:0.1134 loss3:0.0014 | AUC:0.8406 Anomaly AUC:0.6788
[2023-09-09 14:37:37,143][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0003 loss2:0.1099 loss3:0.0013 | AUC:0.8415 Anomaly AUC:0.6802
[2023-09-09 14:37:56,156][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0003 loss2:0.1043 loss3:0.0012 | AUC:0.8391 Anomaly AUC:0.6768
[2023-09-09 14:38:15,264][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0003 loss2:0.1011 loss3:0.0011 | AUC:0.8407 Anomaly AUC:0.6787
[2023-09-09 14:38:34,374][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0003 loss2:0.0968 loss3:0.0010 | AUC:0.8409 Anomaly AUC:0.6787
[2023-09-09 14:38:58,624][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 14:39:01,311][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 14:39:01,311][main.py][line:168][INFO] Training Mode
[2023-09-09 14:39:01,312][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 14:39:01,312][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 14:39:09,375][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 14:39:28,006][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4509 loss2:1.1490 loss3:0.2908 | AUC:0.8134 Anomaly AUC:0.6486
[2023-09-09 14:39:46,404][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1869 loss2:0.8464 loss3:0.2333 | AUC:0.8388 Anomaly AUC:0.6900
[2023-09-09 14:40:05,090][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0662 loss2:0.7416 loss3:0.1819 | AUC:0.8391 Anomaly AUC:0.6851
[2023-09-09 14:40:23,980][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0276 loss2:0.6707 loss3:0.1490 | AUC:0.8463 Anomaly AUC:0.6728
[2023-09-09 14:40:42,781][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0257 loss2:0.6202 loss3:0.1288 | AUC:0.8335 Anomaly AUC:0.6757
[2023-09-09 14:41:01,695][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0171 loss2:0.5642 loss3:0.1187 | AUC:0.8387 Anomaly AUC:0.6741
[2023-09-09 14:41:20,576][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0200 loss2:0.5242 loss3:0.1143 | AUC:0.8441 Anomaly AUC:0.6748
[2023-09-09 14:41:39,509][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0082 loss2:0.4738 loss3:0.1111 | AUC:0.8433 Anomaly AUC:0.6732
[2023-09-09 14:41:58,553][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0040 loss2:0.4296 loss3:0.1087 | AUC:0.8483 Anomaly AUC:0.6786
[2023-09-09 14:42:17,437][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0032 loss2:0.3929 loss3:0.1054 | AUC:0.8459 Anomaly AUC:0.6709
[2023-09-09 14:42:36,349][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0026 loss2:0.3577 loss3:0.0971 | AUC:0.8471 Anomaly AUC:0.6716
[2023-09-09 14:42:55,407][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0078 loss2:0.3451 loss3:0.0386 | AUC:0.8372 Anomaly AUC:0.6657
[2023-09-09 14:43:14,435][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0114 loss2:0.3302 loss3:0.0154 | AUC:0.8364 Anomaly AUC:0.6659
[2023-09-09 14:43:33,402][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0088 loss2:0.3055 loss3:0.0122 | AUC:0.8275 Anomaly AUC:0.6658
[2023-09-09 14:43:52,519][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0270 loss2:0.3104 loss3:0.0117 | AUC:0.7912 Anomaly AUC:0.6352
[2023-09-09 14:44:11,514][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0057 loss2:0.2753 loss3:0.0087 | AUC:0.8223 Anomaly AUC:0.6649
[2023-09-09 14:44:30,668][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0010 loss2:0.2460 loss3:0.0067 | AUC:0.8213 Anomaly AUC:0.6577
[2023-09-09 14:44:49,706][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0008 loss2:0.2283 loss3:0.0050 | AUC:0.8159 Anomaly AUC:0.6573
[2023-09-09 14:45:08,737][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0007 loss2:0.2131 loss3:0.0031 | AUC:0.8152 Anomaly AUC:0.6502
[2023-09-09 14:45:27,897][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0006 loss2:0.2000 loss3:0.0010 | AUC:0.8188 Anomaly AUC:0.6510
[2023-09-09 14:45:46,965][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0005 loss2:0.1895 loss3:0.0007 | AUC:0.8211 Anomaly AUC:0.6595
[2023-09-09 14:46:06,081][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0005 loss2:0.1799 loss3:0.0006 | AUC:0.8167 Anomaly AUC:0.6505
[2023-09-09 14:46:25,080][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0005 loss2:0.1708 loss3:0.0005 | AUC:0.8097 Anomaly AUC:0.6433
[2023-09-09 14:46:44,130][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0004 loss2:0.1628 loss3:0.0004 | AUC:0.8178 Anomaly AUC:0.6511
[2023-09-09 14:47:03,179][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0004 loss2:0.1550 loss3:0.0004 | AUC:0.8129 Anomaly AUC:0.6421
[2023-09-09 14:47:22,237][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0003 loss2:0.1480 loss3:0.0005 | AUC:0.8162 Anomaly AUC:0.6471
[2023-09-09 14:47:41,187][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0003 loss2:0.1417 loss3:0.0005 | AUC:0.8099 Anomaly AUC:0.6455
[2023-09-09 14:48:00,195][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0003 loss2:0.1345 loss3:0.0005 | AUC:0.8166 Anomaly AUC:0.6495
[2023-09-09 14:48:19,159][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0003 loss2:0.1287 loss3:0.0004 | AUC:0.8115 Anomaly AUC:0.6406
[2023-09-09 14:48:38,226][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0003 loss2:0.1231 loss3:0.0005 | AUC:0.8147 Anomaly AUC:0.6392
[2023-09-09 14:48:57,231][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0003 loss2:0.1175 loss3:0.0005 | AUC:0.8171 Anomaly AUC:0.6443
[2023-09-09 14:49:16,298][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0108 loss2:0.1257 loss3:0.0012 | AUC:0.7809 Anomaly AUC:0.6265
[2023-09-09 14:49:35,406][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0444 loss2:0.1882 loss3:0.0062 | AUC:0.8157 Anomaly AUC:0.6577
[2023-09-09 14:49:54,573][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0081 loss2:0.1280 loss3:0.0018 | AUC:0.8268 Anomaly AUC:0.6434
[2023-09-09 14:50:13,735][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0035 loss2:0.1127 loss3:0.0012 | AUC:0.8217 Anomaly AUC:0.6342
[2023-09-09 14:50:32,873][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0099 loss2:0.1181 loss3:0.0015 | AUC:0.8266 Anomaly AUC:0.6345
[2023-09-09 14:50:51,989][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0023 loss2:0.1020 loss3:0.0009 | AUC:0.8227 Anomaly AUC:0.6422
[2023-09-09 14:51:11,158][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0011 loss2:0.0953 loss3:0.0006 | AUC:0.8228 Anomaly AUC:0.6407
[2023-09-09 14:51:30,268][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0003 loss2:0.0879 loss3:0.0005 | AUC:0.8193 Anomaly AUC:0.6388
[2023-09-09 14:51:49,396][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0003 loss2:0.0836 loss3:0.0005 | AUC:0.8199 Anomaly AUC:0.6408
[2023-09-09 14:52:08,491][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0004 loss2:0.0801 loss3:0.0005 | AUC:0.8135 Anomaly AUC:0.6319
[2023-09-09 14:52:27,554][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0003 loss2:0.0764 loss3:0.0005 | AUC:0.8126 Anomaly AUC:0.6323
[2023-09-09 14:52:46,728][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0002 loss2:0.0736 loss3:0.0004 | AUC:0.8122 Anomaly AUC:0.6264
[2023-09-09 14:53:06,021][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0002 loss2:0.0699 loss3:0.0004 | AUC:0.8092 Anomaly AUC:0.6251
[2023-09-09 14:53:25,178][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0002 loss2:0.0671 loss3:0.0004 | AUC:0.8111 Anomaly AUC:0.6277
[2023-09-09 14:53:44,373][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0002 loss2:0.0646 loss3:0.0004 | AUC:0.8121 Anomaly AUC:0.6280
[2023-09-09 14:54:03,559][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0002 loss2:0.0614 loss3:0.0004 | AUC:0.8114 Anomaly AUC:0.6296
[2023-09-09 14:54:22,645][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0002 loss2:0.0601 loss3:0.0004 | AUC:0.8166 Anomaly AUC:0.6330
[2023-09-09 14:54:41,820][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0002 loss2:0.0567 loss3:0.0004 | AUC:0.8139 Anomaly AUC:0.6318
[2023-09-09 14:55:00,984][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0001 loss2:0.0540 loss3:0.0004 | AUC:0.8141 Anomaly AUC:0.6288
[2023-09-09 14:56:36,548][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 14:56:39,206][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 14:56:39,206][main.py][line:168][INFO] Training Mode
[2023-09-09 14:56:39,206][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 14:56:39,207][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 14:56:47,382][main.py][line:82][INFO] Random initialize AUCAUC:0.4858 Anomaly AUC:0.49013
[2023-09-09 14:57:05,931][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4901 loss2:1.1818 loss3:0.3479 | AUC:0.8332 Anomaly AUC:0.6601
[2023-09-09 14:57:24,137][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2145 loss2:0.8773 loss3:0.2274 | AUC:0.8487 Anomaly AUC:0.6853
[2023-09-09 14:57:42,665][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0845 loss2:0.7646 loss3:0.1348 | AUC:0.8491 Anomaly AUC:0.6756
[2023-09-09 14:58:01,388][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0404 loss2:0.6936 loss3:0.0661 | AUC:0.8454 Anomaly AUC:0.6825
[2023-09-09 14:58:20,215][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0268 loss2:0.6379 loss3:0.0350 | AUC:0.8212 Anomaly AUC:0.6568
[2023-09-09 14:58:39,089][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0150 loss2:0.5801 loss3:0.0217 | AUC:0.8311 Anomaly AUC:0.6698
[2023-09-09 14:58:58,040][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0066 loss2:0.5258 loss3:0.0149 | AUC:0.8458 Anomaly AUC:0.6779
[2023-09-09 14:59:17,274][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0037 loss2:0.4733 loss3:0.0104 | AUC:0.8532 Anomaly AUC:0.6921
[2023-09-09 14:59:36,342][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0036 loss2:0.4281 loss3:0.0073 | AUC:0.8532 Anomaly AUC:0.6842
[2023-09-09 14:59:55,291][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0047 loss2:0.3911 loss3:0.0048 | AUC:0.8339 Anomaly AUC:0.6737
[2023-09-09 15:00:14,419][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0243 loss2:0.3830 loss3:0.0067 | AUC:0.8433 Anomaly AUC:0.6899
[2023-09-09 15:00:33,584][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0150 loss2:0.3503 loss3:0.0056 | AUC:0.8551 Anomaly AUC:0.6981
[2023-09-09 15:00:52,693][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0022 loss2:0.3089 loss3:0.0030 | AUC:0.8553 Anomaly AUC:0.6971
[2023-09-09 15:01:11,719][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0011 loss2:0.2839 loss3:0.0025 | AUC:0.8509 Anomaly AUC:0.6919
[2023-09-09 15:01:30,808][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0010 loss2:0.2616 loss3:0.0022 | AUC:0.8515 Anomaly AUC:0.6916
[2023-09-09 15:01:49,816][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0008 loss2:0.2441 loss3:0.0020 | AUC:0.8563 Anomaly AUC:0.6956
[2023-09-09 15:02:08,825][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0007 loss2:0.2278 loss3:0.0019 | AUC:0.8542 Anomaly AUC:0.6942
[2023-09-09 15:02:27,867][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0007 loss2:0.2128 loss3:0.0018 | AUC:0.8545 Anomaly AUC:0.6905
[2023-09-09 15:02:46,918][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0006 loss2:0.2013 loss3:0.0017 | AUC:0.8530 Anomaly AUC:0.6896
[2023-09-09 15:03:05,935][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0006 loss2:0.1896 loss3:0.0016 | AUC:0.8559 Anomaly AUC:0.6934
[2023-09-09 15:03:25,047][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0005 loss2:0.1791 loss3:0.0015 | AUC:0.8535 Anomaly AUC:0.6903
[2023-09-09 15:03:44,158][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0005 loss2:0.1716 loss3:0.0014 | AUC:0.8578 Anomaly AUC:0.6904
[2023-09-09 15:04:03,224][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0005 loss2:0.1645 loss3:0.0013 | AUC:0.8491 Anomaly AUC:0.6803
[2023-09-09 15:04:22,299][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0019 loss2:0.1615 loss3:0.0017 | AUC:0.8318 Anomaly AUC:0.6883
[2023-09-09 15:04:41,462][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0851 loss2:0.2784 loss3:0.0145 | AUC:0.8346 Anomaly AUC:0.6650
[2023-09-09 15:05:00,552][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0023 loss2:0.1632 loss3:0.0024 | AUC:0.8443 Anomaly AUC:0.6767
[2023-09-09 15:05:19,655][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0008 loss2:0.1468 loss3:0.0016 | AUC:0.8448 Anomaly AUC:0.6745
[2023-09-09 15:05:38,765][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0007 loss2:0.1387 loss3:0.0013 | AUC:0.8454 Anomaly AUC:0.6754
[2023-09-09 15:05:57,899][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0006 loss2:0.1324 loss3:0.0011 | AUC:0.8453 Anomaly AUC:0.6749
[2023-09-09 15:06:17,101][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0005 loss2:0.1274 loss3:0.0010 | AUC:0.8466 Anomaly AUC:0.6769
[2023-09-09 15:06:36,205][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0004 loss2:0.1215 loss3:0.0010 | AUC:0.8456 Anomaly AUC:0.6752
[2023-09-09 15:06:55,355][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0004 loss2:0.1167 loss3:0.0009 | AUC:0.8482 Anomaly AUC:0.6794
[2023-09-09 15:07:14,481][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0004 loss2:0.1117 loss3:0.0008 | AUC:0.8487 Anomaly AUC:0.6783
[2023-09-09 15:07:33,676][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0003 loss2:0.1080 loss3:0.0008 | AUC:0.8465 Anomaly AUC:0.6763
[2023-09-09 15:07:52,760][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0003 loss2:0.1041 loss3:0.0008 | AUC:0.8483 Anomaly AUC:0.6776
[2023-09-09 15:08:12,000][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0003 loss2:0.0992 loss3:0.0008 | AUC:0.8491 Anomaly AUC:0.6798
[2023-09-09 15:08:31,266][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0003 loss2:0.0963 loss3:0.0007 | AUC:0.8483 Anomaly AUC:0.6777
[2023-09-09 15:08:50,505][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0002 loss2:0.0928 loss3:0.0007 | AUC:0.8505 Anomaly AUC:0.6782
[2023-09-09 15:09:09,619][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0002 loss2:0.0885 loss3:0.0007 | AUC:0.8502 Anomaly AUC:0.6777
[2023-09-09 15:09:28,785][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0002 loss2:0.0854 loss3:0.0007 | AUC:0.8513 Anomaly AUC:0.6798
[2023-09-09 15:09:48,029][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0002 loss2:0.0819 loss3:0.0007 | AUC:0.8511 Anomaly AUC:0.6796
[2023-09-09 15:10:07,270][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0002 loss2:0.0789 loss3:0.0007 | AUC:0.8522 Anomaly AUC:0.6790
[2023-09-09 15:10:26,367][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0002 loss2:0.0761 loss3:0.0006 | AUC:0.8501 Anomaly AUC:0.6764
[2023-09-09 15:10:45,496][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0701 loss2:0.1483 loss3:0.0104 | AUC:0.8164 Anomaly AUC:0.6406
[2023-09-09 15:11:04,682][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0135 loss2:0.1119 loss3:0.0051 | AUC:0.8319 Anomaly AUC:0.6738
[2023-09-09 15:11:24,024][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0036 loss2:0.0796 loss3:0.0022 | AUC:0.8425 Anomaly AUC:0.6846
[2023-09-09 15:11:43,287][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0005 loss2:0.0691 loss3:0.0011 | AUC:0.8402 Anomaly AUC:0.6815
[2023-09-09 15:12:02,621][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0004 loss2:0.0653 loss3:0.0009 | AUC:0.8388 Anomaly AUC:0.6784
[2023-09-09 15:12:21,855][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0004 loss2:0.0619 loss3:0.0008 | AUC:0.8407 Anomaly AUC:0.6807
[2023-09-09 15:12:41,048][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0003 loss2:0.0591 loss3:0.0007 | AUC:0.8418 Anomaly AUC:0.6817
[2023-09-09 15:13:00,268][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0003 loss2:0.0567 loss3:0.0007 | AUC:0.8434 Anomaly AUC:0.6815
[2023-09-09 15:13:19,467][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0003 loss2:0.0540 loss3:0.0007 | AUC:0.8427 Anomaly AUC:0.6804
[2023-09-09 15:13:38,620][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0002 loss2:0.0519 loss3:0.0006 | AUC:0.8439 Anomaly AUC:0.6817
[2023-09-09 15:13:57,916][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0002 loss2:0.0494 loss3:0.0006 | AUC:0.8442 Anomaly AUC:0.6816
[2023-09-09 15:14:17,179][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0002 loss2:0.0475 loss3:0.0006 | AUC:0.8457 Anomaly AUC:0.6818
[2023-09-09 15:14:36,402][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0002 loss2:0.0460 loss3:0.0006 | AUC:0.8452 Anomaly AUC:0.6792
[2023-09-09 15:14:55,599][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0002 loss2:0.0435 loss3:0.0006 | AUC:0.8470 Anomaly AUC:0.6813
[2023-09-09 15:15:14,756][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0002 loss2:0.0419 loss3:0.0006 | AUC:0.8476 Anomaly AUC:0.6825
[2023-09-09 15:15:34,032][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0001 loss2:0.0401 loss3:0.0006 | AUC:0.8472 Anomaly AUC:0.6797
[2023-09-09 15:15:53,209][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0001 loss2:0.0384 loss3:0.0006 | AUC:0.8490 Anomaly AUC:0.6830
[2023-09-09 15:16:12,474][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0001 loss2:0.0368 loss3:0.0006 | AUC:0.8489 Anomaly AUC:0.6817
[2023-09-09 15:16:31,678][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0001 loss2:0.0351 loss3:0.0005 | AUC:0.8493 Anomaly AUC:0.6817
[2023-09-09 15:16:50,944][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0001 loss2:0.0338 loss3:0.0005 | AUC:0.8490 Anomaly AUC:0.6801
[2023-09-09 15:17:10,149][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0001 loss2:0.0322 loss3:0.0005 | AUC:0.8496 Anomaly AUC:0.6812
[2023-09-09 15:17:29,497][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0001 loss2:0.0311 loss3:0.0005 | AUC:0.8490 Anomaly AUC:0.6796
[2023-09-09 15:17:48,698][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0001 loss2:0.0295 loss3:0.0005 | AUC:0.8494 Anomaly AUC:0.6803
[2023-09-09 15:21:55,393][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:21:58,082][main.py][line:165][INFO] total params:8.0853M
[2023-09-09 15:21:58,082][main.py][line:168][INFO] Training Mode
[2023-09-09 15:21:58,083][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (embedding2): Linear(in_features=1024, out_features=512, bias=True)
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 15:21:58,083][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:22:06,124][main.py][line:82][INFO] Random initialize AUCAUC:0.6041 Anomaly AUC:0.57831
[2023-09-09 15:23:47,565][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:23:50,276][main.py][line:165][INFO] total params:8.0853M
[2023-09-09 15:23:50,277][main.py][line:168][INFO] Training Mode
[2023-09-09 15:23:50,277][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (embedding2): Linear(in_features=1024, out_features=512, bias=True)
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 15:23:50,277][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:23:58,367][main.py][line:82][INFO] Random initialize AUCAUC:0.6041 Anomaly AUC:0.57831
[2023-09-09 15:27:16,475][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:27:19,171][main.py][line:165][INFO] total params:8.6101M
[2023-09-09 15:27:19,172][main.py][line:168][INFO] Training Mode
[2023-09-09 15:27:19,172][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (embedding2): Linear(in_features=1024, out_features=512, bias=True)
      (embedding3): Linear(in_features=1024, out_features=512, bias=True)
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 15:27:19,172][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:27:27,383][main.py][line:82][INFO] Random initialize AUCAUC:0.4906 Anomaly AUC:0.48936
[2023-09-09 15:27:46,162][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.1066 loss2:1.0301 loss3:0.3711 | AUC:0.7827 Anomaly AUC:0.6337
[2023-09-09 15:28:04,652][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0032 loss2:0.6988 loss3:0.2403 | AUC:0.7504 Anomaly AUC:0.6404
[2023-09-09 15:28:23,507][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0059 loss2:0.5982 loss3:0.1226 | AUC:0.7747 Anomaly AUC:0.6629
[2023-09-09 15:28:42,543][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0054 loss2:0.5092 loss3:0.0556 | AUC:0.7930 Anomaly AUC:0.6655
[2023-09-09 15:29:01,749][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0037 loss2:0.4276 loss3:0.0289 | AUC:0.8086 Anomaly AUC:0.6718
[2023-09-09 15:29:20,922][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0031 loss2:0.3685 loss3:0.0210 | AUC:0.8086 Anomaly AUC:0.6655
[2023-09-09 15:29:40,166][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0021 loss2:0.3267 loss3:0.0119 | AUC:0.8115 Anomaly AUC:0.6734
[2023-09-09 15:29:59,511][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0017 loss2:0.2945 loss3:0.0086 | AUC:0.8178 Anomaly AUC:0.6759
[2023-09-09 15:30:18,972][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0014 loss2:0.2688 loss3:0.0062 | AUC:0.8190 Anomaly AUC:0.6738
[2023-09-09 15:30:38,218][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0012 loss2:0.2525 loss3:0.0050 | AUC:0.8168 Anomaly AUC:0.6610
[2023-09-09 15:30:57,519][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0011 loss2:0.2403 loss3:0.0047 | AUC:0.8142 Anomaly AUC:0.6531
[2023-09-09 15:31:16,860][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0011 loss2:0.2292 loss3:0.0048 | AUC:0.8205 Anomaly AUC:0.6558
[2023-09-09 15:31:36,101][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0009 loss2:0.2164 loss3:0.0032 | AUC:0.8164 Anomaly AUC:0.6548
[2023-09-09 15:31:55,394][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0007 loss2:0.2069 loss3:0.0027 | AUC:0.8205 Anomaly AUC:0.6617
[2023-09-09 15:32:14,737][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0006 loss2:0.1998 loss3:0.0023 | AUC:0.8212 Anomaly AUC:0.6679
[2023-09-09 15:32:34,083][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0006 loss2:0.1915 loss3:0.0023 | AUC:0.8215 Anomaly AUC:0.6673
[2023-09-09 15:32:53,468][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0005 loss2:0.1854 loss3:0.0020 | AUC:0.8240 Anomaly AUC:0.6686
[2023-09-09 15:33:12,717][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0046 loss2:0.1994 loss3:0.0184 | AUC:0.7918 Anomaly AUC:0.6477
[2023-09-09 15:33:31,978][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0014 loss2:0.1799 loss3:0.0081 | AUC:0.8090 Anomaly AUC:0.6574
[2023-09-09 15:33:51,342][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0006 loss2:0.1679 loss3:0.0029 | AUC:0.8150 Anomaly AUC:0.6584
[2023-09-09 15:34:10,706][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0005 loss2:0.1607 loss3:0.0020 | AUC:0.8170 Anomaly AUC:0.6564
[2023-09-09 15:34:30,072][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0013 loss2:0.1577 loss3:0.0035 | AUC:0.7824 Anomaly AUC:0.6461
[2023-09-09 15:34:49,362][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0005 loss2:0.1517 loss3:0.0029 | AUC:0.8113 Anomaly AUC:0.6528
[2023-09-09 15:35:08,708][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0004 loss2:0.1456 loss3:0.0015 | AUC:0.8115 Anomaly AUC:0.6515
[2023-09-09 15:35:28,045][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0004 loss2:0.1411 loss3:0.0014 | AUC:0.8076 Anomaly AUC:0.6506
[2023-09-09 15:35:47,390][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0004 loss2:0.1360 loss3:0.0013 | AUC:0.7913 Anomaly AUC:0.6323
[2023-09-09 15:36:06,752][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0004 loss2:0.1318 loss3:0.0013 | AUC:0.7789 Anomaly AUC:0.6194
[2023-09-09 15:36:26,180][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0003 loss2:0.1272 loss3:0.0012 | AUC:0.7719 Anomaly AUC:0.6147
[2023-09-09 15:36:45,473][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0003 loss2:0.1220 loss3:0.0011 | AUC:0.7582 Anomaly AUC:0.6003
[2023-09-09 15:37:04,831][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0003 loss2:0.1183 loss3:0.0010 | AUC:0.7481 Anomaly AUC:0.5855
[2023-09-09 15:37:24,194][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0003 loss2:0.1139 loss3:0.0010 | AUC:0.7294 Anomaly AUC:0.5621
[2023-09-09 15:37:43,594][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0003 loss2:0.1104 loss3:0.0010 | AUC:0.7450 Anomaly AUC:0.5736
[2023-09-09 15:38:02,994][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0002 loss2:0.1063 loss3:0.0009 | AUC:0.7413 Anomaly AUC:0.5698
[2023-09-09 15:38:22,343][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0002 loss2:0.1029 loss3:0.0009 | AUC:0.7288 Anomaly AUC:0.5665
[2023-09-09 15:38:41,727][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0002 loss2:0.0990 loss3:0.0009 | AUC:0.7383 Anomaly AUC:0.5684
[2023-09-09 15:40:21,348][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:40:24,061][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 15:40:24,061][main.py][line:168][INFO] Training Mode
[2023-09-09 15:40:24,062][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 15:40:24,062][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:40:32,132][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 15:41:39,516][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:41:42,258][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 15:41:42,258][main.py][line:168][INFO] Training Mode
[2023-09-09 15:41:42,259][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 15:41:42,259][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:41:50,527][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 15:42:52,071][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:42:54,751][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 15:42:54,751][main.py][line:168][INFO] Training Mode
[2023-09-09 15:42:54,751][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 15:42:54,751][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:43:02,885][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 15:43:21,351][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5489 loss2:1.2543 loss3:0.3635 | AUC:0.8383 Anomaly AUC:0.6516
[2023-09-09 15:43:39,487][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2966 loss2:0.9399 loss3:0.2611 | AUC:0.8530 Anomaly AUC:0.6858
[2023-09-09 15:43:57,956][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1850 loss2:0.8289 loss3:0.1958 | AUC:0.8512 Anomaly AUC:0.6861
[2023-09-09 15:44:16,717][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.1093 loss2:0.7560 loss3:0.1375 | AUC:0.8543 Anomaly AUC:0.6844
[2023-09-09 15:44:35,456][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0740 loss2:0.7014 loss3:0.0879 | AUC:0.8471 Anomaly AUC:0.6760
[2023-09-09 15:44:54,294][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0347 loss2:0.6405 loss3:0.0530 | AUC:0.8545 Anomaly AUC:0.6873
[2023-09-09 15:45:13,054][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0342 loss2:0.6033 loss3:0.0355 | AUC:0.8435 Anomaly AUC:0.6744
[2023-09-09 15:45:32,067][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0226 loss2:0.5617 loss3:0.0258 | AUC:0.8500 Anomaly AUC:0.6727
[2023-09-09 15:45:51,036][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0075 loss2:0.5079 loss3:0.0175 | AUC:0.8569 Anomaly AUC:0.6888
[2023-09-09 15:46:09,966][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0040 loss2:0.4624 loss3:0.0132 | AUC:0.8526 Anomaly AUC:0.6792
[2023-09-09 15:46:28,741][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0027 loss2:0.4210 loss3:0.0104 | AUC:0.8565 Anomaly AUC:0.6786
[2023-09-09 15:46:47,712][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0023 loss2:0.3803 loss3:0.0081 | AUC:0.8571 Anomaly AUC:0.6778
[2023-09-09 15:47:06,563][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0020 loss2:0.3447 loss3:0.0056 | AUC:0.8574 Anomaly AUC:0.6757
[2023-09-09 15:47:25,496][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0015 loss2:0.3148 loss3:0.0034 | AUC:0.8580 Anomaly AUC:0.6748
[2023-09-09 15:47:44,355][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0014 loss2:0.2861 loss3:0.0028 | AUC:0.8495 Anomaly AUC:0.6601
[2023-09-09 15:48:03,302][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0480 loss2:0.3365 loss3:0.0089 | AUC:0.8443 Anomaly AUC:0.6627
[2023-09-09 15:48:22,228][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0508 loss2:0.3536 loss3:0.0102 | AUC:0.8418 Anomaly AUC:0.6648
[2023-09-09 15:48:41,185][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0064 loss2:0.2598 loss3:0.0035 | AUC:0.8376 Anomaly AUC:0.6583
[2023-09-09 15:49:00,103][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0154 loss2:0.2631 loss3:0.0048 | AUC:0.8439 Anomaly AUC:0.6465
[2023-09-09 15:49:18,897][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0108 loss2:0.2361 loss3:0.0037 | AUC:0.8407 Anomaly AUC:0.6471
[2023-09-09 15:49:37,790][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0011 loss2:0.1988 loss3:0.0021 | AUC:0.8419 Anomaly AUC:0.6483
[2023-09-09 15:49:56,610][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0009 loss2:0.1850 loss3:0.0019 | AUC:0.8406 Anomaly AUC:0.6446
[2023-09-09 15:50:15,446][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0008 loss2:0.1732 loss3:0.0017 | AUC:0.8421 Anomaly AUC:0.6475
[2023-09-09 15:50:34,359][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0007 loss2:0.1626 loss3:0.0015 | AUC:0.8397 Anomaly AUC:0.6436
[2023-09-09 15:50:53,224][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0007 loss2:0.1525 loss3:0.0014 | AUC:0.8411 Anomaly AUC:0.6442
[2023-09-09 15:51:12,098][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0006 loss2:0.1439 loss3:0.0013 | AUC:0.8398 Anomaly AUC:0.6459
[2023-09-09 15:51:31,031][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0005 loss2:0.1368 loss3:0.0013 | AUC:0.8389 Anomaly AUC:0.6430
[2023-09-09 15:51:54,371][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 15:51:57,222][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 15:51:57,223][main.py][line:168][INFO] Training Mode
[2023-09-09 15:51:57,223][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 15:51:57,223][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 15:52:05,425][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 15:52:23,906][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.7732 loss2:1.3563 loss3:0.3815 | AUC:0.8165 Anomaly AUC:0.6031
[2023-09-09 15:52:42,302][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.3803 loss2:1.0982 loss3:0.3043 | AUC:0.8443 Anomaly AUC:0.6654
[2023-09-09 15:53:01,096][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.2694 loss2:0.9170 loss3:0.2145 | AUC:0.8511 Anomaly AUC:0.6743
[2023-09-09 15:53:19,704][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.1790 loss2:0.8334 loss3:0.1487 | AUC:0.8476 Anomaly AUC:0.6709
[2023-09-09 15:53:38,565][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.1088 loss2:0.7673 loss3:0.0947 | AUC:0.8465 Anomaly AUC:0.6652
[2023-09-09 15:53:57,496][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0542 loss2:0.7069 loss3:0.0571 | AUC:0.8517 Anomaly AUC:0.6715
[2023-09-09 15:54:16,360][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0687 loss2:0.6852 loss3:0.0409 | AUC:0.8487 Anomaly AUC:0.6653
[2023-09-09 15:54:35,330][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0156 loss2:0.6221 loss3:0.0240 | AUC:0.8482 Anomaly AUC:0.6706
[2023-09-09 15:54:54,452][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0167 loss2:0.5853 loss3:0.0186 | AUC:0.8475 Anomaly AUC:0.6669
[2023-09-09 15:55:13,370][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0347 loss2:0.5689 loss3:0.0173 | AUC:0.8430 Anomaly AUC:0.6634
[2023-09-09 15:55:32,519][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0146 loss2:0.5229 loss3:0.0115 | AUC:0.8407 Anomaly AUC:0.6747
[2023-09-09 15:55:51,643][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0241 loss2:0.5026 loss3:0.0094 | AUC:0.8546 Anomaly AUC:0.6660
[2023-09-09 15:56:10,706][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0217 loss2:0.4793 loss3:0.0074 | AUC:0.8537 Anomaly AUC:0.6614
[2023-09-09 15:56:29,882][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0026 loss2:0.4175 loss3:0.0041 | AUC:0.8528 Anomaly AUC:0.6633
[2023-09-09 15:56:48,923][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0026 loss2:0.3829 loss3:0.0039 | AUC:0.8497 Anomaly AUC:0.6624
[2023-09-09 15:57:07,917][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0020 loss2:0.3518 loss3:0.0035 | AUC:0.8515 Anomaly AUC:0.6615
[2023-09-09 15:57:27,063][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0019 loss2:0.3188 loss3:0.0033 | AUC:0.8502 Anomaly AUC:0.6574
[2023-09-09 15:57:46,062][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0017 loss2:0.2909 loss3:0.0032 | AUC:0.8502 Anomaly AUC:0.6547
[2023-09-09 15:58:05,136][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0016 loss2:0.2681 loss3:0.0030 | AUC:0.8487 Anomaly AUC:0.6548
[2023-09-09 15:58:24,159][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0015 loss2:0.2420 loss3:0.0028 | AUC:0.8476 Anomaly AUC:0.6549
[2023-09-09 15:58:43,139][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0014 loss2:0.2217 loss3:0.0027 | AUC:0.8491 Anomaly AUC:0.6593
[2023-09-09 15:59:02,174][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0033 loss2:0.2126 loss3:0.0028 | AUC:0.8420 Anomaly AUC:0.6386
[2023-09-09 15:59:21,207][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0659 loss2:0.3155 loss3:0.0119 | AUC:0.8540 Anomaly AUC:0.6637
[2023-09-09 15:59:40,166][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0018 loss2:0.1979 loss3:0.0028 | AUC:0.8432 Anomaly AUC:0.6481
[2023-09-09 15:59:59,257][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0014 loss2:0.1779 loss3:0.0022 | AUC:0.8444 Anomaly AUC:0.6508
[2023-09-09 16:00:18,407][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0012 loss2:0.1655 loss3:0.0020 | AUC:0.8402 Anomaly AUC:0.6466
[2023-09-09 16:01:24,460][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:01:27,146][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:01:27,146][main.py][line:168][INFO] Training Mode
[2023-09-09 16:01:27,147][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:01:27,147][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:01:35,244][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:02:17,426][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:02:20,128][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:02:20,128][main.py][line:168][INFO] Training Mode
[2023-09-09 16:02:20,128][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:02:20,129][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:02:28,218][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:02:46,823][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:2.1648 loss2:1.4042 loss3:0.3871 | AUC:0.2738 Anomaly AUC:0.4825
[2023-09-09 16:03:05,036][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:1.3517 loss2:1.3978 loss3:0.3887 | AUC:0.7377 Anomaly AUC:0.5914
[2023-09-09 16:03:23,656][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:1.2135 loss2:1.3771 loss3:0.3855 | AUC:0.8047 Anomaly AUC:0.5867
[2023-09-09 16:03:42,332][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.8868 loss2:1.3222 loss3:0.3778 | AUC:0.8014 Anomaly AUC:0.5829
[2023-09-09 16:04:01,141][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.6975 loss2:1.2806 loss3:0.3648 | AUC:0.8111 Anomaly AUC:0.5879
[2023-09-09 16:04:19,967][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.5332 loss2:1.2409 loss3:0.3462 | AUC:0.8268 Anomaly AUC:0.5920
[2023-09-09 16:04:38,959][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.3972 loss2:1.2140 loss3:0.3215 | AUC:0.8269 Anomaly AUC:0.5858
[2023-09-09 16:04:57,870][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.2453 loss2:1.1959 loss3:0.2915 | AUC:0.8155 Anomaly AUC:0.5664
[2023-09-09 16:05:16,795][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.1895 loss2:1.1826 loss3:0.2587 | AUC:0.8143 Anomaly AUC:0.5636
[2023-09-09 16:05:35,773][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.1978 loss2:1.1757 loss3:0.2277 | AUC:0.7909 Anomaly AUC:0.5486
[2023-09-09 16:05:51,019][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:05:53,855][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:05:53,855][main.py][line:168][INFO] Training Mode
[2023-09-09 16:05:53,856][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:05:53,856][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:06:01,865][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:06:20,186][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:1.5210 loss2:1.4032 loss3:0.3800 | AUC:0.7292 Anomaly AUC:0.5937
[2023-09-09 16:06:38,547][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:1.2166 loss2:1.3951 loss3:0.3255 | AUC:0.8011 Anomaly AUC:0.5859
[2023-09-09 16:06:57,256][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.8200 loss2:1.3077 loss3:0.1674 | AUC:0.8047 Anomaly AUC:0.5905
[2023-09-09 16:07:15,913][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.6520 loss2:1.2467 loss3:0.0903 | AUC:0.8120 Anomaly AUC:0.5902
[2023-09-09 16:07:34,757][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.5288 loss2:1.2274 loss3:0.0526 | AUC:0.8078 Anomaly AUC:0.5744
[2023-09-09 16:07:53,517][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.4390 loss2:1.2128 loss3:0.0367 | AUC:0.8116 Anomaly AUC:0.5899
[2023-09-09 16:08:12,494][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.4130 loss2:1.2086 loss3:0.0337 | AUC:0.8009 Anomaly AUC:0.5741
[2023-09-09 16:08:31,446][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.2966 loss2:1.1922 loss3:0.0222 | AUC:0.8060 Anomaly AUC:0.5786
[2023-09-09 16:08:50,317][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.2431 loss2:1.1839 loss3:0.0167 | AUC:0.7929 Anomaly AUC:0.5553
[2023-09-09 16:09:09,274][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.2133 loss2:1.1793 loss3:0.0138 | AUC:0.7827 Anomaly AUC:0.5543
[2023-09-09 16:09:31,139][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:09:33,805][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:09:33,805][main.py][line:168][INFO] Training Mode
[2023-09-09 16:09:33,805][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:09:33,806][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:09:41,886][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:10:00,202][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:24.9849 loss2:1.4053 loss3:0.4150 | AUC:0.5764 Anomaly AUC:0.5424
[2023-09-09 16:10:18,548][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:15.2751 loss2:1.3992 loss3:0.3825 | AUC:0.6492 Anomaly AUC:0.5948
[2023-09-09 16:10:37,179][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:12.5146 loss2:1.3983 loss3:0.3590 | AUC:0.7420 Anomaly AUC:0.5570
[2023-09-09 16:10:56,002][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:12.0236 loss2:1.3989 loss3:0.3308 | AUC:0.5944 Anomaly AUC:0.5838
[2023-09-09 16:11:14,784][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:13.9748 loss2:1.4016 loss3:0.3079 | AUC:0.6682 Anomaly AUC:0.5674
[2023-09-09 16:11:33,569][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:10.5040 loss2:1.4027 loss3:0.2776 | AUC:0.7060 Anomaly AUC:0.5642
[2023-09-09 16:11:52,461][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:9.9657 loss2:1.4029 loss3:0.2457 | AUC:0.7214 Anomaly AUC:0.5720
[2023-09-09 16:12:11,470][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:10.3849 loss2:1.4004 loss3:0.2546 | AUC:0.7058 Anomaly AUC:0.5488
[2023-09-09 16:12:30,306][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:8.4261 loss2:1.3954 loss3:0.2257 | AUC:0.7508 Anomaly AUC:0.5537
[2023-09-09 16:12:49,350][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:7.1663 loss2:1.3887 loss3:0.2178 | AUC:0.7183 Anomaly AUC:0.5338
[2023-09-09 16:13:05,080][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:13:07,780][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:13:07,781][main.py][line:168][INFO] Training Mode
[2023-09-09 16:13:07,781][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:13:07,781][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:13:15,769][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:13:34,115][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:1.4510 loss2:1.3836 loss3:0.3743 | AUC:0.7751 Anomaly AUC:0.5804
[2023-09-09 16:13:52,372][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.9677 loss2:1.2492 loss3:0.2886 | AUC:0.7956 Anomaly AUC:0.5871
[2023-09-09 16:14:11,060][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.6573 loss2:1.1661 loss3:0.1415 | AUC:0.8167 Anomaly AUC:0.6102
[2023-09-09 16:14:29,640][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.5304 loss2:1.1294 loss3:0.0805 | AUC:0.8002 Anomaly AUC:0.5759
[2023-09-09 16:14:48,375][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.4119 loss2:1.1034 loss3:0.0413 | AUC:0.8050 Anomaly AUC:0.5669
[2023-09-09 16:15:07,197][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.3137 loss2:1.0764 loss3:0.0257 | AUC:0.7713 Anomaly AUC:0.5661
[2023-09-09 16:15:26,078][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.2533 loss2:1.0567 loss3:0.0197 | AUC:0.7833 Anomaly AUC:0.5578
[2023-09-09 16:15:44,987][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.1839 loss2:1.0379 loss3:0.0135 | AUC:0.7892 Anomaly AUC:0.5655
[2023-09-09 16:16:04,082][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.1378 loss2:1.0203 loss3:0.0096 | AUC:0.8168 Anomaly AUC:0.5799
[2023-09-09 16:16:22,859][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.1116 loss2:1.0076 loss3:0.0072 | AUC:0.8013 Anomaly AUC:0.5610
[2023-09-09 16:16:41,810][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.1098 loss2:1.0013 loss3:0.0073 | AUC:0.7791 Anomaly AUC:0.5356
[2023-09-09 16:17:00,714][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0665 loss2:0.9868 loss3:0.0041 | AUC:0.7600 Anomaly AUC:0.5304
[2023-09-09 16:17:19,567][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0750 loss2:0.9825 loss3:0.0049 | AUC:0.7537 Anomaly AUC:0.5456
[2023-09-09 16:17:38,491][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0901 loss2:0.9803 loss3:0.0056 | AUC:0.8029 Anomaly AUC:0.5523
[2023-09-09 16:17:57,396][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0518 loss2:0.9620 loss3:0.0030 | AUC:0.7954 Anomaly AUC:0.5413
[2023-09-09 16:18:16,332][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0699 loss2:0.9640 loss3:0.0041 | AUC:0.7786 Anomaly AUC:0.5468
[2023-09-09 16:18:35,182][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0452 loss2:0.9527 loss3:0.0027 | AUC:0.7816 Anomaly AUC:0.5348
[2023-09-09 16:18:54,110][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.1266 loss2:0.9630 loss3:0.0090 | AUC:0.8066 Anomaly AUC:0.5648
[2023-09-09 16:19:13,031][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0894 loss2:0.9568 loss3:0.0059 | AUC:0.7899 Anomaly AUC:0.5497
[2023-09-09 16:19:32,085][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0431 loss2:0.9435 loss3:0.0030 | AUC:0.7886 Anomaly AUC:0.5635
[2023-09-09 16:19:51,066][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.1176 loss2:0.9555 loss3:0.0088 | AUC:0.7766 Anomaly AUC:0.5563
[2023-09-09 16:20:10,040][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0898 loss2:0.9507 loss3:0.0061 | AUC:0.8178 Anomaly AUC:0.5864
[2023-09-09 16:20:28,991][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0754 loss2:0.9390 loss3:0.0044 | AUC:0.7942 Anomaly AUC:0.5567
[2023-09-09 16:20:47,947][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0296 loss2:0.9318 loss3:0.0017 | AUC:0.8040 Anomaly AUC:0.5422
[2023-09-09 16:21:07,066][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0279 loss2:0.9345 loss3:0.0015 | AUC:0.7896 Anomaly AUC:0.5583
[2023-09-09 16:21:25,997][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0179 loss2:0.9267 loss3:0.0009 | AUC:0.7906 Anomaly AUC:0.5558
[2023-09-09 16:21:44,834][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.1226 loss2:0.9270 loss3:0.0096 | AUC:0.6850 Anomaly AUC:0.5060
[2023-09-09 16:22:03,735][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.1166 loss2:0.8758 loss3:0.0131 | AUC:0.7694 Anomaly AUC:0.5707
[2023-09-09 16:22:22,688][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0237 loss2:0.8038 loss3:0.0015 | AUC:0.8036 Anomaly AUC:0.5739
[2023-09-09 16:22:41,624][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.1025 loss2:0.7838 loss3:0.0094 | AUC:0.7610 Anomaly AUC:0.5444
[2023-09-09 16:23:00,641][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0297 loss2:0.6748 loss3:0.0013 | AUC:0.7966 Anomaly AUC:0.5841
[2023-09-09 16:23:19,682][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0202 loss2:0.5512 loss3:0.0008 | AUC:0.7775 Anomaly AUC:0.5527
[2023-09-09 16:23:38,655][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0328 loss2:0.4756 loss3:0.0016 | AUC:0.7932 Anomaly AUC:0.5680
[2023-09-09 16:23:57,665][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0238 loss2:0.3574 loss3:0.0012 | AUC:0.7814 Anomaly AUC:0.5606
[2023-09-09 16:24:16,628][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0278 loss2:0.2544 loss3:0.0017 | AUC:0.7798 Anomaly AUC:0.5509
[2023-09-09 16:24:35,768][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0392 loss2:0.2019 loss3:0.0020 | AUC:0.7740 Anomaly AUC:0.5552
[2023-09-09 16:24:54,690][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0403 loss2:0.1446 loss3:0.0020 | AUC:0.7207 Anomaly AUC:0.5186
[2023-09-09 16:25:13,728][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0330 loss2:0.0833 loss3:0.0014 | AUC:0.7450 Anomaly AUC:0.5488
[2023-09-09 16:25:32,864][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0283 loss2:0.0717 loss3:0.0018 | AUC:0.7528 Anomaly AUC:0.5536
[2023-09-09 16:25:51,982][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0086 loss2:0.0204 loss3:0.0005 | AUC:0.7522 Anomaly AUC:0.5590
[2023-09-09 16:26:11,236][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0058 loss2:0.0109 loss3:0.0004 | AUC:0.7468 Anomaly AUC:0.5481
[2023-09-09 16:26:30,309][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00050 | loss1:0.0046 loss2:0.0082 loss3:0.0003 | AUC:0.7487 Anomaly AUC:0.5571
[2023-09-09 16:26:49,430][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00050 | loss1:0.0040 loss2:0.0058 loss3:0.0003 | AUC:0.7495 Anomaly AUC:0.5573
[2023-09-09 16:27:08,517][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00050 | loss1:0.0034 loss2:0.0045 loss3:0.0003 | AUC:0.7489 Anomaly AUC:0.5529
[2023-09-09 16:27:27,750][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00050 | loss1:0.0031 loss2:0.0041 loss3:0.0003 | AUC:0.7559 Anomaly AUC:0.5595
[2023-09-09 16:27:46,919][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00050 | loss1:0.0031 loss2:0.0040 loss3:0.0003 | AUC:0.7488 Anomaly AUC:0.5558
[2023-09-09 16:28:06,015][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00050 | loss1:0.0028 loss2:0.0036 loss3:0.0003 | AUC:0.7452 Anomaly AUC:0.5397
[2023-09-09 16:28:25,225][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00050 | loss1:0.0036 loss2:0.0108 loss3:0.0004 | AUC:0.7419 Anomaly AUC:0.5465
[2023-09-09 16:28:44,248][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00050 | loss1:0.1076 loss2:0.1394 loss3:0.0086 | AUC:0.7472 Anomaly AUC:0.5377
[2023-09-09 16:29:03,360][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00050 | loss1:0.1332 loss2:0.1853 loss3:0.0078 | AUC:0.7976 Anomaly AUC:0.5542
[2023-09-09 16:29:22,422][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00050 | loss1:0.0684 loss2:0.0739 loss3:0.0033 | AUC:0.7907 Anomaly AUC:0.5323
[2023-09-09 16:29:41,572][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00050 | loss1:0.0169 loss2:0.0176 loss3:0.0010 | AUC:0.7616 Anomaly AUC:0.5369
[2023-09-09 16:30:00,613][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00050 | loss1:0.0257 loss2:0.0188 loss3:0.0013 | AUC:0.7638 Anomaly AUC:0.5141
[2023-09-09 16:30:19,680][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00050 | loss1:0.0053 loss2:0.0069 loss3:0.0005 | AUC:0.7795 Anomaly AUC:0.5247
[2023-09-09 16:30:38,803][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00050 | loss1:0.0031 loss2:0.0043 loss3:0.0003 | AUC:0.7770 Anomaly AUC:0.5236
[2023-09-09 16:30:57,892][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00050 | loss1:0.0024 loss2:0.0032 loss3:0.0002 | AUC:0.7736 Anomaly AUC:0.5231
[2023-09-09 16:31:16,930][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00050 | loss1:0.0019 loss2:0.0026 loss3:0.0002 | AUC:0.7728 Anomaly AUC:0.5219
[2023-09-09 16:31:35,993][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00050 | loss1:0.0015 loss2:0.0025 loss3:0.0002 | AUC:0.7714 Anomaly AUC:0.5213
[2023-09-09 16:31:55,002][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00050 | loss1:0.0015 loss2:0.0025 loss3:0.0002 | AUC:0.7722 Anomaly AUC:0.5216
[2023-09-09 16:32:14,128][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00050 | loss1:0.0012 loss2:0.0025 loss3:0.0002 | AUC:0.7726 Anomaly AUC:0.5242
[2023-09-09 16:32:33,182][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00050 | loss1:0.0010 loss2:0.0021 loss3:0.0002 | AUC:0.7721 Anomaly AUC:0.5233
[2023-09-09 16:32:52,287][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00050 | loss1:0.0009 loss2:0.0017 loss3:0.0002 | AUC:0.7734 Anomaly AUC:0.5261
[2023-09-09 16:33:11,532][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00050 | loss1:0.0010 loss2:0.0019 loss3:0.0002 | AUC:0.7750 Anomaly AUC:0.5292
[2023-09-09 16:33:30,863][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00050 | loss1:0.0008 loss2:0.0018 loss3:0.0002 | AUC:0.7729 Anomaly AUC:0.5271
[2023-09-09 16:33:50,000][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00050 | loss1:0.0008 loss2:0.0017 loss3:0.0002 | AUC:0.7754 Anomaly AUC:0.5322
[2023-09-09 16:34:09,090][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00050 | loss1:0.0008 loss2:0.0016 loss3:0.0002 | AUC:0.7779 Anomaly AUC:0.5308
[2023-09-09 16:34:28,348][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00050 | loss1:0.0007 loss2:0.0018 loss3:0.0002 | AUC:0.7792 Anomaly AUC:0.5311
[2023-09-09 16:34:47,433][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00050 | loss1:0.0007 loss2:0.0016 loss3:0.0002 | AUC:0.7748 Anomaly AUC:0.5317
[2023-09-09 16:35:06,551][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00050 | loss1:0.0006 loss2:0.0016 loss3:0.0002 | AUC:0.7777 Anomaly AUC:0.5344
[2023-09-09 16:35:25,713][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00050 | loss1:0.0007 loss2:0.0018 loss3:0.0002 | AUC:0.7738 Anomaly AUC:0.5275
[2023-09-09 16:35:44,830][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00050 | loss1:0.0009 loss2:0.0044 loss3:0.0002 | AUC:0.7754 Anomaly AUC:0.5276
[2023-09-09 16:36:04,012][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00050 | loss1:0.1927 loss2:0.2322 loss3:0.0157 | AUC:0.7282 Anomaly AUC:0.4985
[2023-09-09 16:36:23,226][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00050 | loss1:0.0678 loss2:0.0931 loss3:0.0041 | AUC:0.6988 Anomaly AUC:0.4762
[2023-09-09 16:36:42,450][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00050 | loss1:0.0278 loss2:0.0321 loss3:0.0017 | AUC:0.7005 Anomaly AUC:0.4862
[2023-09-09 16:37:01,565][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00050 | loss1:0.0296 loss2:0.0269 loss3:0.0016 | AUC:0.7226 Anomaly AUC:0.5129
[2023-09-09 16:37:20,722][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00050 | loss1:0.0211 loss2:0.0200 loss3:0.0013 | AUC:0.7545 Anomaly AUC:0.4956
[2023-09-09 16:37:39,978][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00050 | loss1:0.0222 loss2:0.0199 loss3:0.0015 | AUC:0.7627 Anomaly AUC:0.5121
[2023-09-09 16:37:59,278][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00050 | loss1:0.0080 loss2:0.0086 loss3:0.0007 | AUC:0.7631 Anomaly AUC:0.5099
[2023-09-09 16:38:18,351][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00050 | loss1:0.0030 loss2:0.0044 loss3:0.0004 | AUC:0.7636 Anomaly AUC:0.5085
[2023-09-09 16:38:37,578][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00050 | loss1:0.0454 loss2:0.0256 loss3:0.0029 | AUC:0.7879 Anomaly AUC:0.5444
[2023-09-09 16:38:56,751][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00050 | loss1:0.0404 loss2:0.0375 loss3:0.0022 | AUC:0.7785 Anomaly AUC:0.5397
[2023-09-09 16:39:15,946][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00050 | loss1:0.0236 loss2:0.0197 loss3:0.0015 | AUC:0.7586 Anomaly AUC:0.5277
[2023-09-09 16:39:35,092][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00050 | loss1:0.0288 loss2:0.0236 loss3:0.0019 | AUC:0.7714 Anomaly AUC:0.5235
[2023-09-09 16:39:54,218][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00050 | loss1:0.0139 loss2:0.0139 loss3:0.0009 | AUC:0.7692 Anomaly AUC:0.5498
[2023-09-09 16:40:13,395][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00050 | loss1:0.0396 loss2:0.0351 loss3:0.0024 | AUC:0.7377 Anomaly AUC:0.5508
[2023-09-09 16:40:32,552][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00050 | loss1:0.0104 loss2:0.0147 loss3:0.0009 | AUC:0.7627 Anomaly AUC:0.5547
[2023-09-09 16:40:51,667][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00050 | loss1:0.0033 loss2:0.0034 loss3:0.0005 | AUC:0.7678 Anomaly AUC:0.5438
[2023-09-09 16:41:10,917][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00050 | loss1:0.0015 loss2:0.0021 loss3:0.0003 | AUC:0.7797 Anomaly AUC:0.5575
[2023-09-09 16:41:30,063][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00050 | loss1:0.0010 loss2:0.0018 loss3:0.0002 | AUC:0.7809 Anomaly AUC:0.5562
[2023-09-09 16:41:49,133][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00050 | loss1:0.0008 loss2:0.0017 loss3:0.0002 | AUC:0.7774 Anomaly AUC:0.5495
[2023-09-09 16:42:08,234][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00050 | loss1:0.0007 loss2:0.0015 loss3:0.0002 | AUC:0.7779 Anomaly AUC:0.5467
[2023-09-09 16:42:27,437][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00050 | loss1:0.0006 loss2:0.0015 loss3:0.0002 | AUC:0.7764 Anomaly AUC:0.5424
[2023-09-09 16:42:46,586][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00050 | loss1:0.0006 loss2:0.0015 loss3:0.0002 | AUC:0.7731 Anomaly AUC:0.5360
[2023-09-09 16:43:05,755][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00050 | loss1:0.0694 loss2:0.0419 loss3:0.0024 | AUC:0.7538 Anomaly AUC:0.5455
[2023-09-09 16:43:24,765][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00050 | loss1:0.0875 loss2:0.1129 loss3:0.0070 | AUC:0.7583 Anomaly AUC:0.5318
[2023-09-09 16:43:44,004][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00050 | loss1:0.0181 loss2:0.0202 loss3:0.0018 | AUC:0.7885 Anomaly AUC:0.5553
[2023-09-09 16:44:03,120][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00050 | loss1:0.0341 loss2:0.0267 loss3:0.0025 | AUC:0.7816 Anomaly AUC:0.5434
[2023-09-09 16:44:22,233][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00050 | loss1:0.0093 loss2:0.0137 loss3:0.0009 | AUC:0.7494 Anomaly AUC:0.5157
[2023-09-09 16:44:41,403][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00050 | loss1:0.0283 loss2:0.0180 loss3:0.0017 | AUC:0.7731 Anomaly AUC:0.5793
[2023-09-09 16:45:00,480][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00050 | loss1:0.0173 loss2:0.0159 loss3:0.0012 | AUC:0.7875 Anomaly AUC:0.5303
[2023-09-09 16:45:00,503][main.py][line:116][INFO] Training completes in 31m 45s | best AUCAUC:0.8178 Anomaly AUC:0.5864

[2023-09-09 16:56:00,645][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:56:03,430][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:56:03,430][main.py][line:168][INFO] Training Mode
[2023-09-09 16:56:03,431][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:56:03,431][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:56:11,510][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:56:29,929][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:1.4510 loss2:1.3836 loss3:0.3743 | AUC:0.7751 Anomaly AUC:0.5804
[2023-09-09 16:56:59,503][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 16:57:02,372][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 16:57:02,372][main.py][line:168][INFO] Training Mode
[2023-09-09 16:57:02,372][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 16:57:02,373][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 16:57:10,451][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 16:57:28,810][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:1.0163 loss2:1.3286 loss3:0.3111 | AUC:0.8074 Anomaly AUC:0.6068
[2023-09-09 16:57:46,953][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.5516 loss2:1.1775 loss3:0.1860 | AUC:0.7944 Anomaly AUC:0.5879
[2023-09-09 16:58:05,446][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.4270 loss2:1.1181 loss3:0.1587 | AUC:0.7946 Anomaly AUC:0.5790
[2023-09-09 16:58:24,098][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.3385 loss2:1.0850 loss3:0.1290 | AUC:0.8009 Anomaly AUC:0.5722
[2023-09-09 16:58:42,878][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.2859 loss2:1.0704 loss3:0.0824 | AUC:0.8150 Anomaly AUC:0.5651
[2023-09-09 16:59:01,697][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.2114 loss2:1.0408 loss3:0.0276 | AUC:0.7966 Anomaly AUC:0.5895
[2023-09-09 16:59:20,614][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.1835 loss2:1.0210 loss3:0.0172 | AUC:0.7916 Anomaly AUC:0.5818
[2023-09-09 16:59:39,642][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.1732 loss2:1.0094 loss3:0.0146 | AUC:0.7922 Anomaly AUC:0.5837
[2023-09-09 16:59:58,502][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0856 loss2:0.9807 loss3:0.0070 | AUC:0.7511 Anomaly AUC:0.5475
[2023-09-09 17:00:17,438][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0889 loss2:0.9710 loss3:0.0068 | AUC:0.7772 Anomaly AUC:0.5576
[2023-09-09 17:00:36,410][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0576 loss2:0.9560 loss3:0.0045 | AUC:0.7901 Anomaly AUC:0.5615
[2023-09-09 17:00:55,390][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0761 loss2:0.9493 loss3:0.0057 | AUC:0.8036 Anomaly AUC:0.5677
[2023-09-09 17:01:14,361][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0387 loss2:0.9353 loss3:0.0031 | AUC:0.7757 Anomaly AUC:0.5627
[2023-09-09 17:01:33,369][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0667 loss2:0.9335 loss3:0.0050 | AUC:0.8011 Anomaly AUC:0.5881
[2023-09-09 17:01:52,412][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0351 loss2:0.9150 loss3:0.0028 | AUC:0.7466 Anomaly AUC:0.5552
[2023-09-09 17:02:11,304][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0397 loss2:0.9095 loss3:0.0030 | AUC:0.7892 Anomaly AUC:0.5714
[2023-09-09 17:02:30,293][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0335 loss2:0.8911 loss3:0.0025 | AUC:0.7738 Anomaly AUC:0.5587
[2023-09-09 17:02:49,310][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0857 loss2:0.8906 loss3:0.0073 | AUC:0.7908 Anomaly AUC:0.5640
[2023-09-09 17:03:08,270][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0985 loss2:0.8865 loss3:0.0070 | AUC:0.7972 Anomaly AUC:0.5863
[2023-09-09 17:03:27,371][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0612 loss2:0.7741 loss3:0.0025 | AUC:0.7589 Anomaly AUC:0.5163
[2023-09-09 17:03:46,420][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0571 loss2:0.6241 loss3:0.0029 | AUC:0.8003 Anomaly AUC:0.5590
[2023-09-09 17:04:05,436][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0350 loss2:0.5374 loss3:0.0024 | AUC:0.7942 Anomaly AUC:0.5986
[2023-09-09 17:04:24,556][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0367 loss2:0.4406 loss3:0.0025 | AUC:0.8094 Anomaly AUC:0.6258
[2023-09-09 17:04:43,643][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0410 loss2:0.3567 loss3:0.0032 | AUC:0.7385 Anomaly AUC:0.5857
[2023-09-09 17:05:02,768][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0158 loss2:0.2346 loss3:0.0015 | AUC:0.8070 Anomaly AUC:0.6091
[2023-09-09 17:05:21,770][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0583 loss2:0.1987 loss3:0.0041 | AUC:0.8110 Anomaly AUC:0.5794
[2023-09-09 17:05:40,901][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0289 loss2:0.1150 loss3:0.0022 | AUC:0.7658 Anomaly AUC:0.5487
[2023-09-09 17:06:00,084][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0171 loss2:0.0626 loss3:0.0015 | AUC:0.7953 Anomaly AUC:0.5715
[2023-09-09 17:06:19,316][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0394 loss2:0.0698 loss3:0.0027 | AUC:0.8092 Anomaly AUC:0.5902
[2023-09-09 17:06:32,046][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:06:34,928][main.py][line:165][INFO] total params:39.0547M
[2023-09-09 17:06:34,929][main.py][line:168][INFO] Training Mode
[2023-09-09 17:06:34,930][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-3): 4 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-3): 4 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 17:06:34,930][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:07:03,150][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:07:05,958][main.py][line:165][INFO] total params:39.0547M
[2023-09-09 17:07:05,958][main.py][line:168][INFO] Training Mode
[2023-09-09 17:07:05,959][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-3): 4 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-3): 4 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 17:07:05,959][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:07:21,181][main.py][line:82][INFO] Random initialize AUCAUC:0.4428 Anomaly AUC:0.45752
[2023-09-09 17:08:05,725][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:1.1148 loss2:1.3417 loss3:0.3481 | AUC:0.8019 Anomaly AUC:0.5835
[2023-09-09 17:08:50,223][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.6038 loss2:1.0627 loss3:0.2104 | AUC:0.8110 Anomaly AUC:0.5854
[2023-09-09 17:09:03,250][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:09:06,096][main.py][line:165][INFO] total params:30.6445M
[2023-09-09 17:09:06,096][main.py][line:168][INFO] Training Mode
[2023-09-09 17:09:06,097][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=4096, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=2048, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 17:09:06,097][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:09:17,336][main.py][line:82][INFO] Random initialize AUCAUC:0.5208 Anomaly AUC:0.48912
[2023-09-09 17:09:50,548][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:1.2571 loss2:1.3597 loss3:0.3718 | AUC:0.7949 Anomaly AUC:0.5865
[2023-09-09 17:10:23,516][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.6183 loss2:1.0950 loss3:0.2415 | AUC:0.8044 Anomaly AUC:0.5840
[2023-09-09 17:10:56,712][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.4489 loss2:0.9578 loss3:0.1742 | AUC:0.8117 Anomaly AUC:0.5849
[2023-09-09 17:11:29,854][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.3187 loss2:0.8964 loss3:0.1498 | AUC:0.8019 Anomaly AUC:0.5779
[2023-09-09 17:12:03,261][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.2525 loss2:0.8591 loss3:0.1404 | AUC:0.8202 Anomaly AUC:0.5675
[2023-09-09 17:12:36,659][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.1710 loss2:0.8214 loss3:0.1294 | AUC:0.8137 Anomaly AUC:0.5629
[2023-09-09 17:13:10,214][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.1213 loss2:0.7863 loss3:0.1211 | AUC:0.7993 Anomaly AUC:0.5527
[2023-09-09 17:13:43,695][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0755 loss2:0.7528 loss3:0.1126 | AUC:0.8105 Anomaly AUC:0.5585
[2023-09-09 17:14:17,207][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0771 loss2:0.7327 loss3:0.1106 | AUC:0.8029 Anomaly AUC:0.5779
[2023-09-09 17:14:50,815][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0656 loss2:0.7088 loss3:0.1040 | AUC:0.7986 Anomaly AUC:0.5581
[2023-09-09 17:15:14,147][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:15:16,914][main.py][line:165][INFO] total params:18.0606M
[2023-09-09 17:15:16,915][main.py][line:168][INFO] Training Mode
[2023-09-09 17:15:16,916][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 17:15:16,916][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:15:27,140][main.py][line:82][INFO] Random initialize AUCAUC:0.5440 Anomaly AUC:0.52168
[2023-09-09 17:15:54,270][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:1.1467 loss2:1.3477 loss3:0.3790 | AUC:0.7981 Anomaly AUC:0.5678
[2023-09-09 17:16:21,235][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.4189 loss2:1.2372 loss3:0.3572 | AUC:0.6058 Anomaly AUC:0.5070
[2023-09-09 17:16:48,408][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0179 loss2:0.8676 loss3:0.3094 | AUC:0.6471 Anomaly AUC:0.6398
[2023-09-09 17:17:15,457][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0162 loss2:0.7400 loss3:0.2327 | AUC:0.7199 Anomaly AUC:0.6549
[2023-09-09 17:17:42,697][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0221 loss2:0.7101 loss3:0.2061 | AUC:0.7380 Anomaly AUC:0.6759
[2023-09-09 17:18:10,082][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0131 loss2:0.6424 loss3:0.1629 | AUC:0.7952 Anomaly AUC:0.6508
[2023-09-09 17:18:37,703][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0090 loss2:0.5940 loss3:0.1255 | AUC:0.8071 Anomaly AUC:0.6525
[2023-09-09 17:19:05,179][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0128 loss2:0.5482 loss3:0.0993 | AUC:0.8037 Anomaly AUC:0.6649
[2023-09-09 17:19:32,450][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0125 loss2:0.5179 loss3:0.0864 | AUC:0.7488 Anomaly AUC:0.5464
[2023-09-09 17:19:59,937][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0124 loss2:0.4717 loss3:0.0608 | AUC:0.7912 Anomaly AUC:0.5808
[2023-09-09 17:20:27,404][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0071 loss2:0.4166 loss3:0.0397 | AUC:0.8020 Anomaly AUC:0.5788
[2023-09-09 17:20:55,078][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0077 loss2:0.3831 loss3:0.0357 | AUC:0.8084 Anomaly AUC:0.5821
[2023-09-09 17:21:22,686][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0060 loss2:0.3478 loss3:0.0283 | AUC:0.8016 Anomaly AUC:0.5584
[2023-09-09 17:21:50,308][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.3867 loss2:0.5551 loss3:0.1201 | AUC:0.6170 Anomaly AUC:0.5211
[2023-09-09 17:22:17,817][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0321 loss2:0.7633 loss3:0.2012 | AUC:0.3526 Anomaly AUC:0.4719
[2023-09-09 17:22:45,306][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0101 loss2:0.4678 loss3:0.0650 | AUC:0.6986 Anomaly AUC:0.5183
[2023-09-09 17:23:12,819][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0057 loss2:0.3463 loss3:0.0366 | AUC:0.7960 Anomaly AUC:0.5597
[2023-09-09 17:25:24,809][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:25:27,477][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 17:25:27,477][main.py][line:168][INFO] Training Mode
[2023-09-09 17:25:27,477][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 17:25:27,478][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:26:20,982][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:26:23,637][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 17:26:23,638][main.py][line:168][INFO] Training Mode
[2023-09-09 17:26:23,638][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-09 17:26:23,638][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:26:32,048][main.py][line:82][INFO] Random initialize AUCAUC:0.5541 Anomaly AUC:0.47597
[2023-09-09 17:26:51,585][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:1.2873 loss2:1.3461 loss3:0.3812 | AUC:0.8086 Anomaly AUC:0.5933
[2023-09-09 17:27:10,935][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.6488 loss2:1.2049 loss3:0.3334 | AUC:0.8136 Anomaly AUC:0.6094
[2023-09-09 17:27:30,242][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.4967 loss2:0.9823 loss3:0.2697 | AUC:0.8132 Anomaly AUC:0.6238
[2023-09-09 17:27:49,851][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.3189 loss2:0.8790 loss3:0.2008 | AUC:0.8361 Anomaly AUC:0.6451
[2023-09-09 17:28:09,483][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.2290 loss2:0.8330 loss3:0.1439 | AUC:0.8278 Anomaly AUC:0.6532
[2023-09-09 17:28:29,193][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.1453 loss2:0.7893 loss3:0.0969 | AUC:0.8190 Anomaly AUC:0.6523
[2023-09-09 17:28:49,107][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.1062 loss2:0.7552 loss3:0.0636 | AUC:0.8397 Anomaly AUC:0.6649
[2023-09-09 17:29:09,044][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0818 loss2:0.7260 loss3:0.0433 | AUC:0.8384 Anomaly AUC:0.6616
[2023-09-09 17:29:29,275][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0841 loss2:0.7055 loss3:0.0334 | AUC:0.8421 Anomaly AUC:0.6736
[2023-09-09 17:29:49,150][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0486 loss2:0.6688 loss3:0.0238 | AUC:0.8368 Anomaly AUC:0.6714
[2023-09-09 17:30:09,040][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0438 loss2:0.6473 loss3:0.0191 | AUC:0.8294 Anomaly AUC:0.6623
[2023-09-09 17:30:28,998][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0229 loss2:0.6117 loss3:0.0139 | AUC:0.8361 Anomaly AUC:0.6449
[2023-09-09 17:30:48,932][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0141 loss2:0.5722 loss3:0.0098 | AUC:0.8343 Anomaly AUC:0.6378
[2023-09-09 17:31:08,857][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0246 loss2:0.5350 loss3:0.0072 | AUC:0.8238 Anomaly AUC:0.6278
[2023-09-09 17:31:28,725][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0224 loss2:0.4978 loss3:0.0053 | AUC:0.8294 Anomaly AUC:0.6286
[2023-09-09 17:31:48,618][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0281 loss2:0.4618 loss3:0.0046 | AUC:0.8212 Anomaly AUC:0.6115
[2023-09-09 17:32:08,494][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0689 loss2:0.4674 loss3:0.0077 | AUC:0.7913 Anomaly AUC:0.5936
[2023-09-09 17:32:28,305][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0951 loss2:0.4920 loss3:0.0113 | AUC:0.7942 Anomaly AUC:0.6384
[2023-09-09 17:32:48,221][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0396 loss2:0.4302 loss3:0.0055 | AUC:0.8020 Anomaly AUC:0.5964
[2023-09-09 17:33:08,212][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0282 loss2:0.3750 loss3:0.0035 | AUC:0.8084 Anomaly AUC:0.5988
[2023-09-09 17:33:28,141][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0249 loss2:0.3402 loss3:0.0028 | AUC:0.7971 Anomaly AUC:0.5919
[2023-09-09 17:33:48,105][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0267 loss2:0.3120 loss3:0.0025 | AUC:0.8150 Anomaly AUC:0.6038
[2023-09-09 17:33:58,346][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:34:01,213][main.py][line:165][INFO] total params:3.3590M
[2023-09-09 17:34:01,213][main.py][line:168][INFO] Training Mode
[2023-09-09 17:34:01,214][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:34:01,214][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:34:07,130][main.py][line:82][INFO] Random initialize AUCAUC:0.4970 Anomaly AUC:0.48541
[2023-09-09 17:34:20,910][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3057 loss2:1.0934 loss3:0.3885 | AUC:0.6684 Anomaly AUC:0.5484
[2023-09-09 17:34:35,012][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0317 loss2:0.8537 loss3:0.3866 | AUC:0.5145 Anomaly AUC:0.5086
[2023-09-09 17:34:49,522][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0110 loss2:0.7631 loss3:0.3814 | AUC:0.5170 Anomaly AUC:0.5059
[2023-09-09 17:35:04,154][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0081 loss2:0.7080 loss3:0.3586 | AUC:0.5121 Anomaly AUC:0.5056
[2023-09-09 17:35:18,696][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0073 loss2:0.6583 loss3:0.3227 | AUC:0.5118 Anomaly AUC:0.5078
[2023-09-09 17:35:33,295][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0061 loss2:0.6102 loss3:0.3113 | AUC:0.4926 Anomaly AUC:0.4985
[2023-09-09 17:35:47,946][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0050 loss2:0.5707 loss3:0.3061 | AUC:0.5008 Anomaly AUC:0.5058
[2023-09-09 17:36:02,699][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0041 loss2:0.5299 loss3:0.3024 | AUC:0.5080 Anomaly AUC:0.5045
[2023-09-09 17:36:17,483][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0033 loss2:0.4992 loss3:0.3001 | AUC:0.5064 Anomaly AUC:0.5094
[2023-09-09 17:36:32,372][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0027 loss2:0.4663 loss3:0.2985 | AUC:0.4917 Anomaly AUC:0.5028
[2023-09-09 17:36:47,237][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0023 loss2:0.4360 loss3:0.2971 | AUC:0.4925 Anomaly AUC:0.5025
[2023-09-09 17:37:01,930][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0020 loss2:0.4088 loss3:0.2961 | AUC:0.5073 Anomaly AUC:0.5116
[2023-09-09 17:37:16,741][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0019 loss2:0.3833 loss3:0.2951 | AUC:0.4935 Anomaly AUC:0.5051
[2023-09-09 17:37:31,616][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0016 loss2:0.3621 loss3:0.2943 | AUC:0.5070 Anomaly AUC:0.5140
[2023-09-09 17:39:19,612][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:39:22,400][main.py][line:165][INFO] total params:20.1516M
[2023-09-09 17:39:22,401][main.py][line:168][INFO] Training Mode
[2023-09-09 17:39:22,401][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:39:22,401][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:40:06,223][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:40:09,061][main.py][line:165][INFO] total params:24.3531M
[2023-09-09 17:40:09,061][main.py][line:168][INFO] Training Mode
[2023-09-09 17:40:09,062][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:40:09,062][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:40:19,903][main.py][line:82][INFO] Random initialize AUCAUC:0.5656 Anomaly AUC:0.51347
[2023-09-09 17:40:49,613][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.8322 loss2:1.1904 loss3:0.3541 | AUC:0.7933 Anomaly AUC:0.5729
[2023-09-09 17:41:19,122][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.3928 loss2:0.9224 loss3:0.2457 | AUC:0.8420 Anomaly AUC:0.6471
[2023-09-09 17:41:48,673][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1928 loss2:0.8320 loss3:0.1603 | AUC:0.8405 Anomaly AUC:0.6644
[2023-09-09 17:42:18,614][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0875 loss2:0.7700 loss3:0.1264 | AUC:0.8494 Anomaly AUC:0.6767
[2023-09-09 17:42:48,415][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0302 loss2:0.6972 loss3:0.0939 | AUC:0.8402 Anomaly AUC:0.6518
[2023-09-09 17:43:18,404][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0289 loss2:0.6814 loss3:0.0925 | AUC:0.8441 Anomaly AUC:0.6484
[2023-09-09 17:43:48,357][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0226 loss2:0.6065 loss3:0.0726 | AUC:0.8198 Anomaly AUC:0.6217
[2023-09-09 17:44:18,336][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0152 loss2:0.5372 loss3:0.0531 | AUC:0.8359 Anomaly AUC:0.6226
[2023-09-09 17:44:48,322][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0227 loss2:0.5333 loss3:0.0614 | AUC:0.8196 Anomaly AUC:0.6046
[2023-09-09 17:45:18,199][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0180 loss2:0.4937 loss3:0.0603 | AUC:0.8310 Anomaly AUC:0.6021
[2023-09-09 17:45:48,233][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0656 loss2:0.4632 loss3:0.0684 | AUC:0.6345 Anomaly AUC:0.5410
[2023-09-09 17:46:18,225][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0957 loss2:0.8192 loss3:0.1941 | AUC:0.8008 Anomaly AUC:0.6402
[2023-09-09 17:46:48,259][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0205 loss2:0.6394 loss3:0.0918 | AUC:0.8135 Anomaly AUC:0.6295
[2023-09-09 17:47:18,298][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0166 loss2:0.5057 loss3:0.0712 | AUC:0.8342 Anomaly AUC:0.6214
[2023-09-09 17:47:48,354][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0105 loss2:0.4042 loss3:0.0448 | AUC:0.8355 Anomaly AUC:0.6142
[2023-09-09 17:48:18,340][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0087 loss2:0.3504 loss3:0.0330 | AUC:0.8330 Anomaly AUC:0.6017
[2023-09-09 17:48:48,401][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0057 loss2:0.3069 loss3:0.0258 | AUC:0.8305 Anomaly AUC:0.6081
[2023-09-09 17:49:18,412][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0072 loss2:0.2842 loss3:0.0267 | AUC:0.8277 Anomaly AUC:0.6006
[2023-09-09 17:49:55,868][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:49:58,575][main.py][line:165][INFO] total params:9.1334M
[2023-09-09 17:49:58,575][main.py][line:168][INFO] Training Mode
[2023-09-09 17:49:58,576][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:49:58,576][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:51:07,558][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:51:10,310][main.py][line:165][INFO] total params:9.1334M
[2023-09-09 17:51:10,310][main.py][line:168][INFO] Training Mode
[2023-09-09 17:51:10,311][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:51:10,311][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:51:18,515][main.py][line:82][INFO] Random initialize AUCAUC:0.3878 Anomaly AUC:0.43862
[2023-09-09 17:51:37,774][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.6650 loss2:1.2821 loss3:0.3872 | AUC:0.7959 Anomaly AUC:0.5782
[2023-09-09 17:51:56,762][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1671 loss2:0.9477 loss3:0.3837 | AUC:0.6799 Anomaly AUC:0.5217
[2023-09-09 17:52:15,911][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0542 loss2:0.8454 loss3:0.3209 | AUC:0.6809 Anomaly AUC:0.5218
[2023-09-09 17:52:35,221][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0307 loss2:0.7709 loss3:0.2693 | AUC:0.6675 Anomaly AUC:0.5252
[2023-09-09 17:52:54,799][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0540 loss2:0.7943 loss3:0.2791 | AUC:0.6564 Anomaly AUC:0.4979
[2023-09-09 17:53:14,361][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0186 loss2:0.6825 loss3:0.2332 | AUC:0.7081 Anomaly AUC:0.5464
[2023-09-09 17:53:33,943][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0182 loss2:0.6243 loss3:0.2002 | AUC:0.7076 Anomaly AUC:0.5492
[2023-09-09 17:53:53,569][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0168 loss2:0.5802 loss3:0.1774 | AUC:0.7077 Anomaly AUC:0.5405
[2023-09-09 17:54:13,438][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0151 loss2:0.5382 loss3:0.1563 | AUC:0.7733 Anomaly AUC:0.5587
[2023-09-09 17:54:33,072][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0161 loss2:0.5049 loss3:0.1422 | AUC:0.6960 Anomaly AUC:0.5369
[2023-09-09 17:54:52,855][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0143 loss2:0.4830 loss3:0.1258 | AUC:0.7383 Anomaly AUC:0.5485
[2023-09-09 17:55:12,566][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0127 loss2:0.4438 loss3:0.1036 | AUC:0.7201 Anomaly AUC:0.5384
[2023-09-09 17:55:32,488][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0154 loss2:0.4305 loss3:0.0992 | AUC:0.7881 Anomaly AUC:0.5571
[2023-09-09 17:55:52,304][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0120 loss2:0.3981 loss3:0.0795 | AUC:0.7590 Anomaly AUC:0.5426
[2023-09-09 17:56:12,123][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0119 loss2:0.3791 loss3:0.0727 | AUC:0.7502 Anomaly AUC:0.5375
[2023-09-09 17:56:31,909][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0091 loss2:0.3443 loss3:0.0531 | AUC:0.7844 Anomaly AUC:0.5492
[2023-09-09 17:56:51,651][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0102 loss2:0.3378 loss3:0.0521 | AUC:0.7394 Anomaly AUC:0.5388
[2023-09-09 17:57:10,708][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:57:13,401][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 17:57:13,401][main.py][line:168][INFO] Training Mode
[2023-09-09 17:57:13,402][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:57:13,402][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:57:21,416][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 17:57:44,474][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 17:57:47,170][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 17:57:47,170][main.py][line:168][INFO] Training Mode
[2023-09-09 17:57:47,171][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 17:57:47,171][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 17:57:55,242][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 17:58:13,699][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.6531 loss2:1.2178 loss3:0.3847 | AUC:0.7689 Anomaly AUC:0.5537
[2023-09-09 17:58:31,859][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1448 loss2:0.7558 loss3:0.3888 | AUC:0.7105 Anomaly AUC:0.5424
[2023-09-09 17:58:50,433][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0507 loss2:0.6368 loss3:0.3377 | AUC:0.6801 Anomaly AUC:0.5232
[2023-09-09 17:59:09,242][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0555 loss2:0.6500 loss3:0.3160 | AUC:0.5615 Anomaly AUC:0.5053
[2023-09-09 17:59:28,037][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0203 loss2:0.5398 loss3:0.2885 | AUC:0.5168 Anomaly AUC:0.5048
[2023-09-09 17:59:46,948][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0137 loss2:0.4865 loss3:0.2642 | AUC:0.5148 Anomaly AUC:0.5048
[2023-09-09 18:00:05,960][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0123 loss2:0.4510 loss3:0.2524 | AUC:0.5358 Anomaly AUC:0.5070
[2023-09-09 18:00:25,232][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0086 loss2:0.4066 loss3:0.2318 | AUC:0.6282 Anomaly AUC:0.5104
[2023-09-09 18:00:49,968][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 18:00:52,690][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 18:00:52,690][main.py][line:168][INFO] Training Mode
[2023-09-09 18:00:52,691][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 18:00:52,691][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 18:01:00,510][main.py][line:82][INFO] Random initialize AUCAUC:0.5659 Anomaly AUC:0.47441
[2023-09-09 18:01:18,153][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5636 loss2:1.4155 loss3:0.3833 | AUC:0.8092 Anomaly AUC:0.5874
[2023-09-09 18:01:35,823][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0300 loss2:1.4223 loss3:0.3239 | AUC:0.7910 Anomaly AUC:0.6307
[2023-09-09 18:01:53,537][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0159 loss2:1.4176 loss3:0.2628 | AUC:0.7163 Anomaly AUC:0.5681
[2023-09-09 18:02:11,490][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0143 loss2:1.4106 loss3:0.2183 | AUC:0.7854 Anomaly AUC:0.6488
[2023-09-09 18:02:29,451][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0138 loss2:1.4118 loss3:0.1744 | AUC:0.7984 Anomaly AUC:0.6385
[2023-09-09 18:02:47,528][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0141 loss2:1.4125 loss3:0.1311 | AUC:0.7865 Anomaly AUC:0.6187
[2023-09-09 18:03:05,749][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0126 loss2:1.4138 loss3:0.1031 | AUC:0.7406 Anomaly AUC:0.5375
[2023-09-09 18:03:23,888][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0216 loss2:1.4108 loss3:0.1223 | AUC:0.7752 Anomaly AUC:0.6634
[2023-09-09 18:03:42,172][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0088 loss2:1.4042 loss3:0.0809 | AUC:0.7687 Anomaly AUC:0.5887
[2023-09-09 18:04:00,532][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0058 loss2:1.4067 loss3:0.0505 | AUC:0.7352 Anomaly AUC:0.5315
[2023-09-09 18:04:18,706][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0062 loss2:1.4062 loss3:0.0404 | AUC:0.7699 Anomaly AUC:0.5732
[2023-09-09 18:04:36,992][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0046 loss2:1.4027 loss3:0.0418 | AUC:0.7902 Anomaly AUC:0.6262
[2023-09-09 18:04:55,168][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0061 loss2:1.4097 loss3:0.0456 | AUC:0.5439 Anomaly AUC:0.4594
[2023-09-09 18:05:13,445][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0055 loss2:1.4111 loss3:0.0548 | AUC:0.7507 Anomaly AUC:0.5663
[2023-09-09 18:05:31,659][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0045 loss2:1.4017 loss3:0.0500 | AUC:0.7705 Anomaly AUC:0.5984
[2023-09-09 18:05:49,960][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0070 loss2:1.4049 loss3:0.0489 | AUC:0.4080 Anomaly AUC:0.3828
[2023-09-09 18:06:08,288][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0029 loss2:1.4068 loss3:0.0441 | AUC:0.7729 Anomaly AUC:0.5815
[2023-09-09 18:06:26,698][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0021 loss2:1.4029 loss3:0.0332 | AUC:0.7609 Anomaly AUC:0.5669
[2023-09-09 18:06:44,979][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0013 loss2:1.4046 loss3:0.0223 | AUC:0.7938 Anomaly AUC:0.6053
[2023-09-09 18:07:03,143][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0011 loss2:1.4051 loss3:0.0197 | AUC:0.7938 Anomaly AUC:0.5717
[2023-09-09 18:07:21,326][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.1692 loss2:1.4029 loss3:0.0879 | AUC:0.6646 Anomaly AUC:0.6060
[2023-09-09 18:07:39,570][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.1666 loss2:1.4043 loss3:0.6775 | AUC:0.3393 Anomaly AUC:0.3466
[2023-09-09 18:07:57,740][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0080 loss2:1.3976 loss3:0.2538 | AUC:0.6150 Anomaly AUC:0.5557
[2023-09-09 18:08:15,947][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0102 loss2:1.4008 loss3:0.1148 | AUC:0.6733 Anomaly AUC:0.5553
[2023-09-09 18:08:34,225][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0067 loss2:1.4085 loss3:0.0591 | AUC:0.7416 Anomaly AUC:0.5927
[2023-09-09 18:08:52,449][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0049 loss2:1.4068 loss3:0.0429 | AUC:0.7339 Anomaly AUC:0.5840
[2023-09-09 18:09:10,768][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0039 loss2:1.4061 loss3:0.0395 | AUC:0.7482 Anomaly AUC:0.5878
[2023-09-09 18:09:28,947][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0029 loss2:1.4066 loss3:0.0318 | AUC:0.7776 Anomaly AUC:0.6166
[2023-09-09 18:09:47,250][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0028 loss2:1.4069 loss3:0.0285 | AUC:0.8015 Anomaly AUC:0.6283
[2023-09-09 18:10:05,588][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0032 loss2:1.4042 loss3:0.0333 | AUC:0.7486 Anomaly AUC:0.5734
[2023-09-09 18:10:23,796][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0028 loss2:1.4049 loss3:0.0272 | AUC:0.7638 Anomaly AUC:0.5733
[2023-09-09 18:10:42,098][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0017 loss2:1.4045 loss3:0.0205 | AUC:0.6781 Anomaly AUC:0.4903
[2023-09-09 18:11:00,465][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0013 loss2:1.4035 loss3:0.0207 | AUC:0.7936 Anomaly AUC:0.5867
[2023-09-09 18:11:18,870][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0019 loss2:1.4022 loss3:0.0261 | AUC:0.7750 Anomaly AUC:0.5684
[2023-09-09 18:11:37,147][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0043 loss2:1.4051 loss3:0.0230 | AUC:0.7631 Anomaly AUC:0.5550
[2023-09-09 18:11:55,377][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0014 loss2:1.4040 loss3:0.0184 | AUC:0.8090 Anomaly AUC:0.5932
[2023-09-09 18:12:13,668][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.1510 loss2:1.3977 loss3:0.2529 | AUC:0.6820 Anomaly AUC:0.5447
[2023-09-09 18:12:32,085][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0087 loss2:1.4033 loss3:0.0745 | AUC:0.7220 Anomaly AUC:0.5614
[2023-09-09 18:12:50,471][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0041 loss2:1.4041 loss3:0.0333 | AUC:0.7856 Anomaly AUC:0.6000
[2023-09-09 18:13:08,758][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0032 loss2:1.4064 loss3:0.0300 | AUC:0.6860 Anomaly AUC:0.5142
[2023-09-09 18:13:27,235][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0034 loss2:1.4031 loss3:0.0384 | AUC:0.7502 Anomaly AUC:0.5679
[2023-09-09 18:13:45,574][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0016 loss2:1.4036 loss3:0.0202 | AUC:0.7928 Anomaly AUC:0.5857
[2023-09-09 18:14:03,984][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0011 loss2:1.4044 loss3:0.0173 | AUC:0.7948 Anomaly AUC:0.5739
[2023-09-09 18:14:22,490][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0011 loss2:1.4026 loss3:0.0177 | AUC:0.7994 Anomaly AUC:0.5821
[2023-09-09 18:14:40,854][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0013 loss2:1.4040 loss3:0.0190 | AUC:0.8187 Anomaly AUC:0.6133
[2023-09-09 18:14:59,226][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0028 loss2:1.4031 loss3:0.0312 | AUC:0.7655 Anomaly AUC:0.5528
[2023-09-09 18:15:17,619][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0010 loss2:1.4022 loss3:0.0167 | AUC:0.7828 Anomaly AUC:0.5512
[2023-09-09 18:15:36,015][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0008 loss2:1.4008 loss3:0.0154 | AUC:0.7945 Anomaly AUC:0.5671
[2023-09-09 18:15:54,406][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0008 loss2:1.4018 loss3:0.0137 | AUC:0.7853 Anomaly AUC:0.5547
[2023-09-09 18:16:12,729][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0029 loss2:1.4006 loss3:0.0109 | AUC:0.7660 Anomaly AUC:0.5138
[2023-09-09 18:16:31,046][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0152 loss2:1.3975 loss3:0.0558 | AUC:0.7255 Anomaly AUC:0.5641
[2023-09-09 18:16:49,428][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0032 loss2:1.3973 loss3:0.0329 | AUC:0.7639 Anomaly AUC:0.5828
[2023-09-09 18:17:07,829][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0013 loss2:1.3991 loss3:0.0190 | AUC:0.7838 Anomaly AUC:0.5757
[2023-09-09 18:17:26,229][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0089 loss2:1.3968 loss3:0.0582 | AUC:0.7908 Anomaly AUC:0.6166
[2023-09-09 18:17:44,583][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0020 loss2:1.3991 loss3:0.0208 | AUC:0.8082 Anomaly AUC:0.6153
[2023-09-09 18:18:03,073][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0015 loss2:1.4003 loss3:0.0168 | AUC:0.7865 Anomaly AUC:0.5711
[2023-09-09 18:18:21,428][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0006 loss2:1.3981 loss3:0.0123 | AUC:0.7992 Anomaly AUC:0.5878
[2023-09-09 18:18:39,789][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0010 loss2:1.3965 loss3:0.0149 | AUC:0.7582 Anomaly AUC:0.5462
[2023-09-09 18:18:58,152][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0030 loss2:1.3983 loss3:0.0118 | AUC:0.7953 Anomaly AUC:0.5694
[2023-09-09 18:19:16,554][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0006 loss2:1.3949 loss3:0.0117 | AUC:0.7988 Anomaly AUC:0.5785
[2023-09-09 18:19:34,933][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0003 loss2:1.3942 loss3:0.0087 | AUC:0.8126 Anomaly AUC:0.5893
[2023-09-09 18:19:53,366][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0030 loss2:1.3940 loss3:0.0150 | AUC:0.7930 Anomaly AUC:0.5722
[2023-09-09 18:20:11,783][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0003 loss2:1.3954 loss3:0.0085 | AUC:0.8008 Anomaly AUC:0.5801
[2023-09-09 18:20:30,206][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0002 loss2:1.3943 loss3:0.0075 | AUC:0.8045 Anomaly AUC:0.5731
[2023-09-09 18:20:48,648][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.5268 loss2:1.3971 loss3:0.2943 | AUC:0.2727 Anomaly AUC:0.3382
[2023-09-09 18:21:07,057][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0086 loss2:1.3911 loss3:0.1531 | AUC:0.7260 Anomaly AUC:0.5351
[2023-09-09 18:21:25,619][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0057 loss2:1.3847 loss3:0.0454 | AUC:0.7697 Anomaly AUC:0.5762
[2023-09-09 18:21:44,001][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0038 loss2:1.3834 loss3:0.0249 | AUC:0.7922 Anomaly AUC:0.5884
[2023-09-09 18:22:02,580][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0022 loss2:1.3827 loss3:0.0159 | AUC:0.7999 Anomaly AUC:0.5930
[2023-09-09 18:22:21,025][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0022 loss2:1.3842 loss3:0.0146 | AUC:0.7896 Anomaly AUC:0.5687
[2023-09-09 18:22:39,476][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0012 loss2:1.3826 loss3:0.0112 | AUC:0.7930 Anomaly AUC:0.5712
[2023-09-09 18:22:57,883][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0012 loss2:1.3841 loss3:0.0104 | AUC:0.7900 Anomaly AUC:0.5698
[2023-09-09 18:23:16,291][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0006 loss2:1.3859 loss3:0.0086 | AUC:0.7937 Anomaly AUC:0.5660
[2023-09-09 18:23:34,576][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0008 loss2:1.3855 loss3:0.0086 | AUC:0.8097 Anomaly AUC:0.5913
[2023-09-09 18:23:53,070][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0033 loss2:1.3852 loss3:0.0089 | AUC:0.8009 Anomaly AUC:0.5826
[2023-09-09 18:24:11,502][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0005 loss2:1.3853 loss3:0.0079 | AUC:0.7552 Anomaly AUC:0.5134
[2023-09-09 18:24:29,869][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0065 loss2:1.3865 loss3:0.0281 | AUC:0.7753 Anomaly AUC:0.5662
[2023-09-09 18:24:48,328][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0006 loss2:1.3862 loss3:0.0086 | AUC:0.7837 Anomaly AUC:0.5681
[2023-09-09 18:25:06,812][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0004 loss2:1.3854 loss3:0.0073 | AUC:0.7941 Anomaly AUC:0.5784
[2023-09-09 18:25:25,219][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0004 loss2:1.3822 loss3:0.0072 | AUC:0.7845 Anomaly AUC:0.5583
[2023-09-09 18:25:43,796][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0003 loss2:1.3861 loss3:0.0067 | AUC:0.8120 Anomaly AUC:0.5988
[2023-09-09 18:26:02,132][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0682 loss2:1.3885 loss3:0.1084 | AUC:0.7489 Anomaly AUC:0.5408
[2023-09-09 18:26:20,596][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0071 loss2:1.3853 loss3:0.0286 | AUC:0.7743 Anomaly AUC:0.5328
[2023-09-09 18:26:39,133][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0080 loss2:1.3858 loss3:0.0174 | AUC:0.8028 Anomaly AUC:0.5708
[2023-09-09 18:26:57,602][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0072 loss2:1.3852 loss3:0.0298 | AUC:0.7660 Anomaly AUC:0.5307
[2023-09-09 18:27:16,000][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0027 loss2:1.3830 loss3:0.0163 | AUC:0.7670 Anomaly AUC:0.5209
[2023-09-09 18:27:34,458][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0065 loss2:1.3860 loss3:0.0294 | AUC:0.7787 Anomaly AUC:0.5759
[2023-09-09 18:27:52,841][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0057 loss2:1.3869 loss3:0.0185 | AUC:0.7806 Anomaly AUC:0.5656
[2023-09-09 18:28:11,215][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0009 loss2:1.3862 loss3:0.0115 | AUC:0.7692 Anomaly AUC:0.5359
[2023-09-09 18:28:29,637][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0006 loss2:1.3868 loss3:0.0090 | AUC:0.7712 Anomaly AUC:0.5205
[2023-09-09 18:28:48,076][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0006 loss2:1.3864 loss3:0.0082 | AUC:0.7965 Anomaly AUC:0.5514
[2023-09-09 18:29:06,517][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0003 loss2:1.3858 loss3:0.0068 | AUC:0.7906 Anomaly AUC:0.5359
[2023-09-09 18:29:24,883][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.2236 loss2:1.3847 loss3:0.0613 | AUC:0.7787 Anomaly AUC:0.5721
[2023-09-09 18:29:43,429][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0249 loss2:1.3973 loss3:0.1177 | AUC:0.8146 Anomaly AUC:0.6338
[2023-09-09 18:30:01,865][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0056 loss2:1.4015 loss3:0.0235 | AUC:0.8185 Anomaly AUC:0.6327
[2023-09-09 18:30:20,318][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0026 loss2:1.3981 loss3:0.0125 | AUC:0.8040 Anomaly AUC:0.5887
[2023-09-09 18:30:38,849][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0016 loss2:1.3978 loss3:0.0101 | AUC:0.8054 Anomaly AUC:0.5834
[2023-09-09 18:30:57,382][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0202 loss2:1.3973 loss3:0.0244 | AUC:0.6656 Anomaly AUC:0.4884
[2023-09-09 18:31:15,887][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0037 loss2:1.3946 loss3:0.0204 | AUC:0.7848 Anomaly AUC:0.5435
[2023-09-09 18:31:34,502][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0016 loss2:1.3941 loss3:0.0098 | AUC:0.7974 Anomaly AUC:0.5655
[2023-09-09 18:31:34,526][main.py][line:116][INFO] Training completes in 30m 34s | best AUCAUC:0.8187 Anomaly AUC:0.6133

[2023-09-09 19:06:47,298][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:06:50,023][main.py][line:165][INFO] total params:3.3590M
[2023-09-09 19:06:50,024][main.py][line:168][INFO] Training Mode
[2023-09-09 19:06:50,024][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:06:50,024][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:06:56,038][main.py][line:82][INFO] Random initialize AUCAUC:0.4894 Anomaly AUC:0.48145
[2023-09-09 19:07:09,447][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.2362 loss2:1.4148 loss3:0.3887 | AUC:0.6664 Anomaly AUC:0.4931
[2023-09-09 19:07:22,566][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0270 loss2:1.4138 loss3:0.3878 | AUC:0.7368 Anomaly AUC:0.5622
[2023-09-09 19:07:36,387][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0069 loss2:1.4085 loss3:0.3768 | AUC:0.7006 Anomaly AUC:0.4930
[2023-09-09 19:07:50,516][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0030 loss2:1.4070 loss3:0.3441 | AUC:0.6328 Anomaly AUC:0.5167
[2023-09-09 19:08:19,058][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:08:21,736][main.py][line:165][INFO] total params:3.3590M
[2023-09-09 19:08:21,736][main.py][line:168][INFO] Training Mode
[2023-09-09 19:08:21,737][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:08:21,737][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:08:27,349][main.py][line:82][INFO] Random initialize AUCAUC:0.4894 Anomaly AUC:0.48145
[2023-09-09 19:08:40,803][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.2223 loss2:1.4141 loss3:0.3887 | AUC:0.6363 Anomaly AUC:0.4988
[2023-09-09 19:08:54,546][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0277 loss2:1.4137 loss3:0.3877 | AUC:0.7188 Anomaly AUC:0.5499
[2023-09-09 19:09:08,729][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0070 loss2:1.4089 loss3:0.3796 | AUC:0.7345 Anomaly AUC:0.5319
[2023-09-09 19:09:22,790][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0032 loss2:1.4046 loss3:0.3455 | AUC:0.6078 Anomaly AUC:0.4859
[2023-09-09 19:09:37,054][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0016 loss2:1.4018 loss3:0.3191 | AUC:0.6505 Anomaly AUC:0.5111
[2023-09-09 19:09:57,658][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:10:00,347][main.py][line:165][INFO] total params:3.3590M
[2023-09-09 19:10:00,348][main.py][line:168][INFO] Training Mode
[2023-09-09 19:10:00,348][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:10:00,348][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:10:44,899][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:10:47,571][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 19:10:47,572][main.py][line:168][INFO] Training Mode
[2023-09-09 19:10:47,572][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:10:47,572][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:10:55,033][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:10:57,745][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 19:10:57,745][main.py][line:168][INFO] Training Mode
[2023-09-09 19:10:57,746][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:10:57,746][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:11:05,775][main.py][line:82][INFO] Random initialize AUCAUC:0.5550 Anomaly AUC:0.47816
[2023-09-09 19:11:24,160][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.6254 loss2:1.2612 loss3:0.3785 | AUC:0.8202 Anomaly AUC:0.6048
[2023-09-09 19:11:42,471][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1217 loss2:0.9086 loss3:0.3064 | AUC:0.8222 Anomaly AUC:0.6888
[2023-09-09 19:12:01,166][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0593 loss2:0.7960 loss3:0.2591 | AUC:0.8290 Anomaly AUC:0.6929
[2023-09-09 19:12:20,146][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0837 loss2:0.7161 loss3:0.2222 | AUC:0.8309 Anomaly AUC:0.6803
[2023-09-09 19:12:38,958][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.1038 loss2:0.6499 loss3:0.1762 | AUC:0.8218 Anomaly AUC:0.6773
[2023-09-09 19:12:57,896][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0878 loss2:0.6207 loss3:0.1520 | AUC:0.8121 Anomaly AUC:0.6741
[2023-09-09 19:13:16,865][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0874 loss2:0.5646 loss3:0.1242 | AUC:0.8423 Anomaly AUC:0.6728
[2023-09-09 19:13:35,852][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0651 loss2:0.5131 loss3:0.0979 | AUC:0.8366 Anomaly AUC:0.6416
[2023-09-09 19:13:54,898][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0663 loss2:0.4829 loss3:0.0808 | AUC:0.8400 Anomaly AUC:0.6499
[2023-09-09 19:14:13,958][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0252 loss2:0.4410 loss3:0.0612 | AUC:0.8400 Anomaly AUC:0.6397
[2023-09-09 19:14:33,041][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0437 loss2:0.4675 loss3:0.0677 | AUC:0.8303 Anomaly AUC:0.6218
[2023-09-09 19:14:52,157][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0217 loss2:0.3875 loss3:0.0459 | AUC:0.8325 Anomaly AUC:0.6171
[2023-09-09 19:15:11,271][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0181 loss2:0.3489 loss3:0.0338 | AUC:0.8334 Anomaly AUC:0.6246
[2023-09-09 19:15:30,305][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0140 loss2:0.3227 loss3:0.0260 | AUC:0.8409 Anomaly AUC:0.6207
[2023-09-09 19:15:49,350][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.1354 loss2:0.4898 loss3:0.0757 | AUC:0.8322 Anomaly AUC:0.6304
[2023-09-09 19:16:12,602][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:16:15,414][main.py][line:165][INFO] total params:24.3531M
[2023-09-09 19:16:15,414][main.py][line:168][INFO] Training Mode
[2023-09-09 19:16:15,414][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:16:15,415][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:16:26,164][main.py][line:82][INFO] Random initialize AUCAUC:0.5656 Anomaly AUC:0.51347
[2023-09-09 19:16:55,979][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.8263 loss2:1.1810 loss3:0.3579 | AUC:0.7990 Anomaly AUC:0.5803
[2023-09-09 19:17:25,618][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.4179 loss2:0.9452 loss3:0.2628 | AUC:0.8393 Anomaly AUC:0.6556
[2023-09-09 19:17:55,312][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.2095 loss2:0.8299 loss3:0.1676 | AUC:0.8120 Anomaly AUC:0.6476
[2023-09-09 19:18:25,239][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0838 loss2:0.7476 loss3:0.1122 | AUC:0.8432 Anomaly AUC:0.6654
[2023-09-09 19:18:55,118][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0615 loss2:0.6893 loss3:0.0740 | AUC:0.8219 Anomaly AUC:0.6388
[2023-09-09 19:19:25,025][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0337 loss2:0.6208 loss3:0.0440 | AUC:0.8380 Anomaly AUC:0.6199
[2023-09-09 19:19:55,189][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0230 loss2:0.5543 loss3:0.0319 | AUC:0.8245 Anomaly AUC:0.5993
[2023-09-09 19:20:25,151][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0556 loss2:0.5488 loss3:0.0538 | AUC:0.7836 Anomaly AUC:0.5991
[2023-09-09 19:20:55,173][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0176 loss2:0.4780 loss3:0.0276 | AUC:0.7711 Anomaly AUC:0.6015
[2023-09-09 19:21:25,252][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0276 loss2:0.4453 loss3:0.0291 | AUC:0.8031 Anomaly AUC:0.6279
[2023-09-09 19:21:55,267][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0121 loss2:0.3761 loss3:0.0202 | AUC:0.8151 Anomaly AUC:0.5916
[2023-09-09 19:22:25,395][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0075 loss2:0.3189 loss3:0.0160 | AUC:0.7656 Anomaly AUC:0.5792
[2023-09-09 19:22:55,618][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0126 loss2:0.3070 loss3:0.0191 | AUC:0.7636 Anomaly AUC:0.5678
[2023-09-09 19:23:25,793][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0107 loss2:0.3136 loss3:0.0222 | AUC:0.8335 Anomaly AUC:0.6197
[2023-09-09 19:23:56,077][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0048 loss2:0.2398 loss3:0.0152 | AUC:0.8190 Anomaly AUC:0.5964
[2023-09-09 19:24:26,249][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0025 loss2:0.2050 loss3:0.0119 | AUC:0.8148 Anomaly AUC:0.5998
[2023-09-09 19:24:56,531][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0060 loss2:0.2301 loss3:0.0150 | AUC:0.8000 Anomaly AUC:0.6098
[2023-09-09 19:25:26,647][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0043 loss2:0.2176 loss3:0.0141 | AUC:0.8291 Anomaly AUC:0.6259
[2023-09-09 19:25:56,881][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0053 loss2:0.2015 loss3:0.0146 | AUC:0.8132 Anomaly AUC:0.6025
[2023-09-09 19:26:27,062][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0206 loss2:0.2648 loss3:0.0329 | AUC:0.7825 Anomaly AUC:0.6048
[2023-09-09 19:26:57,167][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0065 loss2:0.2106 loss3:0.0213 | AUC:0.8204 Anomaly AUC:0.6249
[2023-09-09 19:27:27,431][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0020 loss2:0.1669 loss3:0.0101 | AUC:0.8238 Anomaly AUC:0.6078
[2023-09-09 19:27:45,171][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:27:47,915][main.py][line:165][INFO] total params:24.3531M
[2023-09-09 19:27:47,915][main.py][line:168][INFO] Training Mode
[2023-09-09 19:27:47,916][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(2048, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:27:47,916][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:27:58,689][main.py][line:82][INFO] Random initialize AUCAUC:0.5656 Anomaly AUC:0.51347
[2023-09-09 19:28:28,466][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.8263 loss2:1.1810 loss3:0.3579 | AUC:0.7990 Anomaly AUC:0.5803
[2023-09-09 19:29:04,828][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:29:07,591][main.py][line:165][INFO] total params:18.0606M
[2023-09-09 19:29:07,592][main.py][line:168][INFO] Training Mode
[2023-09-09 19:29:07,592][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (selfatt2): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:29:07,592][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:29:17,711][main.py][line:82][INFO] Random initialize AUCAUC:0.5611 Anomaly AUC:0.53974
[2023-09-09 19:29:44,985][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.6362 loss2:1.1019 loss3:0.3529 | AUC:0.8030 Anomaly AUC:0.5671
[2023-09-09 19:30:11,878][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2589 loss2:0.8754 loss3:0.2524 | AUC:0.8006 Anomaly AUC:0.5809
[2023-09-09 19:30:39,051][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1046 loss2:0.7810 loss3:0.1302 | AUC:0.8030 Anomaly AUC:0.5955
[2023-09-09 19:31:06,337][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0808 loss2:0.7274 loss3:0.0488 | AUC:0.8229 Anomaly AUC:0.6316
[2023-09-09 19:31:33,576][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0382 loss2:0.6381 loss3:0.0220 | AUC:0.8191 Anomaly AUC:0.6097
[2023-09-09 19:32:00,968][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0311 loss2:0.5413 loss3:0.0160 | AUC:0.8106 Anomaly AUC:0.6173
[2023-09-09 19:32:28,505][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0427 loss2:0.4872 loss3:0.0151 | AUC:0.8236 Anomaly AUC:0.6163
[2023-09-09 19:32:55,858][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0486 loss2:0.4593 loss3:0.0145 | AUC:0.8113 Anomaly AUC:0.6129
[2023-09-09 19:33:23,368][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0341 loss2:0.3752 loss3:0.0114 | AUC:0.8016 Anomaly AUC:0.6107
[2023-09-09 19:33:50,774][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0191 loss2:0.3343 loss3:0.0092 | AUC:0.8075 Anomaly AUC:0.5811
[2023-09-09 19:34:18,363][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0206 loss2:0.3009 loss3:0.0083 | AUC:0.8077 Anomaly AUC:0.6185
[2023-09-09 19:34:45,821][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0350 loss2:0.2920 loss3:0.0094 | AUC:0.8208 Anomaly AUC:0.6118
[2023-09-09 19:35:13,479][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0157 loss2:0.2526 loss3:0.0066 | AUC:0.8106 Anomaly AUC:0.5862
[2023-09-09 19:35:41,058][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0159 loss2:0.2434 loss3:0.0058 | AUC:0.8290 Anomaly AUC:0.6201
[2023-09-09 19:35:58,793][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:36:01,471][main.py][line:165][INFO] total params:1.2091M
[2023-09-09 19:36:01,471][main.py][line:168][INFO] Training Mode
[2023-09-09 19:36:19,534][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 19:36:22,218][main.py][line:165][INFO] total params:1.2091M
[2023-09-09 19:36:22,218][main.py][line:168][INFO] Training Mode
[2023-09-09 19:36:22,219][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 19:36:22,219][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 19:36:27,323][main.py][line:82][INFO] Random initialize AUCAUC:0.4774 Anomaly AUC:0.48817
[2023-09-09 20:13:36,733][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 20:13:39,443][main.py][line:165][INFO] total params:1.2091M
[2023-09-09 20:13:39,443][main.py][line:168][INFO] Training Mode
[2023-09-09 20:13:39,443][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 20:13:39,443][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)

[2023-09-09 20:13:44,239][main.py][line:82][INFO] Random initialize AUCAUC:0.4774 Anomaly AUC:0.48817
[2023-09-09 20:13:56,368][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:1.0138 loss2:1.3435 loss3:0.0000 | AUC:0.7820 Anomaly AUC:0.6033
[2023-09-09 20:14:08,059][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.7158 loss2:1.1834 loss3:0.0000 | AUC:0.7995 Anomaly AUC:0.6157
[2023-09-09 20:14:20,524][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.5770 loss2:1.0859 loss3:0.0000 | AUC:0.8042 Anomaly AUC:0.6094
[2023-09-09 20:14:33,457][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.4558 loss2:1.0285 loss3:0.0000 | AUC:0.8190 Anomaly AUC:0.6296
[2023-09-09 20:14:46,141][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.3511 loss2:0.9910 loss3:0.0000 | AUC:0.8119 Anomaly AUC:0.6267
[2023-09-09 20:14:59,051][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.2697 loss2:0.9587 loss3:0.0000 | AUC:0.8269 Anomaly AUC:0.6292
[2023-09-09 20:15:11,835][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.2067 loss2:0.9341 loss3:0.0000 | AUC:0.8249 Anomaly AUC:0.6325
[2023-09-09 20:15:24,661][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.1684 loss2:0.9147 loss3:0.0000 | AUC:0.8241 Anomaly AUC:0.6369
[2023-09-09 20:15:37,637][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.1335 loss2:0.8918 loss3:0.0000 | AUC:0.8248 Anomaly AUC:0.6451
[2023-09-09 20:15:50,705][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.1148 loss2:0.8703 loss3:0.0000 | AUC:0.8278 Anomaly AUC:0.6426
[2023-09-09 20:16:03,636][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0987 loss2:0.8489 loss3:0.0000 | AUC:0.8197 Anomaly AUC:0.6469
[2023-09-09 20:16:16,594][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0867 loss2:0.8316 loss3:0.0000 | AUC:0.8172 Anomaly AUC:0.6444
[2023-09-09 20:16:29,560][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0782 loss2:0.8112 loss3:0.0000 | AUC:0.8216 Anomaly AUC:0.6453
[2023-09-09 20:16:42,664][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0761 loss2:0.7936 loss3:0.0000 | AUC:0.8217 Anomaly AUC:0.6389
[2023-09-09 20:16:55,794][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0742 loss2:0.7769 loss3:0.0000 | AUC:0.8058 Anomaly AUC:0.6377
[2023-09-09 20:17:08,715][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0672 loss2:0.7545 loss3:0.0000 | AUC:0.8226 Anomaly AUC:0.6477
[2023-09-09 20:17:21,422][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0652 loss2:0.7385 loss3:0.0000 | AUC:0.8133 Anomaly AUC:0.6444
[2023-09-09 20:17:34,310][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0659 loss2:0.7209 loss3:0.0000 | AUC:0.7975 Anomaly AUC:0.6348
[2023-09-09 20:17:47,083][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0623 loss2:0.7050 loss3:0.0000 | AUC:0.8119 Anomaly AUC:0.6437
[2023-09-09 20:18:00,029][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0579 loss2:0.6880 loss3:0.0000 | AUC:0.8125 Anomaly AUC:0.6444
[2023-09-09 20:18:13,133][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0624 loss2:0.6723 loss3:0.0000 | AUC:0.8103 Anomaly AUC:0.6446
[2023-09-09 20:18:25,941][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0653 loss2:0.6621 loss3:0.0000 | AUC:0.8053 Anomaly AUC:0.6527
[2023-09-09 20:18:38,952][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0642 loss2:0.6435 loss3:0.0000 | AUC:0.8019 Anomaly AUC:0.6427
[2023-09-09 20:18:52,000][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0659 loss2:0.6299 loss3:0.0000 | AUC:0.8015 Anomaly AUC:0.6454
[2023-09-09 20:19:04,835][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0677 loss2:0.6183 loss3:0.0000 | AUC:0.8052 Anomaly AUC:0.6520
[2023-09-09 20:19:17,888][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0711 loss2:0.6105 loss3:0.0000 | AUC:0.8088 Anomaly AUC:0.6470
[2023-09-09 20:19:30,948][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0621 loss2:0.5943 loss3:0.0000 | AUC:0.7942 Anomaly AUC:0.6286
[2023-09-09 20:19:44,009][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0625 loss2:0.5820 loss3:0.0000 | AUC:0.7962 Anomaly AUC:0.6370
[2023-09-09 20:19:56,956][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0717 loss2:0.5717 loss3:0.0000 | AUC:0.7943 Anomaly AUC:0.6297
[2023-09-09 20:20:10,063][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0539 loss2:0.5528 loss3:0.0000 | AUC:0.7940 Anomaly AUC:0.6301
[2023-09-09 20:20:22,986][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0599 loss2:0.5415 loss3:0.0000 | AUC:0.8017 Anomaly AUC:0.6362
[2023-09-09 20:20:36,175][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0525 loss2:0.5242 loss3:0.0000 | AUC:0.7883 Anomaly AUC:0.6289
[2023-09-09 20:20:49,199][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0688 loss2:0.5212 loss3:0.0000 | AUC:0.7955 Anomaly AUC:0.6446
[2023-09-09 20:21:02,137][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0585 loss2:0.5078 loss3:0.0000 | AUC:0.8032 Anomaly AUC:0.6392
[2023-09-09 20:21:15,143][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0649 loss2:0.4982 loss3:0.0000 | AUC:0.7851 Anomaly AUC:0.6268
[2023-09-09 20:21:28,155][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0583 loss2:0.4872 loss3:0.0000 | AUC:0.7975 Anomaly AUC:0.6327
[2023-09-09 20:21:41,239][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0513 loss2:0.4703 loss3:0.0000 | AUC:0.7985 Anomaly AUC:0.6362
[2023-09-09 20:21:54,317][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0530 loss2:0.4591 loss3:0.0000 | AUC:0.7930 Anomaly AUC:0.6276
[2023-09-09 20:22:07,217][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0452 loss2:0.4452 loss3:0.0000 | AUC:0.7934 Anomaly AUC:0.6300
[2023-09-09 20:22:26,082][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 20:22:28,716][main.py][line:165][INFO] total params:1.2091M
[2023-09-09 20:22:28,716][main.py][line:168][INFO] Training Mode
[2023-09-09 20:22:28,716][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 20:22:28,716][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-09-09 20:22:33,694][main.py][line:82][INFO] Random initialize AUCAUC:0.4774 Anomaly AUC:0.48817
[2023-09-09 20:22:45,908][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.8101 loss2:1.1707 loss3:0.0000 | AUC:0.8154 Anomaly AUC:0.6377
[2023-09-09 20:22:58,351][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.4469 loss2:0.9560 loss3:0.0000 | AUC:0.8197 Anomaly AUC:0.6300
[2023-09-09 20:23:11,170][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2443 loss2:0.8711 loss3:0.0000 | AUC:0.8047 Anomaly AUC:0.6087
[2023-09-09 20:23:23,876][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1435 loss2:0.8075 loss3:0.0000 | AUC:0.8168 Anomaly AUC:0.6286
[2023-09-09 20:23:36,774][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.1066 loss2:0.7491 loss3:0.0000 | AUC:0.8170 Anomaly AUC:0.6315
[2023-09-09 20:23:49,605][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0877 loss2:0.6865 loss3:0.0000 | AUC:0.8089 Anomaly AUC:0.6311
[2023-09-09 20:24:02,420][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0818 loss2:0.6348 loss3:0.0000 | AUC:0.8075 Anomaly AUC:0.6309
[2023-09-09 20:24:15,450][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0841 loss2:0.5810 loss3:0.0000 | AUC:0.8080 Anomaly AUC:0.6252
[2023-09-09 20:24:28,247][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0744 loss2:0.5278 loss3:0.0000 | AUC:0.8207 Anomaly AUC:0.6283
[2023-09-09 20:24:41,204][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0718 loss2:0.4778 loss3:0.0000 | AUC:0.8148 Anomaly AUC:0.6261
[2023-09-09 20:24:54,318][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0706 loss2:0.4308 loss3:0.0000 | AUC:0.7966 Anomaly AUC:0.6133
[2023-09-09 20:25:07,313][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0593 loss2:0.3875 loss3:0.0000 | AUC:0.8095 Anomaly AUC:0.6222
[2023-09-09 20:25:20,371][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0607 loss2:0.3445 loss3:0.0000 | AUC:0.8081 Anomaly AUC:0.6124
[2023-09-09 20:25:33,399][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0609 loss2:0.3095 loss3:0.0000 | AUC:0.8181 Anomaly AUC:0.6287
[2023-09-09 20:25:46,349][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0416 loss2:0.2599 loss3:0.0000 | AUC:0.8213 Anomaly AUC:0.6167
[2023-09-09 20:25:59,566][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0440 loss2:0.2285 loss3:0.0000 | AUC:0.8209 Anomaly AUC:0.6252
[2023-09-09 20:26:12,540][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0724 loss2:0.2164 loss3:0.0000 | AUC:0.8080 Anomaly AUC:0.6141
[2023-09-09 20:26:25,419][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0649 loss2:0.1995 loss3:0.0000 | AUC:0.8301 Anomaly AUC:0.6366
[2023-09-09 20:26:38,230][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0397 loss2:0.1633 loss3:0.0000 | AUC:0.8380 Anomaly AUC:0.6483
[2023-09-09 20:26:51,256][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0316 loss2:0.1308 loss3:0.0000 | AUC:0.8355 Anomaly AUC:0.6481
[2023-09-09 20:27:04,335][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0218 loss2:0.1053 loss3:0.0000 | AUC:0.8304 Anomaly AUC:0.6418
[2023-09-09 20:27:17,384][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0226 loss2:0.0891 loss3:0.0000 | AUC:0.8277 Anomaly AUC:0.6417
[2023-09-09 20:27:30,437][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0209 loss2:0.0781 loss3:0.0000 | AUC:0.8148 Anomaly AUC:0.6278
[2023-09-09 20:27:43,462][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0448 loss2:0.0964 loss3:0.0000 | AUC:0.8173 Anomaly AUC:0.6307
[2023-09-09 20:27:56,451][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0638 loss2:0.1019 loss3:0.0000 | AUC:0.7991 Anomaly AUC:0.6228
[2023-09-09 20:28:09,530][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0317 loss2:0.0723 loss3:0.0000 | AUC:0.8106 Anomaly AUC:0.6391
[2023-09-09 20:28:22,364][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0371 loss2:0.0719 loss3:0.0000 | AUC:0.8103 Anomaly AUC:0.6222
[2023-09-09 20:28:35,451][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0378 loss2:0.0637 loss3:0.0000 | AUC:0.7916 Anomaly AUC:0.6165
[2023-09-09 20:28:48,190][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0235 loss2:0.0490 loss3:0.0000 | AUC:0.8109 Anomaly AUC:0.6370
[2023-09-09 20:29:01,287][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0168 loss2:0.0426 loss3:0.0000 | AUC:0.7975 Anomaly AUC:0.6145
[2023-09-09 20:29:14,362][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0138 loss2:0.0340 loss3:0.0000 | AUC:0.8226 Anomaly AUC:0.6290
[2023-09-09 20:29:27,553][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0111 loss2:0.0265 loss3:0.0000 | AUC:0.8252 Anomaly AUC:0.6341
[2023-09-09 20:29:40,505][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0118 loss2:0.0237 loss3:0.0000 | AUC:0.8164 Anomaly AUC:0.6349
[2023-09-09 20:29:53,578][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0098 loss2:0.0218 loss3:0.0000 | AUC:0.8099 Anomaly AUC:0.6296
[2023-09-09 20:30:06,521][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0135 loss2:0.0242 loss3:0.0000 | AUC:0.8172 Anomaly AUC:0.6553
[2023-09-09 20:30:19,578][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0690 loss2:0.0529 loss3:0.0000 | AUC:0.7953 Anomaly AUC:0.6171
[2023-09-09 20:30:32,643][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0443 loss2:0.0479 loss3:0.0000 | AUC:0.7989 Anomaly AUC:0.6287
[2023-09-09 20:30:45,610][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0347 loss2:0.0397 loss3:0.0000 | AUC:0.8118 Anomaly AUC:0.6270
[2023-09-09 20:30:58,513][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0171 loss2:0.0232 loss3:0.0000 | AUC:0.8071 Anomaly AUC:0.6170
[2023-09-09 20:31:11,491][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0109 loss2:0.0182 loss3:0.0000 | AUC:0.8079 Anomaly AUC:0.6297
[2023-09-09 20:31:30,932][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 50, 'n_nums': 50, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 20:31:33,559][main.py][line:165][INFO] total params:1.2091M
[2023-09-09 20:31:33,559][main.py][line:168][INFO] Training Mode
[2023-09-09 20:31:33,560][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 20:31:33,560][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-09-09 20:31:38,478][main.py][line:82][INFO] Random initialize AUCAUC:0.4774 Anomaly AUC:0.48817
[2023-09-09 20:31:50,639][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.3958 loss2:1.1167 loss3:0.0000 | AUC:0.8046 Anomaly AUC:0.6282
[2023-09-09 20:32:02,996][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1531 loss2:0.8956 loss3:0.0000 | AUC:0.8186 Anomaly AUC:0.6227
[2023-09-09 20:32:15,736][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0594 loss2:0.7891 loss3:0.0000 | AUC:0.8170 Anomaly AUC:0.6294
[2023-09-09 20:32:28,342][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0366 loss2:0.7101 loss3:0.0000 | AUC:0.8236 Anomaly AUC:0.6349
[2023-09-09 20:32:41,109][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0230 loss2:0.6397 loss3:0.0000 | AUC:0.8150 Anomaly AUC:0.6317
[2023-09-09 20:32:53,932][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0217 loss2:0.5772 loss3:0.0000 | AUC:0.8043 Anomaly AUC:0.6290
[2023-09-09 20:33:06,876][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0168 loss2:0.5196 loss3:0.0000 | AUC:0.8233 Anomaly AUC:0.6455
[2023-09-09 20:33:19,682][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0119 loss2:0.4608 loss3:0.0000 | AUC:0.8215 Anomaly AUC:0.6429
[2023-09-09 20:33:32,728][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0196 loss2:0.4133 loss3:0.0000 | AUC:0.8185 Anomaly AUC:0.6437
[2023-09-09 20:33:45,688][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0193 loss2:0.3793 loss3:0.0000 | AUC:0.8090 Anomaly AUC:0.6357
[2023-09-09 20:33:58,661][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0107 loss2:0.3205 loss3:0.0000 | AUC:0.8099 Anomaly AUC:0.6447
[2023-09-09 20:34:11,683][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0088 loss2:0.2749 loss3:0.0000 | AUC:0.8088 Anomaly AUC:0.6412
[2023-09-09 20:34:24,627][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0068 loss2:0.2333 loss3:0.0000 | AUC:0.8043 Anomaly AUC:0.6371
[2023-09-09 20:34:37,668][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0078 loss2:0.1965 loss3:0.0000 | AUC:0.8207 Anomaly AUC:0.6438
[2023-09-09 20:34:50,593][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0094 loss2:0.1731 loss3:0.0000 | AUC:0.7939 Anomaly AUC:0.6228
[2023-09-09 20:35:03,543][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0140 loss2:0.1643 loss3:0.0000 | AUC:0.8157 Anomaly AUC:0.6373
[2023-09-09 20:35:16,615][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0103 loss2:0.1348 loss3:0.0000 | AUC:0.7883 Anomaly AUC:0.6178
[2023-09-09 20:35:29,716][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0116 loss2:0.1191 loss3:0.0000 | AUC:0.7784 Anomaly AUC:0.6205
[2023-09-09 20:35:42,507][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0075 loss2:0.0980 loss3:0.0000 | AUC:0.8072 Anomaly AUC:0.6375
[2023-09-09 20:35:55,365][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0078 loss2:0.0830 loss3:0.0000 | AUC:0.7946 Anomaly AUC:0.6312
[2023-09-09 20:36:08,163][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0035 loss2:0.0619 loss3:0.0000 | AUC:0.8082 Anomaly AUC:0.6360
[2023-09-09 20:36:21,401][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0032 loss2:0.0540 loss3:0.0000 | AUC:0.7858 Anomaly AUC:0.6255
[2023-09-09 20:36:34,353][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0025 loss2:0.0445 loss3:0.0000 | AUC:0.7899 Anomaly AUC:0.6365
[2023-09-09 20:36:47,347][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0036 loss2:0.0392 loss3:0.0000 | AUC:0.8047 Anomaly AUC:0.6471
[2023-09-09 20:37:00,148][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0386 loss2:0.0804 loss3:0.0000 | AUC:0.7830 Anomaly AUC:0.6124
[2023-09-09 20:37:13,140][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0225 loss2:0.0767 loss3:0.0000 | AUC:0.8044 Anomaly AUC:0.6410
[2023-09-09 20:37:25,968][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0055 loss2:0.0442 loss3:0.0000 | AUC:0.8087 Anomaly AUC:0.6358
[2023-09-09 20:37:38,815][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0040 loss2:0.0316 loss3:0.0000 | AUC:0.8188 Anomaly AUC:0.6475
[2023-09-09 20:37:51,769][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0049 loss2:0.0292 loss3:0.0000 | AUC:0.8158 Anomaly AUC:0.6419
[2023-09-09 20:38:04,749][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0017 loss2:0.0203 loss3:0.0000 | AUC:0.7882 Anomaly AUC:0.6188
[2023-09-09 20:38:17,611][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0042 loss2:0.0199 loss3:0.0000 | AUC:0.7829 Anomaly AUC:0.6338
[2023-09-09 20:38:30,661][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0300 loss2:0.0636 loss3:0.0000 | AUC:0.8262 Anomaly AUC:0.6506
[2023-09-09 20:38:43,772][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0062 loss2:0.0274 loss3:0.0000 | AUC:0.8162 Anomaly AUC:0.6522
[2023-09-09 20:38:56,848][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0048 loss2:0.0209 loss3:0.0000 | AUC:0.8116 Anomaly AUC:0.6523
[2023-09-09 20:39:09,783][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0140 loss2:0.0351 loss3:0.0000 | AUC:0.7683 Anomaly AUC:0.6213
[2023-09-09 20:39:22,673][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0089 loss2:0.0265 loss3:0.0000 | AUC:0.8025 Anomaly AUC:0.6489
[2023-09-09 20:39:35,719][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0063 loss2:0.0194 loss3:0.0000 | AUC:0.8004 Anomaly AUC:0.6453
[2023-09-09 20:39:48,836][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0037 loss2:0.0143 loss3:0.0000 | AUC:0.7863 Anomaly AUC:0.6392
[2023-09-09 20:40:06,362][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 20:40:09,103][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 20:40:09,104][main.py][line:168][INFO] Training Mode
[2023-09-09 20:40:09,104][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 20:40:09,104][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0
)

[2023-09-09 20:40:17,172][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-09 20:40:35,595][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.6729 loss2:1.1165 loss3:0.2265 | AUC:0.8170 Anomaly AUC:0.6563
[2023-09-09 20:40:53,745][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2966 loss2:0.8396 loss3:0.0594 | AUC:0.8323 Anomaly AUC:0.6680
[2023-09-09 20:41:12,343][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1564 loss2:0.7163 loss3:0.0279 | AUC:0.8341 Anomaly AUC:0.6633
[2023-09-09 20:41:30,980][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0990 loss2:0.6345 loss3:0.0186 | AUC:0.8391 Anomaly AUC:0.6546
[2023-09-09 20:41:49,680][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0788 loss2:0.5593 loss3:0.0154 | AUC:0.8408 Anomaly AUC:0.6599
[2023-09-09 20:42:08,461][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0523 loss2:0.4667 loss3:0.0122 | AUC:0.8296 Anomaly AUC:0.6319
[2023-09-09 20:42:27,436][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0373 loss2:0.3677 loss3:0.0064 | AUC:0.8239 Anomaly AUC:0.6338
[2023-09-09 20:42:46,410][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0361 loss2:0.3047 loss3:0.0051 | AUC:0.8176 Anomaly AUC:0.6123
[2023-09-09 20:43:05,292][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0284 loss2:0.2210 loss3:0.0038 | AUC:0.8250 Anomaly AUC:0.6150
[2023-09-09 20:43:24,214][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0128 loss2:0.1470 loss3:0.0018 | AUC:0.8142 Anomaly AUC:0.6002
[2023-09-09 20:43:43,128][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0589 loss2:0.1820 loss3:0.0067 | AUC:0.8074 Anomaly AUC:0.5988
[2023-09-09 20:44:01,993][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0487 loss2:0.1483 loss3:0.0065 | AUC:0.8043 Anomaly AUC:0.6047
[2023-09-09 20:44:20,967][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0257 loss2:0.1031 loss3:0.0035 | AUC:0.8005 Anomaly AUC:0.6114
[2023-09-09 20:44:39,910][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0200 loss2:0.0713 loss3:0.0024 | AUC:0.8159 Anomaly AUC:0.6227
[2023-09-09 20:44:58,841][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0120 loss2:0.0495 loss3:0.0017 | AUC:0.8197 Anomaly AUC:0.6240
[2023-09-09 20:45:54,524][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 20:45:57,196][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 20:45:57,197][main.py][line:168][INFO] Training Mode
[2023-09-09 20:45:57,197][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 20:45:57,197][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-09 20:46:05,362][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-09 20:46:23,782][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5795 loss2:1.2456 loss3:0.3798 | AUC:0.7981 Anomaly AUC:0.6067
[2023-09-09 20:46:42,030][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1162 loss2:0.8933 loss3:0.3105 | AUC:0.8096 Anomaly AUC:0.6699
[2023-09-09 20:47:00,815][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0512 loss2:0.7853 loss3:0.2483 | AUC:0.8259 Anomaly AUC:0.6633
[2023-09-09 20:47:19,468][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0416 loss2:0.7155 loss3:0.2048 | AUC:0.8165 Anomaly AUC:0.6514
[2023-09-09 20:47:38,197][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0860 loss2:0.6344 loss3:0.1580 | AUC:0.8055 Anomaly AUC:0.6496
[2023-09-09 20:47:57,085][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0626 loss2:0.5704 loss3:0.1176 | AUC:0.8329 Anomaly AUC:0.6431
[2023-09-09 20:48:15,989][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0492 loss2:0.5211 loss3:0.0881 | AUC:0.8312 Anomaly AUC:0.6159
[2023-09-09 20:48:34,866][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.4527 loss2:0.9795 loss3:0.4200 | AUC:0.5593 Anomaly AUC:0.5275
[2023-09-09 20:48:53,823][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0493 loss2:0.7540 loss3:0.2358 | AUC:0.7199 Anomaly AUC:0.5568
[2023-09-09 20:49:12,681][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0282 loss2:0.6778 loss3:0.1555 | AUC:0.7661 Anomaly AUC:0.5604
[2023-09-09 20:49:33,670][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-09 20:49:36,385][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 20:49:36,386][main.py][line:168][INFO] Training Mode
[2023-09-09 20:49:36,386][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-09 20:49:36,386][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-09 20:49:44,456][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-09 20:50:02,810][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3546 loss2:1.1733 loss3:0.3478 | AUC:0.8167 Anomaly AUC:0.6703
[2023-09-09 20:50:20,929][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0509 loss2:0.8266 loss3:0.2588 | AUC:0.8157 Anomaly AUC:0.6681
[2023-09-09 20:50:39,457][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0257 loss2:0.7165 loss3:0.1992 | AUC:0.8242 Anomaly AUC:0.6697
[2023-09-09 20:50:58,019][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0223 loss2:0.6414 loss3:0.1459 | AUC:0.8304 Anomaly AUC:0.6715
[2023-09-09 20:51:16,740][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0166 loss2:0.5834 loss3:0.1094 | AUC:0.8316 Anomaly AUC:0.6695
[2023-09-09 20:51:35,671][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0099 loss2:0.5145 loss3:0.0781 | AUC:0.8364 Anomaly AUC:0.6712
[2023-09-09 20:51:54,569][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0095 loss2:0.4731 loss3:0.0684 | AUC:0.8345 Anomaly AUC:0.6673
[2023-09-09 20:52:13,512][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0063 loss2:0.4165 loss3:0.0439 | AUC:0.8426 Anomaly AUC:0.6685
[2023-09-09 20:52:32,581][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0128 loss2:0.4404 loss3:0.0637 | AUC:0.8207 Anomaly AUC:0.6622
[2023-09-09 20:52:51,401][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0050 loss2:0.3683 loss3:0.0370 | AUC:0.8381 Anomaly AUC:0.6744
[2023-09-09 20:53:10,288][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0041 loss2:0.3325 loss3:0.0277 | AUC:0.8393 Anomaly AUC:0.6704
[2023-09-09 20:53:29,169][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0032 loss2:0.3035 loss3:0.0206 | AUC:0.8416 Anomaly AUC:0.6677
[2023-09-09 20:53:48,076][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0333 loss2:0.4531 loss3:0.0525 | AUC:0.8357 Anomaly AUC:0.6760
[2023-09-09 20:54:07,136][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0039 loss2:0.3180 loss3:0.0260 | AUC:0.8457 Anomaly AUC:0.6794
[2023-09-09 20:54:26,060][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0027 loss2:0.2695 loss3:0.0177 | AUC:0.8414 Anomaly AUC:0.6779
[2023-09-09 20:54:44,974][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0029 loss2:0.2586 loss3:0.0170 | AUC:0.8415 Anomaly AUC:0.6689
[2023-09-09 20:55:03,879][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0015 loss2:0.2384 loss3:0.0136 | AUC:0.8459 Anomaly AUC:0.6768
[2023-09-09 20:55:22,808][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0410 loss2:0.3934 loss3:0.0572 | AUC:0.7677 Anomaly AUC:0.6199
[2023-09-09 20:55:41,817][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0109 loss2:0.5439 loss3:0.0576 | AUC:0.8340 Anomaly AUC:0.6705
[2023-09-09 20:56:00,751][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0039 loss2:0.2996 loss3:0.0249 | AUC:0.8439 Anomaly AUC:0.6750
[2023-09-09 20:56:19,577][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0026 loss2:0.2441 loss3:0.0189 | AUC:0.8452 Anomaly AUC:0.6749
[2023-09-09 20:56:38,524][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0017 loss2:0.2199 loss3:0.0145 | AUC:0.8427 Anomaly AUC:0.6704
[2023-09-09 20:56:57,420][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0017 loss2:0.2086 loss3:0.0132 | AUC:0.8467 Anomaly AUC:0.6794
[2023-09-09 20:57:16,531][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0013 loss2:0.1976 loss3:0.0117 | AUC:0.8502 Anomaly AUC:0.6821
[2023-09-09 20:57:35,568][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0049 loss2:0.2204 loss3:0.0159 | AUC:0.8448 Anomaly AUC:0.6725
[2023-09-09 20:57:54,605][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0018 loss2:0.1915 loss3:0.0139 | AUC:0.8425 Anomaly AUC:0.6761
[2023-09-09 20:58:13,700][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0011 loss2:0.1774 loss3:0.0117 | AUC:0.8480 Anomaly AUC:0.6801
[2023-09-09 20:58:32,727][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0008 loss2:0.1664 loss3:0.0102 | AUC:0.8465 Anomaly AUC:0.6774
[2023-09-09 20:58:51,599][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0060 loss2:0.1852 loss3:0.0172 | AUC:0.8343 Anomaly AUC:0.6898
[2023-09-09 20:59:10,499][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0079 loss2:0.2016 loss3:0.0248 | AUC:0.8524 Anomaly AUC:0.6852
[2023-09-09 20:59:29,496][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0008 loss2:0.1572 loss3:0.0113 | AUC:0.8521 Anomaly AUC:0.6815
[2023-09-09 20:59:48,465][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0006 loss2:0.1479 loss3:0.0097 | AUC:0.8537 Anomaly AUC:0.6839
[2023-09-09 21:00:07,457][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0005 loss2:0.1398 loss3:0.0092 | AUC:0.8525 Anomaly AUC:0.6818
[2023-09-09 21:00:26,415][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0008 loss2:0.1372 loss3:0.0090 | AUC:0.8528 Anomaly AUC:0.6800
[2023-09-09 21:00:45,352][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0007 loss2:0.1323 loss3:0.0091 | AUC:0.8526 Anomaly AUC:0.6813
[2023-09-09 21:01:04,506][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0006 loss2:0.1265 loss3:0.0084 | AUC:0.8577 Anomaly AUC:0.6798
[2023-09-09 21:01:23,572][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0007 loss2:0.1233 loss3:0.0082 | AUC:0.8540 Anomaly AUC:0.6803
[2023-09-09 21:01:42,719][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0004 loss2:0.1166 loss3:0.0075 | AUC:0.8519 Anomaly AUC:0.6784
[2023-09-09 21:02:01,717][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0003 loss2:0.1115 loss3:0.0069 | AUC:0.8506 Anomaly AUC:0.6764
[2023-09-09 21:02:20,891][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0003 loss2:0.1071 loss3:0.0064 | AUC:0.8541 Anomaly AUC:0.6805
[2023-09-09 21:02:39,801][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.2622 loss2:0.5259 loss3:0.1262 | AUC:0.8438 Anomaly AUC:0.6870
[2023-09-09 21:02:58,869][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0057 loss2:0.3939 loss3:0.0196 | AUC:0.8590 Anomaly AUC:0.6892
[2023-09-09 21:03:17,954][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0055 loss2:0.2072 loss3:0.0116 | AUC:0.8590 Anomaly AUC:0.6915
[2023-09-09 21:03:37,034][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0026 loss2:0.1727 loss3:0.0090 | AUC:0.8583 Anomaly AUC:0.6911
[2023-09-09 21:03:56,191][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0012 loss2:0.1524 loss3:0.0061 | AUC:0.8567 Anomaly AUC:0.6901
[2023-09-09 21:04:15,254][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0012 loss2:0.1444 loss3:0.0054 | AUC:0.8539 Anomaly AUC:0.6838
[2023-09-09 21:04:34,462][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0009 loss2:0.1356 loss3:0.0045 | AUC:0.8543 Anomaly AUC:0.6883
[2023-09-09 21:04:53,543][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0007 loss2:0.1310 loss3:0.0039 | AUC:0.8537 Anomaly AUC:0.6865
[2023-09-09 21:05:12,484][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0006 loss2:0.1227 loss3:0.0033 | AUC:0.8537 Anomaly AUC:0.6876
[2023-09-09 21:05:31,635][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0005 loss2:0.1163 loss3:0.0027 | AUC:0.8535 Anomaly AUC:0.6887
[2023-09-09 21:05:50,711][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0005 loss2:0.1122 loss3:0.0021 | AUC:0.8532 Anomaly AUC:0.6883
[2023-09-09 21:06:09,733][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0004 loss2:0.1072 loss3:0.0014 | AUC:0.8535 Anomaly AUC:0.6892
[2023-09-09 21:06:28,974][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0004 loss2:0.1021 loss3:0.0008 | AUC:0.8540 Anomaly AUC:0.6917
[2023-09-09 21:06:47,971][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0003 loss2:0.0980 loss3:0.0006 | AUC:0.8547 Anomaly AUC:0.6925
[2023-09-09 21:07:07,025][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0003 loss2:0.0929 loss3:0.0006 | AUC:0.8540 Anomaly AUC:0.6924
[2023-09-09 21:07:26,155][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0003 loss2:0.0891 loss3:0.0005 | AUC:0.8532 Anomaly AUC:0.6902
[2023-09-09 21:07:45,270][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0002 loss2:0.0851 loss3:0.0005 | AUC:0.8528 Anomaly AUC:0.6891
[2023-09-09 21:08:04,314][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0002 loss2:0.0819 loss3:0.0005 | AUC:0.8528 Anomaly AUC:0.6895
[2023-09-09 21:08:23,364][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0002 loss2:0.0781 loss3:0.0004 | AUC:0.8525 Anomaly AUC:0.6896
[2023-09-09 21:08:42,524][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0002 loss2:0.0754 loss3:0.0004 | AUC:0.8525 Anomaly AUC:0.6890
[2023-09-09 21:09:01,613][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0150 loss2:0.0802 loss3:0.0022 | AUC:0.7825 Anomaly AUC:0.5468
[2023-09-09 21:09:20,729][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0877 loss2:0.4993 loss3:0.0399 | AUC:0.8416 Anomaly AUC:0.6711
[2023-09-09 21:09:39,917][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0093 loss2:0.1433 loss3:0.0116 | AUC:0.8344 Anomaly AUC:0.6699
[2023-09-16 22:09:14,126][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:09:17,211][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:09:17,211][main.py][line:168][INFO] Training Mode
[2023-09-16 22:09:17,212][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:09:17,212][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:09:25,279][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:11:53,091][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:11:56,813][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:11:56,813][main.py][line:168][INFO] Training Mode
[2023-09-16 22:11:56,814][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:11:56,814][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:12:04,860][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:13:11,239][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:13:14,278][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:13:14,278][main.py][line:168][INFO] Training Mode
[2023-09-16 22:13:14,279][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:13:14,279][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:13:22,364][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:14:12,728][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:14:15,793][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:14:15,793][main.py][line:168][INFO] Training Mode
[2023-09-16 22:14:15,793][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:14:15,794][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:14:23,827][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:14:36,663][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:14:41,042][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:14:41,042][main.py][line:168][INFO] Training Mode
[2023-09-16 22:14:41,043][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:14:41,043][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:14:49,175][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:15:07,521][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:504.4296 loss2:1.3781 loss3:0.3859 | AUC:0.7880 Anomaly AUC:0.5503
[2023-09-16 22:15:25,706][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:503.7646 loss2:1.2810 loss3:0.3894 | AUC:0.7813 Anomaly AUC:0.5501
[2023-09-16 22:15:44,290][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:503.6468 loss2:1.0984 loss3:0.3806 | AUC:0.7704 Anomaly AUC:0.5614
[2023-09-16 22:16:02,928][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:503.6268 loss2:0.9620 loss3:0.3355 | AUC:0.7605 Anomaly AUC:0.5386
[2023-09-16 22:16:21,607][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:503.6198 loss2:0.9011 loss3:0.2463 | AUC:0.7189 Anomaly AUC:0.5351
[2023-09-16 22:16:40,321][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:503.6153 loss2:0.8449 loss3:0.1990 | AUC:0.6296 Anomaly AUC:0.5117
[2023-09-16 22:16:59,227][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:503.6143 loss2:0.8225 loss3:0.1744 | AUC:0.7194 Anomaly AUC:0.5397
[2023-09-16 22:17:18,158][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:503.6129 loss2:0.7792 loss3:0.1445 | AUC:0.7048 Anomaly AUC:0.5303
[2023-09-16 22:17:37,001][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:503.7351 loss2:0.8027 loss3:0.1367 | AUC:0.8080 Anomaly AUC:0.5816
[2023-09-16 22:17:55,834][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:503.7085 loss2:1.1336 loss3:0.3589 | AUC:0.6898 Anomaly AUC:0.5177
[2023-09-16 22:18:14,781][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:503.6153 loss2:0.8899 loss3:0.1689 | AUC:0.7146 Anomaly AUC:0.5258
[2023-09-16 22:18:33,804][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:503.6128 loss2:0.8183 loss3:0.1298 | AUC:0.7266 Anomaly AUC:0.5435
[2023-09-16 22:18:52,790][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:503.6114 loss2:0.7723 loss3:0.1055 | AUC:0.7638 Anomaly AUC:0.5301
[2023-09-16 22:19:11,827][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:503.6115 loss2:0.7572 loss3:0.0990 | AUC:0.7110 Anomaly AUC:0.5366
[2023-09-16 22:19:30,848][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00009 | loss1:503.6107 loss2:0.7324 loss3:0.0869 | AUC:0.6882 Anomaly AUC:0.5271
[2023-09-16 22:19:49,754][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00009 | loss1:503.6120 loss2:0.7348 loss3:0.0962 | AUC:0.7081 Anomaly AUC:0.5272
[2023-09-16 22:20:08,770][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00009 | loss1:503.6190 loss2:0.7782 loss3:0.1411 | AUC:0.5403 Anomaly AUC:0.5084
[2023-09-16 22:20:27,803][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00009 | loss1:503.6095 loss2:0.7025 loss3:0.0855 | AUC:0.7295 Anomaly AUC:0.5370
[2023-09-16 22:20:46,882][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00009 | loss1:503.6098 loss2:0.6771 loss3:0.0697 | AUC:0.7178 Anomaly AUC:0.5332
[2023-09-16 22:21:05,830][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00009 | loss1:503.6159 loss2:0.7411 loss3:0.0861 | AUC:0.6714 Anomaly AUC:0.5077
[2023-09-16 22:21:24,830][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00009 | loss1:503.6092 loss2:0.6819 loss3:0.0669 | AUC:0.7517 Anomaly AUC:0.5705
[2023-09-16 22:21:43,581][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00009 | loss1:503.6579 loss2:0.6129 loss3:0.1830 | AUC:0.6515 Anomaly AUC:0.5068
[2023-09-16 22:22:02,418][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00009 | loss1:503.6143 loss2:0.6027 loss3:0.2206 | AUC:0.7019 Anomaly AUC:0.5165
[2023-09-16 22:23:27,080][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:23:30,101][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:23:30,101][main.py][line:168][INFO] Training Mode
[2023-09-16 22:23:30,101][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:23:30,102][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:23:38,212][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:23:56,620][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5632 loss2:1.3630 loss3:0.3801 | AUC:0.7991 Anomaly AUC:0.5744
[2023-09-16 22:24:14,783][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1540 loss2:1.1709 loss3:0.3519 | AUC:0.7852 Anomaly AUC:0.5619
[2023-09-16 22:24:33,387][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1183 loss2:0.9833 loss3:0.2775 | AUC:0.8094 Anomaly AUC:0.6231
[2023-09-16 22:24:52,135][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.1131 loss2:0.8763 loss3:0.2286 | AUC:0.8246 Anomaly AUC:0.6437
[2023-09-16 22:25:11,036][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.1113 loss2:0.8224 loss3:0.1880 | AUC:0.8152 Anomaly AUC:0.6360
[2023-09-16 22:25:29,881][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.1098 loss2:0.7687 loss3:0.1480 | AUC:0.8236 Anomaly AUC:0.6324
[2023-09-16 22:25:48,856][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.1192 loss2:0.7518 loss3:0.1213 | AUC:0.6718 Anomaly AUC:0.5218
[2023-09-16 22:26:07,716][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.1338 loss2:0.8129 loss3:0.1584 | AUC:0.8190 Anomaly AUC:0.6263
[2023-09-16 22:26:26,658][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.1071 loss2:0.6926 loss3:0.0915 | AUC:0.7898 Anomaly AUC:0.5953
[2023-09-16 22:26:45,668][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.1069 loss2:0.6634 loss3:0.0789 | AUC:0.8241 Anomaly AUC:0.6199
[2023-09-16 22:27:04,736][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.1056 loss2:0.6304 loss3:0.0582 | AUC:0.8390 Anomaly AUC:0.6420
[2023-09-16 22:27:23,802][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.1061 loss2:0.6125 loss3:0.0510 | AUC:0.8246 Anomaly AUC:0.6188
[2023-09-16 22:27:42,806][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.1065 loss2:0.5968 loss3:0.0539 | AUC:0.8376 Anomaly AUC:0.6396
[2023-09-16 22:28:01,737][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.1051 loss2:0.5698 loss3:0.0432 | AUC:0.8228 Anomaly AUC:0.6052
[2023-09-16 22:28:20,640][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00009 | loss1:0.1078 loss2:0.5596 loss3:0.0427 | AUC:0.8178 Anomaly AUC:0.5985
[2023-09-16 22:28:39,727][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00009 | loss1:0.1039 loss2:0.5112 loss3:0.0280 | AUC:0.8339 Anomaly AUC:0.6236
[2023-09-16 22:28:58,613][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00009 | loss1:0.1051 loss2:0.5087 loss3:0.0303 | AUC:0.8285 Anomaly AUC:0.6298
[2023-09-16 22:29:17,630][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00009 | loss1:0.1033 loss2:0.4522 loss3:0.0194 | AUC:0.8269 Anomaly AUC:0.6071
[2023-09-16 22:29:36,695][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00009 | loss1:0.1031 loss2:0.4249 loss3:0.0152 | AUC:0.8307 Anomaly AUC:0.6133
[2023-09-16 22:29:55,717][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00009 | loss1:0.2239 loss2:0.8193 loss3:0.1520 | AUC:0.6523 Anomaly AUC:0.4487
[2023-09-16 22:30:14,693][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00009 | loss1:0.1101 loss2:0.6653 loss3:0.0690 | AUC:0.8040 Anomaly AUC:0.5682
[2023-09-16 22:30:33,659][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00009 | loss1:0.1052 loss2:0.5356 loss3:0.0408 | AUC:0.8189 Anomaly AUC:0.5891
[2023-09-16 22:30:52,697][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00009 | loss1:0.1036 loss2:0.4694 loss3:0.0215 | AUC:0.8238 Anomaly AUC:0.5909
[2023-09-16 22:31:11,675][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00009 | loss1:0.1033 loss2:0.4388 loss3:0.0176 | AUC:0.7882 Anomaly AUC:0.5377
[2023-09-16 22:31:30,637][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00009 | loss1:0.1034 loss2:0.4084 loss3:0.0197 | AUC:0.8362 Anomaly AUC:0.6205
[2023-09-16 22:31:49,701][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00008 | loss1:0.1026 loss2:0.3830 loss3:0.0125 | AUC:0.8274 Anomaly AUC:0.5976
[2023-09-16 22:32:08,606][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00008 | loss1:0.1024 loss2:0.3563 loss3:0.0108 | AUC:0.8271 Anomaly AUC:0.5960
[2023-09-16 22:32:27,639][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00008 | loss1:0.1028 loss2:0.3440 loss3:0.0118 | AUC:0.8288 Anomaly AUC:0.6020
[2023-09-16 22:32:46,548][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00008 | loss1:0.1022 loss2:0.3215 loss3:0.0097 | AUC:0.8304 Anomaly AUC:0.5980
[2023-09-16 22:33:05,545][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00008 | loss1:0.1021 loss2:0.3034 loss3:0.0088 | AUC:0.8268 Anomaly AUC:0.5927
[2023-09-16 22:33:24,577][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00008 | loss1:0.1019 loss2:0.2830 loss3:0.0079 | AUC:0.8273 Anomaly AUC:0.5949
[2023-09-16 22:33:43,558][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00008 | loss1:0.1358 loss2:0.3615 loss3:0.0397 | AUC:0.6434 Anomaly AUC:0.4528
[2023-09-16 22:34:02,613][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00008 | loss1:0.1087 loss2:0.6554 loss3:0.0662 | AUC:0.6796 Anomaly AUC:0.4910
[2023-09-16 22:34:21,715][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00007 | loss1:0.1041 loss2:0.4170 loss3:0.0210 | AUC:0.6783 Anomaly AUC:0.4735
[2023-09-16 22:34:40,780][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00007 | loss1:0.1034 loss2:0.3429 loss3:0.0139 | AUC:0.7031 Anomaly AUC:0.4815
[2023-09-16 22:34:54,040][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:34:57,045][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:34:57,046][main.py][line:168][INFO] Training Mode
[2023-09-16 22:34:57,046][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:34:57,046][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:35:05,096][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:35:23,494][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5632 loss2:1.3630 loss3:0.3801 | AUC:0.7991 Anomaly AUC:0.5744
[2023-09-16 22:35:41,870][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1542 loss2:1.1707 loss3:0.3518 | AUC:0.7840 Anomaly AUC:0.5622
[2023-09-16 22:36:00,609][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1182 loss2:0.9819 loss3:0.2770 | AUC:0.8096 Anomaly AUC:0.6225
[2023-09-16 22:36:19,166][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.1131 loss2:0.8760 loss3:0.2287 | AUC:0.8201 Anomaly AUC:0.6378
[2023-09-16 22:36:37,981][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.1117 loss2:0.8219 loss3:0.1908 | AUC:0.8097 Anomaly AUC:0.6231
[2023-09-16 22:36:56,851][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.1100 loss2:0.7733 loss3:0.1486 | AUC:0.8150 Anomaly AUC:0.6182
[2023-09-16 22:37:15,773][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.1096 loss2:0.7341 loss3:0.1192 | AUC:0.8262 Anomaly AUC:0.6394
[2023-09-16 22:37:34,703][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.1095 loss2:0.7132 loss3:0.1072 | AUC:0.8216 Anomaly AUC:0.6360
[2023-09-16 22:37:53,586][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.1074 loss2:0.6692 loss3:0.0772 | AUC:0.8133 Anomaly AUC:0.6070
[2023-09-16 22:38:12,548][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.1064 loss2:0.6307 loss3:0.0537 | AUC:0.8214 Anomaly AUC:0.6095
[2023-09-16 22:38:31,453][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.1548 loss2:0.7886 loss3:0.1191 | AUC:0.6879 Anomaly AUC:0.4719
[2023-09-16 22:38:50,531][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.1086 loss2:0.7219 loss3:0.0786 | AUC:0.7746 Anomaly AUC:0.5572
[2023-09-16 22:39:09,573][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.1062 loss2:0.6396 loss3:0.0503 | AUC:0.8286 Anomaly AUC:0.6255
[2023-09-16 22:39:28,594][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.1047 loss2:0.5888 loss3:0.0325 | AUC:0.8267 Anomaly AUC:0.6125
[2023-09-16 22:39:47,667][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.1044 loss2:0.5680 loss3:0.0286 | AUC:0.8340 Anomaly AUC:0.6298
[2023-09-16 22:40:06,655][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.1041 loss2:0.5303 loss3:0.0232 | AUC:0.8238 Anomaly AUC:0.6026
[2023-09-16 22:40:25,572][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.1040 loss2:0.5091 loss3:0.0224 | AUC:0.8313 Anomaly AUC:0.6161
[2023-09-16 22:40:44,513][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.1043 loss2:0.4933 loss3:0.0229 | AUC:0.8229 Anomaly AUC:0.5981
[2023-09-16 22:41:03,554][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.1039 loss2:0.4661 loss3:0.0189 | AUC:0.8400 Anomaly AUC:0.6361
[2023-09-16 22:41:22,640][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.1028 loss2:0.4211 loss3:0.0131 | AUC:0.8334 Anomaly AUC:0.6098
[2023-09-16 22:41:41,708][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.1033 loss2:0.4116 loss3:0.0138 | AUC:0.8301 Anomaly AUC:0.6095
[2023-09-16 22:42:00,681][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.1027 loss2:0.3801 loss3:0.0112 | AUC:0.8204 Anomaly AUC:0.5859
[2023-09-16 22:42:19,693][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.1026 loss2:0.3510 loss3:0.0105 | AUC:0.8370 Anomaly AUC:0.6130
[2023-09-16 22:42:38,753][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.1936 loss2:0.8526 loss3:0.1100 | AUC:0.7958 Anomaly AUC:0.5702
[2023-09-16 22:42:57,763][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.1055 loss2:0.5667 loss3:0.0300 | AUC:0.8078 Anomaly AUC:0.5724
[2023-09-16 22:43:16,836][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.1036 loss2:0.4752 loss3:0.0164 | AUC:0.8155 Anomaly AUC:0.5842
[2023-09-16 22:43:35,966][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.1032 loss2:0.4260 loss3:0.0133 | AUC:0.8201 Anomaly AUC:0.5906
[2023-09-16 22:43:55,030][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.1038 loss2:0.3988 loss3:0.0144 | AUC:0.8261 Anomaly AUC:0.5974
[2023-09-16 22:45:30,891][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-16 22:45:34,362][main.py][line:165][INFO] total params:7.5400M
[2023-09-16 22:45:34,362][main.py][line:168][INFO] Training Mode
[2023-09-16 22:45:34,363][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-16 22:45:34,363][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-16 22:45:42,546][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-16 22:46:04,002][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4607 loss2:1.2980 loss3:0.3442 | AUC:0.7980 Anomaly AUC:0.6134
[2023-09-16 22:46:24,468][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0476 loss2:1.0757 loss3:0.2946 | AUC:0.7972 Anomaly AUC:0.5879
[2023-09-16 22:46:44,630][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0110 loss2:0.9482 loss3:0.2549 | AUC:0.7293 Anomaly AUC:0.5540
[2023-09-16 22:47:05,886][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0083 loss2:0.8698 loss3:0.1966 | AUC:0.7501 Anomaly AUC:0.5268
[2023-09-16 22:47:26,520][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0074 loss2:0.8090 loss3:0.1449 | AUC:0.7105 Anomaly AUC:0.4903
[2023-09-16 22:47:46,087][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0079 loss2:0.7674 loss3:0.1088 | AUC:0.2871 Anomaly AUC:0.3526
[2023-09-16 22:48:06,233][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0062 loss2:0.7360 loss3:0.0878 | AUC:0.5975 Anomaly AUC:0.4306
[2023-09-16 22:48:26,372][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0050 loss2:0.6882 loss3:0.0619 | AUC:0.6928 Anomaly AUC:0.4728
[2023-09-16 22:48:46,609][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0068 loss2:0.6794 loss3:0.0584 | AUC:0.6838 Anomaly AUC:0.4507
[2023-09-16 22:49:07,458][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0045 loss2:0.6502 loss3:0.0457 | AUC:0.6608 Anomaly AUC:0.4454
[2023-09-17 01:06:32,900][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 01:06:36,319][main.py][line:165][INFO] total params:7.5400M
[2023-09-17 01:06:36,320][main.py][line:168][INFO] Training Mode
[2023-09-17 01:06:36,320][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 01:06:36,320][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 01:06:44,485][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-17 01:07:04,917][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4619 loss2:1.3742 loss3:0.3815 | AUC:0.7974 Anomaly AUC:0.5900
[2023-09-17 01:07:24,970][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0565 loss2:1.2028 loss3:0.3561 | AUC:0.7665 Anomaly AUC:0.5625
[2023-09-17 01:07:44,747][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0185 loss2:1.0086 loss3:0.2836 | AUC:0.8205 Anomaly AUC:0.6546
[2023-09-17 01:08:04,831][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0165 loss2:0.9303 loss3:0.2400 | AUC:0.8326 Anomaly AUC:0.6729
[2023-09-17 01:08:25,060][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0113 loss2:0.8580 loss3:0.1984 | AUC:0.8298 Anomaly AUC:0.6688
[2023-09-17 01:08:45,237][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0120 loss2:0.8088 loss3:0.1624 | AUC:0.7437 Anomaly AUC:0.5819
[2023-09-17 01:09:05,657][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0090 loss2:0.7662 loss3:0.1328 | AUC:0.8033 Anomaly AUC:0.6073
[2023-09-17 01:09:26,000][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0162 loss2:0.7872 loss3:0.1264 | AUC:0.8342 Anomaly AUC:0.6584
[2023-09-17 01:09:46,250][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0078 loss2:0.7218 loss3:0.0927 | AUC:0.7863 Anomaly AUC:0.5825
[2023-09-17 01:10:06,610][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0091 loss2:0.7157 loss3:0.0954 | AUC:0.8256 Anomaly AUC:0.6686
[2023-09-17 01:10:26,964][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0055 loss2:0.6644 loss3:0.0670 | AUC:0.8290 Anomaly AUC:0.6656
[2023-09-17 01:10:47,290][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0060 loss2:0.6507 loss3:0.0681 | AUC:0.8328 Anomaly AUC:0.6547
[2023-09-17 01:11:07,732][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0048 loss2:0.6047 loss3:0.0428 | AUC:0.8371 Anomaly AUC:0.6605
[2023-09-17 01:11:27,985][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0037 loss2:0.5798 loss3:0.0347 | AUC:0.8501 Anomaly AUC:0.6714
[2023-09-17 01:11:48,330][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0049 loss2:0.5578 loss3:0.0367 | AUC:0.8255 Anomaly AUC:0.6523
[2023-09-17 01:12:08,675][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0042 loss2:0.5678 loss3:0.0375 | AUC:0.8372 Anomaly AUC:0.6582
[2023-09-17 01:12:29,015][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0016 loss2:0.4958 loss3:0.0195 | AUC:0.8269 Anomaly AUC:0.6382
[2023-09-17 01:12:49,357][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0012 loss2:0.4575 loss3:0.0154 | AUC:0.8339 Anomaly AUC:0.6464
[2023-09-17 01:13:09,716][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0014 loss2:0.4314 loss3:0.0145 | AUC:0.8327 Anomaly AUC:0.6407
[2023-09-17 01:13:30,182][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0703 loss2:0.7719 loss3:0.1576 | AUC:0.6609 Anomaly AUC:0.5147
[2023-09-17 01:13:50,658][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0131 loss2:0.6612 loss3:0.1066 | AUC:0.6628 Anomaly AUC:0.4737
[2023-09-17 01:14:11,093][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0070 loss2:0.5503 loss3:0.0456 | AUC:0.7553 Anomaly AUC:0.5274
[2023-09-17 01:14:31,477][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0047 loss2:0.4873 loss3:0.0301 | AUC:0.7738 Anomaly AUC:0.5808
[2023-09-17 01:14:51,823][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0039 loss2:0.4540 loss3:0.0278 | AUC:0.8073 Anomaly AUC:0.6300
[2023-09-17 01:15:12,260][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0066 loss2:0.4714 loss3:0.0419 | AUC:0.8040 Anomaly AUC:0.6263
[2023-09-17 01:15:32,669][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0030 loss2:0.4181 loss3:0.0253 | AUC:0.8182 Anomaly AUC:0.6080
[2023-09-17 01:15:53,045][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0013 loss2:0.3606 loss3:0.0132 | AUC:0.8193 Anomaly AUC:0.6067
[2023-09-17 01:16:13,369][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0010 loss2:0.3303 loss3:0.0113 | AUC:0.8219 Anomaly AUC:0.6126
[2023-09-17 01:16:33,772][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0021 loss2:0.3189 loss3:0.0120 | AUC:0.8076 Anomaly AUC:0.6018
[2023-09-17 01:16:54,243][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0027 loss2:0.3584 loss3:0.0268 | AUC:0.8245 Anomaly AUC:0.6150
[2023-09-17 01:17:14,758][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0008 loss2:0.2807 loss3:0.0103 | AUC:0.8118 Anomaly AUC:0.5968
[2023-09-17 01:17:35,280][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0011 loss2:0.2690 loss3:0.0096 | AUC:0.8157 Anomaly AUC:0.5994
[2023-09-17 01:17:55,760][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0005 loss2:0.2389 loss3:0.0078 | AUC:0.8177 Anomaly AUC:0.5972
[2023-09-17 01:18:16,199][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0005 loss2:0.2228 loss3:0.0071 | AUC:0.8197 Anomaly AUC:0.6014
[2023-09-17 01:18:36,810][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0004 loss2:0.2047 loss3:0.0063 | AUC:0.8169 Anomaly AUC:0.5943
[2023-09-17 01:18:57,308][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0004 loss2:0.1901 loss3:0.0057 | AUC:0.8191 Anomaly AUC:0.6012
[2023-09-17 01:19:17,833][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0597 loss2:0.5620 loss3:0.1292 | AUC:0.6682 Anomaly AUC:0.4794
[2023-09-17 01:19:38,514][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0043 loss2:0.4924 loss3:0.0356 | AUC:0.7750 Anomaly AUC:0.5329
[2023-09-17 01:19:58,909][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0032 loss2:0.2912 loss3:0.0250 | AUC:0.7864 Anomaly AUC:0.5564
[2023-09-17 01:20:19,359][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0019 loss2:0.2482 loss3:0.0138 | AUC:0.7989 Anomaly AUC:0.5684
[2023-09-17 01:20:39,768][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0007 loss2:0.2095 loss3:0.0088 | AUC:0.8122 Anomaly AUC:0.5912
[2023-09-17 01:21:00,212][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0014 loss2:0.2087 loss3:0.0116 | AUC:0.7792 Anomaly AUC:0.5490
[2023-09-17 01:21:20,678][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0026 loss2:0.2470 loss3:0.0255 | AUC:0.8023 Anomaly AUC:0.5814
[2023-09-17 01:21:41,176][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0005 loss2:0.1690 loss3:0.0070 | AUC:0.8089 Anomaly AUC:0.5873
[2023-09-17 01:22:01,668][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0004 loss2:0.1519 loss3:0.0055 | AUC:0.8101 Anomaly AUC:0.5944
[2023-09-17 01:22:22,295][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0004 loss2:0.1409 loss3:0.0047 | AUC:0.8034 Anomaly AUC:0.5784
[2023-09-17 01:22:42,789][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0003 loss2:0.1306 loss3:0.0041 | AUC:0.8051 Anomaly AUC:0.5829
[2023-09-17 01:23:03,332][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0003 loss2:0.1248 loss3:0.0035 | AUC:0.8041 Anomaly AUC:0.5819
[2023-09-17 01:23:23,771][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0003 loss2:0.1159 loss3:0.0029 | AUC:0.7991 Anomaly AUC:0.5740
[2023-09-17 01:23:44,237][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0073 loss2:0.1914 loss3:0.0186 | AUC:0.5177 Anomaly AUC:0.4073
[2023-09-17 01:24:04,730][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0040 loss2:0.3156 loss3:0.0281 | AUC:0.7983 Anomaly AUC:0.5827
[2023-09-17 01:24:25,260][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0006 loss2:0.1352 loss3:0.0054 | AUC:0.7941 Anomaly AUC:0.5801
[2023-09-17 01:24:45,882][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0005 loss2:0.1159 loss3:0.0036 | AUC:0.8045 Anomaly AUC:0.5842
[2023-09-17 01:25:06,487][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0003 loss2:0.1023 loss3:0.0016 | AUC:0.8074 Anomaly AUC:0.5840
[2023-09-17 01:25:27,088][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0002 loss2:0.0917 loss3:0.0009 | AUC:0.8079 Anomaly AUC:0.5843
[2023-09-17 01:25:47,489][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0002 loss2:0.0865 loss3:0.0008 | AUC:0.8077 Anomaly AUC:0.5846
[2023-09-17 01:26:08,093][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0002 loss2:0.0814 loss3:0.0007 | AUC:0.8126 Anomaly AUC:0.5859
[2023-09-17 01:26:28,633][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0002 loss2:0.0766 loss3:0.0006 | AUC:0.8098 Anomaly AUC:0.5843
[2023-09-17 01:26:49,221][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0002 loss2:0.0721 loss3:0.0005 | AUC:0.8093 Anomaly AUC:0.5848
[2023-09-17 01:27:09,773][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0002 loss2:0.0689 loss3:0.0005 | AUC:0.8102 Anomaly AUC:0.5849
[2023-09-17 01:27:30,289][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0001 loss2:0.0648 loss3:0.0005 | AUC:0.8103 Anomaly AUC:0.5856
[2023-09-17 01:27:50,848][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0001 loss2:0.0615 loss3:0.0004 | AUC:0.8070 Anomaly AUC:0.5812
[2023-09-17 01:28:11,408][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0001 loss2:0.0593 loss3:0.0004 | AUC:0.7978 Anomaly AUC:0.5733
[2023-09-17 01:28:31,991][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0001 loss2:0.0557 loss3:0.0004 | AUC:0.8025 Anomaly AUC:0.5793
[2023-09-17 01:28:52,706][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0001 loss2:0.0534 loss3:0.0004 | AUC:0.8021 Anomaly AUC:0.5809
[2023-09-17 01:29:13,353][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0407 loss2:0.1562 loss3:0.0215 | AUC:0.5666 Anomaly AUC:0.4121
[2023-09-17 01:29:33,710][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0426 loss2:0.5347 loss3:0.1521 | AUC:0.4643 Anomaly AUC:0.3673
[2023-09-17 01:29:54,291][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0043 loss2:0.3912 loss3:0.0280 | AUC:0.6832 Anomaly AUC:0.4863
[2023-09-17 01:30:14,915][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0018 loss2:0.1963 loss3:0.0102 | AUC:0.6732 Anomaly AUC:0.4716
[2023-09-17 01:30:35,583][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0014 loss2:0.1301 loss3:0.0072 | AUC:0.6622 Anomaly AUC:0.4801
[2023-09-17 01:30:56,123][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0006 loss2:0.1034 loss3:0.0046 | AUC:0.7204 Anomaly AUC:0.5022
[2023-09-17 01:31:16,695][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0004 loss2:0.0860 loss3:0.0026 | AUC:0.6925 Anomaly AUC:0.4933
[2023-09-17 01:31:37,217][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0004 loss2:0.0756 loss3:0.0018 | AUC:0.6517 Anomaly AUC:0.4555
[2023-09-17 01:31:57,896][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0002 loss2:0.0670 loss3:0.0014 | AUC:0.6528 Anomaly AUC:0.4575
[2023-09-17 01:32:18,573][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0002 loss2:0.0631 loss3:0.0013 | AUC:0.7285 Anomaly AUC:0.5177
[2023-09-17 01:32:39,174][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0002 loss2:0.0589 loss3:0.0012 | AUC:0.6700 Anomaly AUC:0.4696
[2023-09-17 01:32:59,840][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0002 loss2:0.0535 loss3:0.0007 | AUC:0.6902 Anomaly AUC:0.4773
[2023-09-17 01:33:20,464][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0001 loss2:0.0498 loss3:0.0006 | AUC:0.6652 Anomaly AUC:0.4617
[2023-09-17 01:33:41,048][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0001 loss2:0.0474 loss3:0.0007 | AUC:0.6851 Anomaly AUC:0.4699
[2023-09-17 01:34:01,694][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0001 loss2:0.0441 loss3:0.0005 | AUC:0.6550 Anomaly AUC:0.4478
[2023-09-17 01:34:22,286][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0001 loss2:0.0408 loss3:0.0004 | AUC:0.6683 Anomaly AUC:0.4560
[2023-09-17 01:34:42,899][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0002 loss2:0.0413 loss3:0.0010 | AUC:0.6254 Anomaly AUC:0.4129
[2023-09-17 01:35:03,481][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0128 loss2:0.3565 loss3:0.0479 | AUC:0.6103 Anomaly AUC:0.4409
[2023-09-17 01:35:24,117][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0034 loss2:0.1631 loss3:0.0205 | AUC:0.5577 Anomaly AUC:0.4195
[2023-09-17 01:35:44,977][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0008 loss2:0.0842 loss3:0.0053 | AUC:0.6924 Anomaly AUC:0.4831
[2023-09-17 01:36:05,562][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0008 loss2:0.0633 loss3:0.0049 | AUC:0.5998 Anomaly AUC:0.4282
[2023-09-17 01:36:26,273][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0016 loss2:0.0842 loss3:0.0130 | AUC:0.5679 Anomaly AUC:0.4147
[2023-09-17 01:36:46,861][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0016 loss2:0.0664 loss3:0.0091 | AUC:0.6118 Anomaly AUC:0.4287
[2023-09-17 01:37:07,551][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0005 loss2:0.0507 loss3:0.0028 | AUC:0.6276 Anomaly AUC:0.4347
[2023-09-17 01:37:28,177][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0001 loss2:0.0397 loss3:0.0010 | AUC:0.6654 Anomaly AUC:0.4583
[2023-09-17 01:37:48,781][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0001 loss2:0.0360 loss3:0.0008 | AUC:0.6677 Anomaly AUC:0.4599
[2023-09-17 01:38:09,463][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0001 loss2:0.0330 loss3:0.0007 | AUC:0.6483 Anomaly AUC:0.4447
[2023-09-17 01:38:30,105][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.0001 loss2:0.0302 loss3:0.0005 | AUC:0.6702 Anomaly AUC:0.4575
[2023-09-17 01:38:50,797][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0001 loss2:0.0289 loss3:0.0006 | AUC:0.6496 Anomaly AUC:0.4478
[2023-09-17 01:39:11,642][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0001 loss2:0.0270 loss3:0.0004 | AUC:0.6753 Anomaly AUC:0.4646
[2023-09-17 01:39:32,434][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0001 loss2:0.0251 loss3:0.0003 | AUC:0.6720 Anomaly AUC:0.4621
[2023-09-17 01:39:53,149][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0001 loss2:0.0233 loss3:0.0003 | AUC:0.6862 Anomaly AUC:0.4706
[2023-09-17 01:40:13,865][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0000 loss2:0.0220 loss3:0.0003 | AUC:0.6861 Anomaly AUC:0.4714
[2023-09-17 01:40:34,590][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0001 loss2:0.0208 loss3:0.0003 | AUC:0.6962 Anomaly AUC:0.4819
[2023-09-17 01:40:55,280][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0001 loss2:0.0199 loss3:0.0002 | AUC:0.6850 Anomaly AUC:0.4700
[2023-09-17 01:40:55,304][main.py][line:116][INFO] Training completes in 34m 11s | best AUCAUC:0.8501 Anomaly AUC:0.6714

[2023-09-17 12:23:44,458][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 12:23:47,682][main.py][line:165][INFO] total params:7.5400M
[2023-09-17 12:23:47,683][main.py][line:174][INFO] Test Mode
[2023-09-17 12:23:47,683][main.py][line:37][INFO] loading pretrained checkpoint from ./ckpt/ucf__current.pkl.
[2023-09-17 12:23:56,003][infer.py][line:47][INFO] offline AUC:0.8521 AP:0.2830 FAR:0.0305 | Complete in 0m 8s

[2023-09-17 13:10:14,818][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:10:17,893][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:10:17,893][main.py][line:168][INFO] Training Mode
[2023-09-17 13:10:17,893][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 13:10:17,894][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:10:46,826][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:10:49,882][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:10:49,883][main.py][line:168][INFO] Training Mode
[2023-09-17 13:10:49,883][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 13:10:49,883][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:11:20,519][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:11:23,547][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:11:23,547][main.py][line:168][INFO] Training Mode
[2023-09-17 13:11:23,548][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 13:11:23,548][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:12:02,348][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:12:05,358][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:12:05,358][main.py][line:168][INFO] Training Mode
[2023-09-17 13:12:05,358][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 13:12:05,358][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:13:02,441][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:13:05,494][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:13:05,494][main.py][line:168][INFO] Training Mode
[2023-09-17 13:13:05,495][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 13:13:05,495][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:13:13,251][main.py][line:82][INFO] Random initialize AUCAUC:0.4741 Anomaly AUC:0.49810
[2023-09-17 13:14:44,945][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:14:47,964][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:14:47,964][main.py][line:168][INFO] Training Mode
[2023-09-17 13:14:47,964][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 13:14:47,964][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:14:55,748][main.py][line:82][INFO] Random initialize AUCAUC:0.4741 Anomaly AUC:0.49810
[2023-09-17 13:15:15,140][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.6247 loss2:1.3954 loss3:0.3780 | AUC:0.8202 Anomaly AUC:0.6049
[2023-09-17 13:15:34,164][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2763 loss2:1.3716 loss3:0.3309 | AUC:0.8088 Anomaly AUC:0.6195
[2023-09-17 13:15:53,558][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1485 loss2:1.3380 loss3:0.2599 | AUC:0.8301 Anomaly AUC:0.6128
[2023-09-17 13:16:13,173][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0616 loss2:1.3016 loss3:0.1905 | AUC:0.8369 Anomaly AUC:0.6432
[2023-09-17 13:16:32,816][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0606 loss2:1.2697 loss3:0.1359 | AUC:0.8327 Anomaly AUC:0.6460
[2023-09-17 13:16:52,548][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0354 loss2:1.2357 loss3:0.0910 | AUC:0.8487 Anomaly AUC:0.6618
[2023-09-17 13:17:12,424][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0310 loss2:1.2014 loss3:0.0592 | AUC:0.8406 Anomaly AUC:0.6444
[2023-09-17 13:17:32,327][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0385 loss2:1.1722 loss3:0.0451 | AUC:0.8471 Anomaly AUC:0.6523
[2023-09-17 13:17:52,192][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0296 loss2:1.1390 loss3:0.0346 | AUC:0.8329 Anomaly AUC:0.6351
[2023-09-17 13:18:12,034][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0241 loss2:1.1153 loss3:0.0296 | AUC:0.8384 Anomaly AUC:0.6505
[2023-09-17 13:18:31,987][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0217 loss2:1.0860 loss3:0.0250 | AUC:0.8370 Anomaly AUC:0.6426
[2023-09-17 13:18:51,915][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0265 loss2:1.0683 loss3:0.0236 | AUC:0.8333 Anomaly AUC:0.6521
[2023-09-17 13:19:11,795][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0151 loss2:1.0401 loss3:0.0196 | AUC:0.8426 Anomaly AUC:0.6607
[2023-09-17 13:19:31,721][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0148 loss2:1.0111 loss3:0.0173 | AUC:0.8469 Anomaly AUC:0.6556
[2023-09-17 13:19:51,589][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0222 loss2:1.0022 loss3:0.0187 | AUC:0.8386 Anomaly AUC:0.6433
[2023-09-17 13:20:11,522][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0140 loss2:0.9807 loss3:0.0151 | AUC:0.8472 Anomaly AUC:0.6647
[2023-09-17 13:20:31,479][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0155 loss2:0.9602 loss3:0.0142 | AUC:0.8464 Anomaly AUC:0.6584
[2023-09-17 13:20:51,414][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0160 loss2:0.9439 loss3:0.0131 | AUC:0.8477 Anomaly AUC:0.6633
[2023-09-17 13:21:11,360][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0126 loss2:0.9180 loss3:0.0122 | AUC:0.8416 Anomaly AUC:0.6544
[2023-09-17 13:21:31,237][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0084 loss2:0.8550 loss3:0.0087 | AUC:0.8377 Anomaly AUC:0.6501
[2023-09-17 13:21:51,129][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0102 loss2:0.7249 loss3:0.0070 | AUC:0.8277 Anomaly AUC:0.6487
[2023-09-17 13:22:10,721][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0244 loss2:0.2962 loss3:0.0095 | AUC:0.8322 Anomaly AUC:0.6369
[2023-09-17 13:22:30,622][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0157 loss2:0.8207 loss3:0.0071 | AUC:0.8394 Anomaly AUC:0.6543
[2023-09-17 13:22:50,379][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0107 loss2:0.6119 loss3:0.0044 | AUC:0.8375 Anomaly AUC:0.6516
[2023-09-17 13:23:10,259][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0175 loss2:0.7857 loss3:0.0059 | AUC:0.8388 Anomaly AUC:0.6543
[2023-09-17 13:23:30,273][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0115 loss2:0.7537 loss3:0.0042 | AUC:0.8287 Anomaly AUC:0.6345
[2023-09-17 13:23:50,272][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0154 loss2:0.6376 loss3:0.0052 | AUC:0.8315 Anomaly AUC:0.6279
[2023-09-17 13:24:10,249][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0071 loss2:0.6921 loss3:0.0034 | AUC:0.8386 Anomaly AUC:0.6417
[2023-09-17 13:24:30,147][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0054 loss2:0.5729 loss3:0.0021 | AUC:0.8273 Anomaly AUC:0.6325
[2023-09-17 13:24:50,111][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0170 loss2:0.6305 loss3:0.0040 | AUC:0.8347 Anomaly AUC:0.6352
[2023-09-17 13:25:10,014][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0066 loss2:0.5467 loss3:0.0023 | AUC:0.8323 Anomaly AUC:0.6426
[2023-09-17 13:25:29,723][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0049 loss2:0.4334 loss3:0.0015 | AUC:0.8380 Anomaly AUC:0.6450
[2023-09-17 13:25:49,559][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0046 loss2:0.4581 loss3:0.0012 | AUC:0.8356 Anomaly AUC:0.6436
[2023-09-17 13:26:09,172][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0042 loss2:0.3089 loss3:0.0009 | AUC:0.8351 Anomaly AUC:0.6410
[2023-09-17 13:26:28,901][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0041 loss2:0.4289 loss3:0.0009 | AUC:0.8340 Anomaly AUC:0.6361
[2023-09-17 13:26:48,557][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0051 loss2:0.4139 loss3:0.0011 | AUC:0.8175 Anomaly AUC:0.6182
[2023-09-17 13:27:08,347][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0235 loss2:0.5067 loss3:0.0045 | AUC:0.8376 Anomaly AUC:0.6574
[2023-09-17 13:27:28,266][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0078 loss2:0.5470 loss3:0.0025 | AUC:0.8381 Anomaly AUC:0.6469
[2023-09-17 13:27:47,953][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0091 loss2:0.3845 loss3:0.0022 | AUC:0.8157 Anomaly AUC:0.6142
[2023-09-17 13:28:07,749][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0106 loss2:0.5371 loss3:0.0028 | AUC:0.8352 Anomaly AUC:0.6375
[2023-09-17 13:28:27,381][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0046 loss2:0.3268 loss3:0.0013 | AUC:0.8338 Anomaly AUC:0.6324
[2023-09-17 13:28:47,085][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0073 loss2:0.3904 loss3:0.0016 | AUC:0.8389 Anomaly AUC:0.6412
[2023-09-17 13:29:06,680][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0078 loss2:0.1301 loss3:0.0014 | AUC:0.8447 Anomaly AUC:0.6460
[2023-09-17 13:29:26,391][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0064 loss2:0.3951 loss3:0.0015 | AUC:0.8340 Anomaly AUC:0.6436
[2023-09-17 13:29:46,053][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0054 loss2:0.2521 loss3:0.0011 | AUC:0.8366 Anomaly AUC:0.6432
[2023-09-17 13:30:05,757][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0054 loss2:0.2814 loss3:0.0013 | AUC:0.8460 Anomaly AUC:0.6571
[2023-09-17 13:30:25,331][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0038 loss2:0.2547 loss3:0.0007 | AUC:0.8411 Anomaly AUC:0.6468
[2023-09-17 13:30:45,175][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0150 loss2:0.3907 loss3:0.0026 | AUC:0.8386 Anomaly AUC:0.6460
[2023-09-17 13:31:04,838][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0053 loss2:0.2632 loss3:0.0014 | AUC:0.8309 Anomaly AUC:0.6334
[2023-09-17 13:31:24,630][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0033 loss2:0.4129 loss3:0.0006 | AUC:0.8339 Anomaly AUC:0.6374
[2023-09-17 13:31:44,469][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0030 loss2:0.2653 loss3:0.0004 | AUC:0.8339 Anomaly AUC:0.6310
[2023-09-17 13:32:04,135][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0029 loss2:0.2740 loss3:0.0004 | AUC:0.8378 Anomaly AUC:0.6394
[2023-09-17 13:32:23,833][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0030 loss2:0.3397 loss3:0.0003 | AUC:0.8362 Anomaly AUC:0.6386
[2023-09-17 13:32:43,560][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0027 loss2:0.2580 loss3:0.0003 | AUC:0.8366 Anomaly AUC:0.6362
[2023-09-17 13:33:03,249][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0027 loss2:0.2673 loss3:0.0003 | AUC:0.8367 Anomaly AUC:0.6367
[2023-09-17 13:33:23,068][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0028 loss2:0.2900 loss3:0.0002 | AUC:0.8372 Anomaly AUC:0.6343
[2023-09-17 13:33:42,836][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0023 loss2:0.2145 loss3:0.0002 | AUC:0.8395 Anomaly AUC:0.6460
[2023-09-17 13:34:02,540][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0024 loss2:0.2839 loss3:0.0002 | AUC:0.8400 Anomaly AUC:0.6414
[2023-09-17 13:34:22,434][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0023 loss2:0.2625 loss3:0.0002 | AUC:0.8375 Anomaly AUC:0.6394
[2023-09-17 13:34:42,098][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0024 loss2:0.3117 loss3:0.0002 | AUC:0.8407 Anomaly AUC:0.6443
[2023-09-17 13:35:01,773][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0024 loss2:0.2710 loss3:0.0002 | AUC:0.8398 Anomaly AUC:0.6402
[2023-09-17 13:35:21,541][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0034 loss2:0.3208 loss3:0.0003 | AUC:0.8310 Anomaly AUC:0.6412
[2023-09-17 13:35:41,522][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0350 loss2:0.5265 loss3:0.0078 | AUC:0.8364 Anomaly AUC:0.6584
[2023-09-17 13:36:01,696][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0056 loss2:0.4110 loss3:0.0014 | AUC:0.8315 Anomaly AUC:0.6462
[2023-09-17 13:36:21,467][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0063 loss2:0.1763 loss3:0.0011 | AUC:0.8377 Anomaly AUC:0.6491
[2023-09-17 13:36:40,871][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0026 loss2:0.0000 loss3:0.0005 | AUC:0.8403 Anomaly AUC:0.6507
[2023-09-17 13:37:00,309][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0026 loss2:0.0000 loss3:0.0005 | AUC:0.8400 Anomaly AUC:0.6474
[2023-09-17 13:37:19,832][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0034 loss2:0.1967 loss3:0.0009 | AUC:0.8315 Anomaly AUC:0.6444
[2023-09-17 13:37:39,572][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0026 loss2:0.2122 loss3:0.0006 | AUC:0.8300 Anomaly AUC:0.6445
[2023-09-17 13:37:59,235][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0084 loss2:0.2907 loss3:0.0012 | AUC:0.8246 Anomaly AUC:0.6346
[2023-09-17 13:38:19,041][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0025 loss2:0.3526 loss3:0.0003 | AUC:0.8213 Anomaly AUC:0.6401
[2023-09-17 13:38:38,784][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0023 loss2:0.3537 loss3:0.0002 | AUC:0.8245 Anomaly AUC:0.6378
[2023-09-17 13:38:58,524][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0022 loss2:0.2473 loss3:0.0002 | AUC:0.8277 Anomaly AUC:0.6438
[2023-09-17 13:39:18,181][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0019 loss2:0.0967 loss3:0.0002 | AUC:0.8297 Anomaly AUC:0.6433
[2023-09-17 13:39:37,790][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0017 loss2:0.1023 loss3:0.0002 | AUC:0.8300 Anomaly AUC:0.6430
[2023-09-17 13:39:57,528][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0018 loss2:0.1465 loss3:0.0002 | AUC:0.8302 Anomaly AUC:0.6404
[2023-09-17 13:40:17,415][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0019 loss2:0.2489 loss3:0.0002 | AUC:0.8281 Anomaly AUC:0.6399
[2023-09-17 13:40:37,115][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0018 loss2:0.2747 loss3:0.0002 | AUC:0.8296 Anomaly AUC:0.6424
[2023-09-17 13:40:56,853][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0018 loss2:0.2560 loss3:0.0002 | AUC:0.8316 Anomaly AUC:0.6416
[2023-09-17 13:41:16,728][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0019 loss2:0.2425 loss3:0.0001 | AUC:0.8283 Anomaly AUC:0.6417
[2023-09-17 13:41:36,495][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0018 loss2:0.2892 loss3:0.0002 | AUC:0.8296 Anomaly AUC:0.6405
[2023-09-17 13:41:56,414][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0018 loss2:0.3483 loss3:0.0001 | AUC:0.8307 Anomaly AUC:0.6450
[2023-09-17 13:42:16,137][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0021 loss2:0.2668 loss3:0.0002 | AUC:0.8310 Anomaly AUC:0.6490
[2023-09-17 13:42:36,079][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0436 loss2:0.5113 loss3:0.0112 | AUC:0.8228 Anomaly AUC:0.6496
[2023-09-17 13:42:56,273][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0064 loss2:0.5368 loss3:0.0017 | AUC:0.8204 Anomaly AUC:0.6477
[2023-09-17 13:43:16,385][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0034 loss2:0.4516 loss3:0.0009 | AUC:0.8200 Anomaly AUC:0.6436
[2023-09-17 13:43:36,295][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0024 loss2:0.4419 loss3:0.0005 | AUC:0.8204 Anomaly AUC:0.6436
[2023-09-17 13:43:56,323][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0023 loss2:0.4165 loss3:0.0004 | AUC:0.8196 Anomaly AUC:0.6414
[2023-09-17 13:44:16,347][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0023 loss2:0.3785 loss3:0.0003 | AUC:0.8184 Anomaly AUC:0.6383
[2023-09-17 13:44:36,569][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0021 loss2:0.3531 loss3:0.0002 | AUC:0.8176 Anomaly AUC:0.6378
[2023-09-17 13:44:56,524][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0022 loss2:0.3327 loss3:0.0002 | AUC:0.8177 Anomaly AUC:0.6369
[2023-09-17 13:45:16,432][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0021 loss2:0.3283 loss3:0.0002 | AUC:0.8146 Anomaly AUC:0.6326
[2023-09-17 13:45:36,386][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.0019 loss2:0.3040 loss3:0.0002 | AUC:0.8166 Anomaly AUC:0.6344
[2023-09-17 13:45:56,223][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0022 loss2:0.2672 loss3:0.0002 | AUC:0.8123 Anomaly AUC:0.6300
[2023-09-17 13:46:16,452][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0060 loss2:0.3574 loss3:0.0006 | AUC:0.8105 Anomaly AUC:0.6306
[2023-09-17 13:46:36,396][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0113 loss2:0.3724 loss3:0.0020 | AUC:0.8175 Anomaly AUC:0.6362
[2023-09-17 13:46:56,476][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0125 loss2:0.3470 loss3:0.0023 | AUC:0.8223 Anomaly AUC:0.6481
[2023-09-17 13:47:16,096][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0043 loss2:0.0095 loss3:0.0006 | AUC:0.8324 Anomaly AUC:0.6508
[2023-09-17 13:47:35,931][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0040 loss2:0.1900 loss3:0.0007 | AUC:0.8264 Anomaly AUC:0.6430
[2023-09-17 13:47:55,824][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0025 loss2:0.3176 loss3:0.0003 | AUC:0.8218 Anomaly AUC:0.6316
[2023-09-17 13:47:55,847][main.py][line:116][INFO] Training completes in 33m 0s | best AUCAUC:0.8487 Anomaly AUC:0.6618

[2023-09-17 13:48:45,516][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 13:48:48,542][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 13:48:48,542][main.py][line:168][INFO] Training Mode
[2023-09-17 13:48:48,542][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.1, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-17 13:48:48,542][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 13:48:56,162][main.py][line:82][INFO] Random initialize AUCAUC:0.4741 Anomaly AUC:0.49810
[2023-09-17 13:49:15,451][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3804 loss2:1.3840 loss3:0.3756 | AUC:0.8266 Anomaly AUC:0.6304
[2023-09-17 13:49:34,429][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0786 loss2:1.3434 loss3:0.3342 | AUC:0.8042 Anomaly AUC:0.6447
[2023-09-17 13:49:53,873][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0357 loss2:1.2742 loss3:0.2404 | AUC:0.8156 Anomaly AUC:0.6380
[2023-09-17 13:50:13,468][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0264 loss2:1.2068 loss3:0.1638 | AUC:0.8185 Anomaly AUC:0.6570
[2023-09-17 13:50:33,292][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0249 loss2:1.1566 loss3:0.1106 | AUC:0.8298 Anomaly AUC:0.6596
[2023-09-17 13:50:53,079][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0227 loss2:1.1210 loss3:0.0765 | AUC:0.8323 Anomaly AUC:0.6666
[2023-09-17 13:51:12,939][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0227 loss2:1.0947 loss3:0.0546 | AUC:0.8268 Anomaly AUC:0.6468
[2023-09-17 13:51:33,003][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0221 loss2:1.0683 loss3:0.0431 | AUC:0.8259 Anomaly AUC:0.6725
[2023-09-17 13:51:52,847][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0169 loss2:1.0416 loss3:0.0375 | AUC:0.8371 Anomaly AUC:0.6665
[2023-09-17 13:52:12,729][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0139 loss2:1.0174 loss3:0.0310 | AUC:0.8378 Anomaly AUC:0.6590
[2023-09-17 13:52:32,604][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0094 loss2:0.9782 loss3:0.0239 | AUC:0.8375 Anomaly AUC:0.6509
[2023-09-17 13:52:52,470][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0121 loss2:0.9586 loss3:0.0224 | AUC:0.8432 Anomaly AUC:0.6502
[2023-09-17 13:53:12,439][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0226 loss2:0.9732 loss3:0.0275 | AUC:0.8383 Anomaly AUC:0.6628
[2023-09-17 13:53:32,311][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0090 loss2:0.9337 loss3:0.0214 | AUC:0.8460 Anomaly AUC:0.6582
[2023-09-17 13:53:52,216][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0056 loss2:0.8953 loss3:0.0158 | AUC:0.8453 Anomaly AUC:0.6480
[2023-09-17 13:54:12,112][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0049 loss2:0.8709 loss3:0.0133 | AUC:0.8444 Anomaly AUC:0.6468
[2023-09-17 13:54:32,003][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0044 loss2:0.8501 loss3:0.0117 | AUC:0.8406 Anomaly AUC:0.6434
[2023-09-17 13:54:52,045][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0043 loss2:0.7845 loss3:0.0102 | AUC:0.8398 Anomaly AUC:0.6459
[2023-09-17 13:55:11,992][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0276 loss2:0.8100 loss3:0.0178 | AUC:0.8206 Anomaly AUC:0.6578
[2023-09-17 13:55:31,967][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0237 loss2:0.8613 loss3:0.0227 | AUC:0.8286 Anomaly AUC:0.6385
[2023-09-17 13:55:51,998][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0062 loss2:0.8349 loss3:0.0146 | AUC:0.8350 Anomaly AUC:0.6398
[2023-09-17 13:56:12,147][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0103 loss2:0.7937 loss3:0.0141 | AUC:0.8290 Anomaly AUC:0.6332
[2023-09-17 13:56:32,184][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0057 loss2:0.7875 loss3:0.0115 | AUC:0.8375 Anomaly AUC:0.6458
[2023-09-17 13:56:52,227][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0039 loss2:0.6732 loss3:0.0084 | AUC:0.8345 Anomaly AUC:0.6375
[2023-09-17 13:57:11,879][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0168 loss2:0.3880 loss3:0.0090 | AUC:0.8203 Anomaly AUC:0.6406
[2023-09-17 13:57:31,833][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0111 loss2:0.7857 loss3:0.0134 | AUC:0.8229 Anomaly AUC:0.6348
[2023-09-17 13:57:51,672][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0041 loss2:0.6090 loss3:0.0072 | AUC:0.8258 Anomaly AUC:0.6318
[2023-09-17 13:58:11,141][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0077 loss2:0.1778 loss3:0.0063 | AUC:0.8278 Anomaly AUC:0.6441
[2023-09-17 13:58:30,944][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0068 loss2:0.6159 loss3:0.0067 | AUC:0.8306 Anomaly AUC:0.6396
[2023-09-17 13:58:50,519][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0127 loss2:0.2736 loss3:0.0069 | AUC:0.8365 Anomaly AUC:0.6695
[2023-09-17 13:59:09,925][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0059 loss2:0.1566 loss3:0.0057 | AUC:0.8301 Anomaly AUC:0.6543
[2023-09-17 13:59:29,313][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0031 loss2:0.1705 loss3:0.0024 | AUC:0.8373 Anomaly AUC:0.6506
[2023-09-17 13:59:48,899][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0025 loss2:0.0000 loss3:0.0016 | AUC:0.8382 Anomaly AUC:0.6516
[2023-09-17 14:00:08,225][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0023 loss2:0.0000 loss3:0.0014 | AUC:0.8415 Anomaly AUC:0.6533
[2023-09-17 14:00:27,601][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0025 loss2:0.0000 loss3:0.0012 | AUC:0.8399 Anomaly AUC:0.6416
[2023-09-17 14:00:47,251][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0169 loss2:0.4958 loss3:0.0071 | AUC:0.8201 Anomaly AUC:0.6463
[2023-09-17 14:01:06,844][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0044 loss2:0.1555 loss3:0.0037 | AUC:0.8327 Anomaly AUC:0.6408
[2023-09-17 14:01:26,209][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0052 loss2:0.0439 loss3:0.0037 | AUC:0.8340 Anomaly AUC:0.6474
[2023-09-17 14:01:45,568][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0090 loss2:0.0380 loss3:0.0051 | AUC:0.8294 Anomaly AUC:0.6421
[2023-09-17 14:02:05,093][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0084 loss2:0.1844 loss3:0.0059 | AUC:0.8296 Anomaly AUC:0.6404
[2023-09-17 14:02:24,496][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0031 loss2:0.0063 loss3:0.0024 | AUC:0.8336 Anomaly AUC:0.6432
[2023-09-17 14:02:43,760][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0024 loss2:0.0000 loss3:0.0016 | AUC:0.8389 Anomaly AUC:0.6491
[2023-09-17 14:03:03,223][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0022 loss2:0.0000 loss3:0.0012 | AUC:0.8398 Anomaly AUC:0.6512
[2023-09-17 14:03:22,489][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0021 loss2:0.0000 loss3:0.0010 | AUC:0.8407 Anomaly AUC:0.6520
[2023-09-17 14:03:41,895][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0019 loss2:0.0000 loss3:0.0010 | AUC:0.8410 Anomaly AUC:0.6531
[2023-09-17 14:04:01,302][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0018 loss2:0.0000 loss3:0.0009 | AUC:0.8418 Anomaly AUC:0.6543
[2023-09-17 14:04:20,680][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0017 loss2:0.0000 loss3:0.0009 | AUC:0.8437 Anomaly AUC:0.6565
[2023-09-17 14:04:40,054][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0015 loss2:0.0000 loss3:0.0009 | AUC:0.8432 Anomaly AUC:0.6547
[2023-09-17 14:04:59,367][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0016 loss2:0.0000 loss3:0.0007 | AUC:0.8437 Anomaly AUC:0.6572
[2023-09-17 14:05:18,783][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0015 loss2:0.0000 loss3:0.0007 | AUC:0.8461 Anomaly AUC:0.6568
[2023-09-17 14:05:38,529][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0196 loss2:0.6003 loss3:0.0086 | AUC:0.8272 Anomaly AUC:0.6420
[2023-09-17 14:05:58,073][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0068 loss2:0.1731 loss3:0.0033 | AUC:0.8360 Anomaly AUC:0.6608
[2023-09-17 14:06:17,536][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0048 loss2:0.1884 loss3:0.0029 | AUC:0.8304 Anomaly AUC:0.6455
[2023-09-17 14:06:36,974][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0019 loss2:0.0000 loss3:0.0010 | AUC:0.8353 Anomaly AUC:0.6485
[2023-09-17 14:06:56,396][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0018 loss2:0.0000 loss3:0.0008 | AUC:0.8373 Anomaly AUC:0.6504
[2023-09-17 14:07:15,717][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0018 loss2:0.0000 loss3:0.0006 | AUC:0.8370 Anomaly AUC:0.6491
[2023-09-17 14:07:35,103][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0016 loss2:0.0000 loss3:0.0005 | AUC:0.8392 Anomaly AUC:0.6503
[2023-09-17 14:07:54,566][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0014 loss2:0.0000 loss3:0.0005 | AUC:0.8411 Anomaly AUC:0.6520
[2023-09-17 14:08:14,144][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0013 loss2:0.0000 loss3:0.0004 | AUC:0.8422 Anomaly AUC:0.6536
[2023-09-17 14:08:33,441][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0012 loss2:0.0000 loss3:0.0004 | AUC:0.8414 Anomaly AUC:0.6520
[2023-09-17 14:08:52,965][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0012 loss2:0.0000 loss3:0.0006 | AUC:0.8440 Anomaly AUC:0.6536
[2023-09-17 14:09:12,416][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0013 loss2:0.0000 loss3:0.0003 | AUC:0.8424 Anomaly AUC:0.6495
[2023-09-17 14:09:31,767][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0011 loss2:0.0000 loss3:0.0004 | AUC:0.8389 Anomaly AUC:0.6472
[2023-09-17 14:09:51,277][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0011 loss2:0.0000 loss3:0.0003 | AUC:0.8392 Anomaly AUC:0.6487
[2023-09-17 14:10:10,696][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0011 loss2:0.0000 loss3:0.0004 | AUC:0.8374 Anomaly AUC:0.6454
[2023-09-17 14:10:30,167][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0010 loss2:0.0000 loss3:0.0004 | AUC:0.8383 Anomaly AUC:0.6475
[2023-09-17 14:10:49,822][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0286 loss2:0.1071 loss3:0.0079 | AUC:0.8304 Anomaly AUC:0.6803
[2023-09-17 14:11:09,564][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0098 loss2:0.5425 loss3:0.0057 | AUC:0.8210 Anomaly AUC:0.6445
[2023-09-17 14:11:29,007][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0032 loss2:0.0000 loss3:0.0027 | AUC:0.8270 Anomaly AUC:0.6552
[2023-09-17 14:16:00,018][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:16:03,121][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 14:16:03,121][main.py][line:168][INFO] Training Mode
[2023-09-17 14:16:03,122][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:16:03,122][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:16:10,734][main.py][line:82][INFO] Random initialize AUCAUC:0.4741 Anomaly AUC:0.49810
[2023-09-17 14:16:29,939][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.6234 loss2:1.3656 loss3:0.3720 | AUC:0.8196 Anomaly AUC:0.6108
[2023-09-17 14:16:49,127][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2922 loss2:1.2278 loss3:0.2746 | AUC:0.8172 Anomaly AUC:0.6485
[2023-09-17 14:17:08,581][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1651 loss2:1.0988 loss3:0.1719 | AUC:0.8418 Anomaly AUC:0.6477
[2023-09-17 14:17:28,146][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0927 loss2:1.0145 loss3:0.0987 | AUC:0.8355 Anomaly AUC:0.6434
[2023-09-17 14:17:47,983][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0565 loss2:0.9557 loss3:0.0520 | AUC:0.8243 Anomaly AUC:0.6386
[2023-09-17 14:18:07,800][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0432 loss2:0.9145 loss3:0.0333 | AUC:0.8301 Anomaly AUC:0.6483
[2023-09-17 14:18:27,729][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0416 loss2:0.8843 loss3:0.0259 | AUC:0.8175 Anomaly AUC:0.6268
[2023-09-17 14:18:47,520][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0405 loss2:0.8614 loss3:0.0231 | AUC:0.8077 Anomaly AUC:0.6301
[2023-09-17 14:19:07,353][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0304 loss2:0.8372 loss3:0.0186 | AUC:0.8159 Anomaly AUC:0.6368
[2023-09-17 14:19:27,283][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0304 loss2:0.8241 loss3:0.0169 | AUC:0.8063 Anomaly AUC:0.6257
[2023-09-17 14:19:47,337][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0250 loss2:0.8065 loss3:0.0140 | AUC:0.8196 Anomaly AUC:0.6416
[2023-09-17 14:20:07,381][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0240 loss2:0.7943 loss3:0.0121 | AUC:0.8310 Anomaly AUC:0.6454
[2023-09-17 14:20:27,335][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0329 loss2:0.7835 loss3:0.0104 | AUC:0.8259 Anomaly AUC:0.6428
[2023-09-17 14:20:47,257][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0219 loss2:0.7646 loss3:0.0076 | AUC:0.8250 Anomaly AUC:0.6389
[2023-09-17 14:21:07,285][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0118 loss2:0.7330 loss3:0.0039 | AUC:0.8251 Anomaly AUC:0.6398
[2023-09-17 14:21:27,232][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0140 loss2:0.7160 loss3:0.0034 | AUC:0.8161 Anomaly AUC:0.6342
[2023-09-17 14:21:47,250][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0113 loss2:0.6604 loss3:0.0026 | AUC:0.8171 Anomaly AUC:0.6356
[2023-09-17 14:22:07,427][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0160 loss2:0.6452 loss3:0.0027 | AUC:0.8233 Anomaly AUC:0.6320
[2023-09-17 14:22:27,412][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0153 loss2:0.6577 loss3:0.0027 | AUC:0.8279 Anomaly AUC:0.6369
[2023-09-17 14:22:47,539][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0252 loss2:0.6822 loss3:0.0039 | AUC:0.8178 Anomaly AUC:0.6326
[2023-09-17 14:23:07,571][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0137 loss2:0.6259 loss3:0.0024 | AUC:0.8199 Anomaly AUC:0.6392
[2023-09-17 14:23:27,235][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0090 loss2:0.0939 loss3:0.0016 | AUC:0.8163 Anomaly AUC:0.6376
[2023-09-17 14:23:46,873][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0203 loss2:0.3692 loss3:0.0040 | AUC:0.8244 Anomaly AUC:0.6400
[2023-09-17 14:24:06,692][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0085 loss2:0.5767 loss3:0.0016 | AUC:0.8251 Anomaly AUC:0.6416
[2023-09-17 14:24:26,498][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0239 loss2:0.5611 loss3:0.0033 | AUC:0.8216 Anomaly AUC:0.6373
[2023-09-17 14:24:46,383][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0088 loss2:0.5328 loss3:0.0014 | AUC:0.8258 Anomaly AUC:0.6341
[2023-09-17 14:25:06,313][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0082 loss2:0.5371 loss3:0.0010 | AUC:0.8212 Anomaly AUC:0.6372
[2023-09-17 14:25:26,302][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0073 loss2:0.4997 loss3:0.0008 | AUC:0.8221 Anomaly AUC:0.6350
[2023-09-17 14:25:46,141][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0074 loss2:0.5317 loss3:0.0007 | AUC:0.8173 Anomaly AUC:0.6293
[2023-09-17 14:26:05,909][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0069 loss2:0.4773 loss3:0.0006 | AUC:0.8232 Anomaly AUC:0.6333
[2023-09-17 14:26:25,775][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0092 loss2:0.5095 loss3:0.0008 | AUC:0.8198 Anomaly AUC:0.6351
[2023-09-17 14:27:01,863][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:27:04,895][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 14:27:04,895][main.py][line:168][INFO] Training Mode
[2023-09-17 14:27:04,895][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:27:04,896][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:27:12,400][main.py][line:82][INFO] Random initialize AUCAUC:0.4741 Anomaly AUC:0.49810
[2023-09-17 14:27:31,423][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5699 loss2:1.3598 loss3:0.3685 | AUC:0.8286 Anomaly AUC:0.6200
[2023-09-17 14:27:50,510][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.2332 loss2:1.2117 loss3:0.2617 | AUC:0.8362 Anomaly AUC:0.6657
[2023-09-17 14:28:09,906][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.1136 loss2:1.0755 loss3:0.1592 | AUC:0.8271 Anomaly AUC:0.6538
[2023-09-17 14:28:29,457][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0788 loss2:1.0018 loss3:0.0885 | AUC:0.8373 Anomaly AUC:0.6554
[2023-09-17 14:28:49,155][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0451 loss2:0.9429 loss3:0.0485 | AUC:0.8251 Anomaly AUC:0.6509
[2023-09-17 14:29:08,910][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0489 loss2:0.9083 loss3:0.0344 | AUC:0.8358 Anomaly AUC:0.6568
[2023-09-17 14:29:28,762][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0459 loss2:0.8836 loss3:0.0282 | AUC:0.8430 Anomaly AUC:0.6561
[2023-09-17 14:29:48,594][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0349 loss2:0.8533 loss3:0.0235 | AUC:0.8484 Anomaly AUC:0.6604
[2023-09-17 14:30:08,503][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0335 loss2:0.8390 loss3:0.0211 | AUC:0.8268 Anomaly AUC:0.6595
[2023-09-17 14:30:28,334][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0226 loss2:0.8139 loss3:0.0172 | AUC:0.8190 Anomaly AUC:0.6492
[2023-09-17 14:30:48,126][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0209 loss2:0.7911 loss3:0.0151 | AUC:0.8209 Anomaly AUC:0.6490
[2023-09-17 14:31:08,022][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0212 loss2:0.7723 loss3:0.0128 | AUC:0.8312 Anomaly AUC:0.6419
[2023-09-17 14:31:27,757][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0258 loss2:0.7122 loss3:0.0115 | AUC:0.8303 Anomaly AUC:0.6557
[2023-09-17 14:31:47,584][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0205 loss2:0.6304 loss3:0.0085 | AUC:0.8241 Anomaly AUC:0.6582
[2023-09-17 14:32:07,341][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0197 loss2:0.6520 loss3:0.0067 | AUC:0.8276 Anomaly AUC:0.6510
[2023-09-17 14:32:27,289][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0179 loss2:0.5973 loss3:0.0053 | AUC:0.8182 Anomaly AUC:0.6409
[2023-09-17 14:32:47,146][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0186 loss2:0.5632 loss3:0.0053 | AUC:0.8252 Anomaly AUC:0.6503
[2023-09-17 14:33:06,958][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0109 loss2:0.5225 loss3:0.0034 | AUC:0.8265 Anomaly AUC:0.6457
[2023-09-17 14:33:26,654][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0111 loss2:0.5547 loss3:0.0031 | AUC:0.8278 Anomaly AUC:0.6444
[2023-09-17 14:33:46,278][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0101 loss2:0.5245 loss3:0.0027 | AUC:0.8310 Anomaly AUC:0.6476
[2023-09-17 14:34:06,091][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0084 loss2:0.5008 loss3:0.0020 | AUC:0.8311 Anomaly AUC:0.6466
[2023-09-17 14:34:25,653][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0075 loss2:0.4056 loss3:0.0017 | AUC:0.8301 Anomaly AUC:0.6457
[2023-09-17 14:34:45,337][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0076 loss2:0.4619 loss3:0.0014 | AUC:0.8294 Anomaly AUC:0.6467
[2023-09-17 14:35:05,012][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0074 loss2:0.4787 loss3:0.0013 | AUC:0.8297 Anomaly AUC:0.6485
[2023-09-17 14:35:24,644][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0078 loss2:0.4502 loss3:0.0011 | AUC:0.8271 Anomaly AUC:0.6442
[2023-09-17 14:35:44,461][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0478 loss2:0.6414 loss3:0.0085 | AUC:0.8216 Anomaly AUC:0.6321
[2023-09-17 14:36:04,209][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0216 loss2:0.4928 loss3:0.0044 | AUC:0.8248 Anomaly AUC:0.6452
[2023-09-17 14:36:24,061][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0132 loss2:0.4471 loss3:0.0026 | AUC:0.8192 Anomaly AUC:0.6409
[2023-09-17 14:36:43,579][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0194 loss2:0.1544 loss3:0.0037 | AUC:0.8259 Anomaly AUC:0.6462
[2023-09-17 14:37:09,966][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:37:12,969][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 14:37:12,969][main.py][line:168][INFO] Training Mode
[2023-09-17 14:37:12,970][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:37:12,970][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:37:20,651][main.py][line:82][INFO] Random initialize AUCAUC:0.4741 Anomaly AUC:0.49810
[2023-09-17 14:37:39,903][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.7629 loss2:1.3788 loss3:0.3810 | AUC:0.8034 Anomaly AUC:0.5834
[2023-09-17 14:37:59,117][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.3949 loss2:1.2862 loss3:0.3279 | AUC:0.8264 Anomaly AUC:0.6331
[2023-09-17 14:38:18,567][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.2592 loss2:1.1678 loss3:0.2208 | AUC:0.8235 Anomaly AUC:0.6470
[2023-09-17 14:38:38,120][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.1522 loss2:1.0822 loss3:0.1335 | AUC:0.8351 Anomaly AUC:0.6387
[2023-09-17 14:38:57,851][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0890 loss2:1.0166 loss3:0.0736 | AUC:0.8266 Anomaly AUC:0.6342
[2023-09-17 14:39:17,585][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0664 loss2:0.9668 loss3:0.0447 | AUC:0.8317 Anomaly AUC:0.6366
[2023-09-17 14:39:37,544][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0457 loss2:0.9285 loss3:0.0310 | AUC:0.8244 Anomaly AUC:0.6323
[2023-09-17 14:39:57,302][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0327 loss2:0.8938 loss3:0.0242 | AUC:0.8187 Anomaly AUC:0.6401
[2023-09-17 14:40:17,117][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0294 loss2:0.8687 loss3:0.0198 | AUC:0.8258 Anomaly AUC:0.6425
[2023-09-17 14:40:37,010][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0365 loss2:0.8504 loss3:0.0178 | AUC:0.8267 Anomaly AUC:0.6357
[2023-09-17 14:40:56,895][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0266 loss2:0.8274 loss3:0.0133 | AUC:0.8064 Anomaly AUC:0.6361
[2023-09-17 14:41:16,847][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0317 loss2:0.8180 loss3:0.0119 | AUC:0.8156 Anomaly AUC:0.6391
[2023-09-17 14:41:36,876][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0200 loss2:0.7970 loss3:0.0075 | AUC:0.8142 Anomaly AUC:0.6316
[2023-09-17 14:41:56,739][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0275 loss2:0.7852 loss3:0.0081 | AUC:0.8155 Anomaly AUC:0.6371
[2023-09-17 14:42:16,617][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0247 loss2:0.7727 loss3:0.0071 | AUC:0.8182 Anomaly AUC:0.6399
[2023-09-17 14:42:36,546][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0212 loss2:0.7623 loss3:0.0060 | AUC:0.8060 Anomaly AUC:0.6337
[2023-09-17 14:42:56,445][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0203 loss2:0.7505 loss3:0.0056 | AUC:0.8111 Anomaly AUC:0.6311
[2023-09-17 14:43:16,448][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0211 loss2:0.7385 loss3:0.0051 | AUC:0.8160 Anomaly AUC:0.6452
[2023-09-17 14:43:36,376][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0220 loss2:0.7339 loss3:0.0053 | AUC:0.8159 Anomaly AUC:0.6445
[2023-09-17 14:43:56,189][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0155 loss2:0.7115 loss3:0.0041 | AUC:0.8111 Anomaly AUC:0.6439
[2023-09-17 14:44:16,350][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0110 loss2:0.6809 loss3:0.0032 | AUC:0.8171 Anomaly AUC:0.6403
[2023-09-17 14:44:36,345][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0195 loss2:0.6546 loss3:0.0040 | AUC:0.8095 Anomaly AUC:0.6298
[2023-09-17 14:44:56,119][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0112 loss2:0.6418 loss3:0.0027 | AUC:0.8138 Anomaly AUC:0.6353
[2023-09-17 14:45:16,067][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0186 loss2:0.6279 loss3:0.0036 | AUC:0.8153 Anomaly AUC:0.6371
[2023-09-17 14:45:36,128][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0126 loss2:0.6390 loss3:0.0027 | AUC:0.8256 Anomaly AUC:0.6426
[2023-09-17 14:45:56,204][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0197 loss2:0.6188 loss3:0.0034 | AUC:0.8281 Anomaly AUC:0.6274
[2023-09-17 14:46:16,169][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0102 loss2:0.6283 loss3:0.0021 | AUC:0.8275 Anomaly AUC:0.6358
[2023-09-17 14:46:36,193][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0093 loss2:0.5935 loss3:0.0018 | AUC:0.8212 Anomaly AUC:0.6345
[2023-09-17 14:46:56,063][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0239 loss2:0.5933 loss3:0.0036 | AUC:0.8253 Anomaly AUC:0.6452
[2023-09-17 14:47:16,017][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0111 loss2:0.6035 loss3:0.0019 | AUC:0.8275 Anomaly AUC:0.6484
[2023-09-17 14:47:36,027][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0100 loss2:0.5723 loss3:0.0016 | AUC:0.8285 Anomaly AUC:0.6480
[2023-09-17 14:47:55,931][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0165 loss2:0.5698 loss3:0.0027 | AUC:0.8199 Anomaly AUC:0.6319
[2023-09-17 14:48:15,925][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0106 loss2:0.5594 loss3:0.0016 | AUC:0.8270 Anomaly AUC:0.6433
[2023-09-17 14:48:32,519][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:48:35,592][main.py][line:165][INFO] total params:6.4935M
[2023-09-17 14:48:35,592][main.py][line:168][INFO] Training Mode
[2023-09-17 14:48:35,592][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:48:35,593][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:50:47,839][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:50:50,917][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 14:50:50,918][main.py][line:168][INFO] Training Mode
[2023-09-17 14:50:50,918][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:50:50,918][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:56:09,685][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:56:12,767][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 14:56:12,767][main.py][line:168][INFO] Training Mode
[2023-09-17 14:56:12,768][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:56:12,768][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:56:20,579][main.py][line:82][INFO] Random initialize AUCAUC:0.4723 Anomaly AUC:0.50365
[2023-09-17 14:57:52,986][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 14:57:55,964][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 14:57:55,964][main.py][line:168][INFO] Training Mode
[2023-09-17 14:57:55,964][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 14:57:55,964][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 14:58:03,581][main.py][line:82][INFO] Random initialize AUCAUC:0.4723 Anomaly AUC:0.50365
[2023-09-17 14:58:22,836][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00030 | loss1:0.5648 loss2:1.3028 loss3:0.3721 | AUC:0.8200 Anomaly AUC:0.6186
[2023-09-17 14:58:41,792][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00030 | loss1:0.2310 loss2:1.0645 loss3:0.1985 | AUC:0.8286 Anomaly AUC:0.6482
[2023-09-17 14:59:01,197][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00030 | loss1:0.1089 loss2:0.9311 loss3:0.1242 | AUC:0.8152 Anomaly AUC:0.6444
[2023-09-17 14:59:20,762][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00030 | loss1:0.0573 loss2:0.8561 loss3:0.1081 | AUC:0.8331 Anomaly AUC:0.6555
[2023-09-17 14:59:40,414][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00030 | loss1:0.0464 loss2:0.8068 loss3:0.1015 | AUC:0.8257 Anomaly AUC:0.6539
[2023-09-17 15:00:00,236][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00030 | loss1:0.0269 loss2:0.7527 loss3:0.0945 | AUC:0.8448 Anomaly AUC:0.6562
[2023-09-17 15:00:20,046][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00030 | loss1:0.0330 loss2:0.7335 loss3:0.0880 | AUC:0.8365 Anomaly AUC:0.6425
[2023-09-17 15:00:39,765][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00030 | loss1:0.0286 loss2:0.7041 loss3:0.0836 | AUC:0.8159 Anomaly AUC:0.6481
[2023-09-17 15:00:59,573][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00030 | loss1:0.0232 loss2:0.6571 loss3:0.0816 | AUC:0.8371 Anomaly AUC:0.6442
[2023-09-17 15:01:19,511][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00030 | loss1:0.0194 loss2:0.6314 loss3:0.0801 | AUC:0.8114 Anomaly AUC:0.6461
[2023-09-17 15:01:39,495][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0238 loss2:0.6286 loss3:0.0795 | AUC:0.8340 Anomaly AUC:0.6455
[2023-09-17 15:01:59,430][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00030 | loss1:0.0174 loss2:0.5926 loss3:0.0783 | AUC:0.8305 Anomaly AUC:0.6457
[2023-09-17 15:02:19,293][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00030 | loss1:0.0225 loss2:0.5778 loss3:0.0787 | AUC:0.8233 Anomaly AUC:0.6365
[2023-09-17 15:02:39,036][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00030 | loss1:0.0135 loss2:0.5565 loss3:0.0763 | AUC:0.8202 Anomaly AUC:0.6324
[2023-09-17 15:02:58,998][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00030 | loss1:0.0143 loss2:0.5329 loss3:0.0758 | AUC:0.8201 Anomaly AUC:0.6344
[2023-09-17 15:03:18,884][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00030 | loss1:0.0219 loss2:0.5131 loss3:0.0774 | AUC:0.8311 Anomaly AUC:0.6279
[2023-09-17 15:03:38,809][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00030 | loss1:0.0087 loss2:0.4875 loss3:0.0745 | AUC:0.8304 Anomaly AUC:0.6423
[2023-09-17 15:03:58,738][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00030 | loss1:0.0153 loss2:0.4726 loss3:0.0755 | AUC:0.8255 Anomaly AUC:0.6294
[2023-09-17 15:04:18,609][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00030 | loss1:0.0121 loss2:0.4438 loss3:0.0745 | AUC:0.8240 Anomaly AUC:0.6278
[2023-09-17 15:04:38,687][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00030 | loss1:0.0327 loss2:0.4348 loss3:0.0792 | AUC:0.8250 Anomaly AUC:0.6258
[2023-09-17 15:04:58,650][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00030 | loss1:0.0186 loss2:0.4183 loss3:0.0755 | AUC:0.8261 Anomaly AUC:0.6265
[2023-09-17 15:05:18,670][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00030 | loss1:0.0178 loss2:0.4021 loss3:0.0744 | AUC:0.8255 Anomaly AUC:0.6337
[2023-09-17 15:05:38,709][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00030 | loss1:0.0149 loss2:0.3709 loss3:0.0738 | AUC:0.7987 Anomaly AUC:0.6167
[2023-09-17 15:05:58,886][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00030 | loss1:0.0253 loss2:0.3454 loss3:0.0745 | AUC:0.8207 Anomaly AUC:0.6242
[2023-09-17 15:06:18,845][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00030 | loss1:0.0119 loss2:0.3385 loss3:0.0712 | AUC:0.8148 Anomaly AUC:0.6389
[2023-09-17 15:06:38,866][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00030 | loss1:0.0193 loss2:0.3138 loss3:0.0721 | AUC:0.8229 Anomaly AUC:0.6423
[2023-09-17 15:06:58,780][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00030 | loss1:0.0180 loss2:0.3124 loss3:0.0700 | AUC:0.8229 Anomaly AUC:0.6320
[2023-09-17 15:07:19,035][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00030 | loss1:0.0101 loss2:0.2854 loss3:0.0669 | AUC:0.8305 Anomaly AUC:0.6329
[2023-09-17 15:07:39,022][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00030 | loss1:0.0264 loss2:0.2849 loss3:0.0683 | AUC:0.8197 Anomaly AUC:0.6436
[2023-09-17 15:07:59,038][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00030 | loss1:0.0101 loss2:0.2582 loss3:0.0643 | AUC:0.8263 Anomaly AUC:0.6399
[2023-09-17 15:08:21,065][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 15:08:24,062][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 15:08:24,062][main.py][line:168][INFO] Training Mode
[2023-09-17 15:08:24,063][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 15:08:24,063][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 15:08:31,671][main.py][line:82][INFO] Random initialize AUCAUC:0.4756 Anomaly AUC:0.51091
[2023-09-17 15:08:51,006][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00030 | loss1:0.5641 loss2:1.3106 loss3:0.3756 | AUC:0.8322 Anomaly AUC:0.6306
[2023-09-17 15:09:10,330][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00030 | loss1:0.2306 loss2:1.0765 loss3:0.2019 | AUC:0.8377 Anomaly AUC:0.6553
[2023-09-17 15:09:29,848][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00030 | loss1:0.1080 loss2:0.9319 loss3:0.1244 | AUC:0.8228 Anomaly AUC:0.6363
[2023-09-17 15:09:49,506][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00030 | loss1:0.0618 loss2:0.8526 loss3:0.1084 | AUC:0.8327 Anomaly AUC:0.6463
[2023-09-17 15:10:09,152][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00030 | loss1:0.0389 loss2:0.7970 loss3:0.0998 | AUC:0.8289 Anomaly AUC:0.6497
[2023-09-17 15:10:28,878][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00030 | loss1:0.0354 loss2:0.7574 loss3:0.0950 | AUC:0.8251 Anomaly AUC:0.6412
[2023-09-17 15:10:48,878][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00030 | loss1:0.0281 loss2:0.7346 loss3:0.0880 | AUC:0.8292 Anomaly AUC:0.6301
[2023-09-17 15:11:08,690][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00030 | loss1:0.0181 loss2:0.6976 loss3:0.0815 | AUC:0.8231 Anomaly AUC:0.6483
[2023-09-17 15:11:28,533][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00030 | loss1:0.0255 loss2:0.6652 loss3:0.0815 | AUC:0.8151 Anomaly AUC:0.6253
[2023-09-17 15:11:48,483][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00030 | loss1:0.0171 loss2:0.6217 loss3:0.0795 | AUC:0.8242 Anomaly AUC:0.6335
[2023-09-17 15:12:08,355][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0245 loss2:0.6284 loss3:0.0798 | AUC:0.8339 Anomaly AUC:0.6514
[2023-09-17 15:12:28,276][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00030 | loss1:0.0289 loss2:0.5695 loss3:0.0807 | AUC:0.8278 Anomaly AUC:0.6433
[2023-09-17 15:12:48,028][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00030 | loss1:0.0153 loss2:0.5301 loss3:0.0781 | AUC:0.8234 Anomaly AUC:0.6455
[2023-09-17 15:13:07,882][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00030 | loss1:0.0186 loss2:0.4965 loss3:0.0781 | AUC:0.8359 Anomaly AUC:0.6477
[2023-09-17 15:13:27,834][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00030 | loss1:0.0118 loss2:0.5145 loss3:0.0763 | AUC:0.8304 Anomaly AUC:0.6385
[2023-09-17 15:13:47,786][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00030 | loss1:0.0119 loss2:0.5019 loss3:0.0755 | AUC:0.8152 Anomaly AUC:0.6456
[2023-09-17 15:14:07,773][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00030 | loss1:0.0107 loss2:0.4868 loss3:0.0754 | AUC:0.8291 Anomaly AUC:0.6467
[2023-09-17 15:14:27,834][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00030 | loss1:0.0184 loss2:0.4609 loss3:0.0761 | AUC:0.8376 Anomaly AUC:0.6484
[2023-09-17 15:14:47,758][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00030 | loss1:0.0191 loss2:0.4518 loss3:0.0768 | AUC:0.8329 Anomaly AUC:0.6490
[2023-09-17 15:15:07,845][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00030 | loss1:0.0199 loss2:0.4229 loss3:0.0767 | AUC:0.8161 Anomaly AUC:0.6371
[2023-09-17 15:15:27,790][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00030 | loss1:0.0147 loss2:0.4096 loss3:0.0753 | AUC:0.8395 Anomaly AUC:0.6428
[2023-09-17 15:15:47,882][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00030 | loss1:0.0151 loss2:0.3369 loss3:0.0749 | AUC:0.8324 Anomaly AUC:0.6463
[2023-09-17 15:16:07,751][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00030 | loss1:0.0132 loss2:0.3740 loss3:0.0740 | AUC:0.8305 Anomaly AUC:0.6416
[2023-09-17 15:16:27,895][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00030 | loss1:0.0079 loss2:0.3508 loss3:0.0725 | AUC:0.8298 Anomaly AUC:0.6313
[2023-09-17 15:16:47,966][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00030 | loss1:0.0093 loss2:0.3267 loss3:0.0721 | AUC:0.8373 Anomaly AUC:0.6458
[2023-09-17 15:17:07,977][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00030 | loss1:0.0084 loss2:0.3076 loss3:0.0713 | AUC:0.8349 Anomaly AUC:0.6575
[2023-09-17 15:17:27,924][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00030 | loss1:0.0254 loss2:0.2986 loss3:0.0750 | AUC:0.8357 Anomaly AUC:0.6449
[2023-09-17 15:17:47,977][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00030 | loss1:0.0137 loss2:0.2870 loss3:0.0712 | AUC:0.8390 Anomaly AUC:0.6546
[2023-09-17 15:18:02,006][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 15:18:05,056][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 15:18:05,056][main.py][line:168][INFO] Training Mode
[2023-09-17 15:18:05,056][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 15:18:05,056][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 15:18:12,754][main.py][line:82][INFO] Random initialize AUCAUC:0.4599 Anomaly AUC:0.48250
[2023-09-17 15:18:32,082][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5173 loss2:1.2480 loss3:0.3453 | AUC:0.8221 Anomaly AUC:0.6330
[2023-09-17 15:18:51,508][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2008 loss2:0.9686 loss3:0.1531 | AUC:0.8485 Anomaly AUC:0.6622
[2023-09-17 15:19:11,262][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0866 loss2:0.8451 loss3:0.1121 | AUC:0.8387 Anomaly AUC:0.6580
[2023-09-17 15:19:31,079][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0605 loss2:0.7728 loss3:0.1006 | AUC:0.8388 Anomaly AUC:0.6610
[2023-09-17 15:19:50,933][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0530 loss2:0.7289 loss3:0.0908 | AUC:0.8337 Anomaly AUC:0.6626
[2023-09-17 15:20:10,779][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0341 loss2:0.6768 loss3:0.0841 | AUC:0.8529 Anomaly AUC:0.6840
[2023-09-17 15:20:30,678][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0476 loss2:0.5667 loss3:0.0864 | AUC:0.8406 Anomaly AUC:0.6668
[2023-09-17 15:20:50,660][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0163 loss2:0.6037 loss3:0.0788 | AUC:0.8280 Anomaly AUC:0.6683
[2023-09-17 15:21:10,690][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0299 loss2:0.5556 loss3:0.0798 | AUC:0.7997 Anomaly AUC:0.6547
[2023-09-17 15:21:30,617][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0220 loss2:0.5435 loss3:0.0789 | AUC:0.8137 Anomaly AUC:0.6479
[2023-09-17 15:21:50,846][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0201 loss2:0.4940 loss3:0.0775 | AUC:0.8363 Anomaly AUC:0.6677
[2023-09-17 15:22:10,963][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0211 loss2:0.4729 loss3:0.0778 | AUC:0.8175 Anomaly AUC:0.6498
[2023-09-17 15:22:30,994][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0299 loss2:0.4463 loss3:0.0793 | AUC:0.8129 Anomaly AUC:0.6592
[2023-09-17 15:22:51,194][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0154 loss2:0.4201 loss3:0.0759 | AUC:0.8095 Anomaly AUC:0.6657
[2023-09-17 15:23:11,156][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0218 loss2:0.3713 loss3:0.0774 | AUC:0.8246 Anomaly AUC:0.6550
[2023-09-17 15:23:31,176][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0128 loss2:0.3534 loss3:0.0751 | AUC:0.8048 Anomaly AUC:0.6602
[2023-09-17 15:23:51,324][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0199 loss2:0.3414 loss3:0.0754 | AUC:0.8226 Anomaly AUC:0.6634
[2023-09-17 15:24:11,271][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0175 loss2:0.2551 loss3:0.0747 | AUC:0.8268 Anomaly AUC:0.6657
[2023-09-17 15:24:31,269][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0193 loss2:0.2667 loss3:0.0744 | AUC:0.8257 Anomaly AUC:0.6733
[2023-09-17 15:24:51,405][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0171 loss2:0.2696 loss3:0.0736 | AUC:0.8410 Anomaly AUC:0.6784
[2023-09-17 15:25:11,526][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0126 loss2:0.2412 loss3:0.0714 | AUC:0.8433 Anomaly AUC:0.6699
[2023-09-17 15:25:31,775][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0080 loss2:0.2018 loss3:0.0682 | AUC:0.8388 Anomaly AUC:0.6750
[2023-09-17 15:25:51,897][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0396 loss2:0.2289 loss3:0.0734 | AUC:0.8414 Anomaly AUC:0.6661
[2023-09-17 15:26:12,100][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0099 loss2:0.1851 loss3:0.0655 | AUC:0.8365 Anomaly AUC:0.6652
[2023-09-17 15:26:32,295][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0201 loss2:0.1549 loss3:0.0654 | AUC:0.8277 Anomaly AUC:0.6608
[2023-09-17 15:26:52,455][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0157 loss2:0.1706 loss3:0.0637 | AUC:0.8437 Anomaly AUC:0.6681
[2023-09-17 15:27:12,666][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0122 loss2:0.1395 loss3:0.0616 | AUC:0.8287 Anomaly AUC:0.6658
[2023-09-17 15:27:32,857][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0195 loss2:0.1340 loss3:0.0625 | AUC:0.8315 Anomaly AUC:0.6642
[2023-09-17 15:27:53,148][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0106 loss2:0.1151 loss3:0.0606 | AUC:0.8405 Anomaly AUC:0.6695
[2023-09-17 15:28:13,331][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0066 loss2:0.0889 loss3:0.0589 | AUC:0.8383 Anomaly AUC:0.6604
[2023-09-17 15:28:33,428][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0153 loss2:0.0884 loss3:0.0597 | AUC:0.8330 Anomaly AUC:0.6593
[2023-09-17 15:28:53,668][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0110 loss2:0.0784 loss3:0.0600 | AUC:0.8339 Anomaly AUC:0.6642
[2023-09-17 15:29:13,799][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0081 loss2:0.0627 loss3:0.0580 | AUC:0.8329 Anomaly AUC:0.6571
[2023-09-17 15:29:34,017][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0188 loss2:0.0719 loss3:0.0595 | AUC:0.8327 Anomaly AUC:0.6559
[2023-09-17 15:29:54,285][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0288 loss2:0.0823 loss3:0.0622 | AUC:0.8121 Anomaly AUC:0.6498
[2023-09-17 15:30:14,395][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0170 loss2:0.0642 loss3:0.0601 | AUC:0.8277 Anomaly AUC:0.6499
[2023-09-17 15:30:34,606][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0069 loss2:0.0449 loss3:0.0579 | AUC:0.8306 Anomaly AUC:0.6456
[2023-09-17 15:30:54,856][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0054 loss2:0.0351 loss3:0.0565 | AUC:0.8369 Anomaly AUC:0.6580
[2023-09-17 15:31:15,062][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0101 loss2:0.0471 loss3:0.0578 | AUC:0.8122 Anomaly AUC:0.6341
[2023-09-17 15:31:35,401][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0807 loss2:0.1571 loss3:0.0759 | AUC:0.8206 Anomaly AUC:0.6476
[2023-09-17 15:31:55,663][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0100 loss2:0.0540 loss3:0.0628 | AUC:0.8156 Anomaly AUC:0.6431
[2023-09-17 15:32:15,898][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00050 | loss1:0.0086 loss2:0.0392 loss3:0.0604 | AUC:0.8214 Anomaly AUC:0.6455
[2023-09-17 15:32:36,214][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00050 | loss1:0.0055 loss2:0.0297 loss3:0.0591 | AUC:0.8159 Anomaly AUC:0.6419
[2023-09-17 15:32:56,460][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00050 | loss1:0.0083 loss2:0.0298 loss3:0.0584 | AUC:0.8142 Anomaly AUC:0.6403
[2023-09-17 15:33:16,919][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00050 | loss1:0.0263 loss2:0.0498 loss3:0.0619 | AUC:0.7627 Anomaly AUC:0.5998
[2023-09-17 15:33:37,104][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00050 | loss1:0.1364 loss2:0.2227 loss3:0.0896 | AUC:0.7990 Anomaly AUC:0.6304
[2023-09-17 15:33:57,378][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00050 | loss1:0.0180 loss2:0.0626 loss3:0.0655 | AUC:0.8014 Anomaly AUC:0.6258
[2023-09-17 15:34:17,738][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00050 | loss1:0.0112 loss2:0.0436 loss3:0.0630 | AUC:0.8171 Anomaly AUC:0.6435
[2023-09-17 15:34:38,057][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00050 | loss1:0.0317 loss2:0.0662 loss3:0.0666 | AUC:0.8174 Anomaly AUC:0.6450
[2023-09-17 15:34:58,437][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00050 | loss1:0.0130 loss2:0.0501 loss3:0.0628 | AUC:0.7994 Anomaly AUC:0.6355
[2023-09-17 15:35:18,593][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00050 | loss1:0.0071 loss2:0.0305 loss3:0.0610 | AUC:0.7932 Anomaly AUC:0.6298
[2023-09-17 15:35:38,886][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00050 | loss1:0.0064 loss2:0.0255 loss3:0.0603 | AUC:0.7953 Anomaly AUC:0.6230
[2023-09-17 15:35:59,225][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00050 | loss1:0.0043 loss2:0.0184 loss3:0.0593 | AUC:0.7913 Anomaly AUC:0.6216
[2023-09-17 15:36:19,563][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00050 | loss1:0.0063 loss2:0.0174 loss3:0.0590 | AUC:0.8086 Anomaly AUC:0.6306
[2023-09-17 15:36:39,827][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00050 | loss1:0.0250 loss2:0.0591 loss3:0.0625 | AUC:0.8391 Anomaly AUC:0.6478
[2023-09-17 15:37:00,103][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00050 | loss1:0.0161 loss2:0.0412 loss3:0.0613 | AUC:0.8006 Anomaly AUC:0.6119
[2023-09-17 15:37:20,409][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00050 | loss1:0.0162 loss2:0.0355 loss3:0.0612 | AUC:0.8195 Anomaly AUC:0.6341
[2023-09-17 15:37:40,838][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00050 | loss1:0.0081 loss2:0.0218 loss3:0.0596 | AUC:0.8057 Anomaly AUC:0.6192
[2023-09-17 15:38:01,107][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00050 | loss1:0.0059 loss2:0.0171 loss3:0.0588 | AUC:0.8032 Anomaly AUC:0.6179
[2023-09-17 15:38:21,527][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00050 | loss1:0.0043 loss2:0.0136 loss3:0.0579 | AUC:0.8055 Anomaly AUC:0.6182
[2023-09-17 15:38:41,880][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00050 | loss1:0.0199 loss2:0.0273 loss3:0.0608 | AUC:0.8058 Anomaly AUC:0.6128
[2023-09-17 15:39:02,198][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00050 | loss1:0.0132 loss2:0.0210 loss3:0.0601 | AUC:0.8214 Anomaly AUC:0.6238
[2023-09-17 15:39:22,541][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00050 | loss1:0.0088 loss2:0.0195 loss3:0.0593 | AUC:0.8342 Anomaly AUC:0.6446
[2023-09-17 15:39:42,907][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00050 | loss1:0.0087 loss2:0.0215 loss3:0.0591 | AUC:0.8324 Anomaly AUC:0.6469
[2023-09-17 15:40:03,261][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00050 | loss1:0.0047 loss2:0.0146 loss3:0.0581 | AUC:0.8255 Anomaly AUC:0.6371
[2023-09-17 15:40:28,581][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 15:40:31,614][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 15:40:31,615][main.py][line:168][INFO] Training Mode
[2023-09-17 15:40:31,615][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 15:40:31,615][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 15:40:39,266][main.py][line:82][INFO] Random initialize AUCAUC:0.4599 Anomaly AUC:0.48250
[2023-09-17 15:40:58,601][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5775 loss2:1.3023 loss3:0.3475 | AUC:0.8257 Anomaly AUC:0.6329
[2023-09-17 15:41:17,794][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2380 loss2:1.0435 loss3:0.1598 | AUC:0.8418 Anomaly AUC:0.6461
[2023-09-17 15:41:37,312][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1264 loss2:0.9058 loss3:0.1190 | AUC:0.8378 Anomaly AUC:0.6428
[2023-09-17 15:41:56,988][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0855 loss2:0.8242 loss3:0.1047 | AUC:0.8326 Anomaly AUC:0.6471
[2023-09-17 15:42:16,705][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0693 loss2:0.7574 loss3:0.0937 | AUC:0.8196 Anomaly AUC:0.6462
[2023-09-17 15:42:36,541][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0541 loss2:0.7099 loss3:0.0876 | AUC:0.8308 Anomaly AUC:0.6450
[2023-09-17 15:42:56,344][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0441 loss2:0.6437 loss3:0.0841 | AUC:0.8363 Anomaly AUC:0.6569
[2023-09-17 15:43:16,162][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0390 loss2:0.6047 loss3:0.0815 | AUC:0.8303 Anomaly AUC:0.6585
[2023-09-17 15:43:36,084][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0334 loss2:0.5591 loss3:0.0785 | AUC:0.8198 Anomaly AUC:0.6436
[2023-09-17 15:43:55,980][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0440 loss2:0.5590 loss3:0.0798 | AUC:0.8441 Anomaly AUC:0.6598
[2023-09-17 15:44:15,811][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0373 loss2:0.5295 loss3:0.0764 | AUC:0.8326 Anomaly AUC:0.6693
[2023-09-17 15:44:35,799][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0369 loss2:0.4851 loss3:0.0734 | AUC:0.8263 Anomaly AUC:0.6640
[2023-09-17 15:44:55,771][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0261 loss2:0.4632 loss3:0.0681 | AUC:0.8284 Anomaly AUC:0.6582
[2023-09-17 15:45:15,731][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0207 loss2:0.4252 loss3:0.0656 | AUC:0.8241 Anomaly AUC:0.6666
[2023-09-17 15:45:35,611][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0363 loss2:0.3323 loss3:0.0674 | AUC:0.8328 Anomaly AUC:0.6659
[2023-09-17 15:45:55,558][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0307 loss2:0.3927 loss3:0.0656 | AUC:0.8296 Anomaly AUC:0.6587
[2023-09-17 15:46:15,641][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0265 loss2:0.3570 loss3:0.0633 | AUC:0.8261 Anomaly AUC:0.6653
[2023-09-17 15:46:35,650][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0236 loss2:0.3362 loss3:0.0621 | AUC:0.8311 Anomaly AUC:0.6609
[2023-09-17 15:46:55,654][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0246 loss2:0.3102 loss3:0.0615 | AUC:0.8329 Anomaly AUC:0.6699
[2023-09-17 15:47:15,656][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0281 loss2:0.2883 loss3:0.0627 | AUC:0.8196 Anomaly AUC:0.6635
[2023-09-17 15:47:35,738][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0201 loss2:0.2609 loss3:0.0602 | AUC:0.8213 Anomaly AUC:0.6512
[2023-09-17 15:47:55,936][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0463 loss2:0.2759 loss3:0.0653 | AUC:0.8296 Anomaly AUC:0.6658
[2023-09-17 15:48:15,901][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0251 loss2:0.2373 loss3:0.0622 | AUC:0.8225 Anomaly AUC:0.6577
[2023-09-17 15:48:35,990][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0259 loss2:0.1803 loss3:0.0621 | AUC:0.8159 Anomaly AUC:0.6640
[2023-09-17 15:48:55,994][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0147 loss2:0.1844 loss3:0.0588 | AUC:0.8158 Anomaly AUC:0.6525
[2023-09-17 15:49:15,997][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0196 loss2:0.1701 loss3:0.0590 | AUC:0.8332 Anomaly AUC:0.6749
[2023-09-17 15:49:36,103][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0203 loss2:0.1489 loss3:0.0587 | AUC:0.8150 Anomaly AUC:0.6572
[2023-09-17 15:49:56,127][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0239 loss2:0.1418 loss3:0.0593 | AUC:0.8139 Anomaly AUC:0.6630
[2023-09-17 15:50:16,213][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0202 loss2:0.1253 loss3:0.0593 | AUC:0.8211 Anomaly AUC:0.6643
[2023-09-17 15:50:36,175][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0172 loss2:0.1041 loss3:0.0588 | AUC:0.8299 Anomaly AUC:0.6544
[2023-09-17 15:50:56,161][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0859 loss2:0.1599 loss3:0.0818 | AUC:0.7661 Anomaly AUC:0.5857
[2023-09-17 15:51:16,286][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0552 loss2:0.1852 loss3:0.0784 | AUC:0.8049 Anomaly AUC:0.6371
[2023-09-17 15:51:36,658][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00050 | loss1:0.0211 loss2:0.1098 loss3:0.0664 | AUC:0.8190 Anomaly AUC:0.6300
[2023-09-17 15:51:56,895][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00050 | loss1:0.0216 loss2:0.1067 loss3:0.0656 | AUC:0.8050 Anomaly AUC:0.6461
[2023-09-17 15:52:17,035][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00050 | loss1:0.0154 loss2:0.0836 loss3:0.0627 | AUC:0.8144 Anomaly AUC:0.6315
[2023-09-17 15:52:37,136][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00050 | loss1:0.0203 loss2:0.0784 loss3:0.0624 | AUC:0.8169 Anomaly AUC:0.6495
[2023-09-17 15:52:57,390][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00050 | loss1:0.0206 loss2:0.0743 loss3:0.0625 | AUC:0.8061 Anomaly AUC:0.6371
[2023-09-17 15:53:17,686][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00050 | loss1:0.0124 loss2:0.0554 loss3:0.0597 | AUC:0.8125 Anomaly AUC:0.6421
[2023-09-17 15:53:37,896][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00050 | loss1:0.0199 loss2:0.0673 loss3:0.0608 | AUC:0.8284 Anomaly AUC:0.6474
[2023-09-17 15:53:58,133][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00050 | loss1:0.0564 loss2:0.0875 loss3:0.0653 | AUC:0.8289 Anomaly AUC:0.6425
[2023-09-17 15:54:18,271][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00050 | loss1:0.0166 loss2:0.0578 loss3:0.0609 | AUC:0.8348 Anomaly AUC:0.6539
[2023-09-17 15:54:38,555][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00050 | loss1:0.0179 loss2:0.0509 loss3:0.0614 | AUC:0.8352 Anomaly AUC:0.6555
[2023-09-17 15:54:58,775][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00050 | loss1:0.0115 loss2:0.0387 loss3:0.0593 | AUC:0.8247 Anomaly AUC:0.6495
[2023-09-17 15:55:18,907][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00050 | loss1:0.0107 loss2:0.0337 loss3:0.0585 | AUC:0.8215 Anomaly AUC:0.6421
[2023-09-17 15:55:39,107][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00050 | loss1:0.0086 loss2:0.0275 loss3:0.0577 | AUC:0.8207 Anomaly AUC:0.6450
[2023-09-17 15:55:59,288][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00050 | loss1:0.0165 loss2:0.0319 loss3:0.0589 | AUC:0.7926 Anomaly AUC:0.6412
[2023-09-17 15:56:19,516][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00050 | loss1:0.0186 loss2:0.0419 loss3:0.0609 | AUC:0.8164 Anomaly AUC:0.6511
[2023-09-17 15:56:39,833][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00050 | loss1:0.0395 loss2:0.0583 loss3:0.0656 | AUC:0.8315 Anomaly AUC:0.6442
[2023-09-17 15:57:00,093][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00050 | loss1:0.0151 loss2:0.0307 loss3:0.0613 | AUC:0.8210 Anomaly AUC:0.6461
[2023-09-17 15:57:20,404][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00050 | loss1:0.0209 loss2:0.0381 loss3:0.0621 | AUC:0.8230 Anomaly AUC:0.6505
[2023-09-17 15:57:33,858][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 15:57:36,895][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 15:57:36,896][main.py][line:168][INFO] Training Mode
[2023-09-17 15:57:36,896][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 15:57:36,896][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 15:57:44,494][main.py][line:82][INFO] Random initialize AUCAUC:0.4599 Anomaly AUC:0.48250
[2023-09-17 15:58:03,955][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5173 loss2:1.2480 loss3:0.3453 | AUC:0.8221 Anomaly AUC:0.6330
[2023-09-17 15:58:23,307][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1987 loss2:0.9685 loss3:0.1530 | AUC:0.8554 Anomaly AUC:0.6648
[2023-09-17 15:58:42,904][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1048 loss2:0.8543 loss3:0.1146 | AUC:0.8438 Anomaly AUC:0.6468
[2023-09-17 15:59:02,538][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0569 loss2:0.7746 loss3:0.1004 | AUC:0.8145 Anomaly AUC:0.6315
[2023-09-17 15:59:22,285][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0450 loss2:0.7228 loss3:0.0894 | AUC:0.8292 Anomaly AUC:0.6489
[2023-09-17 15:59:42,192][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0362 loss2:0.6743 loss3:0.0847 | AUC:0.8371 Anomaly AUC:0.6593
[2023-09-17 16:00:02,269][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0368 loss2:0.6344 loss3:0.0847 | AUC:0.8293 Anomaly AUC:0.6525
[2023-09-17 16:00:22,203][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0322 loss2:0.6068 loss3:0.0832 | AUC:0.8166 Anomaly AUC:0.6415
[2023-09-17 16:00:42,162][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0260 loss2:0.5730 loss3:0.0809 | AUC:0.8076 Anomaly AUC:0.6338
[2023-09-17 16:01:02,072][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0156 loss2:0.5150 loss3:0.0780 | AUC:0.8263 Anomaly AUC:0.6442
[2023-09-17 16:01:21,948][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0274 loss2:0.3702 loss3:0.0796 | AUC:0.8469 Anomaly AUC:0.6693
[2023-09-17 16:01:42,029][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0186 loss2:0.4622 loss3:0.0774 | AUC:0.8080 Anomaly AUC:0.6402
[2023-09-17 16:02:02,011][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0096 loss2:0.4318 loss3:0.0748 | AUC:0.8261 Anomaly AUC:0.6539
[2023-09-17 16:02:22,097][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0591 loss2:0.4382 loss3:0.0856 | AUC:0.8147 Anomaly AUC:0.6385
[2023-09-17 16:02:42,073][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0321 loss2:0.4282 loss3:0.0848 | AUC:0.8404 Anomaly AUC:0.6641
[2023-09-17 16:03:02,083][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0282 loss2:0.3880 loss3:0.0791 | AUC:0.8244 Anomaly AUC:0.6573
[2023-09-17 16:03:22,285][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0126 loss2:0.3429 loss3:0.0748 | AUC:0.8198 Anomaly AUC:0.6394
[2023-09-17 16:03:42,541][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0164 loss2:0.3172 loss3:0.0748 | AUC:0.8202 Anomaly AUC:0.6526
[2023-09-17 16:04:02,716][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00046 | loss1:0.0203 loss2:0.2988 loss3:0.0750 | AUC:0.8253 Anomaly AUC:0.6478
[2023-09-17 16:04:23,035][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00045 | loss1:0.0101 loss2:0.2636 loss3:0.0722 | AUC:0.8220 Anomaly AUC:0.6550
[2023-09-17 16:04:43,097][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00045 | loss1:0.0071 loss2:0.2258 loss3:0.0702 | AUC:0.8017 Anomaly AUC:0.6475
[2023-09-17 16:05:12,345][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:05:15,336][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 16:05:15,336][main.py][line:168][INFO] Training Mode
[2023-09-17 16:05:15,337][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:05:15,337][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 16:05:22,935][main.py][line:82][INFO] Random initialize AUCAUC:0.4794 Anomaly AUC:0.47027
[2023-09-17 16:05:42,210][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5201 loss2:1.2672 loss3:0.3451 | AUC:0.8330 Anomaly AUC:0.6500
[2023-09-17 16:06:01,447][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2273 loss2:0.9780 loss3:0.1601 | AUC:0.8414 Anomaly AUC:0.6787
[2023-09-17 16:06:20,927][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1275 loss2:0.8601 loss3:0.1204 | AUC:0.8365 Anomaly AUC:0.6596
[2023-09-17 16:06:40,520][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0635 loss2:0.7764 loss3:0.1026 | AUC:0.8389 Anomaly AUC:0.6716
[2023-09-17 16:07:00,218][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0608 loss2:0.7351 loss3:0.0937 | AUC:0.8467 Anomaly AUC:0.6648
[2023-09-17 16:07:19,996][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0392 loss2:0.6809 loss3:0.0867 | AUC:0.8093 Anomaly AUC:0.6279
[2023-09-17 16:07:39,950][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0344 loss2:0.6432 loss3:0.0843 | AUC:0.8189 Anomaly AUC:0.6450
[2023-09-17 16:07:59,698][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0410 loss2:0.6109 loss3:0.0836 | AUC:0.8391 Anomaly AUC:0.6655
[2023-09-17 16:08:19,487][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0268 loss2:0.5796 loss3:0.0809 | AUC:0.8309 Anomaly AUC:0.6479
[2023-09-17 16:08:39,389][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0228 loss2:0.5421 loss3:0.0793 | AUC:0.8063 Anomaly AUC:0.6236
[2023-09-17 16:08:59,298][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0343 loss2:0.4943 loss3:0.0811 | AUC:0.8255 Anomaly AUC:0.6553
[2023-09-17 16:09:19,572][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0390 loss2:0.4719 loss3:0.0843 | AUC:0.8202 Anomaly AUC:0.6306
[2023-09-17 16:09:39,735][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0179 loss2:0.4396 loss3:0.0772 | AUC:0.8287 Anomaly AUC:0.6386
[2023-09-17 16:10:05,189][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0002, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:10:08,222][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 16:10:08,223][main.py][line:168][INFO] Training Mode
[2023-09-17 16:10:08,223][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:10:08,223][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:10:15,994][main.py][line:82][INFO] Random initialize AUCAUC:0.4794 Anomaly AUC:0.47027
[2023-09-17 16:10:35,224][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00020 | loss1:0.6689 loss2:1.3520 loss3:0.3997 | AUC:0.8132 Anomaly AUC:0.6103
[2023-09-17 16:10:54,480][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00020 | loss1:0.3098 loss2:1.1511 loss3:0.3160 | AUC:0.8404 Anomaly AUC:0.6573
[2023-09-17 16:11:14,101][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00020 | loss1:0.1697 loss2:1.0057 loss3:0.1947 | AUC:0.8372 Anomaly AUC:0.6448
[2023-09-17 16:11:33,761][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00020 | loss1:0.0917 loss2:0.9231 loss3:0.1278 | AUC:0.8407 Anomaly AUC:0.6649
[2023-09-17 16:11:53,611][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00020 | loss1:0.0612 loss2:0.8667 loss3:0.1102 | AUC:0.8300 Anomaly AUC:0.6444
[2023-09-17 16:12:13,385][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00020 | loss1:0.0419 loss2:0.8193 loss3:0.1018 | AUC:0.8306 Anomaly AUC:0.6506
[2023-09-17 16:12:33,306][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00020 | loss1:0.0362 loss2:0.7915 loss3:0.0982 | AUC:0.8299 Anomaly AUC:0.6538
[2023-09-17 16:12:53,210][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00020 | loss1:0.0288 loss2:0.7594 loss3:0.0933 | AUC:0.8370 Anomaly AUC:0.6502
[2023-09-17 16:13:13,088][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00020 | loss1:0.0232 loss2:0.7406 loss3:0.0871 | AUC:0.8328 Anomaly AUC:0.6497
[2023-09-17 16:13:33,013][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00020 | loss1:0.0232 loss2:0.7111 loss3:0.0836 | AUC:0.8330 Anomaly AUC:0.6586
[2023-09-17 16:13:52,927][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00019 | loss1:0.0235 loss2:0.6968 loss3:0.0820 | AUC:0.8294 Anomaly AUC:0.6535
[2023-09-17 16:14:12,846][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00019 | loss1:0.0162 loss2:0.6753 loss3:0.0801 | AUC:0.8257 Anomaly AUC:0.6547
[2023-09-17 16:14:32,958][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00019 | loss1:0.0189 loss2:0.6584 loss3:0.0802 | AUC:0.8244 Anomaly AUC:0.6569
[2023-09-17 16:14:52,807][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00019 | loss1:0.0213 loss2:0.6539 loss3:0.0798 | AUC:0.8248 Anomaly AUC:0.6413
[2023-09-17 16:15:12,782][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00019 | loss1:0.0107 loss2:0.6211 loss3:0.0777 | AUC:0.8262 Anomaly AUC:0.6439
[2023-09-17 16:15:32,720][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00019 | loss1:0.0136 loss2:0.6014 loss3:0.0779 | AUC:0.8236 Anomaly AUC:0.6496
[2023-09-17 16:15:52,669][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00019 | loss1:0.0157 loss2:0.5933 loss3:0.0777 | AUC:0.8000 Anomaly AUC:0.6381
[2023-09-17 16:16:12,673][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00018 | loss1:0.0199 loss2:0.5815 loss3:0.0781 | AUC:0.8197 Anomaly AUC:0.6574
[2023-09-17 16:16:32,712][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00018 | loss1:0.0099 loss2:0.5519 loss3:0.0760 | AUC:0.8088 Anomaly AUC:0.6629
[2023-09-17 16:16:52,625][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00018 | loss1:0.0095 loss2:0.5315 loss3:0.0759 | AUC:0.8338 Anomaly AUC:0.6630
[2023-09-17 16:17:12,554][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00018 | loss1:0.0258 loss2:0.5383 loss3:0.0785 | AUC:0.8240 Anomaly AUC:0.6460
[2023-09-17 16:17:32,729][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00018 | loss1:0.0141 loss2:0.5183 loss3:0.0764 | AUC:0.8194 Anomaly AUC:0.6490
[2023-09-17 16:17:52,723][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00018 | loss1:0.0103 loss2:0.5035 loss3:0.0751 | AUC:0.8190 Anomaly AUC:0.6491
[2023-09-17 16:18:12,669][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00017 | loss1:0.0093 loss2:0.4768 loss3:0.0748 | AUC:0.8214 Anomaly AUC:0.6566
[2023-09-17 16:18:32,917][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00017 | loss1:0.0269 loss2:0.4906 loss3:0.0776 | AUC:0.8336 Anomaly AUC:0.6596
[2023-09-17 16:18:52,885][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00017 | loss1:0.0109 loss2:0.4656 loss3:0.0748 | AUC:0.8337 Anomaly AUC:0.6672
[2023-09-17 16:19:12,993][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00017 | loss1:0.0151 loss2:0.4557 loss3:0.0753 | AUC:0.8350 Anomaly AUC:0.6629
[2023-09-17 16:19:33,075][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00016 | loss1:0.0098 loss2:0.4364 loss3:0.0742 | AUC:0.8308 Anomaly AUC:0.6629
[2023-09-17 16:19:53,113][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00016 | loss1:0.0085 loss2:0.4183 loss3:0.0735 | AUC:0.8317 Anomaly AUC:0.6621
[2023-09-17 16:20:13,268][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00016 | loss1:0.0093 loss2:0.4048 loss3:0.0731 | AUC:0.8309 Anomaly AUC:0.6586
[2023-09-17 16:20:33,524][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00016 | loss1:0.0096 loss2:0.3906 loss3:0.0731 | AUC:0.8208 Anomaly AUC:0.6524
[2023-09-17 16:20:50,306][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:20:53,295][main.py][line:165][INFO] total params:2.3207M
[2023-09-17 16:20:53,295][main.py][line:168][INFO] Training Mode
[2023-09-17 16:20:53,295][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:20:53,295][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:20:58,651][main.py][line:82][INFO] Random initialize AUCAUC:0.5431 Anomaly AUC:0.51041
[2023-09-17 16:21:12,978][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.3381 loss2:1.2334 loss3:0.4288 | AUC:0.7555 Anomaly AUC:0.6502
[2023-09-17 16:21:27,743][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0376 loss2:0.8488 loss3:0.4064 | AUC:0.7744 Anomaly AUC:0.6612
[2023-09-17 16:21:42,900][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0209 loss2:0.7154 loss3:0.3791 | AUC:0.7793 Anomaly AUC:0.6648
[2023-09-17 16:21:58,056][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0137 loss2:0.6359 loss3:0.3621 | AUC:0.7684 Anomaly AUC:0.6572
[2023-09-17 16:22:13,467][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0097 loss2:0.5662 loss3:0.3473 | AUC:0.7546 Anomaly AUC:0.6546
[2023-09-17 16:22:28,853][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0086 loss2:0.5069 loss3:0.3334 | AUC:0.7567 Anomaly AUC:0.6561
[2023-09-17 16:22:44,272][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0072 loss2:0.4512 loss3:0.3170 | AUC:0.7660 Anomaly AUC:0.6682
[2023-09-17 16:22:59,642][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0066 loss2:0.3919 loss3:0.2984 | AUC:0.7731 Anomaly AUC:0.6694
[2023-09-17 16:23:15,148][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0065 loss2:0.3482 loss3:0.2812 | AUC:0.7584 Anomaly AUC:0.6615
[2023-09-17 16:23:30,563][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0050 loss2:0.3019 loss3:0.2686 | AUC:0.7666 Anomaly AUC:0.6589
[2023-09-17 16:23:46,129][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0053 loss2:0.2614 loss3:0.2567 | AUC:0.7496 Anomaly AUC:0.6556
[2023-09-17 16:24:01,689][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0053 loss2:0.2239 loss3:0.2503 | AUC:0.7562 Anomaly AUC:0.6600
[2023-09-17 16:24:17,215][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0046 loss2:0.1905 loss3:0.2433 | AUC:0.7635 Anomaly AUC:0.6558
[2023-09-17 16:24:32,582][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0040 loss2:0.1592 loss3:0.2345 | AUC:0.7682 Anomaly AUC:0.6587
[2023-09-17 16:25:41,463][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:25:44,468][main.py][line:165][INFO] total params:7.2784M
[2023-09-17 16:25:44,468][main.py][line:168][INFO] Training Mode
[2023-09-17 16:25:44,469][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:25:44,469][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:25:52,579][main.py][line:82][INFO] Random initialize AUCAUC:0.5315 Anomaly AUC:0.49661
[2023-09-17 16:26:12,512][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4911 loss2:1.2490 loss3:0.2975 | AUC:0.8488 Anomaly AUC:0.6614
[2023-09-17 16:26:32,048][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2020 loss2:0.9748 loss3:0.1475 | AUC:0.8401 Anomaly AUC:0.6591
[2023-09-17 16:26:52,003][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1012 loss2:0.8618 loss3:0.1146 | AUC:0.8419 Anomaly AUC:0.6570
[2023-09-17 16:27:12,083][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0673 loss2:0.7906 loss3:0.1023 | AUC:0.8227 Anomaly AUC:0.6345
[2023-09-17 16:27:32,298][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0502 loss2:0.7387 loss3:0.0917 | AUC:0.8335 Anomaly AUC:0.6505
[2023-09-17 16:27:52,493][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0492 loss2:0.6958 loss3:0.0867 | AUC:0.8106 Anomaly AUC:0.6394
[2023-09-17 16:28:12,911][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0384 loss2:0.6538 loss3:0.0834 | AUC:0.8185 Anomaly AUC:0.6252
[2023-09-17 16:28:33,314][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0461 loss2:0.6190 loss3:0.0840 | AUC:0.8160 Anomaly AUC:0.6467
[2023-09-17 16:28:53,737][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0273 loss2:0.5774 loss3:0.0792 | AUC:0.8284 Anomaly AUC:0.6338
[2023-09-17 16:29:14,361][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0272 loss2:0.5424 loss3:0.0786 | AUC:0.8127 Anomaly AUC:0.6193
[2023-09-17 16:29:34,896][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0196 loss2:0.5070 loss3:0.0763 | AUC:0.8196 Anomaly AUC:0.6309
[2023-09-17 16:29:55,362][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0209 loss2:0.4700 loss3:0.0764 | AUC:0.8053 Anomaly AUC:0.6141
[2023-09-17 16:30:15,753][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0475 loss2:0.4573 loss3:0.0803 | AUC:0.8062 Anomaly AUC:0.6279
[2023-09-17 16:30:36,252][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0425 loss2:0.4446 loss3:0.0797 | AUC:0.8332 Anomaly AUC:0.6476
[2023-09-17 16:30:56,645][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0363 loss2:0.4414 loss3:0.0771 | AUC:0.8235 Anomaly AUC:0.6367
[2023-09-17 16:31:17,056][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0338 loss2:0.4213 loss3:0.0746 | AUC:0.8367 Anomaly AUC:0.6463
[2023-09-17 16:31:37,513][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0325 loss2:0.3827 loss3:0.0732 | AUC:0.8310 Anomaly AUC:0.6422
[2023-09-17 16:31:58,043][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0211 loss2:0.3518 loss3:0.0700 | AUC:0.8087 Anomaly AUC:0.6376
[2023-09-17 16:32:18,636][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00046 | loss1:0.0130 loss2:0.3130 loss3:0.0658 | AUC:0.8173 Anomaly AUC:0.6415
[2023-09-17 16:32:39,088][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00045 | loss1:0.0152 loss2:0.2921 loss3:0.0649 | AUC:0.8164 Anomaly AUC:0.6318
[2023-09-17 16:32:59,550][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00045 | loss1:0.0136 loss2:0.2649 loss3:0.0632 | AUC:0.8230 Anomaly AUC:0.6352
[2023-09-17 16:33:20,178][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00044 | loss1:0.0200 loss2:0.2504 loss3:0.0639 | AUC:0.8125 Anomaly AUC:0.6325
[2023-09-17 16:33:40,697][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00044 | loss1:0.0112 loss2:0.2212 loss3:0.0615 | AUC:0.8162 Anomaly AUC:0.6381
[2023-09-17 16:34:01,187][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00043 | loss1:0.0107 loss2:0.2006 loss3:0.0606 | AUC:0.8093 Anomaly AUC:0.6373
[2023-09-17 16:34:21,918][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00043 | loss1:0.0350 loss2:0.2132 loss3:0.0657 | AUC:0.8005 Anomaly AUC:0.6363
[2023-09-17 16:34:42,466][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00042 | loss1:0.0220 loss2:0.2068 loss3:0.0654 | AUC:0.8081 Anomaly AUC:0.6530
[2023-09-17 16:35:03,149][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00042 | loss1:0.0225 loss2:0.1746 loss3:0.0645 | AUC:0.8071 Anomaly AUC:0.6173
[2023-09-17 16:35:23,664][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00041 | loss1:0.0106 loss2:0.1454 loss3:0.0615 | AUC:0.8193 Anomaly AUC:0.6405
[2023-09-17 16:35:44,177][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00040 | loss1:0.0082 loss2:0.1211 loss3:0.0598 | AUC:0.8204 Anomaly AUC:0.6430
[2023-09-17 16:36:04,707][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00040 | loss1:0.0106 loss2:0.1145 loss3:0.0599 | AUC:0.8237 Anomaly AUC:0.6406
[2023-09-17 16:36:25,232][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00039 | loss1:0.0086 loss2:0.0970 loss3:0.0586 | AUC:0.8178 Anomaly AUC:0.6398
[2023-09-17 16:36:45,872][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00038 | loss1:0.0135 loss2:0.0975 loss3:0.0589 | AUC:0.8104 Anomaly AUC:0.6536
[2023-09-17 16:37:06,546][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00038 | loss1:0.0180 loss2:0.0982 loss3:0.0624 | AUC:0.8186 Anomaly AUC:0.6330
[2023-09-17 16:37:27,202][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00037 | loss1:0.0113 loss2:0.0819 loss3:0.0600 | AUC:0.8238 Anomaly AUC:0.6430
[2023-09-17 16:37:47,737][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00036 | loss1:0.0283 loss2:0.1082 loss3:0.0622 | AUC:0.8192 Anomaly AUC:0.6365
[2023-09-17 16:38:08,415][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00036 | loss1:0.0281 loss2:0.1140 loss3:0.0637 | AUC:0.8300 Anomaly AUC:0.6569
[2023-09-17 16:38:29,126][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00035 | loss1:0.0099 loss2:0.0740 loss3:0.0603 | AUC:0.8253 Anomaly AUC:0.6441
[2023-09-17 16:38:49,945][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00034 | loss1:0.0068 loss2:0.0565 loss3:0.0586 | AUC:0.8238 Anomaly AUC:0.6507
[2023-09-17 16:39:10,603][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00033 | loss1:0.0077 loss2:0.0505 loss3:0.0579 | AUC:0.7789 Anomaly AUC:0.6504
[2023-09-17 16:39:31,232][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00033 | loss1:0.0143 loss2:0.0591 loss3:0.0607 | AUC:0.8286 Anomaly AUC:0.6418
[2023-09-17 16:39:52,036][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00032 | loss1:0.0051 loss2:0.0417 loss3:0.0583 | AUC:0.8199 Anomaly AUC:0.6387
[2023-09-17 16:40:12,663][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00031 | loss1:0.0105 loss2:0.0460 loss3:0.0585 | AUC:0.8199 Anomaly AUC:0.6436
[2023-09-17 16:40:33,383][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00030 | loss1:0.0227 loss2:0.0702 loss3:0.0606 | AUC:0.8347 Anomaly AUC:0.6666
[2023-09-17 16:40:54,017][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00030 | loss1:0.0163 loss2:0.0608 loss3:0.0599 | AUC:0.8228 Anomaly AUC:0.6479
[2023-09-17 16:41:14,507][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00029 | loss1:0.0066 loss2:0.0314 loss3:0.0583 | AUC:0.8261 Anomaly AUC:0.6429
[2023-09-17 16:41:35,150][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00028 | loss1:0.0064 loss2:0.0335 loss3:0.0573 | AUC:0.8200 Anomaly AUC:0.6467
[2023-09-17 16:41:55,746][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00027 | loss1:0.0047 loss2:0.0281 loss3:0.0570 | AUC:0.8246 Anomaly AUC:0.6474
[2023-09-17 16:42:16,483][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00027 | loss1:0.0057 loss2:0.0274 loss3:0.0566 | AUC:0.8296 Anomaly AUC:0.6472
[2023-09-17 16:42:37,193][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00026 | loss1:0.0043 loss2:0.0226 loss3:0.0562 | AUC:0.8249 Anomaly AUC:0.6526
[2023-09-17 16:42:57,888][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00025 | loss1:0.0046 loss2:0.0225 loss3:0.0560 | AUC:0.8310 Anomaly AUC:0.6566
[2023-09-17 16:43:18,582][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00024 | loss1:0.0069 loss2:0.0271 loss3:0.0566 | AUC:0.8258 Anomaly AUC:0.6528
[2023-09-17 16:43:39,179][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00023 | loss1:0.0072 loss2:0.0241 loss3:0.0565 | AUC:0.8295 Anomaly AUC:0.6544
[2023-09-17 16:43:59,890][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00023 | loss1:0.0039 loss2:0.0200 loss3:0.0565 | AUC:0.8286 Anomaly AUC:0.6540
[2023-09-17 16:44:20,599][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00022 | loss1:0.0031 loss2:0.0158 loss3:0.0555 | AUC:0.8254 Anomaly AUC:0.6513
[2023-09-17 16:44:41,359][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00021 | loss1:0.0080 loss2:0.0276 loss3:0.0565 | AUC:0.8268 Anomaly AUC:0.6497
[2023-09-17 16:45:02,140][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00020 | loss1:0.0091 loss2:0.0287 loss3:0.0574 | AUC:0.8246 Anomaly AUC:0.6572
[2023-09-17 16:45:22,819][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00020 | loss1:0.0059 loss2:0.0226 loss3:0.0559 | AUC:0.8217 Anomaly AUC:0.6513
[2023-09-17 16:45:43,595][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00019 | loss1:0.0028 loss2:0.0146 loss3:0.0553 | AUC:0.8204 Anomaly AUC:0.6509
[2023-09-17 16:46:04,319][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00018 | loss1:0.0029 loss2:0.0125 loss3:0.0549 | AUC:0.8195 Anomaly AUC:0.6541
[2023-09-17 16:46:30,976][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:46:34,034][main.py][line:165][INFO] total params:7.2784M
[2023-09-17 16:46:34,034][main.py][line:168][INFO] Training Mode
[2023-09-17 16:46:34,035][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:46:34,035][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:50:09,703][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:50:12,708][main.py][line:165][INFO] total params:7.2784M
[2023-09-17 16:50:12,708][main.py][line:168][INFO] Training Mode
[2023-09-17 16:50:12,709][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:50:12,709][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:51:25,843][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:51:29,120][main.py][line:165][INFO] total params:7.2784M
[2023-09-17 16:51:29,120][main.py][line:168][INFO] Training Mode
[2023-09-17 16:51:29,121][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:51:29,121][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:54:39,820][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:54:43,040][main.py][line:165][INFO] total params:7.2784M
[2023-09-17 16:54:43,040][main.py][line:168][INFO] Training Mode
[2023-09-17 16:54:43,041][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:54:43,041][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:55:41,711][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 16:55:44,747][main.py][line:165][INFO] total params:7.2794M
[2023-09-17 16:55:44,748][main.py][line:168][INFO] Training Mode
[2023-09-17 16:55:44,748][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 16:55:44,748][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 16:55:52,993][main.py][line:82][INFO] Random initialize AUCAUC:0.5451 Anomaly AUC:0.48789
[2023-09-17 16:56:12,689][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4497 loss2:1.2217 loss3:0.2893 | AUC:0.8459 Anomaly AUC:0.6545
[2023-09-17 16:56:32,146][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1958 loss2:0.9580 loss3:0.1430 | AUC:0.8388 Anomaly AUC:0.6543
[2023-09-17 16:56:51,913][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1031 loss2:0.8465 loss3:0.1144 | AUC:0.8398 Anomaly AUC:0.6563
[2023-09-17 16:57:12,075][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0732 loss2:0.7766 loss3:0.1026 | AUC:0.8351 Anomaly AUC:0.6433
[2023-09-17 16:57:32,369][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0398 loss2:0.7186 loss3:0.0870 | AUC:0.8344 Anomaly AUC:0.6411
[2023-09-17 16:57:52,604][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0375 loss2:0.6710 loss3:0.0823 | AUC:0.8361 Anomaly AUC:0.6348
[2023-09-17 16:58:12,864][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0454 loss2:0.6418 loss3:0.0840 | AUC:0.8210 Anomaly AUC:0.6353
[2023-09-17 16:58:33,131][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0330 loss2:0.6000 loss3:0.0809 | AUC:0.8258 Anomaly AUC:0.6331
[2023-09-17 16:58:53,498][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0230 loss2:0.5602 loss3:0.0780 | AUC:0.8225 Anomaly AUC:0.6388
[2023-09-17 16:59:13,862][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0359 loss2:0.5395 loss3:0.0796 | AUC:0.8292 Anomaly AUC:0.6441
[2023-09-17 16:59:34,190][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0264 loss2:0.5083 loss3:0.0782 | AUC:0.8250 Anomaly AUC:0.6253
[2023-09-17 16:59:54,872][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0173 loss2:0.4673 loss3:0.0756 | AUC:0.8117 Anomaly AUC:0.6250
[2023-09-17 17:00:15,317][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0295 loss2:0.4412 loss3:0.0771 | AUC:0.8164 Anomaly AUC:0.6203
[2023-09-17 17:00:35,751][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0252 loss2:0.4133 loss3:0.0766 | AUC:0.7989 Anomaly AUC:0.6302
[2023-09-17 17:00:56,078][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0151 loss2:0.3751 loss3:0.0732 | AUC:0.8136 Anomaly AUC:0.6265
[2023-09-17 17:01:16,481][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0250 loss2:0.3525 loss3:0.0747 | AUC:0.8237 Anomaly AUC:0.6283
[2023-09-17 17:01:36,911][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0166 loss2:0.3247 loss3:0.0725 | AUC:0.8322 Anomaly AUC:0.6391
[2023-09-17 17:01:57,274][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0260 loss2:0.3078 loss3:0.0734 | AUC:0.8114 Anomaly AUC:0.6300
[2023-09-17 17:02:17,690][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00046 | loss1:0.0152 loss2:0.2762 loss3:0.0700 | AUC:0.8199 Anomaly AUC:0.6408
[2023-09-17 17:02:38,099][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00045 | loss1:0.0116 loss2:0.2466 loss3:0.0677 | AUC:0.8032 Anomaly AUC:0.6299
[2023-09-17 17:02:58,640][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00045 | loss1:0.0158 loss2:0.2406 loss3:0.0674 | AUC:0.8188 Anomaly AUC:0.6298
[2023-09-17 17:03:19,132][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00044 | loss1:0.0188 loss2:0.2204 loss3:0.0661 | AUC:0.8181 Anomaly AUC:0.6296
[2023-09-17 17:03:39,601][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00044 | loss1:0.0115 loss2:0.1939 loss3:0.0638 | AUC:0.8153 Anomaly AUC:0.6266
[2023-09-17 17:04:00,042][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00043 | loss1:0.0133 loss2:0.1633 loss3:0.0625 | AUC:0.8352 Anomaly AUC:0.6414
[2023-09-17 17:04:20,746][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00043 | loss1:0.0124 loss2:0.1616 loss3:0.0617 | AUC:0.8283 Anomaly AUC:0.6417
[2023-09-17 17:04:36,598][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:04:39,669][main.py][line:165][INFO] total params:7.2794M
[2023-09-17 17:04:39,670][main.py][line:168][INFO] Training Mode
[2023-09-17 17:04:39,670][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:04:39,670][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 17:04:47,769][main.py][line:82][INFO] Random initialize AUCAUC:0.4234 Anomaly AUC:0.50017
[2023-09-17 17:05:07,387][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4404 loss2:1.1838 loss3:0.2746 | AUC:0.8463 Anomaly AUC:0.6519
[2023-09-17 17:05:27,046][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1853 loss2:0.9416 loss3:0.1410 | AUC:0.8457 Anomaly AUC:0.6520
[2023-09-17 17:05:46,923][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.1058 loss2:0.8439 loss3:0.1144 | AUC:0.8318 Anomaly AUC:0.6315
[2023-09-17 17:06:06,845][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0623 loss2:0.7778 loss3:0.0985 | AUC:0.8268 Anomaly AUC:0.6310
[2023-09-17 17:06:26,926][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0543 loss2:0.7351 loss3:0.0938 | AUC:0.8088 Anomaly AUC:0.6187
[2023-09-17 17:06:47,088][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0433 loss2:0.6880 loss3:0.0892 | AUC:0.8338 Anomaly AUC:0.6298
[2023-09-17 17:07:07,288][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0398 loss2:0.6540 loss3:0.0877 | AUC:0.8238 Anomaly AUC:0.6463
[2023-09-17 17:07:27,566][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0424 loss2:0.6224 loss3:0.0874 | AUC:0.8118 Anomaly AUC:0.6280
[2023-09-17 17:07:47,822][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0373 loss2:0.5933 loss3:0.0875 | AUC:0.8364 Anomaly AUC:0.6458
[2023-09-17 17:08:08,183][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0313 loss2:0.5441 loss3:0.0826 | AUC:0.8282 Anomaly AUC:0.6416
[2023-09-17 17:08:28,953][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:08:31,959][main.py][line:165][INFO] total params:7.2794M
[2023-09-17 17:08:31,959][main.py][line:168][INFO] Training Mode
[2023-09-17 17:08:31,960][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:08:31,960][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 17:08:40,046][main.py][line:82][INFO] Random initialize AUCAUC:0.4234 Anomaly AUC:0.50017
[2023-09-17 17:08:59,872][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4378 loss2:1.1827 loss3:0.2745 | AUC:0.8451 Anomaly AUC:0.6519
[2023-09-17 17:09:19,709][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1844 loss2:0.9433 loss3:0.1388 | AUC:0.8370 Anomaly AUC:0.6481
[2023-09-17 17:09:39,656][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0912 loss2:0.8416 loss3:0.1110 | AUC:0.8381 Anomaly AUC:0.6539
[2023-09-17 17:09:59,766][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0714 loss2:0.7821 loss3:0.0986 | AUC:0.8295 Anomaly AUC:0.6401
[2023-09-17 17:10:19,940][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0508 loss2:0.7315 loss3:0.0942 | AUC:0.8407 Anomaly AUC:0.6573
[2023-09-17 17:10:40,211][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0540 loss2:0.6967 loss3:0.0933 | AUC:0.8349 Anomaly AUC:0.6441
[2023-09-17 17:11:00,633][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0511 loss2:0.6664 loss3:0.0911 | AUC:0.8406 Anomaly AUC:0.6506
[2023-09-17 17:11:21,057][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0383 loss2:0.6277 loss3:0.0873 | AUC:0.8194 Anomaly AUC:0.6392
[2023-09-17 17:11:41,441][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0310 loss2:0.5930 loss3:0.0846 | AUC:0.8434 Anomaly AUC:0.6471
[2023-09-17 17:12:01,832][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0312 loss2:0.5600 loss3:0.0837 | AUC:0.8360 Anomaly AUC:0.6433
[2023-09-17 17:12:22,237][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0229 loss2:0.5213 loss3:0.0805 | AUC:0.8294 Anomaly AUC:0.6296
[2023-09-17 17:12:42,611][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0229 loss2:0.4889 loss3:0.0794 | AUC:0.8152 Anomaly AUC:0.6331
[2023-09-17 17:13:03,020][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0444 loss2:0.4803 loss3:0.0845 | AUC:0.8407 Anomaly AUC:0.6372
[2023-09-17 17:13:23,412][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0243 loss2:0.4391 loss3:0.0788 | AUC:0.8333 Anomaly AUC:0.6277
[2023-09-17 17:13:43,789][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0225 loss2:0.4082 loss3:0.0784 | AUC:0.8343 Anomaly AUC:0.6393
[2023-09-17 17:14:04,303][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0311 loss2:0.3797 loss3:0.0786 | AUC:0.8348 Anomaly AUC:0.6293
[2023-09-17 17:14:24,845][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0158 loss2:0.3605 loss3:0.0759 | AUC:0.8253 Anomaly AUC:0.6302
[2023-09-17 17:14:55,262][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:14:58,234][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 17:14:58,234][main.py][line:168][INFO] Training Mode
[2023-09-17 17:14:58,234][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:14:58,234][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.01
)

[2023-09-17 17:15:05,995][main.py][line:82][INFO] Random initialize AUCAUC:0.4734 Anomaly AUC:0.50240
[2023-09-17 17:15:25,213][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4418 loss2:1.1786 loss3:0.2939 | AUC:0.8342 Anomaly AUC:0.6383
[2023-09-17 17:15:44,404][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1655 loss2:0.9431 loss3:0.1327 | AUC:0.8406 Anomaly AUC:0.6495
[2023-09-17 17:16:03,977][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0762 loss2:0.8418 loss3:0.1065 | AUC:0.8434 Anomaly AUC:0.6587
[2023-09-17 17:16:23,535][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0700 loss2:0.7834 loss3:0.0931 | AUC:0.8509 Anomaly AUC:0.6649
[2023-09-17 17:16:43,108][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0376 loss2:0.7236 loss3:0.0818 | AUC:0.8473 Anomaly AUC:0.6522
[2023-09-17 17:17:02,843][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0417 loss2:0.6946 loss3:0.0767 | AUC:0.8499 Anomaly AUC:0.6530
[2023-09-17 17:17:22,611][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0289 loss2:0.6497 loss3:0.0710 | AUC:0.8350 Anomaly AUC:0.6480
[2023-09-17 17:17:42,413][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0210 loss2:0.6051 loss3:0.0662 | AUC:0.8278 Anomaly AUC:0.6473
[2023-09-17 17:18:02,343][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0396 loss2:0.5926 loss3:0.0702 | AUC:0.8431 Anomaly AUC:0.6577
[2023-09-17 17:18:22,127][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0231 loss2:0.5437 loss3:0.0651 | AUC:0.8291 Anomaly AUC:0.6465
[2023-09-17 17:18:42,065][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0245 loss2:0.5219 loss3:0.0650 | AUC:0.8341 Anomaly AUC:0.6471
[2023-09-17 17:19:02,060][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0160 loss2:0.4795 loss3:0.0628 | AUC:0.8287 Anomaly AUC:0.6438
[2023-09-17 17:19:21,902][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0548 loss2:0.4850 loss3:0.0724 | AUC:0.8252 Anomaly AUC:0.6372
[2023-09-17 17:19:41,889][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0240 loss2:0.4384 loss3:0.0646 | AUC:0.8284 Anomaly AUC:0.6396
[2023-09-17 17:20:01,870][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0144 loss2:0.3954 loss3:0.0624 | AUC:0.8303 Anomaly AUC:0.6452
[2023-09-17 17:20:21,744][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0091 loss2:0.3608 loss3:0.0601 | AUC:0.8277 Anomaly AUC:0.6402
[2023-09-17 17:20:41,697][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0119 loss2:0.3209 loss3:0.0595 | AUC:0.8281 Anomaly AUC:0.6478
[2023-09-17 17:21:01,593][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0159 loss2:0.3126 loss3:0.0602 | AUC:0.8223 Anomaly AUC:0.6314
[2023-09-17 17:21:21,645][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00046 | loss1:0.0155 loss2:0.2807 loss3:0.0596 | AUC:0.8316 Anomaly AUC:0.6447
[2023-09-17 17:21:41,670][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00045 | loss1:0.0142 loss2:0.2574 loss3:0.0589 | AUC:0.8288 Anomaly AUC:0.6469
[2023-09-17 17:22:01,587][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00045 | loss1:0.0209 loss2:0.2407 loss3:0.0605 | AUC:0.8318 Anomaly AUC:0.6459
[2023-09-17 17:22:21,610][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00044 | loss1:0.0243 loss2:0.2260 loss3:0.0606 | AUC:0.8367 Anomaly AUC:0.6419
[2023-09-17 17:22:41,610][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00044 | loss1:0.0168 loss2:0.2064 loss3:0.0601 | AUC:0.8351 Anomaly AUC:0.6419
[2023-09-17 17:23:01,691][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00043 | loss1:0.0106 loss2:0.1812 loss3:0.0580 | AUC:0.8261 Anomaly AUC:0.6349
[2023-09-17 17:23:21,712][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00043 | loss1:0.0086 loss2:0.1504 loss3:0.0566 | AUC:0.8237 Anomaly AUC:0.6309
[2023-09-17 17:23:47,827][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:23:50,869][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 17:23:50,869][main.py][line:168][INFO] Training Mode
[2023-09-17 17:23:50,869][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:23:50,869][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 17:23:58,347][main.py][line:82][INFO] Random initialize AUCAUC:0.4734 Anomaly AUC:0.50240
[2023-09-17 17:24:17,422][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4440 loss2:1.1761 loss3:0.2936 | AUC:0.8315 Anomaly AUC:0.6335
[2023-09-17 17:24:36,622][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1689 loss2:0.9386 loss3:0.1337 | AUC:0.8381 Anomaly AUC:0.6483
[2023-09-17 17:24:56,032][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0868 loss2:0.8380 loss3:0.1084 | AUC:0.8293 Anomaly AUC:0.6502
[2023-09-17 17:25:15,556][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0613 loss2:0.7761 loss3:0.0998 | AUC:0.8415 Anomaly AUC:0.6547
[2023-09-17 17:25:35,204][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0408 loss2:0.7226 loss3:0.0885 | AUC:0.8485 Anomaly AUC:0.6624
[2023-09-17 17:25:54,808][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0328 loss2:0.6750 loss3:0.0839 | AUC:0.8356 Anomaly AUC:0.6499
[2023-09-17 17:26:14,472][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0401 loss2:0.6473 loss3:0.0831 | AUC:0.8423 Anomaly AUC:0.6533
[2023-09-17 17:26:34,190][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0231 loss2:0.6000 loss3:0.0789 | AUC:0.8367 Anomaly AUC:0.6495
[2023-09-17 17:26:54,137][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0264 loss2:0.5636 loss3:0.0758 | AUC:0.8422 Anomaly AUC:0.6498
[2023-09-17 17:27:13,920][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0200 loss2:0.5300 loss3:0.0720 | AUC:0.8318 Anomaly AUC:0.6498
[2023-09-17 17:27:33,716][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0229 loss2:0.4950 loss3:0.0694 | AUC:0.8314 Anomaly AUC:0.6493
[2023-09-17 17:27:53,432][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0308 loss2:0.4588 loss3:0.0690 | AUC:0.8382 Anomaly AUC:0.6425
[2023-09-17 17:28:13,134][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0459 loss2:0.4566 loss3:0.0726 | AUC:0.8248 Anomaly AUC:0.6386
[2023-09-17 17:28:32,966][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0237 loss2:0.4098 loss3:0.0660 | AUC:0.8322 Anomaly AUC:0.6400
[2023-09-17 17:28:52,818][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0159 loss2:0.3750 loss3:0.0633 | AUC:0.8254 Anomaly AUC:0.6423
[2023-09-17 17:29:12,684][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0193 loss2:0.3452 loss3:0.0630 | AUC:0.8183 Anomaly AUC:0.6386
[2023-09-17 17:29:32,554][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0141 loss2:0.3109 loss3:0.0626 | AUC:0.8346 Anomaly AUC:0.6388
[2023-09-17 17:29:52,351][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0119 loss2:0.2826 loss3:0.0613 | AUC:0.8264 Anomaly AUC:0.6442
[2023-09-17 17:30:46,343][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:30:49,953][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 17:30:49,953][main.py][line:168][INFO] Training Mode
[2023-09-17 17:30:49,954][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:30:49,954][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 17:30:57,468][main.py][line:82][INFO] Random initialize AUCAUC:0.4734 Anomaly AUC:0.50240
[2023-09-17 17:31:16,773][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4508 loss2:1.1817 loss3:0.3508 | AUC:0.8353 Anomaly AUC:0.6424
[2023-09-17 17:31:35,650][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1644 loss2:0.9377 loss3:0.1513 | AUC:0.8342 Anomaly AUC:0.6538
[2023-09-17 17:31:54,983][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0838 loss2:0.8343 loss3:0.1119 | AUC:0.8442 Anomaly AUC:0.6634
[2023-09-17 17:32:14,660][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0564 loss2:0.7657 loss3:0.1021 | AUC:0.8486 Anomaly AUC:0.6571
[2023-09-17 17:32:34,100][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0300 loss2:0.7095 loss3:0.0939 | AUC:0.8286 Anomaly AUC:0.6418
[2023-09-17 17:32:53,697][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0325 loss2:0.6715 loss3:0.0870 | AUC:0.8449 Anomaly AUC:0.6566
[2023-09-17 17:33:13,368][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00049 | loss1:0.0386 loss2:0.6276 loss3:0.0849 | AUC:0.8404 Anomaly AUC:0.6535
[2023-09-17 17:33:33,095][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00049 | loss1:0.0275 loss2:0.5850 loss3:0.0820 | AUC:0.8410 Anomaly AUC:0.6600
[2023-09-17 17:33:52,756][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00049 | loss1:0.0173 loss2:0.5246 loss3:0.0788 | AUC:0.8343 Anomaly AUC:0.6610
[2023-09-17 17:34:12,305][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00049 | loss1:0.0148 loss2:0.4833 loss3:0.0772 | AUC:0.8367 Anomaly AUC:0.6472
[2023-09-17 17:34:31,985][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00049 | loss1:0.0144 loss2:0.4484 loss3:0.0761 | AUC:0.8372 Anomaly AUC:0.6590
[2023-09-17 17:34:51,673][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00048 | loss1:0.0215 loss2:0.4425 loss3:0.0776 | AUC:0.8304 Anomaly AUC:0.6519
[2023-09-17 17:35:11,409][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00048 | loss1:0.0228 loss2:0.4061 loss3:0.0769 | AUC:0.8370 Anomaly AUC:0.6587
[2023-09-17 17:35:30,975][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00048 | loss1:0.0197 loss2:0.3904 loss3:0.0743 | AUC:0.8385 Anomaly AUC:0.6567
[2023-09-17 17:35:50,731][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00047 | loss1:0.0202 loss2:0.3646 loss3:0.0724 | AUC:0.8385 Anomaly AUC:0.6582
[2023-09-17 17:36:10,520][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00047 | loss1:0.0090 loss2:0.3070 loss3:0.0667 | AUC:0.8342 Anomaly AUC:0.6529
[2023-09-17 17:36:30,292][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00047 | loss1:0.0088 loss2:0.2745 loss3:0.0630 | AUC:0.8320 Anomaly AUC:0.6513
[2023-09-17 17:36:49,935][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00046 | loss1:0.0146 loss2:0.2550 loss3:0.0635 | AUC:0.8281 Anomaly AUC:0.6409
[2023-09-17 17:37:09,710][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00046 | loss1:0.0255 loss2:0.2739 loss3:0.0647 | AUC:0.8303 Anomaly AUC:0.6473
[2023-09-17 17:37:29,369][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00045 | loss1:0.0127 loss2:0.2309 loss3:0.0609 | AUC:0.8303 Anomaly AUC:0.6493
[2023-09-17 17:37:49,130][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00045 | loss1:0.0074 loss2:0.1908 loss3:0.0591 | AUC:0.8297 Anomaly AUC:0.6414
[2023-09-17 17:38:09,015][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00044 | loss1:0.0072 loss2:0.1594 loss3:0.0579 | AUC:0.8281 Anomaly AUC:0.6423
[2023-09-17 17:38:40,978][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:38:44,027][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 17:38:44,027][main.py][line:168][INFO] Training Mode
[2023-09-17 17:38:44,027][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:38:44,027][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 17:38:51,526][main.py][line:82][INFO] Random initialize AUCAUC:0.4734 Anomaly AUC:0.50240
[2023-09-17 17:39:10,540][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00020 | loss1:0.4779 loss2:1.2842 loss3:0.2962 | AUC:0.8233 Anomaly AUC:0.6332
[2023-09-17 17:39:29,573][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00020 | loss1:0.2046 loss2:1.0771 loss3:0.1403 | AUC:0.8280 Anomaly AUC:0.6511
[2023-09-17 17:39:49,026][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00020 | loss1:0.1003 loss2:0.9724 loss3:0.1108 | AUC:0.8413 Anomaly AUC:0.6600
[2023-09-17 17:40:08,428][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00020 | loss1:0.0688 loss2:0.9080 loss3:0.0988 | AUC:0.8434 Anomaly AUC:0.6617
[2023-09-17 17:40:27,938][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00020 | loss1:0.0387 loss2:0.8577 loss3:0.0880 | AUC:0.8380 Anomaly AUC:0.6624
[2023-09-17 17:40:47,584][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00020 | loss1:0.0512 loss2:0.8365 loss3:0.0883 | AUC:0.8386 Anomaly AUC:0.6627
[2023-09-17 17:41:07,306][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00020 | loss1:0.0483 loss2:0.8145 loss3:0.0855 | AUC:0.8404 Anomaly AUC:0.6626
[2023-09-17 17:41:26,878][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00020 | loss1:0.0299 loss2:0.7812 loss3:0.0794 | AUC:0.8363 Anomaly AUC:0.6638
[2023-09-17 17:41:46,529][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00020 | loss1:0.0382 loss2:0.7695 loss3:0.0784 | AUC:0.8367 Anomaly AUC:0.6574
[2023-09-17 17:42:06,302][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00020 | loss1:0.0320 loss2:0.7510 loss3:0.0753 | AUC:0.8369 Anomaly AUC:0.6560
[2023-09-17 17:42:26,092][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00019 | loss1:0.0178 loss2:0.7254 loss3:0.0694 | AUC:0.8324 Anomaly AUC:0.6623
[2023-09-17 17:42:45,872][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00019 | loss1:0.0164 loss2:0.7067 loss3:0.0666 | AUC:0.8396 Anomaly AUC:0.6605
[2023-09-17 17:43:05,642][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00019 | loss1:0.0320 loss2:0.7056 loss3:0.0679 | AUC:0.8365 Anomaly AUC:0.6662
[2023-09-17 17:43:25,548][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00019 | loss1:0.0233 loss2:0.6827 loss3:0.0650 | AUC:0.8350 Anomaly AUC:0.6600
[2023-09-17 17:43:45,350][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00019 | loss1:0.0343 loss2:0.6796 loss3:0.0693 | AUC:0.8334 Anomaly AUC:0.6577
[2023-09-17 17:44:00,818][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:44:03,850][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 17:44:03,850][main.py][line:168][INFO] Training Mode
[2023-09-17 17:44:03,851][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:44:03,851][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 17:44:11,570][main.py][line:82][INFO] Random initialize AUCAUC:0.4734 Anomaly AUC:0.50240
[2023-09-17 17:44:30,802][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00020 | loss1:0.4779 loss2:1.2842 loss3:0.2962 | AUC:0.8233 Anomaly AUC:0.6332
[2023-09-17 17:44:49,931][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00020 | loss1:0.2081 loss2:1.0771 loss3:0.1408 | AUC:0.8403 Anomaly AUC:0.6623
[2023-09-17 17:45:09,362][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00020 | loss1:0.0952 loss2:0.9706 loss3:0.1115 | AUC:0.8433 Anomaly AUC:0.6550
[2023-09-17 17:45:28,908][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00020 | loss1:0.0680 loss2:0.9082 loss3:0.0992 | AUC:0.8480 Anomaly AUC:0.6575
[2023-09-17 17:45:48,451][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00020 | loss1:0.0487 loss2:0.8657 loss3:0.0890 | AUC:0.8458 Anomaly AUC:0.6629
[2023-09-17 17:46:07,991][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00020 | loss1:0.0435 loss2:0.8317 loss3:0.0856 | AUC:0.8430 Anomaly AUC:0.6572
[2023-09-17 17:46:27,781][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00020 | loss1:0.0320 loss2:0.8042 loss3:0.0826 | AUC:0.8352 Anomaly AUC:0.6538
[2023-09-17 17:46:47,373][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00020 | loss1:0.0336 loss2:0.7852 loss3:0.0811 | AUC:0.8468 Anomaly AUC:0.6567
[2023-09-17 17:47:07,031][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00020 | loss1:0.0230 loss2:0.7587 loss3:0.0763 | AUC:0.8311 Anomaly AUC:0.6553
[2023-09-17 17:47:26,758][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00020 | loss1:0.0264 loss2:0.7416 loss3:0.0730 | AUC:0.8363 Anomaly AUC:0.6600
[2023-09-17 17:47:46,396][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00020 | loss1:0.0327 loss2:0.7294 loss3:0.0720 | AUC:0.8274 Anomaly AUC:0.6460
[2023-09-17 17:48:06,193][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00020 | loss1:0.0277 loss2:0.7131 loss3:0.0690 | AUC:0.8396 Anomaly AUC:0.6663
[2023-09-17 17:48:26,113][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00020 | loss1:0.0179 loss2:0.6889 loss3:0.0653 | AUC:0.8357 Anomaly AUC:0.6644
[2023-09-17 17:48:46,050][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00020 | loss1:0.0193 loss2:0.6730 loss3:0.0642 | AUC:0.8422 Anomaly AUC:0.6668
[2023-09-17 17:49:06,013][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00020 | loss1:0.0229 loss2:0.6618 loss3:0.0648 | AUC:0.8308 Anomaly AUC:0.6590
[2023-09-17 17:49:25,901][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00020 | loss1:0.0142 loss2:0.6430 loss3:0.0630 | AUC:0.8329 Anomaly AUC:0.6537
[2023-09-17 17:49:45,768][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00020 | loss1:0.0236 loss2:0.5980 loss3:0.0628 | AUC:0.8150 Anomaly AUC:0.6469
[2023-09-17 17:50:17,563][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:50:20,668][main.py][line:165][INFO] total params:6.4925M
[2023-09-17 17:50:20,669][main.py][line:168][INFO] Training Mode
[2023-09-17 17:50:20,669][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:50:20,669][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 17:51:12,173][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:51:15,271][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 17:51:15,271][main.py][line:168][INFO] Training Mode
[2023-09-17 17:51:15,271][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:51:15,272][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)

[2023-09-17 17:51:22,890][main.py][line:82][INFO] Random initialize AUCAUC:0.4756 Anomaly AUC:0.51091
[2023-09-17 17:51:42,141][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00030 | loss1:0.5373 loss2:1.2962 loss3:0.3290 | AUC:0.8265 Anomaly AUC:0.6291
[2023-09-17 17:52:01,192][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00030 | loss1:0.2242 loss2:1.0598 loss3:0.1539 | AUC:0.8407 Anomaly AUC:0.6485
[2023-09-17 17:52:20,686][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00030 | loss1:0.0987 loss2:0.9285 loss3:0.1166 | AUC:0.8421 Anomaly AUC:0.6540
[2023-09-17 17:52:40,251][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00030 | loss1:0.0612 loss2:0.8559 loss3:0.1051 | AUC:0.8227 Anomaly AUC:0.6537
[2023-09-17 17:52:59,899][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00030 | loss1:0.0441 loss2:0.8064 loss3:0.0961 | AUC:0.8415 Anomaly AUC:0.6614
[2023-09-17 17:53:19,802][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00030 | loss1:0.0376 loss2:0.7714 loss3:0.0871 | AUC:0.8406 Anomaly AUC:0.6583
[2023-09-17 17:53:39,659][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00030 | loss1:0.0327 loss2:0.7385 loss3:0.0847 | AUC:0.8371 Anomaly AUC:0.6542
[2023-09-17 17:53:59,457][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00030 | loss1:0.0234 loss2:0.7063 loss3:0.0814 | AUC:0.8304 Anomaly AUC:0.6490
[2023-09-17 17:54:19,263][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00030 | loss1:0.0239 loss2:0.6447 loss3:0.0806 | AUC:0.8105 Anomaly AUC:0.6293
[2023-09-17 17:54:39,093][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00030 | loss1:0.0321 loss2:0.6596 loss3:0.0815 | AUC:0.8148 Anomaly AUC:0.6386
[2023-09-17 17:54:58,797][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00030 | loss1:0.0237 loss2:0.6076 loss3:0.0811 | AUC:0.8146 Anomaly AUC:0.6391
[2023-09-17 17:55:18,776][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00030 | loss1:0.0121 loss2:0.5982 loss3:0.0768 | AUC:0.8213 Anomaly AUC:0.6445
[2023-09-17 17:56:35,662][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:57:40,268][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 100, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 17:57:43,305][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 17:57:43,305][main.py][line:168][INFO] Training Mode
[2023-09-17 17:57:43,305][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 17:57:43,305][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 17:57:50,977][main.py][line:82][INFO] Random initialize AUCAUC:0.4756 Anomaly AUC:0.51091
[2023-09-17 17:58:10,086][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.4913 loss2:1.3859 loss3:0.3319 | AUC:0.8296 Anomaly AUC:0.6055
[2023-09-17 17:58:29,086][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.1846 loss2:1.3259 loss3:0.1671 | AUC:0.8281 Anomaly AUC:0.6132
[2023-09-17 17:58:48,516][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0594 loss2:1.2591 loss3:0.1256 | AUC:0.8334 Anomaly AUC:0.6159
[2023-09-17 17:59:08,098][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0370 loss2:1.2031 loss3:0.1144 | AUC:0.8361 Anomaly AUC:0.6429
[2023-09-17 17:59:27,724][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0181 loss2:1.1364 loss3:0.1052 | AUC:0.8312 Anomaly AUC:0.6404
[2023-09-17 17:59:47,472][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0194 loss2:1.0825 loss3:0.1024 | AUC:0.8381 Anomaly AUC:0.6358
[2023-09-17 18:00:07,219][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0221 loss2:1.0382 loss3:0.1008 | AUC:0.8439 Anomaly AUC:0.6539
[2023-09-17 18:00:27,165][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0167 loss2:0.9814 loss3:0.0942 | AUC:0.8424 Anomaly AUC:0.6574
[2023-09-17 18:00:47,122][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0129 loss2:0.9254 loss3:0.0837 | AUC:0.8357 Anomaly AUC:0.6516
[2023-09-17 18:01:06,984][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0123 loss2:0.8716 loss3:0.0802 | AUC:0.8405 Anomaly AUC:0.6611
[2023-09-17 18:01:26,887][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0174 loss2:0.8269 loss3:0.0790 | AUC:0.8419 Anomaly AUC:0.6529
[2023-09-17 18:01:46,865][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0136 loss2:0.8000 loss3:0.0774 | AUC:0.8374 Anomaly AUC:0.6463
[2023-09-17 18:02:06,780][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0132 loss2:0.7494 loss3:0.0753 | AUC:0.8419 Anomaly AUC:0.6549
[2023-09-17 18:02:26,651][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0118 loss2:0.6916 loss3:0.0730 | AUC:0.8428 Anomaly AUC:0.6621
[2023-09-17 18:02:46,612][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0180 loss2:0.6579 loss3:0.0726 | AUC:0.8416 Anomaly AUC:0.6471
[2023-09-17 18:03:06,612][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0089 loss2:0.6089 loss3:0.0694 | AUC:0.8442 Anomaly AUC:0.6634
[2023-09-17 18:03:26,582][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0050 loss2:0.5594 loss3:0.0666 | AUC:0.8417 Anomaly AUC:0.6638
[2023-09-17 18:03:46,612][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0038 loss2:0.5046 loss3:0.0644 | AUC:0.8100 Anomaly AUC:0.6357
[2023-09-17 18:04:06,617][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0200 loss2:0.5281 loss3:0.0670 | AUC:0.8438 Anomaly AUC:0.6646
[2023-09-17 18:04:26,620][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0104 loss2:0.4864 loss3:0.0646 | AUC:0.8027 Anomaly AUC:0.6537
[2023-09-17 18:04:46,592][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0145 loss2:0.4673 loss3:0.0647 | AUC:0.8448 Anomaly AUC:0.6669
[2023-09-17 18:05:06,666][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0268 loss2:0.4554 loss3:0.0660 | AUC:0.8338 Anomaly AUC:0.6566
[2023-09-17 18:05:26,701][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0089 loss2:0.4204 loss3:0.0632 | AUC:0.8221 Anomaly AUC:0.6518
[2023-09-17 18:05:46,807][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0075 loss2:0.3684 loss3:0.0613 | AUC:0.8263 Anomaly AUC:0.6539
[2023-09-17 18:06:06,812][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0188 loss2:0.3765 loss3:0.0628 | AUC:0.8329 Anomaly AUC:0.6543
[2023-09-17 18:06:29,558][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:06:32,648][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 18:06:32,648][main.py][line:168][INFO] Training Mode
[2023-09-17 18:06:32,649][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:06:32,649][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:06:40,314][main.py][line:82][INFO] Random initialize AUCAUC:0.4756 Anomaly AUC:0.51091
[2023-09-17 18:06:59,526][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.4913 loss2:1.3859 loss3:0.3319 | AUC:0.8296 Anomaly AUC:0.6055
[2023-09-17 18:07:18,848][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1820 loss2:1.3264 loss3:0.1665 | AUC:0.8290 Anomaly AUC:0.6195
[2023-09-17 18:07:38,219][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0610 loss2:1.2587 loss3:0.1258 | AUC:0.8347 Anomaly AUC:0.6201
[2023-09-17 18:07:57,735][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00049 | loss1:0.0316 loss2:1.2015 loss3:0.1127 | AUC:0.8379 Anomaly AUC:0.6437
[2023-09-17 18:08:17,285][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00049 | loss1:0.0198 loss2:1.1346 loss3:0.1057 | AUC:0.8246 Anomaly AUC:0.6224
[2023-09-17 18:08:37,047][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00049 | loss1:0.0258 loss2:1.0879 loss3:0.1025 | AUC:0.8331 Anomaly AUC:0.6236
[2023-09-17 18:08:56,744][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00048 | loss1:0.0175 loss2:1.0448 loss3:0.0968 | AUC:0.8297 Anomaly AUC:0.6342
[2023-09-17 18:09:16,442][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00048 | loss1:0.0247 loss2:0.9983 loss3:0.0939 | AUC:0.8372 Anomaly AUC:0.6407
[2023-09-17 18:09:36,238][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00047 | loss1:0.0111 loss2:0.9354 loss3:0.0807 | AUC:0.8433 Anomaly AUC:0.6694
[2023-09-17 18:09:55,977][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00047 | loss1:0.0106 loss2:0.8901 loss3:0.0786 | AUC:0.8456 Anomaly AUC:0.6614
[2023-09-17 18:10:15,754][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00046 | loss1:0.0119 loss2:0.8341 loss3:0.0765 | AUC:0.8330 Anomaly AUC:0.6478
[2023-09-17 18:10:35,746][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00045 | loss1:0.0116 loss2:0.7924 loss3:0.0755 | AUC:0.8353 Anomaly AUC:0.6493
[2023-09-17 18:10:55,646][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00044 | loss1:0.0100 loss2:0.7330 loss3:0.0731 | AUC:0.8349 Anomaly AUC:0.6469
[2023-09-17 18:11:15,496][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00044 | loss1:0.0147 loss2:0.7125 loss3:0.0738 | AUC:0.8372 Anomaly AUC:0.6482
[2023-09-17 18:11:35,342][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00043 | loss1:0.0090 loss2:0.6678 loss3:0.0710 | AUC:0.8385 Anomaly AUC:0.6484
[2023-09-17 18:11:55,288][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00042 | loss1:0.0154 loss2:0.6319 loss3:0.0696 | AUC:0.8400 Anomaly AUC:0.6566
[2023-09-17 18:12:15,180][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00041 | loss1:0.0067 loss2:0.6112 loss3:0.0676 | AUC:0.8197 Anomaly AUC:0.6425
[2023-09-17 18:12:35,002][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00040 | loss1:0.0173 loss2:0.5354 loss3:0.0677 | AUC:0.7702 Anomaly AUC:0.6410
[2023-09-17 18:12:54,917][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00039 | loss1:0.0183 loss2:0.5061 loss3:0.0677 | AUC:0.8428 Anomaly AUC:0.6618
[2023-09-17 18:13:14,741][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00038 | loss1:0.0033 loss2:0.5296 loss3:0.0638 | AUC:0.8133 Anomaly AUC:0.6465
[2023-09-17 18:13:34,663][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00036 | loss1:0.0122 loss2:0.5094 loss3:0.0643 | AUC:0.8470 Anomaly AUC:0.6658
[2023-09-17 18:13:54,768][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00035 | loss1:0.0024 loss2:0.4714 loss3:0.0625 | AUC:0.8448 Anomaly AUC:0.6677
[2023-09-17 18:14:14,796][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00034 | loss1:0.0092 loss2:0.4459 loss3:0.0626 | AUC:0.8433 Anomaly AUC:0.6726
[2023-09-17 18:14:34,837][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00033 | loss1:0.0014 loss2:0.4148 loss3:0.0606 | AUC:0.8475 Anomaly AUC:0.6730
[2023-09-17 18:14:54,831][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00031 | loss1:0.0010 loss2:0.3770 loss3:0.0597 | AUC:0.8412 Anomaly AUC:0.6674
[2023-09-17 18:15:14,643][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.0003 loss2:0.3471 loss3:0.0589 | AUC:0.8394 Anomaly AUC:0.6645
[2023-09-17 18:15:34,770][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00029 | loss1:0.0056 loss2:0.3436 loss3:0.0598 | AUC:0.8392 Anomaly AUC:0.6557
[2023-09-17 18:15:54,699][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00028 | loss1:0.0058 loss2:0.3261 loss3:0.0597 | AUC:0.8408 Anomaly AUC:0.6569
[2023-09-17 18:16:14,817][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00026 | loss1:0.0012 loss2:0.2951 loss3:0.0581 | AUC:0.8325 Anomaly AUC:0.6547
[2023-09-17 18:16:34,666][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00025 | loss1:0.0045 loss2:0.2787 loss3:0.0584 | AUC:0.8405 Anomaly AUC:0.6586
[2023-09-17 18:16:54,758][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00024 | loss1:0.0004 loss2:0.2520 loss3:0.0574 | AUC:0.8315 Anomaly AUC:0.6536
[2023-09-17 18:17:14,883][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00022 | loss1:0.0002 loss2:0.2251 loss3:0.0571 | AUC:0.8340 Anomaly AUC:0.6533
[2023-09-17 18:17:34,991][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00021 | loss1:0.0002 loss2:0.2085 loss3:0.0569 | AUC:0.8295 Anomaly AUC:0.6532
[2023-09-17 18:18:00,883][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:18:03,931][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 18:18:03,931][main.py][line:168][INFO] Training Mode
[2023-09-17 18:18:03,931][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:18:03,931][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:18:11,482][main.py][line:82][INFO] Random initialize AUCAUC:0.4756 Anomaly AUC:0.51091
[2023-09-17 18:18:30,854][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.7637 loss2:1.4039 loss3:0.4204 | AUC:0.7970 Anomaly AUC:0.5784
[2023-09-17 18:18:50,306][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.3966 loss2:1.3888 loss3:0.3748 | AUC:0.8138 Anomaly AUC:0.6052
[2023-09-17 18:19:09,934][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.2482 loss2:1.3748 loss3:0.3215 | AUC:0.8092 Anomaly AUC:0.5998
[2023-09-17 18:19:29,737][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.1436 loss2:1.3626 loss3:0.2497 | AUC:0.8207 Anomaly AUC:0.6134
[2023-09-17 18:19:49,583][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0796 loss2:1.3476 loss3:0.1790 | AUC:0.8119 Anomaly AUC:0.6303
[2023-09-17 18:20:09,364][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0514 loss2:1.3322 loss3:0.1419 | AUC:0.8390 Anomaly AUC:0.6469
[2023-09-17 18:20:29,340][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0407 loss2:1.3155 loss3:0.1253 | AUC:0.8301 Anomaly AUC:0.6262
[2023-09-17 18:20:49,185][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0288 loss2:1.3008 loss3:0.1161 | AUC:0.8385 Anomaly AUC:0.6513
[2023-09-17 18:21:09,135][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0236 loss2:1.2845 loss3:0.1101 | AUC:0.8434 Anomaly AUC:0.6573
[2023-09-17 18:21:29,081][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0221 loss2:1.2720 loss3:0.1066 | AUC:0.8411 Anomaly AUC:0.6585
[2023-09-17 18:21:49,046][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0244 loss2:1.2576 loss3:0.1053 | AUC:0.8364 Anomaly AUC:0.6353
[2023-09-17 18:22:08,992][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0223 loss2:1.2487 loss3:0.1049 | AUC:0.8347 Anomaly AUC:0.6497
[2023-09-17 18:22:28,915][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0144 loss2:1.2303 loss3:0.1006 | AUC:0.8287 Anomaly AUC:0.6525
[2023-09-17 18:22:48,822][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0220 loss2:1.2138 loss3:0.1002 | AUC:0.8353 Anomaly AUC:0.6586
[2023-09-17 18:23:08,855][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0192 loss2:1.1984 loss3:0.0993 | AUC:0.8294 Anomaly AUC:0.6471
[2023-09-17 18:23:28,818][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0156 loss2:1.1853 loss3:0.0973 | AUC:0.8265 Anomaly AUC:0.6568
[2023-09-17 18:24:00,053][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:24:03,137][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 18:24:03,137][main.py][line:168][INFO] Training Mode
[2023-09-17 18:24:03,138][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:24:03,138][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:24:10,826][main.py][line:82][INFO] Random initialize AUCAUC:0.4756 Anomaly AUC:0.51091
[2023-09-17 18:24:30,279][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.7596 loss2:1.4047 loss3:0.3821 | AUC:0.7986 Anomaly AUC:0.5802
[2023-09-17 18:24:49,514][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.3951 loss2:1.3905 loss3:0.3418 | AUC:0.8084 Anomaly AUC:0.6061
[2023-09-17 18:25:09,145][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.2523 loss2:1.3739 loss3:0.2505 | AUC:0.8228 Anomaly AUC:0.6156
[2023-09-17 18:25:28,753][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.1442 loss2:1.3582 loss3:0.1485 | AUC:0.8276 Anomaly AUC:0.6272
[2023-09-17 18:25:48,501][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0847 loss2:1.3435 loss3:0.0801 | AUC:0.8000 Anomaly AUC:0.6281
[2023-09-17 18:26:08,437][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0631 loss2:1.3316 loss3:0.0503 | AUC:0.8222 Anomaly AUC:0.6355
[2023-09-17 18:26:28,400][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0416 loss2:1.3167 loss3:0.0360 | AUC:0.8270 Anomaly AUC:0.6374
[2023-09-17 18:26:48,273][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0306 loss2:1.3019 loss3:0.0280 | AUC:0.8263 Anomaly AUC:0.6538
[2023-09-17 18:27:08,173][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0308 loss2:1.2852 loss3:0.0239 | AUC:0.8379 Anomaly AUC:0.6408
[2023-09-17 18:27:28,068][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0250 loss2:1.2726 loss3:0.0212 | AUC:0.8375 Anomaly AUC:0.6544
[2023-09-17 18:27:48,032][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0252 loss2:1.2594 loss3:0.0195 | AUC:0.8296 Anomaly AUC:0.6466
[2023-09-17 18:28:08,183][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0174 loss2:1.2454 loss3:0.0155 | AUC:0.8248 Anomaly AUC:0.6475
[2023-09-17 18:28:28,060][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0154 loss2:1.2289 loss3:0.0119 | AUC:0.8271 Anomaly AUC:0.6440
[2023-09-17 18:28:48,358][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0216 loss2:1.2131 loss3:0.0119 | AUC:0.8405 Anomaly AUC:0.6567
[2023-09-17 18:29:08,542][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0162 loss2:1.1944 loss3:0.0088 | AUC:0.8372 Anomaly AUC:0.6614
[2023-09-17 18:29:28,465][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0155 loss2:1.1829 loss3:0.0077 | AUC:0.8320 Anomaly AUC:0.6427
[2023-09-17 18:29:48,562][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0126 loss2:1.1679 loss3:0.0072 | AUC:0.8336 Anomaly AUC:0.6563
[2023-09-17 18:30:08,476][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0117 loss2:1.1465 loss3:0.0058 | AUC:0.8323 Anomaly AUC:0.6530
[2023-09-17 18:30:28,661][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0104 loss2:1.1332 loss3:0.0057 | AUC:0.8420 Anomaly AUC:0.6639
[2023-09-17 18:30:48,737][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0113 loss2:1.1173 loss3:0.0062 | AUC:0.8373 Anomaly AUC:0.6550
[2023-09-17 18:31:08,783][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0118 loss2:1.1039 loss3:0.0062 | AUC:0.8411 Anomaly AUC:0.6691
[2023-09-17 18:31:28,899][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0155 loss2:1.0872 loss3:0.0067 | AUC:0.8446 Anomaly AUC:0.6614
[2023-09-17 18:31:48,996][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0110 loss2:1.0655 loss3:0.0051 | AUC:0.8421 Anomaly AUC:0.6639
[2023-09-17 18:32:09,043][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0171 loss2:1.0602 loss3:0.0064 | AUC:0.8480 Anomaly AUC:0.6636
[2023-09-17 18:32:29,163][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0090 loss2:1.0381 loss3:0.0044 | AUC:0.8480 Anomaly AUC:0.6600
[2023-09-17 18:32:49,314][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0110 loss2:1.0240 loss3:0.0041 | AUC:0.8441 Anomaly AUC:0.6563
[2023-09-17 18:33:09,631][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0140 loss2:1.0091 loss3:0.0049 | AUC:0.8481 Anomaly AUC:0.6558
[2023-09-17 18:33:29,811][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0132 loss2:0.9901 loss3:0.0042 | AUC:0.8483 Anomaly AUC:0.6569
[2023-09-17 18:33:49,832][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0082 loss2:0.9722 loss3:0.0032 | AUC:0.8496 Anomaly AUC:0.6610
[2023-09-17 18:34:09,798][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0163 loss2:0.9626 loss3:0.0047 | AUC:0.8487 Anomaly AUC:0.6635
[2023-09-17 18:34:30,009][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0096 loss2:0.9449 loss3:0.0033 | AUC:0.8473 Anomaly AUC:0.6628
[2023-09-17 18:34:43,510][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:34:46,512][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 18:34:46,512][main.py][line:168][INFO] Training Mode
[2023-09-17 18:34:46,512][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:34:46,513][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:35:16,501][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 30, 'n_nums': 30, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:35:19,538][main.py][line:165][INFO] total params:6.4915M
[2023-09-17 18:35:19,538][main.py][line:168][INFO] Training Mode
[2023-09-17 18:35:19,539][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:35:19,539][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:35:27,247][main.py][line:82][INFO] Random initialize AUCAUC:0.4913 Anomaly AUC:0.49610
[2023-09-17 18:35:46,638][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.7936 loss2:1.4069 loss3:0.4526 | AUC:0.7759 Anomaly AUC:0.5548
[2023-09-17 18:36:05,979][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.2017 loss2:1.3892 loss3:0.3703 | AUC:0.8008 Anomaly AUC:0.5881
[2023-09-17 18:36:25,591][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.0494 loss2:1.3708 loss3:0.2659 | AUC:0.7926 Anomaly AUC:0.5838
[2023-09-17 18:36:45,340][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.0316 loss2:1.3499 loss3:0.2004 | AUC:0.7762 Anomaly AUC:0.5724
[2023-09-17 18:37:05,161][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.0237 loss2:1.3263 loss3:0.1748 | AUC:0.7538 Anomaly AUC:0.5592
[2023-09-17 18:37:24,857][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0193 loss2:1.3003 loss3:0.1590 | AUC:0.7857 Anomaly AUC:0.5713
[2023-09-17 18:37:44,820][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0190 loss2:1.2819 loss3:0.1492 | AUC:0.7737 Anomaly AUC:0.5707
[2023-09-17 18:38:04,815][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0149 loss2:1.2676 loss3:0.1394 | AUC:0.7889 Anomaly AUC:0.5785
[2023-09-17 18:38:24,920][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0132 loss2:1.2406 loss3:0.1322 | AUC:0.7852 Anomaly AUC:0.5721
[2023-09-17 18:39:54,170][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:39:57,178][main.py][line:165][INFO] total params:6.5232M
[2023-09-17 18:39:57,178][main.py][line:168][INFO] Training Mode
[2023-09-17 18:39:57,178][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:39:57,179][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:42:26,169][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:42:29,206][main.py][line:165][INFO] total params:6.5232M
[2023-09-17 18:42:29,207][main.py][line:168][INFO] Training Mode
[2023-09-17 18:42:29,207][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:42:29,207][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:42:47,169][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:42:50,202][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 18:42:50,202][main.py][line:168][INFO] Training Mode
[2023-09-17 18:42:50,202][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:42:50,202][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:43:55,147][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:43:58,120][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 18:43:58,120][main.py][line:168][INFO] Training Mode
[2023-09-17 18:43:58,121][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:43:58,121][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:44:05,822][main.py][line:82][INFO] Random initialize AUCAUC:0.4599 Anomaly AUC:0.48250
[2023-09-17 18:44:25,056][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.8747 loss2:1.4075 loss3:0.5332 | AUC:0.7940 Anomaly AUC:0.5794
[2023-09-17 18:44:44,115][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.4973 loss2:1.3983 loss3:0.4488 | AUC:0.8075 Anomaly AUC:0.5940
[2023-09-17 18:45:03,533][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.3320 loss2:1.3911 loss3:0.4102 | AUC:0.8168 Anomaly AUC:0.6001
[2023-09-17 18:45:23,026][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.2373 loss2:1.3827 loss3:0.3508 | AUC:0.8188 Anomaly AUC:0.5982
[2023-09-17 18:45:42,672][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.1649 loss2:1.3757 loss3:0.2824 | AUC:0.8187 Anomaly AUC:0.5935
[2023-09-17 18:46:02,457][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0904 loss2:1.3661 loss3:0.2239 | AUC:0.8167 Anomaly AUC:0.6075
[2023-09-17 18:46:22,198][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0532 loss2:1.3581 loss3:0.1885 | AUC:0.8060 Anomaly AUC:0.5918
[2023-09-17 18:46:41,970][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0324 loss2:1.3400 loss3:0.1676 | AUC:0.8061 Anomaly AUC:0.6021
[2023-09-17 18:47:01,764][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0224 loss2:1.3245 loss3:0.1545 | AUC:0.8203 Anomaly AUC:0.6103
[2023-09-17 18:47:21,756][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0181 loss2:1.2933 loss3:0.1463 | AUC:0.8231 Anomaly AUC:0.5980
[2023-09-17 18:47:41,696][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0209 loss2:1.2755 loss3:0.1415 | AUC:0.8404 Anomaly AUC:0.6103
[2023-09-17 18:48:01,566][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0139 loss2:1.2346 loss3:0.1356 | AUC:0.8224 Anomaly AUC:0.6049
[2023-09-17 18:48:21,346][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0113 loss2:1.2201 loss3:0.1323 | AUC:0.8274 Anomaly AUC:0.5943
[2023-09-17 18:48:41,083][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0129 loss2:1.1406 loss3:0.1300 | AUC:0.8382 Anomaly AUC:0.6181
[2023-09-17 18:49:00,830][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0130 loss2:1.1529 loss3:0.1274 | AUC:0.8233 Anomaly AUC:0.6030
[2023-09-17 18:49:32,410][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 18:49:35,452][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 18:49:35,452][main.py][line:168][INFO] Training Mode
[2023-09-17 18:49:35,452][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 18:49:35,453][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 18:49:43,036][main.py][line:82][INFO] Random initialize AUCAUC:0.4599 Anomaly AUC:0.48250
[2023-09-17 18:50:02,385][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.8784 loss2:1.3904 loss3:0.5339 | AUC:0.7963 Anomaly AUC:0.5853
[2023-09-17 18:50:21,519][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.4964 loss2:1.3162 loss3:0.4526 | AUC:0.8140 Anomaly AUC:0.6082
[2023-09-17 18:50:40,993][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.3384 loss2:1.2102 loss3:0.4196 | AUC:0.8397 Anomaly AUC:0.6413
[2023-09-17 18:51:00,501][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.2296 loss2:1.1177 loss3:0.3685 | AUC:0.8442 Anomaly AUC:0.6547
[2023-09-17 18:51:20,113][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.1380 loss2:1.0477 loss3:0.3056 | AUC:0.8462 Anomaly AUC:0.6530
[2023-09-17 18:51:39,802][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0716 loss2:0.9822 loss3:0.2499 | AUC:0.8500 Anomaly AUC:0.6544
[2023-09-17 18:51:59,659][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0522 loss2:0.9266 loss3:0.2142 | AUC:0.8418 Anomaly AUC:0.6494
[2023-09-17 18:52:19,377][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0346 loss2:0.8801 loss3:0.1920 | AUC:0.8413 Anomaly AUC:0.6540
[2023-09-17 18:52:39,249][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0269 loss2:0.8445 loss3:0.1770 | AUC:0.8406 Anomaly AUC:0.6485
[2023-09-17 18:52:59,056][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0289 loss2:0.8147 loss3:0.1662 | AUC:0.8368 Anomaly AUC:0.6538
[2023-09-17 18:53:18,888][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0324 loss2:0.7994 loss3:0.1585 | AUC:0.8382 Anomaly AUC:0.6556
[2023-09-17 18:53:38,919][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0183 loss2:0.7699 loss3:0.1506 | AUC:0.8384 Anomaly AUC:0.6563
[2023-09-17 18:53:58,766][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0184 loss2:0.7513 loss3:0.1451 | AUC:0.8406 Anomaly AUC:0.6504
[2023-09-17 18:54:18,569][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0154 loss2:0.7342 loss3:0.1402 | AUC:0.8405 Anomaly AUC:0.6423
[2023-09-17 18:54:38,592][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0177 loss2:0.7167 loss3:0.1369 | AUC:0.8339 Anomaly AUC:0.6401
[2023-09-17 18:54:58,445][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0319 loss2:0.7150 loss3:0.1353 | AUC:0.8346 Anomaly AUC:0.6425
[2023-09-17 18:55:18,490][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0192 loss2:0.6992 loss3:0.1318 | AUC:0.8352 Anomaly AUC:0.6340
[2023-09-17 18:55:38,516][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0352 loss2:0.6959 loss3:0.1320 | AUC:0.8412 Anomaly AUC:0.6367
[2023-09-17 18:55:58,424][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0153 loss2:0.6739 loss3:0.1278 | AUC:0.8418 Anomaly AUC:0.6413
[2023-09-17 18:56:18,497][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0128 loss2:0.6553 loss3:0.1272 | AUC:0.8438 Anomaly AUC:0.6479
[2023-09-17 18:56:38,656][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0254 loss2:0.6576 loss3:0.1291 | AUC:0.8370 Anomaly AUC:0.6501
[2023-09-17 18:56:58,729][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0192 loss2:0.6514 loss3:0.1287 | AUC:0.8363 Anomaly AUC:0.6414
[2023-09-17 18:57:18,685][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0129 loss2:0.6329 loss3:0.1269 | AUC:0.8396 Anomaly AUC:0.6489
[2023-09-17 18:57:38,937][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0119 loss2:0.6224 loss3:0.1272 | AUC:0.8359 Anomaly AUC:0.6400
[2023-09-17 18:57:58,904][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0141 loss2:0.6132 loss3:0.1279 | AUC:0.8240 Anomaly AUC:0.6249
[2023-09-17 18:58:18,956][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0138 loss2:0.6048 loss3:0.1261 | AUC:0.8311 Anomaly AUC:0.6355
[2023-09-17 18:58:38,956][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0177 loss2:0.5962 loss3:0.1268 | AUC:0.8338 Anomaly AUC:0.6315
[2023-09-17 18:58:58,931][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0123 loss2:0.5858 loss3:0.1242 | AUC:0.8318 Anomaly AUC:0.6412
[2023-09-17 18:59:18,871][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0121 loss2:0.5749 loss3:0.1247 | AUC:0.8354 Anomaly AUC:0.6407
[2023-09-17 18:59:38,941][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0103 loss2:0.5609 loss3:0.1240 | AUC:0.8327 Anomaly AUC:0.6295
[2023-09-17 18:59:59,003][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0105 loss2:0.5494 loss3:0.1229 | AUC:0.8313 Anomaly AUC:0.6329
[2023-09-17 19:00:19,080][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.0105 loss2:0.5377 loss3:0.1214 | AUC:0.8294 Anomaly AUC:0.6251
[2023-09-17 19:00:39,228][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.0103 loss2:0.5283 loss3:0.1214 | AUC:0.8260 Anomaly AUC:0.6134
[2023-09-17 19:00:59,216][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.0137 loss2:0.5248 loss3:0.1207 | AUC:0.8313 Anomaly AUC:0.6358
[2023-09-17 19:01:19,235][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.0130 loss2:0.5151 loss3:0.1197 | AUC:0.8262 Anomaly AUC:0.6460
[2023-09-17 19:01:39,258][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.0197 loss2:0.5143 loss3:0.1223 | AUC:0.8270 Anomaly AUC:0.6378
[2023-09-17 19:01:59,085][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 19:02:02,203][main.py][line:165][INFO] total params:6.5222M
[2023-09-17 19:02:02,203][main.py][line:168][INFO] Training Mode
[2023-09-17 19:02:02,204][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (linear3): Linear(in_features=1024, out_features=512, bias=True)
    (dropout3): Dropout(p=0.5, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 19:02:02,204][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 19:02:09,723][main.py][line:82][INFO] Random initialize AUCAUC:0.4794 Anomaly AUC:0.47027
[2023-09-17 19:02:28,765][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.8707 loss2:1.3905 loss3:0.5143 | AUC:0.7957 Anomaly AUC:0.5832
[2023-09-17 19:02:47,950][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.5094 loss2:1.3211 loss3:0.4507 | AUC:0.8142 Anomaly AUC:0.6069
[2023-09-17 19:03:07,354][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.3430 loss2:1.2030 loss3:0.4199 | AUC:0.8343 Anomaly AUC:0.6373
[2023-09-17 19:03:26,807][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.2337 loss2:1.0924 loss3:0.3677 | AUC:0.8371 Anomaly AUC:0.6516
[2023-09-17 19:03:46,284][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.1399 loss2:1.0172 loss3:0.2967 | AUC:0.8382 Anomaly AUC:0.6582
[2023-09-17 19:04:05,818][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.0724 loss2:0.9547 loss3:0.2357 | AUC:0.8479 Anomaly AUC:0.6634
[2023-09-17 19:04:25,547][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.0484 loss2:0.9036 loss3:0.1970 | AUC:0.8388 Anomaly AUC:0.6601
[2023-09-17 19:04:45,451][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.0416 loss2:0.8685 loss3:0.1761 | AUC:0.8408 Anomaly AUC:0.6509
[2023-09-17 19:05:05,229][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0353 loss2:0.8453 loss3:0.1628 | AUC:0.8334 Anomaly AUC:0.6533
[2023-09-17 19:05:25,023][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0261 loss2:0.8131 loss3:0.1537 | AUC:0.8324 Anomaly AUC:0.6425
[2023-09-17 19:05:44,751][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0208 loss2:0.7908 loss3:0.1467 | AUC:0.8342 Anomaly AUC:0.6364
[2023-09-17 19:06:04,641][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0201 loss2:0.7707 loss3:0.1422 | AUC:0.8330 Anomaly AUC:0.6444
[2023-09-17 19:06:24,596][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0246 loss2:0.7561 loss3:0.1386 | AUC:0.8394 Anomaly AUC:0.6465
[2023-09-17 19:06:44,299][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0219 loss2:0.7434 loss3:0.1348 | AUC:0.8284 Anomaly AUC:0.6398
[2023-09-17 19:07:04,024][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0213 loss2:0.7247 loss3:0.1310 | AUC:0.8438 Anomaly AUC:0.6454
[2023-09-17 19:07:23,863][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0143 loss2:0.7098 loss3:0.1283 | AUC:0.8431 Anomaly AUC:0.6420
[2023-09-17 19:07:43,783][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0263 loss2:0.7029 loss3:0.1271 | AUC:0.8415 Anomaly AUC:0.6423
[2023-09-17 19:08:03,663][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0168 loss2:0.6883 loss3:0.1261 | AUC:0.8335 Anomaly AUC:0.6402
[2023-09-17 19:08:23,606][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0185 loss2:0.6749 loss3:0.1258 | AUC:0.8410 Anomaly AUC:0.6564
[2023-09-17 19:08:43,464][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0208 loss2:0.6686 loss3:0.1273 | AUC:0.8419 Anomaly AUC:0.6520
[2023-09-17 19:09:03,268][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0218 loss2:0.6621 loss3:0.1293 | AUC:0.8371 Anomaly AUC:0.6448
[2023-09-17 19:09:23,124][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0187 loss2:0.6504 loss3:0.1274 | AUC:0.8345 Anomaly AUC:0.6526
[2023-09-17 19:09:43,017][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0194 loss2:0.6423 loss3:0.1272 | AUC:0.8396 Anomaly AUC:0.6559
[2023-09-17 19:10:02,823][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0152 loss2:0.6288 loss3:0.1266 | AUC:0.8354 Anomaly AUC:0.6519
[2023-09-17 19:10:22,744][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0148 loss2:0.6177 loss3:0.1257 | AUC:0.8368 Anomaly AUC:0.6434
[2023-09-17 19:10:42,681][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0108 loss2:0.6024 loss3:0.1241 | AUC:0.8377 Anomaly AUC:0.6492
[2023-09-17 19:11:02,572][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0116 loss2:0.5924 loss3:0.1232 | AUC:0.8404 Anomaly AUC:0.6475
[2023-09-17 19:11:22,575][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0176 loss2:0.5879 loss3:0.1232 | AUC:0.8400 Anomaly AUC:0.6490
[2023-09-17 19:11:42,404][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0179 loss2:0.5838 loss3:0.1226 | AUC:0.8369 Anomaly AUC:0.6529
[2023-09-17 19:12:02,319][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0150 loss2:0.5741 loss3:0.1212 | AUC:0.8329 Anomaly AUC:0.6433
[2023-09-17 19:12:22,233][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0124 loss2:0.5582 loss3:0.1214 | AUC:0.8205 Anomaly AUC:0.6481
[2023-09-17 19:12:42,245][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.0152 loss2:0.5515 loss3:0.1213 | AUC:0.8305 Anomaly AUC:0.6505
[2023-09-17 19:13:02,148][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.0142 loss2:0.5410 loss3:0.1200 | AUC:0.8319 Anomaly AUC:0.6445
[2023-09-17 19:13:21,943][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.0130 loss2:0.5358 loss3:0.1195 | AUC:0.8302 Anomaly AUC:0.6431
[2023-09-17 19:13:41,790][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.0267 loss2:0.5372 loss3:0.1235 | AUC:0.8328 Anomaly AUC:0.6420
[2023-09-17 19:14:01,761][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.0127 loss2:0.5167 loss3:0.1170 | AUC:0.8354 Anomaly AUC:0.6533
[2023-09-17 19:14:21,737][main.py][line:106][INFO] [Epoch:37/50]: lr:0.00010 | loss1:0.0148 loss2:0.5102 loss3:0.1182 | AUC:0.8309 Anomaly AUC:0.6464
[2023-09-17 19:14:41,688][main.py][line:106][INFO] [Epoch:38/50]: lr:0.00010 | loss1:0.0111 loss2:0.4951 loss3:0.1164 | AUC:0.8375 Anomaly AUC:0.6454
[2023-09-17 19:15:01,762][main.py][line:106][INFO] [Epoch:39/50]: lr:0.00010 | loss1:0.0123 loss2:0.4888 loss3:0.1160 | AUC:0.8406 Anomaly AUC:0.6531
[2023-09-17 19:15:21,534][main.py][line:106][INFO] [Epoch:40/50]: lr:0.00010 | loss1:0.0120 loss2:0.4757 loss3:0.1150 | AUC:0.8373 Anomaly AUC:0.6503
[2023-09-17 19:15:41,412][main.py][line:106][INFO] [Epoch:41/50]: lr:0.00010 | loss1:0.0273 loss2:0.4835 loss3:0.1176 | AUC:0.8268 Anomaly AUC:0.6453
[2023-09-17 19:16:01,377][main.py][line:106][INFO] [Epoch:42/50]: lr:0.00010 | loss1:0.0132 loss2:0.4630 loss3:0.1119 | AUC:0.8340 Anomaly AUC:0.6520
[2023-09-17 19:16:21,465][main.py][line:106][INFO] [Epoch:43/50]: lr:0.00010 | loss1:0.0194 loss2:0.4641 loss3:0.1139 | AUC:0.8227 Anomaly AUC:0.6499
[2023-09-17 19:16:41,386][main.py][line:106][INFO] [Epoch:44/50]: lr:0.00010 | loss1:0.0148 loss2:0.4543 loss3:0.1127 | AUC:0.8276 Anomaly AUC:0.6478
[2023-09-17 19:17:01,582][main.py][line:106][INFO] [Epoch:45/50]: lr:0.00010 | loss1:0.0114 loss2:0.4361 loss3:0.1103 | AUC:0.8287 Anomaly AUC:0.6425
[2023-09-17 19:17:21,693][main.py][line:106][INFO] [Epoch:46/50]: lr:0.00010 | loss1:0.0111 loss2:0.4237 loss3:0.1105 | AUC:0.8322 Anomaly AUC:0.6457
[2023-09-17 19:17:41,783][main.py][line:106][INFO] [Epoch:47/50]: lr:0.00010 | loss1:0.0109 loss2:0.4120 loss3:0.1101 | AUC:0.8336 Anomaly AUC:0.6500
[2023-09-17 19:18:01,835][main.py][line:106][INFO] [Epoch:48/50]: lr:0.00010 | loss1:0.0106 loss2:0.4020 loss3:0.1097 | AUC:0.8332 Anomaly AUC:0.6498
[2023-09-17 19:18:21,991][main.py][line:106][INFO] [Epoch:49/50]: lr:0.00010 | loss1:0.0154 loss2:0.3949 loss3:0.1110 | AUC:0.8429 Anomaly AUC:0.6594
[2023-09-17 19:18:42,097][main.py][line:106][INFO] [Epoch:50/50]: lr:0.00010 | loss1:0.0365 loss2:0.4218 loss3:0.1166 | AUC:0.8276 Anomaly AUC:0.6504
[2023-09-17 19:18:42,118][main.py][line:116][INFO] Training completes in 16m 32s | best AUCAUC:0.8479 Anomaly AUC:0.6634

[2023-09-17 21:38:50,848][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 21:38:54,009][main.py][line:165][INFO] total params:5.9974M
[2023-09-17 21:38:54,009][main.py][line:168][INFO] Training Mode
[2023-09-17 21:38:54,010][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 21:38:54,010][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 21:40:16,019][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 21:40:19,046][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 21:40:19,046][main.py][line:168][INFO] Training Mode
[2023-09-17 21:40:19,047][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 21:40:19,047][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 21:40:27,143][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 21:40:46,471][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.7206 loss2:1.3824 loss3:0.4267 | AUC:0.7899 Anomaly AUC:0.5890
[2023-09-17 21:41:05,560][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.4492 loss2:1.2506 loss3:0.4007 | AUC:0.8012 Anomaly AUC:0.6094
[2023-09-17 21:41:24,923][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.3561 loss2:1.0990 loss3:0.3383 | AUC:0.8077 Anomaly AUC:0.6159
[2023-09-17 21:41:44,686][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.2882 loss2:0.9772 loss3:0.2971 | AUC:0.8123 Anomaly AUC:0.6175
[2023-09-17 21:42:04,408][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.2323 loss2:0.8764 loss3:0.3197 | AUC:0.8218 Anomaly AUC:0.6181
[2023-09-17 21:42:24,234][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.1847 loss2:0.7844 loss3:0.3359 | AUC:0.8138 Anomaly AUC:0.6093
[2023-09-17 21:42:44,232][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.1462 loss2:0.7087 loss3:0.3181 | AUC:0.8151 Anomaly AUC:0.6112
[2023-09-17 21:43:04,189][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.1092 loss2:0.6579 loss3:0.3065 | AUC:0.8195 Anomaly AUC:0.6086
[2023-09-17 21:43:24,085][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0906 loss2:0.5858 loss3:0.2745 | AUC:0.8074 Anomaly AUC:0.5926
[2023-09-17 21:43:44,041][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0657 loss2:0.5121 loss3:0.2318 | AUC:0.8162 Anomaly AUC:0.6088
[2023-09-17 21:44:04,005][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0487 loss2:0.4561 loss3:0.2085 | AUC:0.8195 Anomaly AUC:0.6080
[2023-09-17 21:44:24,249][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0384 loss2:0.4003 loss3:0.1958 | AUC:0.8226 Anomaly AUC:0.6087
[2023-09-17 21:44:44,143][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.0313 loss2:0.3676 loss3:0.1900 | AUC:0.8191 Anomaly AUC:0.6103
[2023-09-17 21:45:04,145][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.0238 loss2:0.3365 loss3:0.1899 | AUC:0.8217 Anomaly AUC:0.6067
[2023-09-17 21:45:24,202][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.0175 loss2:0.3189 loss3:0.1928 | AUC:0.8212 Anomaly AUC:0.6072
[2023-09-17 21:45:44,159][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.0173 loss2:0.2920 loss3:0.1973 | AUC:0.8149 Anomaly AUC:0.5970
[2023-09-17 21:46:04,266][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.0119 loss2:0.2826 loss3:0.1982 | AUC:0.8118 Anomaly AUC:0.5980
[2023-09-17 21:46:24,366][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.0111 loss2:0.2667 loss3:0.1996 | AUC:0.8071 Anomaly AUC:0.5955
[2023-09-17 21:46:44,419][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.0104 loss2:0.2536 loss3:0.1970 | AUC:0.8193 Anomaly AUC:0.5974
[2023-09-17 21:47:04,433][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.0097 loss2:0.2360 loss3:0.1968 | AUC:0.8230 Anomaly AUC:0.6008
[2023-09-17 21:47:24,636][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.0091 loss2:0.2346 loss3:0.2007 | AUC:0.8205 Anomaly AUC:0.6064
[2023-09-17 21:47:44,752][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.0105 loss2:0.2334 loss3:0.2074 | AUC:0.8186 Anomaly AUC:0.5998
[2023-09-17 21:48:04,843][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.0101 loss2:0.2255 loss3:0.2114 | AUC:0.8083 Anomaly AUC:0.5909
[2023-09-17 21:48:24,981][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.0095 loss2:0.2272 loss3:0.2256 | AUC:0.8181 Anomaly AUC:0.6113
[2023-09-17 21:48:45,134][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0076 loss2:0.2223 loss3:0.2286 | AUC:0.8099 Anomaly AUC:0.5974
[2023-09-17 21:49:05,331][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0087 loss2:0.2256 loss3:0.2425 | AUC:0.8109 Anomaly AUC:0.6050
[2023-09-17 21:49:25,464][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0073 loss2:0.2176 loss3:0.2604 | AUC:0.8181 Anomaly AUC:0.6012
[2023-09-17 21:49:45,606][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0073 loss2:0.2157 loss3:0.2625 | AUC:0.8230 Anomaly AUC:0.6034
[2023-09-17 21:50:05,753][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0093 loss2:0.2233 loss3:0.2946 | AUC:0.8178 Anomaly AUC:0.5960
[2023-09-17 21:50:25,886][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0105 loss2:0.2260 loss3:0.3143 | AUC:0.8194 Anomaly AUC:0.6006
[2023-09-17 21:53:06,459][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.2, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 21:53:09,805][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 21:53:09,805][main.py][line:168][INFO] Training Mode
[2023-09-17 21:53:09,806][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.2, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.2, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.2, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.2, inplace=False)
)

[2023-09-17 21:53:09,806][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 21:53:18,065][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 21:53:37,360][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.4074 loss2:1.3309 loss3:0.3403 | AUC:0.8209 Anomaly AUC:0.6162
[2023-09-17 21:53:56,670][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.1676 loss2:1.0883 loss3:0.2661 | AUC:0.8219 Anomaly AUC:0.6388
[2023-09-17 21:54:16,108][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.0647 loss2:0.9196 loss3:0.2740 | AUC:0.8276 Anomaly AUC:0.6461
[2023-09-17 21:54:35,872][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00050 | loss1:0.0385 loss2:0.7798 loss3:0.2706 | AUC:0.8327 Anomaly AUC:0.6486
[2023-09-17 21:54:55,644][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00050 | loss1:0.0253 loss2:0.6999 loss3:0.2495 | AUC:0.8326 Anomaly AUC:0.6322
[2023-09-17 21:55:15,622][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00050 | loss1:0.0407 loss2:0.6197 loss3:0.2423 | AUC:0.8232 Anomaly AUC:0.6258
[2023-09-17 21:55:35,600][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00050 | loss1:0.0141 loss2:0.5115 loss3:0.2184 | AUC:0.8218 Anomaly AUC:0.6367
[2023-09-17 21:55:55,620][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00050 | loss1:0.0152 loss2:0.4166 loss3:0.2071 | AUC:0.8342 Anomaly AUC:0.6541
[2023-09-17 21:56:15,748][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00050 | loss1:0.0129 loss2:0.3308 loss3:0.1902 | AUC:0.8147 Anomaly AUC:0.6334
[2023-09-17 21:56:35,878][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00050 | loss1:0.0127 loss2:0.2609 loss3:0.1829 | AUC:0.8225 Anomaly AUC:0.6464
[2023-09-17 21:56:55,870][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00050 | loss1:0.0089 loss2:0.2028 loss3:0.1816 | AUC:0.8164 Anomaly AUC:0.6399
[2023-09-17 21:57:16,013][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00050 | loss1:0.0236 loss2:0.1513 loss3:0.1711 | AUC:0.8071 Anomaly AUC:0.6368
[2023-09-17 21:57:36,016][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00050 | loss1:0.0077 loss2:0.1158 loss3:0.1689 | AUC:0.8285 Anomaly AUC:0.6539
[2023-09-17 21:57:55,989][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00050 | loss1:0.0073 loss2:0.0821 loss3:0.1593 | AUC:0.8123 Anomaly AUC:0.6476
[2023-09-17 21:58:16,129][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00050 | loss1:0.0043 loss2:0.0781 loss3:0.1553 | AUC:0.8302 Anomaly AUC:0.6493
[2023-09-17 21:58:36,252][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00050 | loss1:0.0052 loss2:0.0671 loss3:0.1574 | AUC:0.8202 Anomaly AUC:0.6410
[2023-09-17 21:58:56,279][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00050 | loss1:0.0117 loss2:0.0837 loss3:0.1631 | AUC:0.8084 Anomaly AUC:0.6364
[2023-09-17 21:59:16,253][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00050 | loss1:0.0076 loss2:0.0593 loss3:0.1531 | AUC:0.8258 Anomaly AUC:0.6430
[2023-09-17 21:59:36,370][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00050 | loss1:0.0064 loss2:0.0520 loss3:0.1489 | AUC:0.8251 Anomaly AUC:0.6546
[2023-09-17 21:59:56,521][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00050 | loss1:0.0062 loss2:0.0337 loss3:0.1423 | AUC:0.8266 Anomaly AUC:0.6411
[2023-09-17 22:00:16,674][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00050 | loss1:0.0048 loss2:0.0311 loss3:0.1403 | AUC:0.8261 Anomaly AUC:0.6380
[2023-09-17 22:00:36,864][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00050 | loss1:0.0036 loss2:0.0375 loss3:0.1420 | AUC:0.8336 Anomaly AUC:0.6545
[2023-09-17 22:00:55,297][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.2, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:00:58,329][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 22:00:58,329][main.py][line:168][INFO] Training Mode
[2023-09-17 22:00:58,329][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.2, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.2, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.2, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.2, inplace=False)
)

[2023-09-17 22:00:58,330][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:01:06,431][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 22:01:25,844][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00100 | loss1:0.3735 loss2:1.3863 loss3:0.2750 | AUC:0.8150 Anomaly AUC:0.6059
[2023-09-17 22:01:45,202][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00100 | loss1:0.1214 loss2:1.1317 loss3:0.2228 | AUC:0.8295 Anomaly AUC:0.6524
[2023-09-17 22:02:04,807][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00100 | loss1:0.0734 loss2:0.9137 loss3:0.1910 | AUC:0.8316 Anomaly AUC:0.6440
[2023-09-17 22:02:24,480][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00100 | loss1:0.0484 loss2:0.8123 loss3:0.1923 | AUC:0.8337 Anomaly AUC:0.6524
[2023-09-17 22:02:44,270][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00100 | loss1:0.0646 loss2:0.7422 loss3:0.2005 | AUC:0.8358 Anomaly AUC:0.6545
[2023-09-17 22:03:04,020][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00100 | loss1:0.0380 loss2:0.6452 loss3:0.2066 | AUC:0.8274 Anomaly AUC:0.6431
[2023-09-17 22:03:23,891][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00100 | loss1:0.0329 loss2:0.5571 loss3:0.2095 | AUC:0.8309 Anomaly AUC:0.6509
[2023-09-17 22:03:43,760][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00100 | loss1:0.0278 loss2:0.4651 loss3:0.1961 | AUC:0.8373 Anomaly AUC:0.6518
[2023-09-17 22:04:03,678][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00100 | loss1:0.0146 loss2:0.3370 loss3:0.1830 | AUC:0.8250 Anomaly AUC:0.6589
[2023-09-17 22:04:23,550][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00100 | loss1:0.0148 loss2:0.2495 loss3:0.1724 | AUC:0.8280 Anomaly AUC:0.6515
[2023-09-17 22:04:43,518][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00100 | loss1:0.0073 loss2:0.1359 loss3:0.1594 | AUC:0.8182 Anomaly AUC:0.6415
[2023-09-17 22:05:03,511][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00100 | loss1:0.0131 loss2:0.1043 loss3:0.1528 | AUC:0.8213 Anomaly AUC:0.6376
[2023-09-17 22:05:23,675][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00100 | loss1:0.0066 loss2:0.0752 loss3:0.1461 | AUC:0.8234 Anomaly AUC:0.6405
[2023-09-17 22:05:43,685][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00100 | loss1:0.0087 loss2:0.0703 loss3:0.1428 | AUC:0.8257 Anomaly AUC:0.6505
[2023-09-17 22:06:03,579][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00100 | loss1:0.0101 loss2:0.0538 loss3:0.1375 | AUC:0.8317 Anomaly AUC:0.6552
[2023-09-17 22:06:23,584][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00100 | loss1:0.0235 loss2:0.0516 loss3:0.1364 | AUC:0.8371 Anomaly AUC:0.6646
[2023-09-17 22:06:43,744][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00100 | loss1:0.0352 loss2:0.0696 loss3:0.1371 | AUC:0.8424 Anomaly AUC:0.6771
[2023-09-17 22:07:03,641][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00100 | loss1:0.0464 loss2:0.0732 loss3:0.1379 | AUC:0.8350 Anomaly AUC:0.6630
[2023-09-17 22:07:23,542][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00100 | loss1:0.0245 loss2:0.0307 loss3:0.1241 | AUC:0.8257 Anomaly AUC:0.6464
[2023-09-17 22:07:43,484][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00100 | loss1:0.0072 loss2:0.0234 loss3:0.1195 | AUC:0.8309 Anomaly AUC:0.6489
[2023-09-17 22:08:03,554][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00100 | loss1:0.0042 loss2:0.0252 loss3:0.1187 | AUC:0.8339 Anomaly AUC:0.6555
[2023-09-17 22:08:23,700][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00100 | loss1:0.0059 loss2:0.0324 loss3:0.1202 | AUC:0.8203 Anomaly AUC:0.6551
[2023-09-17 22:08:43,789][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00100 | loss1:0.0094 loss2:0.0289 loss3:0.1182 | AUC:0.8180 Anomaly AUC:0.6486
[2023-09-17 22:09:03,668][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00100 | loss1:0.0069 loss2:0.0371 loss3:0.1198 | AUC:0.8152 Anomaly AUC:0.6435
[2023-09-17 22:09:23,500][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00100 | loss1:0.0294 loss2:0.0600 loss3:0.1259 | AUC:0.8154 Anomaly AUC:0.6472
[2023-09-17 22:09:43,566][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00100 | loss1:0.0052 loss2:0.0226 loss3:0.1182 | AUC:0.7854 Anomaly AUC:0.6138
[2023-09-17 22:10:03,703][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00100 | loss1:0.0095 loss2:0.0313 loss3:0.1182 | AUC:0.7885 Anomaly AUC:0.6419
[2023-09-17 22:10:23,763][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00100 | loss1:0.0363 loss2:0.0759 loss3:0.1297 | AUC:0.7986 Anomaly AUC:0.6328
[2023-09-17 22:10:43,744][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00100 | loss1:0.0046 loss2:0.0185 loss3:0.1148 | AUC:0.7906 Anomaly AUC:0.6185
[2023-09-17 22:11:03,876][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00100 | loss1:0.0040 loss2:0.0148 loss3:0.1117 | AUC:0.7926 Anomaly AUC:0.6216
[2023-09-17 22:11:24,036][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00100 | loss1:0.0023 loss2:0.0185 loss3:0.1132 | AUC:0.8033 Anomaly AUC:0.6251
[2023-09-17 22:11:44,124][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00100 | loss1:0.0085 loss2:0.0263 loss3:0.1148 | AUC:0.8093 Anomaly AUC:0.6484
[2023-09-17 22:12:04,386][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00100 | loss1:0.0523 loss2:0.0673 loss3:0.1252 | AUC:0.7990 Anomaly AUC:0.6323
[2023-09-17 22:12:24,408][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00100 | loss1:0.0182 loss2:0.0298 loss3:0.1157 | AUC:0.8003 Anomaly AUC:0.6261
[2023-09-17 22:12:44,327][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00100 | loss1:0.0093 loss2:0.0197 loss3:0.1143 | AUC:0.8156 Anomaly AUC:0.6373
[2023-09-17 22:13:04,207][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00100 | loss1:0.0013 loss2:0.0109 loss3:0.1083 | AUC:0.8157 Anomaly AUC:0.6395
[2023-09-17 22:13:23,920][main.py][line:106][INFO] [Epoch:37/50]: lr:0.00100 | loss1:0.0011 loss2:0.0052 loss3:0.1080 | AUC:0.8065 Anomaly AUC:0.6347
[2023-09-17 22:13:43,786][main.py][line:106][INFO] [Epoch:38/50]: lr:0.00100 | loss1:0.0075 loss2:0.0188 loss3:0.1137 | AUC:0.8026 Anomaly AUC:0.6343
[2023-09-17 22:14:03,683][main.py][line:106][INFO] [Epoch:39/50]: lr:0.00100 | loss1:0.0021 loss2:0.0164 loss3:0.1113 | AUC:0.8173 Anomaly AUC:0.6456
[2023-09-17 22:14:23,579][main.py][line:106][INFO] [Epoch:40/50]: lr:0.00100 | loss1:0.0012 loss2:0.0115 loss3:0.1079 | AUC:0.8076 Anomaly AUC:0.6321
[2023-09-17 22:14:43,579][main.py][line:106][INFO] [Epoch:41/50]: lr:0.00100 | loss1:0.0036 loss2:0.0471 loss3:0.1219 | AUC:0.7982 Anomaly AUC:0.6316
[2023-09-17 22:15:03,737][main.py][line:106][INFO] [Epoch:42/50]: lr:0.00100 | loss1:0.0111 loss2:0.0523 loss3:0.1233 | AUC:0.8151 Anomaly AUC:0.6288
[2023-09-17 22:15:23,873][main.py][line:106][INFO] [Epoch:43/50]: lr:0.00100 | loss1:0.0422 loss2:0.0630 loss3:0.1221 | AUC:0.8210 Anomaly AUC:0.6523
[2023-09-17 22:15:44,031][main.py][line:106][INFO] [Epoch:44/50]: lr:0.00100 | loss1:0.0542 loss2:0.0740 loss3:0.1317 | AUC:0.8161 Anomaly AUC:0.6337
[2023-09-17 22:16:04,104][main.py][line:106][INFO] [Epoch:45/50]: lr:0.00100 | loss1:0.0098 loss2:0.0209 loss3:0.1124 | AUC:0.8206 Anomaly AUC:0.6322
[2023-09-17 22:16:27,255][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:16:30,259][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 22:16:30,259][main.py][line:168][INFO] Training Mode
[2023-09-17 22:16:30,260][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:16:30,260][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:16:38,446][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 22:16:57,849][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00100 | loss1:0.4468 loss2:1.3801 loss3:0.2727 | AUC:0.8219 Anomaly AUC:0.6079
[2023-09-17 22:17:17,285][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00100 | loss1:0.1937 loss2:1.0886 loss3:0.2195 | AUC:0.8335 Anomaly AUC:0.6529
[2023-09-17 22:17:36,929][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00099 | loss1:0.1075 loss2:0.8227 loss3:0.1953 | AUC:0.8336 Anomaly AUC:0.6529
[2023-09-17 22:17:56,608][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00099 | loss1:0.0672 loss2:0.6456 loss3:0.1802 | AUC:0.8404 Anomaly AUC:0.6629
[2023-09-17 22:18:16,418][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00098 | loss1:0.0720 loss2:0.5490 loss3:0.1705 | AUC:0.8411 Anomaly AUC:0.6534
[2023-09-17 22:18:36,236][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00098 | loss1:0.0450 loss2:0.4048 loss3:0.1678 | AUC:0.8335 Anomaly AUC:0.6401
[2023-09-17 22:18:56,289][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00097 | loss1:0.0312 loss2:0.2800 loss3:0.1634 | AUC:0.8308 Anomaly AUC:0.6339
[2023-09-17 22:19:16,063][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00096 | loss1:0.0268 loss2:0.1919 loss3:0.1551 | AUC:0.8398 Anomaly AUC:0.6503
[2023-09-17 22:19:35,799][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00095 | loss1:0.0176 loss2:0.1124 loss3:0.1444 | AUC:0.8341 Anomaly AUC:0.6391
[2023-09-17 22:19:55,511][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00093 | loss1:0.0133 loss2:0.0800 loss3:0.1387 | AUC:0.8375 Anomaly AUC:0.6475
[2023-09-17 22:20:15,210][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00092 | loss1:0.0201 loss2:0.0554 loss3:0.1299 | AUC:0.8323 Anomaly AUC:0.6455
[2023-09-17 22:20:35,008][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00090 | loss1:0.0122 loss2:0.0726 loss3:0.1299 | AUC:0.8299 Anomaly AUC:0.6433
[2023-09-17 22:20:54,845][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00089 | loss1:0.0094 loss2:0.0594 loss3:0.1288 | AUC:0.8385 Anomaly AUC:0.6543
[2023-09-17 22:21:14,615][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00087 | loss1:0.0128 loss2:0.0376 loss3:0.1230 | AUC:0.8398 Anomaly AUC:0.6529
[2023-09-17 22:21:34,242][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00085 | loss1:0.0052 loss2:0.0167 loss3:0.1173 | AUC:0.8271 Anomaly AUC:0.6401
[2023-09-17 22:21:53,749][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00083 | loss1:0.0083 loss2:0.0339 loss3:0.1268 | AUC:0.8414 Anomaly AUC:0.6608
[2023-09-17 22:22:13,376][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00081 | loss1:0.0181 loss2:0.0358 loss3:0.1222 | AUC:0.8270 Anomaly AUC:0.6456
[2023-09-17 22:22:33,028][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00079 | loss1:0.0351 loss2:0.0493 loss3:0.1222 | AUC:0.8300 Anomaly AUC:0.6455
[2023-09-17 22:22:52,749][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00077 | loss1:0.0073 loss2:0.0172 loss3:0.1157 | AUC:0.8391 Anomaly AUC:0.6548
[2023-09-17 22:23:12,310][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00075 | loss1:0.0046 loss2:0.0099 loss3:0.1120 | AUC:0.8353 Anomaly AUC:0.6491
[2023-09-17 22:23:31,898][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00073 | loss1:0.0076 loss2:0.2087 loss3:0.2175 | AUC:0.8341 Anomaly AUC:0.6444
[2023-09-17 22:23:51,762][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00070 | loss1:0.0173 loss2:0.0705 loss3:0.1552 | AUC:0.8257 Anomaly AUC:0.6359
[2023-09-17 22:24:11,541][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00068 | loss1:0.0032 loss2:0.0337 loss3:0.1349 | AUC:0.8309 Anomaly AUC:0.6382
[2023-09-17 22:24:31,200][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00065 | loss1:0.0044 loss2:0.0262 loss3:0.1273 | AUC:0.8319 Anomaly AUC:0.6481
[2023-09-17 22:24:50,977][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00063 | loss1:0.0033 loss2:0.0237 loss3:0.1268 | AUC:0.8419 Anomaly AUC:0.6559
[2023-09-17 22:25:10,772][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00060 | loss1:0.0094 loss2:0.0365 loss3:0.1288 | AUC:0.8349 Anomaly AUC:0.6465
[2023-09-17 22:25:30,544][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00058 | loss1:0.0057 loss2:0.0262 loss3:0.1292 | AUC:0.8311 Anomaly AUC:0.6428
[2023-09-17 22:25:50,458][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00055 | loss1:0.0218 loss2:0.1135 loss3:0.1737 | AUC:0.8288 Anomaly AUC:0.6351
[2023-09-17 22:26:10,537][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00053 | loss1:0.0075 loss2:0.0302 loss3:0.1270 | AUC:0.8248 Anomaly AUC:0.6356
[2023-09-17 22:26:30,394][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00050 | loss1:0.0021 loss2:0.0179 loss3:0.1222 | AUC:0.8272 Anomaly AUC:0.6408
[2023-09-17 22:26:50,214][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00047 | loss1:0.0016 loss2:0.0143 loss3:0.1212 | AUC:0.8242 Anomaly AUC:0.6378
[2023-09-17 22:27:10,005][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00045 | loss1:0.0025 loss2:0.0156 loss3:0.1228 | AUC:0.8254 Anomaly AUC:0.6371
[2023-09-17 22:27:29,811][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00042 | loss1:0.0013 loss2:0.0168 loss3:0.1200 | AUC:0.8316 Anomaly AUC:0.6429
[2023-09-17 22:27:49,649][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00040 | loss1:0.0063 loss2:0.0254 loss3:0.1294 | AUC:0.8285 Anomaly AUC:0.6373
[2023-09-17 22:28:09,616][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00037 | loss1:0.0035 loss2:0.0193 loss3:0.1220 | AUC:0.8238 Anomaly AUC:0.6364
[2023-09-17 22:28:29,540][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00035 | loss1:0.0028 loss2:0.0139 loss3:0.1194 | AUC:0.8333 Anomaly AUC:0.6406
[2023-09-17 22:28:49,468][main.py][line:106][INFO] [Epoch:37/50]: lr:0.00032 | loss1:0.0014 loss2:0.0132 loss3:0.1200 | AUC:0.8253 Anomaly AUC:0.6394
[2023-09-17 22:29:09,371][main.py][line:106][INFO] [Epoch:38/50]: lr:0.00030 | loss1:0.0019 loss2:0.0122 loss3:0.1220 | AUC:0.8249 Anomaly AUC:0.6335
[2023-09-17 22:29:29,259][main.py][line:106][INFO] [Epoch:39/50]: lr:0.00027 | loss1:0.0009 loss2:0.0103 loss3:0.1166 | AUC:0.8255 Anomaly AUC:0.6393
[2023-09-17 22:29:49,114][main.py][line:106][INFO] [Epoch:40/50]: lr:0.00025 | loss1:0.0008 loss2:0.0131 loss3:0.1209 | AUC:0.8241 Anomaly AUC:0.6425
[2023-09-17 22:30:09,098][main.py][line:106][INFO] [Epoch:41/50]: lr:0.00023 | loss1:0.0007 loss2:0.0095 loss3:0.1191 | AUC:0.8202 Anomaly AUC:0.6319
[2023-09-17 22:30:28,948][main.py][line:106][INFO] [Epoch:42/50]: lr:0.00021 | loss1:0.0012 loss2:0.0114 loss3:0.1179 | AUC:0.8227 Anomaly AUC:0.6334
[2023-09-17 22:30:48,877][main.py][line:106][INFO] [Epoch:43/50]: lr:0.00019 | loss1:0.0010 loss2:0.0108 loss3:0.1198 | AUC:0.8232 Anomaly AUC:0.6360
[2023-09-17 22:31:08,842][main.py][line:106][INFO] [Epoch:44/50]: lr:0.00017 | loss1:0.0011 loss2:0.0083 loss3:0.1137 | AUC:0.8161 Anomaly AUC:0.6253
[2023-09-17 22:31:40,792][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0005, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:31:43,836][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 22:31:43,836][main.py][line:168][INFO] Training Mode
[2023-09-17 22:31:43,836][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:31:43,836][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0005
    lr: 0.0005
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:31:51,894][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 22:32:11,330][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00050 | loss1:0.4994 loss2:1.3484 loss3:0.3303 | AUC:0.8112 Anomaly AUC:0.6114
[2023-09-17 22:32:30,608][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00050 | loss1:0.2530 loss2:1.0881 loss3:0.2523 | AUC:0.8046 Anomaly AUC:0.6222
[2023-09-17 22:32:50,213][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00050 | loss1:0.1310 loss2:0.9174 loss3:0.2618 | AUC:0.8253 Anomaly AUC:0.6374
[2023-09-17 22:33:10,031][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00049 | loss1:0.0680 loss2:0.7952 loss3:0.2808 | AUC:0.8350 Anomaly AUC:0.6339
[2023-09-17 22:33:29,933][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00049 | loss1:0.0470 loss2:0.6725 loss3:0.2546 | AUC:0.8346 Anomaly AUC:0.6358
[2023-09-17 22:33:49,897][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00049 | loss1:0.0301 loss2:0.5552 loss3:0.2307 | AUC:0.8413 Anomaly AUC:0.6575
[2023-09-17 22:34:09,820][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00048 | loss1:0.0247 loss2:0.4679 loss3:0.2228 | AUC:0.8247 Anomaly AUC:0.6486
[2023-09-17 22:34:29,717][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00048 | loss1:0.0197 loss2:0.3766 loss3:0.2104 | AUC:0.8301 Anomaly AUC:0.6510
[2023-09-17 22:34:49,617][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00047 | loss1:0.0119 loss2:0.2926 loss3:0.1957 | AUC:0.8235 Anomaly AUC:0.6345
[2023-09-17 22:35:09,582][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00047 | loss1:0.0119 loss2:0.2148 loss3:0.2001 | AUC:0.8261 Anomaly AUC:0.6437
[2023-09-17 22:35:29,543][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00046 | loss1:0.0147 loss2:0.1707 loss3:0.2003 | AUC:0.8316 Anomaly AUC:0.6491
[2023-09-17 22:35:49,577][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00045 | loss1:0.0063 loss2:0.1412 loss3:0.1902 | AUC:0.8301 Anomaly AUC:0.6550
[2023-09-17 22:36:09,576][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00044 | loss1:0.0093 loss2:0.1184 loss3:0.1805 | AUC:0.8308 Anomaly AUC:0.6468
[2023-09-17 22:36:41,189][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:36:44,407][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 22:36:44,408][main.py][line:168][INFO] Training Mode
[2023-09-17 22:36:44,408][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:36:44,408][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:36:52,459][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 22:37:11,837][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.7187 loss2:1.3746 loss3:0.4207 | AUC:0.7895 Anomaly AUC:0.5903
[2023-09-17 22:37:31,122][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.4491 loss2:1.1651 loss3:0.4138 | AUC:0.8000 Anomaly AUC:0.6073
[2023-09-17 22:37:50,800][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.3546 loss2:1.0551 loss3:0.3383 | AUC:0.8102 Anomaly AUC:0.6168
[2023-09-17 22:38:10,557][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.2908 loss2:1.0165 loss3:0.3214 | AUC:0.8103 Anomaly AUC:0.6157
[2023-09-17 22:38:30,320][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.2334 loss2:0.9310 loss3:0.3120 | AUC:0.8119 Anomaly AUC:0.6149
[2023-09-17 22:38:50,148][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.1860 loss2:0.8557 loss3:0.2840 | AUC:0.8097 Anomaly AUC:0.6097
[2023-09-17 22:39:10,099][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.1424 loss2:0.8021 loss3:0.2667 | AUC:0.8160 Anomaly AUC:0.6185
[2023-09-17 22:39:30,237][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.1090 loss2:0.7642 loss3:0.2581 | AUC:0.8264 Anomaly AUC:0.6276
[2023-09-17 22:39:50,386][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00009 | loss1:0.0856 loss2:0.7202 loss3:0.2523 | AUC:0.8198 Anomaly AUC:0.6249
[2023-09-17 22:40:10,570][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00009 | loss1:0.0609 loss2:0.6854 loss3:0.2456 | AUC:0.8145 Anomaly AUC:0.6151
[2023-09-17 22:40:30,766][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00009 | loss1:0.0515 loss2:0.6399 loss3:0.2415 | AUC:0.8139 Anomaly AUC:0.6178
[2023-09-17 22:40:50,887][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00009 | loss1:0.0375 loss2:0.5996 loss3:0.2388 | AUC:0.8241 Anomaly AUC:0.6198
[2023-09-17 22:41:24,926][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:41:28,004][main.py][line:165][INFO] total params:7.5707M
[2023-09-17 22:41:28,004][main.py][line:168][INFO] Training Mode
[2023-09-17 22:41:28,005][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:41:28,005][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:41:36,090][main.py][line:82][INFO] Random initialize AUCAUC:0.5214 Anomaly AUC:0.50195
[2023-09-17 22:41:55,536][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.5553 loss2:1.3233 loss3:0.3685 | AUC:0.8056 Anomaly AUC:0.6097
[2023-09-17 22:42:14,969][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.3137 loss2:1.0681 loss3:0.2665 | AUC:0.8171 Anomaly AUC:0.6255
[2023-09-17 22:42:34,738][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.2008 loss2:0.9545 loss3:0.2571 | AUC:0.8308 Anomaly AUC:0.6374
[2023-09-17 22:42:54,716][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.1093 loss2:0.8781 loss3:0.2620 | AUC:0.8399 Anomaly AUC:0.6514
[2023-09-17 22:43:14,600][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.0615 loss2:0.8041 loss3:0.2559 | AUC:0.8351 Anomaly AUC:0.6391
[2023-09-17 22:43:34,558][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.0333 loss2:0.7314 loss3:0.2426 | AUC:0.8333 Anomaly AUC:0.6355
[2023-09-17 22:43:54,554][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.0200 loss2:0.6585 loss3:0.2386 | AUC:0.8356 Anomaly AUC:0.6471
[2023-09-17 22:44:14,557][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.0145 loss2:0.5921 loss3:0.2323 | AUC:0.8394 Anomaly AUC:0.6490
[2023-09-17 22:44:34,657][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.0130 loss2:0.5390 loss3:0.2343 | AUC:0.8347 Anomaly AUC:0.6417
[2023-09-17 22:44:54,759][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0107 loss2:0.4837 loss3:0.2284 | AUC:0.8319 Anomaly AUC:0.6452
[2023-09-17 22:45:14,790][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.0120 loss2:0.4300 loss3:0.2297 | AUC:0.8245 Anomaly AUC:0.6380
[2023-09-17 22:45:34,826][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.0083 loss2:0.3840 loss3:0.2285 | AUC:0.8390 Anomaly AUC:0.6558
[2023-09-17 22:45:54,810][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.0085 loss2:0.3369 loss3:0.2209 | AUC:0.8395 Anomaly AUC:0.6526
[2023-09-17 22:46:14,937][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.0065 loss2:0.2947 loss3:0.2237 | AUC:0.8343 Anomaly AUC:0.6555
[2023-09-17 22:46:34,880][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.0057 loss2:0.2610 loss3:0.2153 | AUC:0.8336 Anomaly AUC:0.6531
[2023-09-17 22:46:54,826][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.0079 loss2:0.2292 loss3:0.2059 | AUC:0.8366 Anomaly AUC:0.6560
[2023-09-17 22:47:14,816][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.0046 loss2:0.2024 loss3:0.2005 | AUC:0.8339 Anomaly AUC:0.6543
[2023-09-17 22:47:34,776][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.0048 loss2:0.1799 loss3:0.1990 | AUC:0.8249 Anomaly AUC:0.6407
[2023-09-17 22:47:54,772][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.0044 loss2:0.1565 loss3:0.1885 | AUC:0.8273 Anomaly AUC:0.6579
[2023-09-17 22:48:14,605][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.0047 loss2:0.1339 loss3:0.1756 | AUC:0.8306 Anomaly AUC:0.6547
[2023-09-17 22:48:34,356][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.0045 loss2:0.1170 loss3:0.1736 | AUC:0.8161 Anomaly AUC:0.6467
[2023-09-17 22:48:54,333][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.0082 loss2:0.1353 loss3:0.1789 | AUC:0.8245 Anomaly AUC:0.6490
[2023-09-17 22:49:14,182][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.0040 loss2:0.1094 loss3:0.1728 | AUC:0.8172 Anomaly AUC:0.6435
[2023-09-17 22:49:33,988][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.0056 loss2:0.1008 loss3:0.1623 | AUC:0.8259 Anomaly AUC:0.6475
[2023-09-17 22:49:50,970][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:55:56,354][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:55:59,443][main.py][line:165][INFO] total params:15.9737M
[2023-09-17 22:55:59,443][main.py][line:168][INFO] Training Mode
[2023-09-17 22:55:59,444][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:55:59,444][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:56:47,630][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:56:50,727][main.py][line:165][INFO] total params:15.9737M
[2023-09-17 22:56:50,728][main.py][line:168][INFO] Training Mode
[2023-09-17 22:56:50,728][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:56:50,729][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 22:58:46,131][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 22:58:49,202][main.py][line:165][INFO] total params:15.9737M
[2023-09-17 22:58:49,202][main.py][line:168][INFO] Training Mode
[2023-09-17 22:58:49,203][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 22:58:49,203][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:06:18,633][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:06:21,788][main.py][line:165][INFO] total params:15.9737M
[2023-09-17 23:06:21,789][main.py][line:168][INFO] Training Mode
[2023-09-17 23:06:21,790][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (attention): Transformer(
          (layers): ModuleList(
            (0-1): 2 x ModuleList(
              (0): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): Attention(
                  (attend): Softmax(dim=-1)
                  (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                  (to_out): Sequential(
                    (0): Linear(in_features=1024, out_features=512, bias=True)
                    (1): Dropout(p=0.5, inplace=False)
                  )
                )
              )
              (1): PreNorm(
                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (fn): FeedForward(
                  (net): Sequential(
                    (0): Linear(in_features=512, out_features=512, bias=True)
                    (1): GELU(approximate='none')
                    (2): Dropout(p=0.5, inplace=False)
                    (3): Linear(in_features=512, out_features=512, bias=True)
                    (4): Dropout(p=0.5, inplace=False)
                  )
                )
              )
            )
          )
        )
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:06:21,790][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:06:34,249][main.py][line:82][INFO] Random initialize AUCAUC:0.5098 Anomaly AUC:0.53230
[2023-09-17 23:07:03,224][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.8141 loss2:1.4047 loss3:0.4859 | AUC:0.8154 Anomaly AUC:0.6155
[2023-09-17 23:07:31,920][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.3752 loss2:1.4002 loss3:0.3961 | AUC:0.8145 Anomaly AUC:0.6154
[2023-09-17 23:08:01,116][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.2411 loss2:1.4000 loss3:0.3614 | AUC:0.8155 Anomaly AUC:0.6160
[2023-09-17 23:08:30,571][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.1474 loss2:1.4018 loss3:0.3233 | AUC:0.8264 Anomaly AUC:0.6246
[2023-09-17 23:08:59,739][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.0750 loss2:1.3999 loss3:0.2922 | AUC:0.8196 Anomaly AUC:0.6258
[2023-09-17 23:09:28,998][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.0432 loss2:1.3997 loss3:0.2698 | AUC:0.8092 Anomaly AUC:0.6206
[2023-09-17 23:09:58,324][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.0281 loss2:1.3873 loss3:0.2497 | AUC:0.8238 Anomaly AUC:0.6299
[2023-09-17 23:10:27,720][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.0139 loss2:1.3543 loss3:0.2392 | AUC:0.8235 Anomaly AUC:0.6366
[2023-09-17 23:10:57,121][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.0107 loss2:1.2988 loss3:0.2268 | AUC:0.8243 Anomaly AUC:0.6427
[2023-09-17 23:11:26,527][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0101 loss2:1.1630 loss3:0.2183 | AUC:0.8173 Anomaly AUC:0.6334
[2023-09-17 23:11:55,608][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.0078 loss2:1.0937 loss3:0.2126 | AUC:0.8149 Anomaly AUC:0.6254
[2023-09-17 23:12:24,918][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.0081 loss2:1.0399 loss3:0.2084 | AUC:0.8153 Anomaly AUC:0.6269
[2023-09-17 23:12:54,058][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.0196 loss2:0.9719 loss3:0.2050 | AUC:0.8004 Anomaly AUC:0.6252
[2023-09-17 23:13:23,275][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.0150 loss2:1.0374 loss3:0.2007 | AUC:0.8071 Anomaly AUC:0.6310
[2023-09-17 23:13:52,410][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.0064 loss2:0.7901 loss3:0.1962 | AUC:0.8152 Anomaly AUC:0.6376
[2023-09-17 23:14:21,356][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.0103 loss2:0.5582 loss3:0.1934 | AUC:0.8144 Anomaly AUC:0.6256
[2023-09-17 23:14:50,534][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.0097 loss2:0.5806 loss3:0.1930 | AUC:0.8139 Anomaly AUC:0.6416
[2023-09-17 23:15:19,496][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.0079 loss2:0.5579 loss3:0.1907 | AUC:0.8106 Anomaly AUC:0.6446
[2023-09-17 23:15:48,348][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.0068 loss2:0.5119 loss3:0.1852 | AUC:0.8083 Anomaly AUC:0.6345
[2023-09-17 23:16:17,431][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.0092 loss2:0.3664 loss3:0.1800 | AUC:0.8076 Anomaly AUC:0.6429
[2023-09-17 23:16:46,294][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.0052 loss2:0.2569 loss3:0.1746 | AUC:0.8051 Anomaly AUC:0.6400
[2023-09-17 23:17:15,276][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.0057 loss2:0.2115 loss3:0.1750 | AUC:0.8348 Anomaly AUC:0.6516
[2023-09-17 23:17:44,164][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.0083 loss2:0.2908 loss3:0.1726 | AUC:0.8112 Anomaly AUC:0.6402
[2023-09-17 23:18:13,258][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.0066 loss2:0.3119 loss3:0.1733 | AUC:0.8214 Anomaly AUC:0.6598
[2023-09-17 23:18:42,122][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00030 | loss1:0.0096 loss2:0.2332 loss3:0.1689 | AUC:0.7776 Anomaly AUC:0.5954
[2023-09-17 23:19:11,106][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.0076 loss2:0.1994 loss3:0.1661 | AUC:0.8125 Anomaly AUC:0.6260
[2023-09-17 23:27:49,980][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:27:53,072][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:27:53,072][main.py][line:168][INFO] Training Mode
[2023-09-17 23:27:53,072][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:27:53,072][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:28:37,381][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:28:40,843][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:28:40,844][main.py][line:168][INFO] Training Mode
[2023-09-17 23:28:40,844][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:28:40,844][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:29:51,012][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:29:55,899][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:29:55,899][main.py][line:168][INFO] Training Mode
[2023-09-17 23:29:55,900][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:29:55,900][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:31:25,747][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:31:28,772][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:31:28,772][main.py][line:168][INFO] Training Mode
[2023-09-17 23:31:28,772][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:31:28,772][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:32:59,926][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:33:03,016][main.py][line:165][INFO] total params:8.0968M
[2023-09-17 23:33:03,016][main.py][line:168][INFO] Training Mode
[2023-09-17 23:33:03,017][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:33:03,017][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:34:40,171][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:34:43,602][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:34:43,603][main.py][line:168][INFO] Training Mode
[2023-09-17 23:34:43,603][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:34:43,603][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:35:15,361][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:35:18,438][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:35:18,439][main.py][line:168][INFO] Training Mode
[2023-09-17 23:35:18,439][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:35:18,439][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:37:45,328][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:37:48,390][main.py][line:165][INFO] total params:7.5711M
[2023-09-17 23:37:48,390][main.py][line:168][INFO] Training Mode
[2023-09-17 23:37:48,391][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:37:48,391][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:38:26,818][main.py][line:82][INFO] Random initialize AUCAUC:0.4166 Anomaly AUC:0.49164
[2023-09-17 23:39:22,735][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:1.4198 loss2:1.3974 loss3:0.1246 | AUC:0.7881 Anomaly AUC:0.5931
[2023-09-17 23:40:19,566][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.6840 loss2:1.3610 loss3:0.0317 | AUC:0.8024 Anomaly AUC:0.6109
[2023-09-17 23:41:16,511][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.5646 loss2:1.3247 loss3:0.0248 | AUC:0.8120 Anomaly AUC:0.6275
[2023-09-17 23:42:14,023][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.4778 loss2:1.2818 loss3:0.0229 | AUC:0.8176 Anomaly AUC:0.6354
[2023-09-17 23:43:11,906][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.4339 loss2:1.2333 loss3:0.0170 | AUC:0.8121 Anomaly AUC:0.6369
[2023-09-17 23:44:10,234][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.4021 loss2:1.1798 loss3:0.0162 | AUC:0.8152 Anomaly AUC:0.6341
[2023-09-17 23:45:08,193][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.3551 loss2:1.1286 loss3:0.0149 | AUC:0.8158 Anomaly AUC:0.6330
[2023-09-17 23:46:06,471][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.3312 loss2:1.0821 loss3:0.0134 | AUC:0.8201 Anomaly AUC:0.6383
[2023-09-17 23:47:04,794][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.3079 loss2:1.0424 loss3:0.0129 | AUC:0.8189 Anomaly AUC:0.6386
[2023-09-17 23:48:02,950][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.2762 loss2:0.9956 loss3:0.0095 | AUC:0.8171 Anomaly AUC:0.6364
[2023-09-17 23:49:00,994][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.2512 loss2:0.9568 loss3:0.0068 | AUC:0.8221 Anomaly AUC:0.6454
[2023-09-17 23:49:59,319][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.2296 loss2:0.9222 loss3:0.0086 | AUC:0.8181 Anomaly AUC:0.6364
[2023-09-17 23:50:57,474][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.1960 loss2:0.8893 loss3:0.0051 | AUC:0.8191 Anomaly AUC:0.6415
[2023-09-17 23:51:55,525][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.1802 loss2:0.8536 loss3:0.0081 | AUC:0.8169 Anomaly AUC:0.6391
[2023-09-17 23:52:53,542][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.1798 loss2:0.8225 loss3:0.0093 | AUC:0.8146 Anomaly AUC:0.6319
[2023-09-17 23:53:51,225][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.1539 loss2:0.7880 loss3:0.0059 | AUC:0.8228 Anomaly AUC:0.6377
[2023-09-17 23:54:20,348][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-17 23:54:23,501][main.py][line:165][INFO] total params:8.0968M
[2023-09-17 23:54:23,502][main.py][line:168][INFO] Training Mode
[2023-09-17 23:54:23,502][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-17 23:54:23,502][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-17 23:55:03,051][main.py][line:82][INFO] Random initialize AUCAUC:0.4782 Anomaly AUC:0.55252
[2023-09-17 23:56:01,914][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:1.2797 loss2:1.4035 loss3:0.1271 | AUC:0.7668 Anomaly AUC:0.5985
[2023-09-17 23:57:01,034][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.6897 loss2:1.3851 loss3:0.0359 | AUC:0.7848 Anomaly AUC:0.6097
[2023-09-17 23:58:00,779][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.5739 loss2:1.3592 loss3:0.0255 | AUC:0.8064 Anomaly AUC:0.6245
[2023-09-17 23:59:00,624][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.4962 loss2:1.3336 loss3:0.0236 | AUC:0.8114 Anomaly AUC:0.6271
[2023-09-18 00:00:00,353][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.4604 loss2:1.2916 loss3:0.0212 | AUC:0.8104 Anomaly AUC:0.6275
[2023-09-18 00:01:00,325][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.4043 loss2:1.2263 loss3:0.0166 | AUC:0.8217 Anomaly AUC:0.6381
[2023-09-18 00:02:00,226][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.3842 loss2:1.1480 loss3:0.0156 | AUC:0.8213 Anomaly AUC:0.6484
[2023-09-18 00:03:00,372][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.3332 loss2:1.0825 loss3:0.0112 | AUC:0.8232 Anomaly AUC:0.6535
[2023-09-18 00:04:00,650][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.2888 loss2:1.0230 loss3:0.0111 | AUC:0.8251 Anomaly AUC:0.6462
[2023-09-18 00:05:00,767][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.2601 loss2:0.9716 loss3:0.0112 | AUC:0.8283 Anomaly AUC:0.6545
[2023-09-18 00:06:01,682][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.2329 loss2:0.9367 loss3:0.0113 | AUC:0.8250 Anomaly AUC:0.6538
[2023-09-18 00:07:02,465][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.2039 loss2:0.8883 loss3:0.0096 | AUC:0.8222 Anomaly AUC:0.6515
[2023-09-18 00:08:03,769][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.1780 loss2:0.8520 loss3:0.0082 | AUC:0.8311 Anomaly AUC:0.6613
[2023-09-18 00:09:03,964][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.1512 loss2:0.8140 loss3:0.0125 | AUC:0.8266 Anomaly AUC:0.6559
[2023-09-18 00:10:04,032][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.1431 loss2:0.7968 loss3:0.0060 | AUC:0.8217 Anomaly AUC:0.6475
[2023-09-18 00:11:04,515][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.1226 loss2:0.7440 loss3:0.0055 | AUC:0.8265 Anomaly AUC:0.6587
[2023-09-18 00:11:23,773][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 00:11:26,913][main.py][line:165][INFO] total params:8.3609M
[2023-09-18 00:11:26,913][main.py][line:168][INFO] Training Mode
[2023-09-18 00:11:26,913][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 00:11:26,913][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 00:12:21,915][main.py][line:82][INFO] Random initialize AUCAUC:0.5687 Anomaly AUC:0.52189
[2023-09-18 00:13:39,352][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:2.1979 loss2:1.4022 loss3:0.3553 | AUC:0.8138 Anomaly AUC:0.6046
[2023-09-18 00:14:57,310][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.8004 loss2:1.4004 loss3:0.2786 | AUC:0.8216 Anomaly AUC:0.6229
[2023-09-18 00:16:16,098][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.5464 loss2:1.4015 loss3:0.2244 | AUC:0.8234 Anomaly AUC:0.6291
[2023-09-18 00:17:34,809][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.4066 loss2:1.4006 loss3:0.1916 | AUC:0.8337 Anomaly AUC:0.6390
[2023-09-18 00:18:53,986][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.3047 loss2:1.3982 loss3:0.1745 | AUC:0.8308 Anomaly AUC:0.6322
[2023-09-18 00:20:13,005][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.2425 loss2:1.3992 loss3:0.1627 | AUC:0.8307 Anomaly AUC:0.6453
[2023-09-18 00:21:32,389][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.2187 loss2:1.3431 loss3:0.1551 | AUC:0.8359 Anomaly AUC:0.6437
[2023-09-18 00:22:51,508][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.1588 loss2:1.3283 loss3:0.1468 | AUC:0.8333 Anomaly AUC:0.6424
[2023-09-18 00:24:10,778][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.1172 loss2:1.1609 loss3:0.1381 | AUC:0.8343 Anomaly AUC:0.6394
[2023-09-18 00:25:30,116][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0999 loss2:0.9830 loss3:0.1322 | AUC:0.8378 Anomaly AUC:0.6426
[2023-09-18 00:26:49,388][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.1230 loss2:0.9964 loss3:0.1234 | AUC:0.8314 Anomaly AUC:0.6382
[2023-09-18 00:28:08,711][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.1343 loss2:0.9521 loss3:0.1152 | AUC:0.8415 Anomaly AUC:0.6520
[2023-09-18 00:29:27,691][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.1553 loss2:0.9265 loss3:0.1127 | AUC:0.8325 Anomaly AUC:0.6358
[2023-09-18 00:30:46,490][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.2257 loss2:0.6501 loss3:0.1132 | AUC:0.8352 Anomaly AUC:0.6336
[2023-09-18 00:32:05,733][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.1915 loss2:0.8244 loss3:0.1142 | AUC:0.8313 Anomaly AUC:0.6463
[2023-09-18 00:33:24,813][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.1963 loss2:0.6617 loss3:0.1122 | AUC:0.8303 Anomaly AUC:0.6491
[2023-09-18 00:34:43,523][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.1800 loss2:0.4012 loss3:0.1124 | AUC:0.8287 Anomaly AUC:0.6330
[2023-09-18 00:36:02,401][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.1759 loss2:0.2667 loss3:0.1163 | AUC:0.8218 Anomaly AUC:0.6430
[2023-09-18 00:37:21,063][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.1516 loss2:0.1450 loss3:0.1054 | AUC:0.8285 Anomaly AUC:0.6526
[2023-09-18 00:38:40,172][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.1526 loss2:0.1905 loss3:0.1067 | AUC:0.8182 Anomaly AUC:0.6319
[2023-09-18 00:39:58,946][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00030 | loss1:0.1371 loss2:0.3133 loss3:0.1026 | AUC:0.8221 Anomaly AUC:0.6341
[2023-09-18 00:41:17,865][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00030 | loss1:0.1335 loss2:0.3014 loss3:0.0991 | AUC:0.8117 Anomaly AUC:0.6237
[2023-09-18 00:42:36,787][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00030 | loss1:0.1363 loss2:0.2125 loss3:0.0951 | AUC:0.8311 Anomaly AUC:0.6470
[2023-09-18 00:43:55,880][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00030 | loss1:0.1582 loss2:0.2240 loss3:0.0932 | AUC:0.8199 Anomaly AUC:0.6325
[2023-09-18 00:45:14,423][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00030 | loss1:0.1543 loss2:0.2022 loss3:0.0910 | AUC:0.8165 Anomaly AUC:0.6337
[2023-09-18 00:46:33,299][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00030 | loss1:0.1502 loss2:0.2792 loss3:0.0833 | AUC:0.8199 Anomaly AUC:0.6327
[2023-09-18 00:47:52,044][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00030 | loss1:0.1169 loss2:0.0781 loss3:0.0798 | AUC:0.8116 Anomaly AUC:0.6299
[2023-09-18 00:49:10,890][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00030 | loss1:0.1051 loss2:0.0329 loss3:0.0803 | AUC:0.8163 Anomaly AUC:0.6340
[2023-09-18 00:50:29,418][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00030 | loss1:0.1193 loss2:0.0000 loss3:0.0762 | AUC:0.8125 Anomaly AUC:0.6370
[2023-09-18 00:51:48,439][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00030 | loss1:0.1053 loss2:0.0220 loss3:0.0689 | AUC:0.8113 Anomaly AUC:0.6318
[2023-09-18 00:53:07,326][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00030 | loss1:0.0878 loss2:0.0332 loss3:0.0631 | AUC:0.8205 Anomaly AUC:0.6315
[2023-09-18 00:54:26,140][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00030 | loss1:0.1183 loss2:0.0000 loss3:0.0590 | AUC:0.8205 Anomaly AUC:0.6337
[2023-09-18 00:55:45,071][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00030 | loss1:0.0871 loss2:0.0331 loss3:0.0571 | AUC:0.8150 Anomaly AUC:0.6442
[2023-09-18 00:57:03,667][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00030 | loss1:0.1032 loss2:0.0110 loss3:0.0589 | AUC:0.8224 Anomaly AUC:0.6445
[2023-09-18 00:58:22,201][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00030 | loss1:0.0997 loss2:0.0897 loss3:0.0580 | AUC:0.8111 Anomaly AUC:0.6363
[2023-09-18 00:59:40,938][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00030 | loss1:0.0983 loss2:0.1108 loss3:0.0533 | AUC:0.8220 Anomaly AUC:0.6439
[2023-09-18 01:00:59,806][main.py][line:106][INFO] [Epoch:37/50]: lr:0.00030 | loss1:0.0823 loss2:0.0332 loss3:0.0531 | AUC:0.8116 Anomaly AUC:0.6252
[2023-09-18 01:02:18,848][main.py][line:106][INFO] [Epoch:38/50]: lr:0.00030 | loss1:0.0960 loss2:0.0115 loss3:0.0514 | AUC:0.8210 Anomaly AUC:0.6409
[2023-09-18 01:03:37,570][main.py][line:106][INFO] [Epoch:39/50]: lr:0.00030 | loss1:0.0652 loss2:0.0227 loss3:0.0472 | AUC:0.8097 Anomaly AUC:0.6361
[2023-09-18 01:04:56,652][main.py][line:106][INFO] [Epoch:40/50]: lr:0.00030 | loss1:0.1105 loss2:0.0000 loss3:0.0509 | AUC:0.8311 Anomaly AUC:0.6406
[2023-09-18 01:06:15,348][main.py][line:106][INFO] [Epoch:41/50]: lr:0.00030 | loss1:0.0489 loss2:0.0109 loss3:0.0459 | AUC:0.8268 Anomaly AUC:0.6382
[2023-09-18 01:07:34,623][main.py][line:106][INFO] [Epoch:42/50]: lr:0.00030 | loss1:0.0462 loss2:0.0000 loss3:0.0460 | AUC:0.8206 Anomaly AUC:0.6329
[2023-09-18 01:08:53,381][main.py][line:106][INFO] [Epoch:43/50]: lr:0.00030 | loss1:0.0354 loss2:0.0000 loss3:0.0446 | AUC:0.8272 Anomaly AUC:0.6373
[2023-09-18 01:10:12,128][main.py][line:106][INFO] [Epoch:44/50]: lr:0.00030 | loss1:0.0427 loss2:0.0000 loss3:0.0439 | AUC:0.8122 Anomaly AUC:0.6184
[2023-09-18 01:11:30,974][main.py][line:106][INFO] [Epoch:45/50]: lr:0.00030 | loss1:0.0470 loss2:0.0000 loss3:0.0441 | AUC:0.8291 Anomaly AUC:0.6382
[2023-09-18 01:12:49,601][main.py][line:106][INFO] [Epoch:46/50]: lr:0.00030 | loss1:0.0848 loss2:0.0109 loss3:0.0445 | AUC:0.8253 Anomaly AUC:0.6351
[2023-09-18 01:14:08,288][main.py][line:106][INFO] [Epoch:47/50]: lr:0.00030 | loss1:0.0670 loss2:0.0000 loss3:0.0452 | AUC:0.8186 Anomaly AUC:0.6307
[2023-09-18 01:15:27,270][main.py][line:106][INFO] [Epoch:48/50]: lr:0.00030 | loss1:0.0842 loss2:0.0559 loss3:0.0425 | AUC:0.8334 Anomaly AUC:0.6442
[2023-09-18 01:16:46,281][main.py][line:106][INFO] [Epoch:49/50]: lr:0.00030 | loss1:0.0753 loss2:0.0230 loss3:0.0636 | AUC:0.8304 Anomaly AUC:0.6364
[2023-09-18 01:18:04,661][main.py][line:106][INFO] [Epoch:50/50]: lr:0.00030 | loss1:0.0425 loss2:0.0000 loss3:0.0448 | AUC:0.8168 Anomaly AUC:0.6245
[2023-09-18 01:18:04,687][main.py][line:116][INFO] Training completes in 65m 43s | best AUCAUC:0.8415 Anomaly AUC:0.6520

[2023-09-18 10:37:23,986][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 0.288, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 10:37:27,138][main.py][line:165][INFO] total params:8.3609M
[2023-09-18 10:37:27,139][main.py][line:168][INFO] Training Mode
[2023-09-18 10:37:27,139][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 10:37:27,139][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 10:38:22,583][main.py][line:82][INFO] Random initialize AUCAUC:0.5687 Anomaly AUC:0.52189
[2023-09-18 10:39:40,881][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:2.4156 loss2:1.4086 loss3:0.3449 | AUC:0.8126 Anomaly AUC:0.6071
[2023-09-18 10:40:59,655][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.8189 loss2:1.4068 loss3:0.2746 | AUC:0.8218 Anomaly AUC:0.6237
[2023-09-18 10:42:19,348][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.6490 loss2:1.4065 loss3:0.2299 | AUC:0.8236 Anomaly AUC:0.6261
[2023-09-18 10:43:39,256][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.4425 loss2:1.4022 loss3:0.2037 | AUC:0.8189 Anomaly AUC:0.6219
[2023-09-18 10:44:59,273][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.3615 loss2:1.3992 loss3:0.1874 | AUC:0.8331 Anomaly AUC:0.6419
[2023-09-18 10:46:19,149][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.2744 loss2:1.4013 loss3:0.1766 | AUC:0.8290 Anomaly AUC:0.6443
[2023-09-18 10:47:39,157][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.2066 loss2:1.3562 loss3:0.1665 | AUC:0.8257 Anomaly AUC:0.6403
[2023-09-18 10:48:59,442][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.1498 loss2:1.3197 loss3:0.1535 | AUC:0.8218 Anomaly AUC:0.6347
[2023-09-18 10:50:19,539][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.1404 loss2:1.2522 loss3:0.1308 | AUC:0.8284 Anomaly AUC:0.6496
[2023-09-18 10:51:40,085][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.1056 loss2:1.0955 loss3:0.1044 | AUC:0.8226 Anomaly AUC:0.6387
[2023-09-18 10:53:00,189][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.1006 loss2:1.1070 loss3:0.0944 | AUC:0.8097 Anomaly AUC:0.6226
[2023-09-18 10:54:19,963][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00030 | loss1:0.1256 loss2:0.9618 loss3:0.0874 | AUC:0.8257 Anomaly AUC:0.6451
[2023-09-18 10:55:40,174][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00030 | loss1:0.1463 loss2:0.8600 loss3:0.0894 | AUC:0.8246 Anomaly AUC:0.6412
[2023-09-18 10:56:59,777][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00030 | loss1:0.1521 loss2:0.8171 loss3:0.0874 | AUC:0.8253 Anomaly AUC:0.6393
[2023-09-18 10:58:19,234][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00030 | loss1:0.1795 loss2:0.7024 loss3:0.0943 | AUC:0.8220 Anomaly AUC:0.6287
[2023-09-18 10:59:38,771][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00030 | loss1:0.1442 loss2:0.5058 loss3:0.0929 | AUC:0.8255 Anomaly AUC:0.6407
[2023-09-18 11:00:58,887][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00030 | loss1:0.2046 loss2:0.4461 loss3:0.1005 | AUC:0.8333 Anomaly AUC:0.6527
[2023-09-18 11:02:19,242][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00030 | loss1:0.2420 loss2:0.4825 loss3:0.1146 | AUC:0.8047 Anomaly AUC:0.6370
[2023-09-18 11:03:39,222][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00030 | loss1:0.1866 loss2:0.5019 loss3:0.1141 | AUC:0.8127 Anomaly AUC:0.6361
[2023-09-18 11:04:59,080][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00030 | loss1:0.1930 loss2:0.2141 loss3:0.1150 | AUC:0.8106 Anomaly AUC:0.6252
[2023-09-18 11:06:20,878][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0003, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 11:06:23,887][main.py][line:165][INFO] total params:8.3609M
[2023-09-18 11:06:23,887][main.py][line:168][INFO] Training Mode
[2023-09-18 11:06:23,887][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 11:06:23,888][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 11:07:20,374][main.py][line:82][INFO] Random initialize AUCAUC:0.5687 Anomaly AUC:0.52189
[2023-09-18 11:08:40,351][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00030 | loss1:0.8624 loss2:1.4045 loss3:0.3660 | AUC:0.8145 Anomaly AUC:0.6053
[2023-09-18 11:10:00,504][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00030 | loss1:0.3660 loss2:1.3988 loss3:0.3184 | AUC:0.8222 Anomaly AUC:0.6209
[2023-09-18 11:11:21,651][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00030 | loss1:0.2199 loss2:1.4001 loss3:0.2712 | AUC:0.8202 Anomaly AUC:0.6254
[2023-09-18 11:12:42,593][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00030 | loss1:0.1230 loss2:1.3989 loss3:0.2393 | AUC:0.8287 Anomaly AUC:0.6347
[2023-09-18 11:14:03,988][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00030 | loss1:0.0648 loss2:1.3951 loss3:0.2179 | AUC:0.8302 Anomaly AUC:0.6382
[2023-09-18 11:15:25,727][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00030 | loss1:0.0399 loss2:1.3839 loss3:0.1957 | AUC:0.8268 Anomaly AUC:0.6363
[2023-09-18 11:16:47,554][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00030 | loss1:0.0286 loss2:1.3617 loss3:0.1812 | AUC:0.8334 Anomaly AUC:0.6389
[2023-09-18 11:18:09,451][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00030 | loss1:0.0160 loss2:1.3477 loss3:0.1719 | AUC:0.8335 Anomaly AUC:0.6472
[2023-09-18 11:19:31,106][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00030 | loss1:0.0112 loss2:1.2699 loss3:0.1646 | AUC:0.8305 Anomaly AUC:0.6458
[2023-09-18 11:20:52,795][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00030 | loss1:0.0139 loss2:1.1462 loss3:0.1582 | AUC:0.8371 Anomaly AUC:0.6486
[2023-09-18 11:22:14,682][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00030 | loss1:0.0093 loss2:1.1341 loss3:0.1482 | AUC:0.8362 Anomaly AUC:0.6460
[2023-09-18 11:22:55,093][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 11:22:58,097][main.py][line:165][INFO] total params:7.8352M
[2023-09-18 11:22:58,097][main.py][line:168][INFO] Training Mode
[2023-09-18 11:22:58,097][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-18 11:22:58,098][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 11:23:52,773][main.py][line:82][INFO] Random initialize AUCAUC:0.5092 Anomaly AUC:0.52983
[2023-09-18 11:25:08,632][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:1.1158 loss2:1.3999 loss3:0.3845 | AUC:0.7982 Anomaly AUC:0.5994
[2023-09-18 11:26:24,491][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.5967 loss2:1.3958 loss3:0.3818 | AUC:0.8016 Anomaly AUC:0.6068
[2023-09-18 11:27:40,777][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.5063 loss2:1.3978 loss3:0.3755 | AUC:0.7967 Anomaly AUC:0.6137
[2023-09-18 11:28:57,658][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.3194 loss2:1.3961 loss3:0.3699 | AUC:0.8027 Anomaly AUC:0.6207
[2023-09-18 11:30:15,007][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.2120 loss2:1.3963 loss3:0.3660 | AUC:0.8179 Anomaly AUC:0.6222
[2023-09-18 11:31:32,381][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.2271 loss2:1.3991 loss3:0.3605 | AUC:0.8094 Anomaly AUC:0.6132
[2023-09-18 11:32:50,099][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.1086 loss2:1.3975 loss3:0.3544 | AUC:0.8122 Anomaly AUC:0.6224
[2023-09-18 11:34:07,302][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.2263 loss2:1.3972 loss3:0.3542 | AUC:0.8074 Anomaly AUC:0.6160
[2023-09-18 11:35:24,798][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.1221 loss2:1.3977 loss3:0.3378 | AUC:0.8116 Anomaly AUC:0.6234
[2023-09-18 11:36:42,530][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.0847 loss2:1.3990 loss3:0.3265 | AUC:0.8165 Anomaly AUC:0.6296
[2023-09-18 11:38:00,643][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.0616 loss2:1.3988 loss3:0.3141 | AUC:0.8209 Anomaly AUC:0.6243
[2023-09-18 11:39:17,648][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.0433 loss2:1.3986 loss3:0.3008 | AUC:0.8182 Anomaly AUC:0.6268
[2023-09-18 11:39:46,945][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 11:39:49,975][main.py][line:165][INFO] total params:8.6221M
[2023-09-18 11:39:49,975][main.py][line:168][INFO] Training Mode
[2023-09-18 11:39:49,976][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-18 11:39:49,976][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 11:40:44,630][main.py][line:82][INFO] Random initialize AUCAUC:0.6630 Anomaly AUC:0.57623
[2023-09-18 11:41:59,667][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:0.9462 loss2:1.3918 loss3:0.3707 | AUC:0.7934 Anomaly AUC:0.5983
[2023-09-18 11:43:14,761][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.4865 loss2:1.3781 loss3:0.3583 | AUC:0.8003 Anomaly AUC:0.6030
[2023-09-18 11:44:30,503][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.4023 loss2:1.3807 loss3:0.3574 | AUC:0.8088 Anomaly AUC:0.6100
[2023-09-18 11:45:46,277][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.4551 loss2:1.4009 loss3:0.3722 | AUC:0.8175 Anomaly AUC:0.6201
[2023-09-18 11:47:03,079][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.2350 loss2:1.3935 loss3:0.3554 | AUC:0.8099 Anomaly AUC:0.6143
[2023-09-18 11:48:19,709][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.1494 loss2:1.3913 loss3:0.3475 | AUC:0.8179 Anomaly AUC:0.6285
[2023-09-18 11:49:36,629][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.1520 loss2:1.3994 loss3:0.3627 | AUC:0.8220 Anomaly AUC:0.6258
[2023-09-18 11:50:53,642][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.1026 loss2:1.3972 loss3:0.3445 | AUC:0.8163 Anomaly AUC:0.6153
[2023-09-18 11:52:10,337][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.0680 loss2:1.3961 loss3:0.3337 | AUC:0.8230 Anomaly AUC:0.6274
[2023-09-18 11:52:40,575][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.1, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 11:52:43,594][main.py][line:165][INFO] total params:8.6221M
[2023-09-18 11:52:43,594][main.py][line:168][INFO] Training Mode
[2023-09-18 11:52:43,595][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)

[2023-09-18 11:52:43,595][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 11:53:37,396][main.py][line:82][INFO] Random initialize AUCAUC:0.6630 Anomaly AUC:0.57623
[2023-09-18 11:54:52,113][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:1.8161 loss2:1.4022 loss3:0.2048 | AUC:0.7957 Anomaly AUC:0.6010
[2023-09-18 11:56:07,123][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.8841 loss2:1.3933 loss3:0.0448 | AUC:0.8033 Anomaly AUC:0.6061
[2023-09-18 11:57:22,712][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.6270 loss2:1.3897 loss3:0.0324 | AUC:0.8098 Anomaly AUC:0.6121
[2023-09-18 11:58:38,241][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.4827 loss2:1.3856 loss3:0.0293 | AUC:0.8185 Anomaly AUC:0.6224
[2023-09-18 11:59:54,400][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.3710 loss2:1.3771 loss3:0.0252 | AUC:0.8105 Anomaly AUC:0.6151
[2023-09-18 12:01:10,844][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.2923 loss2:1.3688 loss3:0.0238 | AUC:0.8178 Anomaly AUC:0.6299
[2023-09-18 12:02:27,141][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.2682 loss2:1.3581 loss3:0.0226 | AUC:0.8222 Anomaly AUC:0.6263
[2023-09-18 12:03:43,483][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.2314 loss2:1.3360 loss3:0.0208 | AUC:0.8164 Anomaly AUC:0.6136
[2023-09-18 12:04:59,944][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.2083 loss2:1.3130 loss3:0.0198 | AUC:0.8204 Anomaly AUC:0.6231
[2023-09-18 12:06:16,561][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.1723 loss2:1.2846 loss3:0.0214 | AUC:0.8179 Anomaly AUC:0.6102
[2023-09-18 12:07:32,952][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.1640 loss2:1.2578 loss3:0.0161 | AUC:0.8159 Anomaly AUC:0.6140
[2023-09-18 12:08:49,422][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.1482 loss2:1.2351 loss3:0.0190 | AUC:0.8152 Anomaly AUC:0.6156
[2023-09-18 12:10:05,666][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.1698 loss2:1.2096 loss3:0.0146 | AUC:0.8089 Anomaly AUC:0.6059
[2023-09-18 12:11:22,187][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.1612 loss2:1.1911 loss3:0.0158 | AUC:0.8145 Anomaly AUC:0.6079
[2023-09-18 12:12:39,391][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.1300 loss2:1.1668 loss3:0.0131 | AUC:0.8171 Anomaly AUC:0.6087
[2023-09-18 12:13:56,157][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.1266 loss2:1.1446 loss3:0.0131 | AUC:0.8071 Anomaly AUC:0.6010
[2023-09-18 12:15:12,669][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.1281 loss2:1.1189 loss3:0.0125 | AUC:0.8162 Anomaly AUC:0.6077
[2023-09-18 12:16:28,971][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.1213 loss2:1.0944 loss3:0.0110 | AUC:0.8144 Anomaly AUC:0.6070
[2023-09-18 12:17:45,227][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.1237 loss2:1.0775 loss3:0.0137 | AUC:0.8147 Anomaly AUC:0.6017
[2023-09-18 12:19:01,825][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.1313 loss2:1.0594 loss3:0.0094 | AUC:0.8121 Anomaly AUC:0.5945
[2023-09-18 12:20:18,467][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.1228 loss2:1.0388 loss3:0.0089 | AUC:0.8143 Anomaly AUC:0.5945
[2023-09-18 12:21:35,010][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.1161 loss2:1.0136 loss3:0.0072 | AUC:0.8151 Anomaly AUC:0.5933
[2023-09-18 12:22:51,196][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.1054 loss2:0.9819 loss3:0.0084 | AUC:0.8121 Anomaly AUC:0.5950
[2023-09-18 12:24:07,877][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.1116 loss2:0.9535 loss3:0.0129 | AUC:0.8166 Anomaly AUC:0.5989
[2023-09-18 12:25:24,441][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.0867 loss2:0.9230 loss3:0.0076 | AUC:0.8158 Anomaly AUC:0.5954
[2023-09-18 12:26:40,186][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.0844 loss2:0.8742 loss3:0.0094 | AUC:0.8130 Anomaly AUC:0.6010
[2023-09-18 12:27:56,475][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.0846 loss2:0.8425 loss3:0.0086 | AUC:0.8148 Anomaly AUC:0.6041
[2023-09-18 12:29:12,380][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.0851 loss2:0.8074 loss3:0.0064 | AUC:0.8100 Anomaly AUC:0.5910
[2023-09-18 12:30:28,634][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.0765 loss2:0.7952 loss3:0.0058 | AUC:0.8090 Anomaly AUC:0.5943
[2023-09-18 12:31:44,915][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.0798 loss2:0.7739 loss3:0.0069 | AUC:0.8139 Anomaly AUC:0.6071
[2023-09-18 12:33:01,378][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.0726 loss2:0.7489 loss3:0.0048 | AUC:0.8093 Anomaly AUC:0.5948
[2023-09-18 12:34:16,933][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.0781 loss2:0.7356 loss3:0.0063 | AUC:0.8130 Anomaly AUC:0.5937
[2023-09-18 12:35:32,948][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.0759 loss2:0.7094 loss3:0.0063 | AUC:0.8127 Anomaly AUC:0.5927
[2023-09-18 12:36:49,244][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.0697 loss2:0.6877 loss3:0.0069 | AUC:0.8177 Anomaly AUC:0.6046
[2023-09-18 12:38:05,629][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.0776 loss2:0.6756 loss3:0.0055 | AUC:0.8093 Anomaly AUC:0.5879
[2023-09-18 12:39:23,062][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.0762 loss2:0.6634 loss3:0.0065 | AUC:0.8139 Anomaly AUC:0.5910
[2023-09-18 12:40:39,218][main.py][line:106][INFO] [Epoch:37/50]: lr:0.00010 | loss1:0.0828 loss2:0.6496 loss3:0.0039 | AUC:0.8145 Anomaly AUC:0.5898
[2023-09-18 12:41:49,567][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 12:41:52,855][main.py][line:165][INFO] total params:8.6221M
[2023-09-18 12:41:52,856][main.py][line:168][INFO] Training Mode
[2023-09-18 12:41:52,856][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 12:41:52,856][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 12:42:47,758][main.py][line:82][INFO] Random initialize AUCAUC:0.6630 Anomaly AUC:0.57623
[2023-09-18 12:44:03,568][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:1.4213 loss2:1.4011 loss3:0.2344 | AUC:0.7749 Anomaly AUC:0.5892
[2023-09-18 12:45:19,471][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.5380 loss2:1.3994 loss3:0.0571 | AUC:0.7918 Anomaly AUC:0.5956
[2023-09-18 12:46:36,090][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.4250 loss2:1.3991 loss3:0.0445 | AUC:0.7986 Anomaly AUC:0.6005
[2023-09-18 12:47:52,881][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.3478 loss2:1.3989 loss3:0.0374 | AUC:0.8003 Anomaly AUC:0.6016
[2023-09-18 12:49:10,509][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.2919 loss2:1.3941 loss3:0.0331 | AUC:0.8065 Anomaly AUC:0.6051
[2023-09-18 12:50:28,130][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.2344 loss2:1.3925 loss3:0.0312 | AUC:0.8091 Anomaly AUC:0.6105
[2023-09-18 12:51:35,104][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 12:51:38,169][main.py][line:165][INFO] total params:8.6221M
[2023-09-18 12:51:38,170][main.py][line:168][INFO] Training Mode
[2023-09-18 12:51:38,170][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (Nmemory): EnhancedMemoryUnit(
        (memory): Memory_Unit(
          (sig): Sigmoid()
        )
        (self_attn): TCA(
          (q): Linear(in_features=512, out_features=128, bias=True)
          (k): Linear(in_features=512, out_features=128, bias=True)
          (v): Linear(in_features=512, out_features=128, bias=True)
          (o): Linear(in_features=128, out_features=512, bias=True)
          (act): Softmax(dim=-1)
        )
        (loc_adj): DistanceAdj()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 12:51:38,170][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 12:52:30,955][main.py][line:82][INFO] Random initialize AUCAUC:0.6630 Anomaly AUC:0.57623
[2023-09-18 12:53:44,665][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:2.3396 loss2:1.4104 loss3:0.2107 | AUC:0.7314 Anomaly AUC:0.5845
[2023-09-18 12:54:58,903][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:1.0957 loss2:1.3975 loss3:0.0473 | AUC:0.7601 Anomaly AUC:0.5889
[2023-09-18 12:56:13,724][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.8358 loss2:1.3870 loss3:0.0308 | AUC:0.7743 Anomaly AUC:0.5947
[2023-09-18 12:57:28,611][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.7345 loss2:1.3765 loss3:0.0225 | AUC:0.7888 Anomaly AUC:0.6008
[2023-09-18 12:58:44,260][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.6541 loss2:1.3613 loss3:0.0193 | AUC:0.7976 Anomaly AUC:0.6047
[2023-09-18 12:59:59,864][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.5960 loss2:1.3482 loss3:0.0161 | AUC:0.8061 Anomaly AUC:0.6155
[2023-09-18 13:01:14,985][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.5553 loss2:1.3369 loss3:0.0129 | AUC:0.8073 Anomaly AUC:0.6183
[2023-09-18 13:01:49,978][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 60, 'n_nums': 60, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 13:01:53,012][main.py][line:165][INFO] total params:8.0961M
[2023-09-18 13:01:53,012][main.py][line:168][INFO] Training Mode
[2023-09-18 13:01:53,013][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 13:01:53,013][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 13:02:14,905][main.py][line:82][INFO] Random initialize AUCAUC:0.4709 Anomaly AUC:0.45023
[2023-09-18 13:02:48,908][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:2.4531 loss2:1.4077 loss3:0.2156 | AUC:0.7466 Anomaly AUC:0.5733
[2023-09-18 13:03:23,537][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:1.0667 loss2:1.3978 loss3:0.0434 | AUC:0.7729 Anomaly AUC:0.5905
[2023-09-18 13:03:58,465][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.8324 loss2:1.3857 loss3:0.0314 | AUC:0.7811 Anomaly AUC:0.5953
[2023-09-18 13:04:33,312][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.7140 loss2:1.3739 loss3:0.0228 | AUC:0.7845 Anomaly AUC:0.5976
[2023-09-18 13:05:08,488][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.6514 loss2:1.3603 loss3:0.0215 | AUC:0.7892 Anomaly AUC:0.6029
[2023-09-18 13:05:52,071][main.py][line:123][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'lamda': 1.0, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 7, 'ckpt_path': './ckpt/ucf__current.pkl', 'a_nums': 20, 'n_nums': 20, 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 64, 'max_seqlen': 200, 'max_epoch': 50, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-09-18 13:05:55,656][main.py][line:165][INFO] total params:8.0551M
[2023-09-18 13:05:55,657][main.py][line:168][INFO] Training Mode
[2023-09-18 13:05:55,657][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
      (self_attn): TCA(
        (q): Linear(in_features=512, out_features=128, bias=True)
        (k): Linear(in_features=512, out_features=128, bias=True)
        (v): Linear(in_features=512, out_features=128, bias=True)
        (o): Linear(in_features=128, out_features=512, bias=True)
        (act): Softmax(dim=-1)
      )
      (loc_adj): DistanceAdj()
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (embedding2): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-09-18 13:05:55,657][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)

[2023-09-18 13:06:17,552][main.py][line:82][INFO] Random initialize AUCAUC:0.5555 Anomaly AUC:0.50715
[2023-09-18 13:06:51,619][main.py][line:106][INFO] [Epoch:1/50]: lr:0.00010 | loss1:1.9622 loss2:1.4070 loss3:0.1741 | AUC:0.7436 Anomaly AUC:0.5967
[2023-09-18 13:07:25,986][main.py][line:106][INFO] [Epoch:2/50]: lr:0.00010 | loss1:0.9873 loss2:1.3925 loss3:0.0465 | AUC:0.7658 Anomaly AUC:0.5960
[2023-09-18 13:08:00,882][main.py][line:106][INFO] [Epoch:3/50]: lr:0.00010 | loss1:0.8236 loss2:1.3790 loss3:0.0346 | AUC:0.7803 Anomaly AUC:0.6024
[2023-09-18 13:08:35,824][main.py][line:106][INFO] [Epoch:4/50]: lr:0.00010 | loss1:0.6802 loss2:1.3672 loss3:0.0295 | AUC:0.7908 Anomaly AUC:0.6037
[2023-09-18 13:09:11,008][main.py][line:106][INFO] [Epoch:5/50]: lr:0.00010 | loss1:0.6390 loss2:1.3556 loss3:0.0192 | AUC:0.7982 Anomaly AUC:0.6115
[2023-09-18 13:09:46,228][main.py][line:106][INFO] [Epoch:6/50]: lr:0.00010 | loss1:0.5864 loss2:1.3404 loss3:0.0137 | AUC:0.8004 Anomaly AUC:0.6092
[2023-09-18 13:10:21,260][main.py][line:106][INFO] [Epoch:7/50]: lr:0.00010 | loss1:0.5571 loss2:1.3268 loss3:0.0138 | AUC:0.8023 Anomaly AUC:0.6139
[2023-09-18 13:10:56,337][main.py][line:106][INFO] [Epoch:8/50]: lr:0.00010 | loss1:0.5184 loss2:1.3114 loss3:0.0114 | AUC:0.8052 Anomaly AUC:0.6200
[2023-09-18 13:11:31,629][main.py][line:106][INFO] [Epoch:9/50]: lr:0.00010 | loss1:0.4784 loss2:1.2939 loss3:0.0070 | AUC:0.8086 Anomaly AUC:0.6260
[2023-09-18 13:12:06,925][main.py][line:106][INFO] [Epoch:10/50]: lr:0.00010 | loss1:0.4529 loss2:1.2754 loss3:0.0066 | AUC:0.8167 Anomaly AUC:0.6326
[2023-09-18 13:12:42,185][main.py][line:106][INFO] [Epoch:11/50]: lr:0.00010 | loss1:0.4309 loss2:1.2574 loss3:0.0100 | AUC:0.8165 Anomaly AUC:0.6333
[2023-09-18 13:13:17,600][main.py][line:106][INFO] [Epoch:12/50]: lr:0.00010 | loss1:0.4138 loss2:1.2376 loss3:0.0076 | AUC:0.8196 Anomaly AUC:0.6381
[2023-09-18 13:13:52,760][main.py][line:106][INFO] [Epoch:13/50]: lr:0.00010 | loss1:0.3966 loss2:1.2210 loss3:0.0051 | AUC:0.8189 Anomaly AUC:0.6355
[2023-09-18 13:14:28,244][main.py][line:106][INFO] [Epoch:14/50]: lr:0.00010 | loss1:0.3919 loss2:1.2001 loss3:0.0029 | AUC:0.8220 Anomaly AUC:0.6414
[2023-09-18 13:15:03,507][main.py][line:106][INFO] [Epoch:15/50]: lr:0.00010 | loss1:0.3676 loss2:1.1795 loss3:0.0053 | AUC:0.8240 Anomaly AUC:0.6413
[2023-09-18 13:15:38,766][main.py][line:106][INFO] [Epoch:16/50]: lr:0.00010 | loss1:0.3600 loss2:1.1604 loss3:0.0057 | AUC:0.8200 Anomaly AUC:0.6400
[2023-09-18 13:16:14,115][main.py][line:106][INFO] [Epoch:17/50]: lr:0.00010 | loss1:0.3390 loss2:1.1444 loss3:0.0047 | AUC:0.8211 Anomaly AUC:0.6420
[2023-09-18 13:16:49,403][main.py][line:106][INFO] [Epoch:18/50]: lr:0.00010 | loss1:0.3307 loss2:1.1261 loss3:0.0048 | AUC:0.8214 Anomaly AUC:0.6412
[2023-09-18 13:17:24,651][main.py][line:106][INFO] [Epoch:19/50]: lr:0.00010 | loss1:0.3310 loss2:1.1061 loss3:0.0029 | AUC:0.8227 Anomaly AUC:0.6450
[2023-09-18 13:17:59,813][main.py][line:106][INFO] [Epoch:20/50]: lr:0.00010 | loss1:0.3021 loss2:1.0904 loss3:0.0035 | AUC:0.8244 Anomaly AUC:0.6478
[2023-09-18 13:18:35,220][main.py][line:106][INFO] [Epoch:21/50]: lr:0.00010 | loss1:0.2893 loss2:1.0743 loss3:0.0072 | AUC:0.8222 Anomaly AUC:0.6502
[2023-09-18 13:19:10,801][main.py][line:106][INFO] [Epoch:22/50]: lr:0.00010 | loss1:0.2647 loss2:1.0574 loss3:0.0016 | AUC:0.8201 Anomaly AUC:0.6500
[2023-09-18 13:19:46,098][main.py][line:106][INFO] [Epoch:23/50]: lr:0.00010 | loss1:0.2710 loss2:1.0463 loss3:0.0013 | AUC:0.8246 Anomaly AUC:0.6517
[2023-09-18 13:20:21,397][main.py][line:106][INFO] [Epoch:24/50]: lr:0.00010 | loss1:0.2549 loss2:1.0366 loss3:0.0039 | AUC:0.8236 Anomaly AUC:0.6547
[2023-09-18 13:20:56,768][main.py][line:106][INFO] [Epoch:25/50]: lr:0.00010 | loss1:0.2411 loss2:1.0228 loss3:0.0046 | AUC:0.8262 Anomaly AUC:0.6556
[2023-09-18 13:21:32,153][main.py][line:106][INFO] [Epoch:26/50]: lr:0.00010 | loss1:0.2264 loss2:1.0107 loss3:0.0022 | AUC:0.8275 Anomaly AUC:0.6567
[2023-09-18 13:22:07,410][main.py][line:106][INFO] [Epoch:27/50]: lr:0.00010 | loss1:0.2122 loss2:0.9964 loss3:0.0038 | AUC:0.8269 Anomaly AUC:0.6542
[2023-09-18 13:22:42,658][main.py][line:106][INFO] [Epoch:28/50]: lr:0.00010 | loss1:0.2109 loss2:0.9808 loss3:0.0009 | AUC:0.8268 Anomaly AUC:0.6528
[2023-09-18 13:23:18,082][main.py][line:106][INFO] [Epoch:29/50]: lr:0.00010 | loss1:0.1988 loss2:0.9717 loss3:0.0015 | AUC:0.8294 Anomaly AUC:0.6563
[2023-09-18 13:23:53,513][main.py][line:106][INFO] [Epoch:30/50]: lr:0.00010 | loss1:0.1975 loss2:0.9603 loss3:0.0081 | AUC:0.8233 Anomaly AUC:0.6559
[2023-09-18 13:24:28,912][main.py][line:106][INFO] [Epoch:31/50]: lr:0.00010 | loss1:0.1907 loss2:0.9512 loss3:0.0015 | AUC:0.8276 Anomaly AUC:0.6598
[2023-09-18 13:25:04,612][main.py][line:106][INFO] [Epoch:32/50]: lr:0.00010 | loss1:0.1816 loss2:0.9384 loss3:0.0005 | AUC:0.8260 Anomaly AUC:0.6595
[2023-09-18 13:25:39,950][main.py][line:106][INFO] [Epoch:33/50]: lr:0.00010 | loss1:0.1868 loss2:0.9337 loss3:0.0003 | AUC:0.8255 Anomaly AUC:0.6560
[2023-09-18 13:26:15,291][main.py][line:106][INFO] [Epoch:34/50]: lr:0.00010 | loss1:0.1697 loss2:0.9213 loss3:0.0003 | AUC:0.8237 Anomaly AUC:0.6612
[2023-09-18 13:26:50,662][main.py][line:106][INFO] [Epoch:35/50]: lr:0.00010 | loss1:0.1614 loss2:0.9139 loss3:0.0003 | AUC:0.8284 Anomaly AUC:0.6590
[2023-09-18 13:27:26,010][main.py][line:106][INFO] [Epoch:36/50]: lr:0.00010 | loss1:0.1499 loss2:0.8968 loss3:0.0003 | AUC:0.8257 Anomaly AUC:0.6636
[2023-09-18 13:28:01,395][main.py][line:106][INFO] [Epoch:37/50]: lr:0.00010 | loss1:0.1509 loss2:0.8889 loss3:0.0003 | AUC:0.8232 Anomaly AUC:0.6585
[2023-09-18 13:28:37,075][main.py][line:106][INFO] [Epoch:38/50]: lr:0.00010 | loss1:0.1587 loss2:0.8763 loss3:0.0038 | AUC:0.8274 Anomaly AUC:0.6603
[2023-09-18 13:29:12,593][main.py][line:106][INFO] [Epoch:39/50]: lr:0.00010 | loss1:0.1481 loss2:0.8654 loss3:0.0047 | AUC:0.8222 Anomaly AUC:0.6563
[2023-09-18 13:29:48,066][main.py][line:106][INFO] [Epoch:40/50]: lr:0.00010 | loss1:0.1455 loss2:0.8532 loss3:0.0027 | AUC:0.8249 Anomaly AUC:0.6534
[2023-09-18 13:30:23,521][main.py][line:106][INFO] [Epoch:41/50]: lr:0.00010 | loss1:0.1337 loss2:0.8439 loss3:0.0025 | AUC:0.8197 Anomaly AUC:0.6545
[2023-09-18 13:30:59,051][main.py][line:106][INFO] [Epoch:42/50]: lr:0.00010 | loss1:0.1410 loss2:0.8353 loss3:0.0008 | AUC:0.8268 Anomaly AUC:0.6592
[2023-09-18 13:31:34,539][main.py][line:106][INFO] [Epoch:43/50]: lr:0.00010 | loss1:0.1365 loss2:0.8256 loss3:0.0004 | AUC:0.8215 Anomaly AUC:0.6568
[2023-09-18 13:32:10,189][main.py][line:106][INFO] [Epoch:44/50]: lr:0.00010 | loss1:0.1364 loss2:0.8126 loss3:0.0138 | AUC:0.8254 Anomaly AUC:0.6549
[2023-09-18 13:32:45,668][main.py][line:106][INFO] [Epoch:45/50]: lr:0.00010 | loss1:0.1252 loss2:0.8042 loss3:0.0023 | AUC:0.8262 Anomaly AUC:0.6578
[2023-09-18 13:33:21,242][main.py][line:106][INFO] [Epoch:46/50]: lr:0.00010 | loss1:0.1286 loss2:0.7908 loss3:0.0018 | AUC:0.8208 Anomaly AUC:0.6550
[2023-09-18 13:33:56,981][main.py][line:106][INFO] [Epoch:47/50]: lr:0.00010 | loss1:0.1316 loss2:0.7791 loss3:0.0007 | AUC:0.8196 Anomaly AUC:0.6520
[2023-09-18 13:34:32,497][main.py][line:106][INFO] [Epoch:48/50]: lr:0.00010 | loss1:0.1247 loss2:0.7644 loss3:0.0003 | AUC:0.8221 Anomaly AUC:0.6528
[2023-09-18 13:35:07,963][main.py][line:106][INFO] [Epoch:49/50]: lr:0.00010 | loss1:0.1264 loss2:0.7610 loss3:0.0003 | AUC:0.8198 Anomaly AUC:0.6489
[2023-09-18 13:35:43,611][main.py][line:106][INFO] [Epoch:50/50]: lr:0.00010 | loss1:0.1181 loss2:0.7575 loss3:0.0003 | AUC:0.8181 Anomaly AUC:0.6476
[2023-09-18 13:35:43,635][main.py][line:116][INFO] Training completes in 29m 26s | best AUCAUC:0.8294 Anomaly AUC:0.6563

