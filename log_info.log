[2023-11-21 19:24:15,569][main.py][line:292][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:24:19,223][main.py][line:344][INFO] total params:8.2169M
[2023-11-21 19:24:19,224][main.py][line:347][INFO] Training Mode
[2023-11-21 19:24:19,226][main.py][line:143][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:24:48,398][main.py][line:292][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:24:51,463][main.py][line:344][INFO] total params:8.2169M
[2023-11-21 19:24:51,463][main.py][line:347][INFO] Training Mode
[2023-11-21 19:24:51,465][main.py][line:143][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:27:56,657][main.py][line:292][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:27:59,749][main.py][line:344][INFO] total params:8.2169M
[2023-11-21 19:27:59,749][main.py][line:347][INFO] Training Mode
[2023-11-21 19:27:59,752][main.py][line:143][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:28:19,108][main.py][line:192][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-21 19:29:44,418][main.py][line:292][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:29:47,509][main.py][line:344][INFO] total params:8.2169M
[2023-11-21 19:29:47,509][main.py][line:347][INFO] Training Mode
[2023-11-21 19:29:47,512][main.py][line:143][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:30:05,280][main.py][line:192][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-21 19:33:11,408][main.py][line:292][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:33:14,539][main.py][line:344][INFO] total params:8.2169M
[2023-11-21 19:33:14,539][main.py][line:347][INFO] Training Mode
[2023-11-21 19:33:14,542][main.py][line:143][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:33:32,186][main.py][line:192][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-21 19:36:41,150][main.py][line:292][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:36:44,301][main.py][line:344][INFO] total params:8.2169M
[2023-11-21 19:36:44,302][main.py][line:347][INFO] Training Mode
[2023-11-21 19:36:44,304][main.py][line:143][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:37:01,833][main.py][line:192][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-21 19:37:45,052][main.py][line:293][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:37:48,259][main.py][line:345][INFO] total params:8.2169M
[2023-11-21 19:37:48,260][main.py][line:348][INFO] Training Mode
[2023-11-21 19:37:48,262][main.py][line:144][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 19:38:06,059][main.py][line:193][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-21 19:39:08,862][main.py][line:293][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 19:39:12,031][main.py][line:345][INFO] total params:8.2169M
[2023-11-21 19:39:12,032][main.py][line:348][INFO] Training Mode
[2023-11-21 19:39:12,034][main.py][line:144][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 23:27:20,376][main.py][line:293][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-21 23:27:23,888][main.py][line:345][INFO] total params:8.2169M
[2023-11-21 23:27:23,888][main.py][line:348][INFO] Training Mode
[2023-11-21 23:27:23,891][main.py][line:144][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-21 23:28:20,939][main.py][line:193][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-21 23:31:44,527][main.py][line:266][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.7457 loss2:1.3911 loss3:0.4231 | AUC:0.7665 Anomaly AUC:0.5551
[2023-11-21 23:36:34,439][main.py][line:266][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.3537 loss2:1.1609 loss3:0.5252 | AUC:0.8213 Anomaly AUC:0.6034
[2023-11-21 23:40:47,895][main.py][line:266][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.3112 loss2:1.2374 loss3:0.4957 | AUC:0.8432 Anomaly AUC:0.6320
[2023-11-21 23:44:00,762][main.py][line:266][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.3138 loss2:1.0634 loss3:0.5359 | AUC:0.8591 Anomaly AUC:0.6665
[2023-11-21 23:47:55,495][main.py][line:266][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.3383 loss2:0.9088 loss3:0.5478 | AUC:0.8713 Anomaly AUC:0.6939
[2023-11-21 23:53:20,641][main.py][line:266][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-21 23:53:20,641][main.py][line:272][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-21 23:53:20,664][main.py][line:282][INFO] [IDX:2/10] Training completes in 24m 60s | best AUCAUC:0.8713 Anomaly AUC:0.6939

[2023-11-22 00:50:18,559][main.py][line:289][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-22 00:50:21,919][main.py][line:341][INFO] total params:8.2169M
[2023-11-22 00:50:21,920][main.py][line:344][INFO] Training Mode
[2023-11-22 00:50:21,922][main.py][line:140][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-22 00:50:40,269][main.py][line:189][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-22 00:51:02,096][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.7457 loss2:1.3911 loss3:0.4231 | AUC:0.7665 Anomaly AUC:0.5551
[2023-11-22 00:51:26,363][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.3537 loss2:1.1609 loss3:0.5252 | AUC:0.8213 Anomaly AUC:0.6034
[2023-11-22 00:51:47,871][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.3112 loss2:1.2374 loss3:0.4957 | AUC:0.8432 Anomaly AUC:0.6320
[2023-11-22 00:52:12,974][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.3138 loss2:1.0634 loss3:0.5359 | AUC:0.8591 Anomaly AUC:0.6665
[2023-11-22 00:52:39,498][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.3383 loss2:0.9088 loss3:0.5478 | AUC:0.8713 Anomaly AUC:0.6939
[2023-11-22 00:53:05,350][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 00:53:05,351][main.py][line:268][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 00:53:05,417][main.py][line:278][INFO] [IDX:2/10] Training completes in 2m 25s | best AUCAUC:0.8713 Anomaly AUC:0.6939

[2023-11-22 00:54:44,524][main.py][line:189][INFO] Random initialize AUCAUC:0.5698 Anomaly AUC:0.51608
[2023-11-22 00:55:28,657][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.4395 loss2:1.2718 loss3:0.4957 | AUC:0.8169 Anomaly AUC:0.5873
[2023-11-22 00:56:03,039][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.2435 loss2:0.9719 loss3:0.4734 | AUC:0.8284 Anomaly AUC:0.6485
[2023-11-22 00:56:37,544][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.1097 loss2:0.7156 loss3:0.4578 | AUC:0.8365 Anomaly AUC:0.6503
[2023-11-22 00:57:11,448][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.0696 loss2:0.7005 loss3:0.4246 | AUC:0.8367 Anomaly AUC:0.6931
[2023-11-22 00:57:46,137][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.0467 loss2:0.6305 loss3:0.4148 | AUC:0.8263 Anomaly AUC:0.6862
[2023-11-22 00:58:19,970][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.0273 loss2:0.5899 loss3:0.4168 | AUC:0.8380 Anomaly AUC:0.6662
[2023-11-22 00:58:19,971][main.py][line:268][INFO] [IDX:5/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.0273 loss2:0.5899 loss3:0.4168 | AUC:0.8380 Anomaly AUC:0.6662
[2023-11-22 00:58:19,993][main.py][line:278][INFO] [IDX:5/10] Training completes in 3m 35s | best AUCAUC:0.8380 Anomaly AUC:0.6662

[2023-11-22 01:00:46,817][main.py][line:189][INFO] Random initialize AUCAUC:0.6666 Anomaly AUC:0.52703
[2023-11-22 01:02:33,083][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.2521 loss2:0.8488 loss3:0.4695 | AUC:0.8466 Anomaly AUC:0.6485
[2023-11-22 01:03:57,076][main.py][line:234][INFO] [Epoch:2/6, Batch:9/250]: loss1:0.1736 loss2:0.9288 loss3:0.4834 | AUC:0.8353 Anomaly AUC:0.6517
[2023-11-22 01:05:09,989][main.py][line:234][INFO] [Epoch:2/6, Batch:19/250]: loss1:0.0570 loss2:0.7838 loss3:0.5002 | AUC:0.8353 Anomaly AUC:0.6510
[2023-11-22 01:06:12,137][main.py][line:234][INFO] [Epoch:2/6, Batch:29/250]: loss1:0.2853 loss2:0.8300 loss3:0.4792 | AUC:0.8410 Anomaly AUC:0.6590
[2023-11-22 01:07:02,563][main.py][line:234][INFO] [Epoch:2/6, Batch:39/250]: loss1:0.1888 loss2:0.7621 loss3:0.4673 | AUC:0.8472 Anomaly AUC:0.6571
[2023-11-22 01:07:49,447][main.py][line:234][INFO] [Epoch:2/6, Batch:49/250]: loss1:0.3059 loss2:0.9682 loss3:0.4873 | AUC:0.8566 Anomaly AUC:0.6636
[2023-11-22 01:08:26,304][main.py][line:234][INFO] [Epoch:2/6, Batch:59/250]: loss1:0.1447 loss2:0.8242 loss3:0.4573 | AUC:0.8541 Anomaly AUC:0.6677
[2023-11-22 01:09:01,359][main.py][line:234][INFO] [Epoch:2/6, Batch:69/250]: loss1:0.1272 loss2:0.8520 loss3:0.4725 | AUC:0.8438 Anomaly AUC:0.6555
[2023-11-22 01:09:34,685][main.py][line:234][INFO] [Epoch:2/6, Batch:79/250]: loss1:0.1096 loss2:0.8461 loss3:0.4647 | AUC:0.8400 Anomaly AUC:0.6557
[2023-11-22 01:09:58,325][main.py][line:234][INFO] [Epoch:2/6, Batch:89/250]: loss1:0.1188 loss2:0.9306 loss3:0.4667 | AUC:0.8381 Anomaly AUC:0.6601
[2023-11-22 01:10:36,050][main.py][line:234][INFO] [Epoch:2/6, Batch:99/250]: loss1:0.1136 loss2:0.8619 loss3:0.4654 | AUC:0.8426 Anomaly AUC:0.6671
[2023-11-22 01:11:07,156][main.py][line:234][INFO] [Epoch:2/6, Batch:109/250]: loss1:0.1161 loss2:0.8750 loss3:0.4606 | AUC:0.8415 Anomaly AUC:0.6692
[2023-11-22 01:11:40,001][main.py][line:234][INFO] [Epoch:2/6, Batch:119/250]: loss1:0.1693 loss2:0.8778 loss3:0.4323 | AUC:0.8356 Anomaly AUC:0.6693
[2023-11-22 01:12:00,894][main.py][line:234][INFO] [Epoch:2/6, Batch:129/250]: loss1:0.1485 loss2:0.8724 loss3:0.4590 | AUC:0.8312 Anomaly AUC:0.6646
[2023-11-22 01:12:33,121][main.py][line:234][INFO] [Epoch:2/6, Batch:139/250]: loss1:0.0936 loss2:0.7611 loss3:0.4388 | AUC:0.8447 Anomaly AUC:0.6686
[2023-11-22 01:13:01,551][main.py][line:234][INFO] [Epoch:2/6, Batch:149/250]: loss1:0.1154 loss2:0.8775 loss3:0.4394 | AUC:0.8498 Anomaly AUC:0.6728
[2023-11-22 01:13:27,069][main.py][line:234][INFO] [Epoch:2/6, Batch:159/250]: loss1:0.0889 loss2:0.7984 loss3:0.4416 | AUC:0.8480 Anomaly AUC:0.6775
[2023-11-22 01:13:58,557][main.py][line:234][INFO] [Epoch:2/6, Batch:169/250]: loss1:0.0857 loss2:0.7925 loss3:0.4398 | AUC:0.8503 Anomaly AUC:0.6820
[2023-11-22 01:14:25,215][main.py][line:234][INFO] [Epoch:2/6, Batch:179/250]: loss1:0.1110 loss2:0.9000 loss3:0.4515 | AUC:0.8440 Anomaly AUC:0.6744
[2023-11-22 01:14:48,431][main.py][line:234][INFO] [Epoch:2/6, Batch:189/250]: loss1:0.1227 loss2:0.7563 loss3:0.4330 | AUC:0.8530 Anomaly AUC:0.6807
[2023-11-22 01:15:14,279][main.py][line:234][INFO] [Epoch:2/6, Batch:199/250]: loss1:0.0917 loss2:0.7750 loss3:0.4233 | AUC:0.8540 Anomaly AUC:0.6809
[2023-11-22 01:15:36,809][main.py][line:234][INFO] [Epoch:2/6, Batch:209/250]: loss1:0.0818 loss2:0.7465 loss3:0.4531 | AUC:0.8510 Anomaly AUC:0.6750
[2023-11-22 01:15:58,705][main.py][line:234][INFO] [Epoch:2/6, Batch:219/250]: loss1:0.0784 loss2:0.7364 loss3:0.4315 | AUC:0.8518 Anomaly AUC:0.6769
[2023-11-22 01:16:20,659][main.py][line:234][INFO] [Epoch:2/6, Batch:229/250]: loss1:0.0814 loss2:0.7099 loss3:0.4243 | AUC:0.8535 Anomaly AUC:0.6836
[2023-11-22 01:16:42,661][main.py][line:234][INFO] [Epoch:2/6, Batch:239/250]: loss1:0.0810 loss2:0.7932 loss3:0.4135 | AUC:0.8400 Anomaly AUC:0.6767
[2023-11-22 01:17:05,949][main.py][line:234][INFO] [Epoch:2/6, Batch:249/250]: loss1:0.0603 loss2:0.8606 loss3:0.4214 | AUC:0.8408 Anomaly AUC:0.6730
[2023-11-22 01:17:31,021][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.0603 loss2:0.8606 loss3:0.4214 | AUC:0.8408 Anomaly AUC:0.6730
[2023-11-22 01:17:52,951][main.py][line:234][INFO] [Epoch:3/6, Batch:9/250]: loss1:0.0595 loss2:0.8129 loss3:0.4224 | AUC:0.8446 Anomaly AUC:0.6722
[2023-11-22 01:18:23,765][main.py][line:234][INFO] [Epoch:3/6, Batch:19/250]: loss1:0.0399 loss2:0.7129 loss3:0.4198 | AUC:0.8414 Anomaly AUC:0.6829
[2023-11-22 01:19:50,468][main.py][line:289][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-22 01:19:53,811][main.py][line:341][INFO] total params:8.2169M
[2023-11-22 01:19:53,811][main.py][line:344][INFO] Training Mode
[2023-11-22 01:19:53,814][main.py][line:140][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-22 01:20:16,132][main.py][line:189][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-22 01:20:40,430][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.7457 loss2:1.3911 loss3:0.4231 | AUC:0.7665 Anomaly AUC:0.5551
[2023-11-22 01:21:06,400][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.3537 loss2:1.1609 loss3:0.5252 | AUC:0.8213 Anomaly AUC:0.6034
[2023-11-22 01:21:35,188][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.3112 loss2:1.2374 loss3:0.4957 | AUC:0.8432 Anomaly AUC:0.6320
[2023-11-22 01:22:00,076][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.3138 loss2:1.0634 loss3:0.5359 | AUC:0.8591 Anomaly AUC:0.6665
[2023-11-22 01:22:29,270][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.3383 loss2:0.9088 loss3:0.5478 | AUC:0.8713 Anomaly AUC:0.6939
[2023-11-22 01:22:53,915][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 01:22:53,915][main.py][line:268][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 01:22:53,949][main.py][line:278][INFO] [IDX:2/10] Training completes in 2m 38s | best AUCAUC:0.8713 Anomaly AUC:0.6939

[2023-11-22 01:23:59,873][main.py][line:189][INFO] Random initialize AUCAUC:0.5698 Anomaly AUC:0.51608
[2023-11-22 01:24:34,668][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.3882 loss2:1.2715 loss3:0.4908 | AUC:0.8216 Anomaly AUC:0.5922
[2023-11-22 01:25:10,415][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.2728 loss2:0.9854 loss3:0.4854 | AUC:0.8417 Anomaly AUC:0.6494
[2023-11-22 01:25:48,714][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.0925 loss2:0.7213 loss3:0.4580 | AUC:0.8487 Anomaly AUC:0.6675
[2023-11-22 01:26:26,014][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.0515 loss2:0.6985 loss3:0.4193 | AUC:0.8451 Anomaly AUC:0.6847
[2023-11-22 01:27:01,233][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.0599 loss2:0.6178 loss3:0.4097 | AUC:0.8426 Anomaly AUC:0.6854
[2023-11-22 01:27:35,420][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.0434 loss2:0.5654 loss3:0.4051 | AUC:0.8494 Anomaly AUC:0.6779
[2023-11-22 01:27:35,421][main.py][line:268][INFO] [IDX:5/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.0434 loss2:0.5654 loss3:0.4051 | AUC:0.8494 Anomaly AUC:0.6779
[2023-11-22 01:27:35,443][main.py][line:278][INFO] [IDX:5/10] Training completes in 3m 36s | best AUCAUC:0.8494 Anomaly AUC:0.6779

[2023-11-22 01:30:31,899][main.py][line:189][INFO] Random initialize AUCAUC:0.6666 Anomaly AUC:0.52703
[2023-11-22 01:32:32,965][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.2421 loss2:0.8301 loss3:0.4840 | AUC:0.8577 Anomaly AUC:0.6627
[2023-11-22 01:34:59,812][main.py][line:289][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-22 01:35:03,095][main.py][line:341][INFO] total params:8.2169M
[2023-11-22 01:35:03,096][main.py][line:344][INFO] Training Mode
[2023-11-22 01:35:03,098][main.py][line:140][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-22 01:35:23,928][main.py][line:189][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-22 01:35:46,452][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.7457 loss2:1.3911 loss3:0.4231 | AUC:0.7665 Anomaly AUC:0.5551
[2023-11-22 01:36:10,819][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.3537 loss2:1.1609 loss3:0.5252 | AUC:0.8213 Anomaly AUC:0.6034
[2023-11-22 01:36:35,492][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.3112 loss2:1.2374 loss3:0.4957 | AUC:0.8432 Anomaly AUC:0.6320
[2023-11-22 01:37:00,624][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.3138 loss2:1.0634 loss3:0.5359 | AUC:0.8591 Anomaly AUC:0.6665
[2023-11-22 01:37:25,207][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.3383 loss2:0.9088 loss3:0.5478 | AUC:0.8713 Anomaly AUC:0.6939
[2023-11-22 01:37:49,549][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 01:37:49,549][main.py][line:268][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 01:37:49,583][main.py][line:278][INFO] [IDX:2/10] Training completes in 2m 26s | best AUCAUC:0.8713 Anomaly AUC:0.6939

[2023-11-22 01:38:57,994][main.py][line:189][INFO] Random initialize AUCAUC:0.5698 Anomaly AUC:0.51608
[2023-11-22 01:39:32,609][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.4013 loss2:1.2700 loss3:0.4950 | AUC:0.8200 Anomaly AUC:0.5868
[2023-11-22 01:40:08,674][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.2725 loss2:0.9740 loss3:0.4825 | AUC:0.8319 Anomaly AUC:0.6421
[2023-11-22 01:40:42,724][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.1496 loss2:0.7351 loss3:0.4513 | AUC:0.8416 Anomaly AUC:0.6474
[2023-11-22 01:41:18,001][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.0784 loss2:0.7238 loss3:0.4252 | AUC:0.8559 Anomaly AUC:0.6753
[2023-11-22 01:41:50,327][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.0794 loss2:0.6206 loss3:0.4111 | AUC:0.8446 Anomaly AUC:0.6762
[2023-11-22 01:42:24,916][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.0388 loss2:0.5575 loss3:0.4094 | AUC:0.8570 Anomaly AUC:0.6767
[2023-11-22 01:42:24,916][main.py][line:268][INFO] [IDX:5/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.0388 loss2:0.5575 loss3:0.4094 | AUC:0.8570 Anomaly AUC:0.6767
[2023-11-22 01:42:24,938][main.py][line:278][INFO] [IDX:5/10] Training completes in 3m 27s | best AUCAUC:0.8570 Anomaly AUC:0.6767

[2023-11-22 01:44:38,081][main.py][line:189][INFO] Random initialize AUCAUC:0.6666 Anomaly AUC:0.52703
[2023-11-22 01:46:21,624][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.2120 loss2:0.8233 loss3:0.4944 | AUC:0.8613 Anomaly AUC:0.6671
[2023-11-22 01:49:58,978][main.py][line:234][INFO] [Epoch:2/6, Batch:9/250]: loss1:0.2173 loss2:0.9519 loss3:0.4729 | AUC:0.8600 Anomaly AUC:0.6678
[2023-11-22 01:53:49,419][main.py][line:234][INFO] [Epoch:2/6, Batch:19/250]: loss1:0.0774 loss2:0.7939 loss3:0.5029 | AUC:0.8611 Anomaly AUC:0.6694
[2023-11-22 01:56:42,506][main.py][line:289][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-22 01:56:45,916][main.py][line:341][INFO] total params:8.2169M
[2023-11-22 01:56:45,916][main.py][line:344][INFO] Training Mode
[2023-11-22 01:56:45,919][main.py][line:140][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-22 01:57:05,552][main.py][line:189][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-22 01:57:27,558][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.7457 loss2:1.3911 loss3:0.4231 | AUC:0.7665 Anomaly AUC:0.5551
[2023-11-22 01:57:49,316][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.3537 loss2:1.1609 loss3:0.5252 | AUC:0.8213 Anomaly AUC:0.6034
[2023-11-22 01:58:10,855][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.3112 loss2:1.2374 loss3:0.4957 | AUC:0.8432 Anomaly AUC:0.6320
[2023-11-22 01:58:32,579][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.3138 loss2:1.0634 loss3:0.5359 | AUC:0.8591 Anomaly AUC:0.6665
[2023-11-22 01:58:54,234][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.3383 loss2:0.9088 loss3:0.5478 | AUC:0.8713 Anomaly AUC:0.6939
[2023-11-22 01:59:15,732][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 01:59:15,733][main.py][line:268][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 01:59:15,769][main.py][line:278][INFO] [IDX:2/10] Training completes in 2m 10s | best AUCAUC:0.8713 Anomaly AUC:0.6939

[2023-11-22 02:00:13,755][main.py][line:189][INFO] Random initialize AUCAUC:0.5698 Anomaly AUC:0.51608
[2023-11-22 02:00:44,129][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.4046 loss2:1.2690 loss3:0.4984 | AUC:0.8243 Anomaly AUC:0.5936
[2023-11-22 02:01:14,631][main.py][line:262][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.2717 loss2:0.9745 loss3:0.4764 | AUC:0.8445 Anomaly AUC:0.6485
[2023-11-22 02:01:45,084][main.py][line:262][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.0850 loss2:0.7176 loss3:0.4680 | AUC:0.8447 Anomaly AUC:0.6812
[2023-11-22 02:02:15,337][main.py][line:262][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.0453 loss2:0.6924 loss3:0.4271 | AUC:0.8535 Anomaly AUC:0.6832
[2023-11-22 02:02:45,784][main.py][line:262][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.0330 loss2:0.6157 loss3:0.4153 | AUC:0.8665 Anomaly AUC:0.6977
[2023-11-22 02:03:16,093][main.py][line:262][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.0403 loss2:0.5498 loss3:0.4050 | AUC:0.8593 Anomaly AUC:0.6949
[2023-11-22 02:03:16,093][main.py][line:268][INFO] [IDX:5/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.0403 loss2:0.5498 loss3:0.4050 | AUC:0.8593 Anomaly AUC:0.6949
[2023-11-22 02:03:16,115][main.py][line:278][INFO] [IDX:5/10] Training completes in 3m 2s | best AUCAUC:0.8665 Anomaly AUC:0.6977

[2023-11-22 02:04:57,440][main.py][line:189][INFO] Random initialize AUCAUC:0.6666 Anomaly AUC:0.52703
[2023-11-22 02:06:32,990][main.py][line:262][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.2340 loss2:0.8221 loss3:0.4739 | AUC:0.8651 Anomaly AUC:0.6704
[2023-11-22 02:09:58,513][main.py][line:234][INFO] [Epoch:2/6, Batch:9/250]: loss1:0.1487 loss2:0.9245 loss3:0.4834 | AUC:0.8631 Anomaly AUC:0.6699
[2023-11-22 02:11:08,116][main.py][line:288][INFO] Config:{'dataset': 'ucf-crime', 'model_name': 'ucf_', 'metrics': 'AUC', 'feat_prefix': './data/ucf-i3d', 'train_list': './list/ucf/train.list', 'test_list': './list/ucf/test.list', 'token_feat': './list/ucf/ucf-prompt.npy', 'gt': './list/ucf/ucf-gt.npy', 'win_size': 9, 'gamma': 0.6, 'bias': 0.2, 'norm': True, 't_step': 9, 'temp': 0.09, 'seed': 2023, 'test_bs': 10, 'smooth': 'slide', 'kappa': 8, 'ckpt_path': './ckpt/ucf__current.pkl', 'pesudo_label': '../VAE/pesudo_label.pkl', 'a_nums': 50, 'n_nums': 50, 'k': 20, 'margin': 100, 'max_epoch': 6, 'clip_feat_prefix': '/home/yukaneko/dev/CLIP-TSA_dataset/ucf/features/', 'feat_dim': 1024, 'head_num': 1, 'hid_dim': 128, 'out_dim': 300, 'lr': 0.0001, 'dropout': 0.5, 'train_bs': 32, 'max_seqlen': 200, 'workers': 8, 'save_dir': './ckpt/', 'logs_dir': './log_info.log'}
[2023-11-22 02:11:11,329][main.py][line:340][INFO] total params:8.2169M
[2023-11-22 02:11:11,329][main.py][line:343][INFO] Training Mode
[2023-11-22 02:11:11,332][main.py][line:140][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Pdropout()
    (dropout2): Pdropout()
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (UR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
    (hard_atten): HardAttention(
      (scorer): MLP(
        (fc1): Linear(in_features=512, out_features=256, bias=True)
        (fc2): Linear(in_features=256, out_features=1, bias=True)
        (relu): ReLU()
        (sigmoid): Sigmoid()
      )
      (hard_att): PerturbedTopK()
    )
    (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)

[2023-11-22 02:11:31,966][main.py][line:188][INFO] Random initialize AUCAUC:0.5732 Anomaly AUC:0.53754
[2023-11-22 02:11:53,907][main.py][line:261][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.7457 loss2:1.3911 loss3:0.4231 | AUC:0.7665 Anomaly AUC:0.5551
[2023-11-22 02:12:15,157][main.py][line:261][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.3537 loss2:1.1609 loss3:0.5252 | AUC:0.8213 Anomaly AUC:0.6034
[2023-11-22 02:12:36,882][main.py][line:261][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.3112 loss2:1.2374 loss3:0.4957 | AUC:0.8432 Anomaly AUC:0.6320
[2023-11-22 02:12:58,368][main.py][line:261][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.3138 loss2:1.0634 loss3:0.5359 | AUC:0.8591 Anomaly AUC:0.6665
[2023-11-22 02:13:19,757][main.py][line:261][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.3383 loss2:0.9088 loss3:0.5478 | AUC:0.8713 Anomaly AUC:0.6939
[2023-11-22 02:13:41,161][main.py][line:261][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 02:13:41,161][main.py][line:267][INFO] [IDX:2/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.1723 loss2:0.9314 loss3:0.4862 | AUC:0.8707 Anomaly AUC:0.6898
[2023-11-22 02:13:41,196][main.py][line:277][INFO] [IDX:2/10] Training completes in 2m 9s | best AUCAUC:0.8713 Anomaly AUC:0.6939

[2023-11-22 02:14:46,672][main.py][line:188][INFO] Random initialize AUCAUC:0.8713 Anomaly AUC:0.69398
[2023-11-22 02:15:16,645][main.py][line:261][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.1400 loss2:0.8245 loss3:0.4369 | AUC:0.8669 Anomaly AUC:0.6954
[2023-11-22 02:15:47,310][main.py][line:261][INFO] [Epoch:2/6]: lr:0.00010 | loss1:0.1143 loss2:0.7729 loss3:0.4132 | AUC:0.8673 Anomaly AUC:0.7049
[2023-11-22 02:16:18,477][main.py][line:261][INFO] [Epoch:3/6]: lr:0.00010 | loss1:0.0346 loss2:0.6669 loss3:0.3967 | AUC:0.8629 Anomaly AUC:0.7048
[2023-11-22 02:16:48,996][main.py][line:261][INFO] [Epoch:4/6]: lr:0.00010 | loss1:0.0477 loss2:0.6582 loss3:0.3829 | AUC:0.8593 Anomaly AUC:0.6896
[2023-11-22 02:17:19,445][main.py][line:261][INFO] [Epoch:5/6]: lr:0.00010 | loss1:0.0318 loss2:0.6014 loss3:0.3681 | AUC:0.8567 Anomaly AUC:0.6629
[2023-11-22 02:17:51,011][main.py][line:261][INFO] [Epoch:6/6]: lr:0.00010 | loss1:0.0335 loss2:0.5223 loss3:0.3642 | AUC:0.8348 Anomaly AUC:0.6265
[2023-11-22 02:17:51,012][main.py][line:267][INFO] [IDX:5/10, Epoch:6/6]: lr:1.000e-04 | loss1:0.0335 loss2:0.5223 loss3:0.3642 | AUC:0.8348 Anomaly AUC:0.6265
[2023-11-22 02:17:51,034][main.py][line:277][INFO] [IDX:5/10] Training completes in 3m 4s | best AUCAUC:0.8673 Anomaly AUC:0.7049

[2023-11-22 02:19:58,822][main.py][line:188][INFO] Random initialize AUCAUC:0.8674 Anomaly AUC:0.70511
[2023-11-22 02:20:47,995][main.py][line:261][INFO] [Epoch:1/6]: lr:0.00010 | loss1:0.0596 loss2:0.6701 loss3:0.3814 | AUC:0.8738 Anomaly AUC:0.7022
[2023-11-22 02:25:35,421][main.py][line:233][INFO] [Epoch:2/6, Batch:9/250]: loss1:0.0140 loss2:0.6581 loss3:0.3796 | AUC:0.8722 Anomaly AUC:0.7046
[2023-11-22 02:31:41,549][main.py][line:233][INFO] [Epoch:2/6, Batch:19/250]: loss1:0.0353 loss2:0.6646 loss3:0.3833 | AUC:0.8690 Anomaly AUC:0.7113
[2023-11-22 02:39:57,390][main.py][line:233][INFO] [Epoch:2/6, Batch:29/250]: loss1:0.0282 loss2:0.7472 loss3:0.3773 | AUC:0.8648 Anomaly AUC:0.6988
