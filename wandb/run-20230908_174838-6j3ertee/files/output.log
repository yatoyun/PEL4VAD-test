
8000 8100 2900
[2023-09-08 17:48:40,655][main.py][line:165][INFO] total params:7.5195M
[2023-09-08 17:48:40,656][main.py][line:168][INFO] Training Mode
[2023-09-08 17:48:40,656][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)
[2023-09-08 17:48:40,656][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)
[2023-09-08 17:48:48,759][main.py][line:82][INFO] Random initialize AUCAUC:0.5223 Anomaly AUC:0.49998
[2023-09-08 17:49:09,529][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3262 loss2:1.1322 loss3:0.3181 | AUC:0.7969 Anomaly AUC:0.6682
[2023-09-08 17:49:30,094][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0478 loss2:0.8238 loss3:0.2107 | AUC:0.8239 Anomaly AUC:0.6698
[2023-09-08 17:49:50,878][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0265 loss2:0.7094 loss3:0.1155 | AUC:0.8168 Anomaly AUC:0.6588
[2023-09-08 17:50:11,762][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0207 loss2:0.6232 loss3:0.0649 | AUC:0.8281 Anomaly AUC:0.6657
[2023-09-08 17:50:32,780][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0148 loss2:0.5602 loss3:0.0434 | AUC:0.8361 Anomaly AUC:0.6723
[2023-09-08 17:50:53,889][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0103 loss2:0.4951 loss3:0.0321 | AUC:0.8478 Anomaly AUC:0.6779
[2023-09-08 17:51:14,908][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0073 loss2:0.4433 loss3:0.0232 | AUC:0.8478 Anomaly AUC:0.6770
[2023-09-08 17:51:36,061][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0066 loss2:0.3938 loss3:0.0203 | AUC:0.8434 Anomaly AUC:0.6826
[2023-09-08 17:51:57,344][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0048 loss2:0.3519 loss3:0.0168 | AUC:0.8444 Anomaly AUC:0.6747
[2023-09-08 17:52:18,512][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0033 loss2:0.3134 loss3:0.0143 | AUC:0.8440 Anomaly AUC:0.6595
[2023-09-08 17:52:39,636][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0050 loss2:0.2965 loss3:0.0134 | AUC:0.8448 Anomaly AUC:0.6653
[2023-09-08 17:53:00,796][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0077 loss2:0.2847 loss3:0.0145 | AUC:0.8470 Anomaly AUC:0.6712
[2023-09-08 17:53:22,041][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0020 loss2:0.2539 loss3:0.0118 | AUC:0.8449 Anomaly AUC:0.6627
[2023-09-08 17:53:43,309][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0023 loss2:0.2459 loss3:0.0116 | AUC:0.8439 Anomaly AUC:0.6615
[2023-09-08 17:54:04,500][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0031 loss2:0.2294 loss3:0.0115 | AUC:0.8455 Anomaly AUC:0.6785
[2023-09-08 17:54:25,666][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0042 loss2:0.2258 loss3:0.0114 | AUC:0.8456 Anomaly AUC:0.6720
[2023-09-08 17:54:46,859][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0050 loss2:0.2167 loss3:0.0117 | AUC:0.8476 Anomaly AUC:0.6743
[2023-09-08 17:55:08,212][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0027 loss2:0.2078 loss3:0.0108 | AUC:0.8414 Anomaly AUC:0.6620
[2023-09-08 17:55:29,573][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0059 loss2:0.2103 loss3:0.0116 | AUC:0.8524 Anomaly AUC:0.6825
[2023-09-08 17:55:50,794][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0009 loss2:0.1877 loss3:0.0100 | AUC:0.8567 Anomaly AUC:0.6792
[2023-09-08 17:56:12,018][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0014 loss2:0.1838 loss3:0.0103 | AUC:0.8514 Anomaly AUC:0.6872
[2023-09-08 17:56:33,375][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0121 loss2:0.1878 loss3:0.0125 | AUC:0.8534 Anomaly AUC:0.6844
[2023-09-08 17:56:54,771][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0072 loss2:0.1879 loss3:0.0121 | AUC:0.8601 Anomaly AUC:0.6943
[2023-09-08 17:57:16,023][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0055 loss2:0.1806 loss3:0.0118 | AUC:0.8448 Anomaly AUC:0.6685
[2023-09-08 17:57:37,172][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0022 loss2:0.1630 loss3:0.0102 | AUC:0.8446 Anomaly AUC:0.6754
[2023-09-08 17:57:58,438][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0003 loss2:0.1523 loss3:0.0093 | AUC:0.8518 Anomaly AUC:0.6807
[2023-09-08 17:58:19,666][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0003 loss2:0.1459 loss3:0.0088 | AUC:0.8512 Anomaly AUC:0.6804
[2023-09-08 17:58:40,919][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0002 loss2:0.1390 loss3:0.0085 | AUC:0.8484 Anomaly AUC:0.6791
[2023-09-08 17:59:02,375][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0002 loss2:0.1350 loss3:0.0083 | AUC:0.8513 Anomaly AUC:0.6839
[2023-09-08 17:59:23,581][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0018 loss2:0.1375 loss3:0.0083 | AUC:0.8529 Anomaly AUC:0.6872
[2023-09-08 17:59:44,808][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0123 loss2:0.1631 loss3:0.0112 | AUC:0.8529 Anomaly AUC:0.6673
[2023-09-08 18:00:06,105][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0117 loss2:0.1533 loss3:0.0110 | AUC:0.8428 Anomaly AUC:0.6642
[2023-09-08 18:00:27,471][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0081 loss2:0.1385 loss3:0.0103 | AUC:0.8375 Anomaly AUC:0.6740
[2023-09-08 18:00:48,667][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0048 loss2:0.1313 loss3:0.0101 | AUC:0.8442 Anomaly AUC:0.6690
[2023-09-08 18:01:09,882][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0032 loss2:0.1210 loss3:0.0087 | AUC:0.8380 Anomaly AUC:0.6640
[2023-09-08 18:01:31,175][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0009 loss2:0.1125 loss3:0.0077 | AUC:0.8479 Anomaly AUC:0.6656
[2023-09-08 18:01:52,553][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0002 loss2:0.1052 loss3:0.0069 | AUC:0.8506 Anomaly AUC:0.6705
[2023-09-08 18:02:13,783][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0002 loss2:0.1009 loss3:0.0063 | AUC:0.8483 Anomaly AUC:0.6675
[2023-09-08 18:02:35,064][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0002 loss2:0.0970 loss3:0.0057 | AUC:0.8386 Anomaly AUC:0.6493
[2023-09-08 18:02:56,416][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0159 loss2:0.1161 loss3:0.0081 | AUC:0.8433 Anomaly AUC:0.6607
[2023-09-08 18:03:17,865][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0081 loss2:0.1034 loss3:0.0065 | AUC:0.8424 Anomaly AUC:0.6782
[2023-09-08 18:03:39,316][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0105 loss2:0.1121 loss3:0.0074 | AUC:0.8353 Anomaly AUC:0.6806
[2023-09-08 18:04:00,657][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0171 loss2:0.1054 loss3:0.0076 | AUC:0.8258 Anomaly AUC:0.6641
[2023-09-08 18:04:22,010][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0057 loss2:0.0952 loss3:0.0057 | AUC:0.8404 Anomaly AUC:0.6658
[2023-09-08 18:04:43,396][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0040 loss2:0.0888 loss3:0.0047 | AUC:0.8523 Anomaly AUC:0.6955
[2023-09-08 18:05:04,893][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0089 loss2:0.0897 loss3:0.0051 | AUC:0.8472 Anomaly AUC:0.6852
[2023-09-08 18:05:26,283][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0026 loss2:0.0796 loss3:0.0030 | AUC:0.8510 Anomaly AUC:0.6807
[2023-09-08 18:05:47,532][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0023 loss2:0.0726 loss3:0.0016 | AUC:0.8421 Anomaly AUC:0.6714
[2023-09-08 18:06:08,899][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0001 loss2:0.0678 loss3:0.0003 | AUC:0.8429 Anomaly AUC:0.6719
[2023-09-08 18:06:30,282][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0001 loss2:0.0645 loss3:0.0002 | AUC:0.8309 Anomaly AUC:0.6396
[2023-09-08 18:06:51,720][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0030 loss2:0.0657 loss3:0.0007 | AUC:0.8486 Anomaly AUC:0.6773
[2023-09-08 18:07:13,020][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0068 loss2:0.0718 loss3:0.0017 | AUC:0.8433 Anomaly AUC:0.6598
[2023-09-08 18:07:34,393][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0068 loss2:0.0715 loss3:0.0015 | AUC:0.8440 Anomaly AUC:0.6762
[2023-09-08 18:07:55,725][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0037 loss2:0.0641 loss3:0.0010 | AUC:0.8238 Anomaly AUC:0.6546
[2023-09-08 18:08:17,125][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0088 loss2:0.0675 loss3:0.0020 | AUC:0.8178 Anomaly AUC:0.6452
[2023-09-08 18:08:38,446][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0015 loss2:0.0567 loss3:0.0011 | AUC:0.8415 Anomaly AUC:0.6774
[2023-09-08 18:08:59,843][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0015 loss2:0.0508 loss3:0.0005 | AUC:0.8415 Anomaly AUC:0.6819
[2023-09-08 18:09:21,159][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0079 loss2:0.0559 loss3:0.0014 | AUC:0.8085 Anomaly AUC:0.6454
[2023-09-08 18:09:42,558][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0040 loss2:0.0524 loss3:0.0014 | AUC:0.8235 Anomaly AUC:0.6584
[2023-09-08 18:10:03,827][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0004 loss2:0.0453 loss3:0.0004 | AUC:0.8190 Anomaly AUC:0.6448
[2023-09-08 18:10:25,212][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0001 loss2:0.0414 loss3:0.0002 | AUC:0.8225 Anomaly AUC:0.6473
[2023-09-08 18:10:46,591][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0002 loss2:0.0399 loss3:0.0002 | AUC:0.8338 Anomaly AUC:0.6503
[2023-09-08 18:11:07,940][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0034 loss2:0.0429 loss3:0.0011 | AUC:0.8289 Anomaly AUC:0.6601
[2023-09-08 18:11:29,427][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0073 loss2:0.0533 loss3:0.0019 | AUC:0.8409 Anomaly AUC:0.6762
[2023-09-08 18:11:50,905][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0021 loss2:0.0383 loss3:0.0007 | AUC:0.8277 Anomaly AUC:0.6706
[2023-09-08 18:12:12,287][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0039 loss2:0.0391 loss3:0.0009 | AUC:0.8288 Anomaly AUC:0.6672
[2023-09-08 18:12:33,677][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0019 loss2:0.0360 loss3:0.0008 | AUC:0.8207 Anomaly AUC:0.6682
[2023-09-08 18:12:55,133][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0018 loss2:0.0346 loss3:0.0007 | AUC:0.8297 Anomaly AUC:0.6755
[2023-09-08 18:13:16,518][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0001 loss2:0.0296 loss3:0.0003 | AUC:0.8351 Anomaly AUC:0.6748
[2023-09-08 18:13:37,970][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0001 loss2:0.0283 loss3:0.0003 | AUC:0.8450 Anomaly AUC:0.6665
[2023-09-08 18:13:59,340][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0084 loss2:0.0400 loss3:0.0019 | AUC:0.8169 Anomaly AUC:0.6609
[2023-09-08 18:14:20,697][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0052 loss2:0.0372 loss3:0.0017 | AUC:0.8429 Anomaly AUC:0.6698
[2023-09-08 18:14:42,164][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0038 loss2:0.0305 loss3:0.0008 | AUC:0.8261 Anomaly AUC:0.6677
[2023-09-08 18:15:03,551][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0031 loss2:0.0284 loss3:0.0012 | AUC:0.8311 Anomaly AUC:0.6880
[2023-09-08 18:15:24,911][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0006 loss2:0.0249 loss3:0.0005 | AUC:0.8285 Anomaly AUC:0.6704
[2023-09-08 18:15:46,335][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0001 loss2:0.0216 loss3:0.0002 | AUC:0.8353 Anomaly AUC:0.6732
[2023-09-08 18:16:07,762][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0001 loss2:0.0206 loss3:0.0002 | AUC:0.8392 Anomaly AUC:0.6736
[2023-09-08 18:16:29,138][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0001 loss2:0.0197 loss3:0.0002 | AUC:0.8418 Anomaly AUC:0.6744
[2023-09-08 18:16:50,495][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0001 loss2:0.0184 loss3:0.0002 | AUC:0.8415 Anomaly AUC:0.6737
[2023-09-08 18:17:12,080][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0001 loss2:0.0176 loss3:0.0002 | AUC:0.8419 Anomaly AUC:0.6715
[2023-09-08 18:17:33,538][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0001 loss2:0.0168 loss3:0.0002 | AUC:0.8418 Anomaly AUC:0.6699
[2023-09-08 18:17:55,016][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0001 loss2:0.0161 loss3:0.0002 | AUC:0.8428 Anomaly AUC:0.6710
[2023-09-08 18:18:16,518][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0001 loss2:0.0155 loss3:0.0002 | AUC:0.8404 Anomaly AUC:0.6696
[2023-09-08 18:18:37,948][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0001 loss2:0.0145 loss3:0.0002 | AUC:0.8418 Anomaly AUC:0.6692
[2023-09-08 18:18:59,368][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0001 loss2:0.0142 loss3:0.0002 | AUC:0.8405 Anomaly AUC:0.6690
[2023-09-08 18:19:20,795][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0001 loss2:0.0136 loss3:0.0002 | AUC:0.8415 Anomaly AUC:0.6677
[2023-09-08 18:19:42,174][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0001 loss2:0.0125 loss3:0.0002 | AUC:0.8437 Anomaly AUC:0.6690
[2023-09-08 18:20:03,511][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0001 loss2:0.0120 loss3:0.0002 | AUC:0.8417 Anomaly AUC:0.6686
[2023-09-08 18:20:25,030][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0205 loss2:0.0513 loss3:0.0044 | AUC:0.8321 Anomaly AUC:0.6760
[2023-09-08 18:20:46,410][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0130 loss2:0.0336 loss3:0.0030 | AUC:0.8333 Anomaly AUC:0.6756
[2023-09-08 18:21:07,760][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0097 loss2:0.0276 loss3:0.0021 | AUC:0.8320 Anomaly AUC:0.6645
[2023-09-08 18:21:29,119][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0027 loss2:0.0146 loss3:0.0008 | AUC:0.8154 Anomaly AUC:0.6737
[2023-09-08 18:21:50,397][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.0033 loss2:0.0149 loss3:0.0010 | AUC:0.8219 Anomaly AUC:0.6747
[2023-09-08 18:22:11,725][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0065 loss2:0.0187 loss3:0.0013 | AUC:0.8362 Anomaly AUC:0.6821
[2023-09-08 18:22:33,092][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0001 loss2:0.0109 loss3:0.0004 | AUC:0.8387 Anomaly AUC:0.6645
[2023-09-08 18:22:54,416][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0002 loss2:0.0090 loss3:0.0003 | AUC:0.8416 Anomaly AUC:0.6650
[2023-09-08 18:23:15,708][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0003 loss2:0.0083 loss3:0.0002 | AUC:0.8440 Anomaly AUC:0.6686
[2023-09-08 18:23:37,148][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0024 loss2:0.0103 loss3:0.0006 | AUC:0.8324 Anomaly AUC:0.6656
[2023-09-08 18:23:58,626][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0002 loss2:0.0077 loss3:0.0004 | AUC:0.8292 Anomaly AUC:0.6548
[2023-09-08 18:24:20,079][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0001 loss2:0.0070 loss3:0.0003 | AUC:0.8310 Anomaly AUC:0.6567
[2023-09-08 18:24:20,103][main.py][line:116][INFO] Training completes in 35m 31s | best AUCAUC:0.8601 Anomaly AUC:0.6943