[2023-09-08 20:10:12,748][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 20:10:12,748][main.py][line:168][INFO] Training Mode
[2023-09-08 20:10:12,749][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)
[2023-09-08 20:10:12,749][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)
8000 8100 2900
[2023-09-08 20:10:20,816][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-08 20:10:39,053][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.5273 loss2:1.2215 loss3:0.2657 | AUC:0.8208 Anomaly AUC:0.6607
[2023-09-08 20:10:57,090][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.2955 loss2:0.8976 loss3:0.0725 | AUC:0.8298 Anomaly AUC:0.6711
[2023-09-08 20:11:15,737][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.2125 loss2:0.7922 loss3:0.0425 | AUC:0.8048 Anomaly AUC:0.6619
[2023-09-08 20:11:34,361][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.1763 loss2:0.7313 loss3:0.0345 | AUC:0.8353 Anomaly AUC:0.6802
[2023-09-08 20:11:53,035][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0987 loss2:0.6299 loss3:0.0188 | AUC:0.8331 Anomaly AUC:0.6586
[2023-09-08 20:12:11,851][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0780 loss2:0.5650 loss3:0.0140 | AUC:0.8296 Anomaly AUC:0.6864
[2023-09-08 20:12:30,691][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0369 loss2:0.4620 loss3:0.0066 | AUC:0.8414 Anomaly AUC:0.6826
[2023-09-08 20:12:49,469][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0246 loss2:0.3866 loss3:0.0045 | AUC:0.8420 Anomaly AUC:0.6866
[2023-09-08 20:13:08,235][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0302 loss2:0.3160 loss3:0.0048 | AUC:0.8300 Anomaly AUC:0.6739
[2023-09-08 20:13:27,014][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0195 loss2:0.2438 loss3:0.0035 | AUC:0.8170 Anomaly AUC:0.6526
[2023-09-08 20:13:45,782][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0192 loss2:0.1786 loss3:0.0033 | AUC:0.8202 Anomaly AUC:0.6681
[2023-09-08 20:14:04,596][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0171 loss2:0.1304 loss3:0.0032 | AUC:0.8278 Anomaly AUC:0.6721
[2023-09-08 20:14:23,434][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0054 loss2:0.0754 loss3:0.0014 | AUC:0.8342 Anomaly AUC:0.6473
[2023-09-08 20:14:42,261][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0100 loss2:0.0628 loss3:0.0020 | AUC:0.8378 Anomaly AUC:0.6651
[2023-09-08 20:15:01,088][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0142 loss2:0.0679 loss3:0.0028 | AUC:0.8141 Anomaly AUC:0.6272
[2023-09-08 20:15:20,055][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0139 loss2:0.0570 loss3:0.0026 | AUC:0.8005 Anomaly AUC:0.6490
[2023-09-08 20:15:38,846][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0085 loss2:0.0399 loss3:0.0017 | AUC:0.8210 Anomaly AUC:0.6487
[2023-09-08 20:15:57,627][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0015 loss2:0.0192 loss3:0.0007 | AUC:0.8221 Anomaly AUC:0.6310
[2023-09-08 20:16:16,433][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0103 loss2:0.0267 loss3:0.0017 | AUC:0.8277 Anomaly AUC:0.6700
[2023-09-08 20:16:35,244][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0220 loss2:0.0514 loss3:0.0035 | AUC:0.8197 Anomaly AUC:0.6845
[2023-09-08 20:16:54,057][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0115 loss2:0.0331 loss3:0.0020 | AUC:0.8043 Anomaly AUC:0.6544
[2023-09-08 20:17:12,934][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0011 loss2:0.0128 loss3:0.0005 | AUC:0.8222 Anomaly AUC:0.6466
[2023-09-08 20:17:31,768][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0068 loss2:0.0178 loss3:0.0012 | AUC:0.8231 Anomaly AUC:0.6636
[2023-09-08 20:17:50,710][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0083 loss2:0.0200 loss3:0.0017 | AUC:0.8253 Anomaly AUC:0.6275
[2023-09-08 20:18:09,541][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0011 loss2:0.0139 loss3:0.0006 | AUC:0.8545 Anomaly AUC:0.6852
[2023-09-08 20:18:28,317][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0004 loss2:0.0076 loss3:0.0003 | AUC:0.8440 Anomaly AUC:0.6632
[2023-09-08 20:18:47,091][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0001 loss2:0.0045 loss3:0.0003 | AUC:0.8386 Anomaly AUC:0.6692
[2023-09-08 20:19:05,369][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0002 loss2:0.0000 loss3:0.0003 | AUC:0.8292 Anomaly AUC:0.6488
[2023-09-08 20:19:23,578][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8304 Anomaly AUC:0.6504
[2023-09-08 20:19:41,723][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8318 Anomaly AUC:0.6450
[2023-09-08 20:19:59,962][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8325 Anomaly AUC:0.6427
[2023-09-08 20:20:18,096][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00050 | loss1:0.0000 loss2:0.0000 loss3:0.0002 | AUC:0.8329 Anomaly AUC:0.6401
Traceback (most recent call last):
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 203, in <module>
    main(cfg)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 170, in main
    train(model, train_nloader, train_aloader, test_loader, gt, logger)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 90, in train
    loss1, loss2, cost = train_func(train_nloader, train_aloader, model, optimizer, criterion, criterion2, criterion3, logger_wandb, args.lamda, args.alpha)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/train.py", line 23, in train_func
    seq_len = torch.sum(torch.max(torch.abs(v_input), dim=2)[0] > 0, 1)
KeyboardInterrupt