[2023-09-08 20:58:40,416][main.py][line:165][INFO] total params:17.0166M
[2023-09-08 20:58:40,416][main.py][line:168][INFO] Training Mode
[2023-09-08 20:58:40,417][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=1024, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=1024, out_features=1024, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=1024, out_features=1024, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)
[2023-09-08 20:58:40,417][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0005
    maximize: False
    weight_decay: 5e-05
)
8000 8100 2900
[2023-09-08 20:58:47,876][main.py][line:82][INFO] Random initialize AUCAUC:0.5615 Anomaly AUC:0.52366
[2023-09-08 20:59:09,469][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00050 | loss1:0.0624 loss2:1.0443 loss3:0.1426 | AUC:0.7357 Anomaly AUC:0.6533
[2023-09-08 20:59:30,898][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00050 | loss1:0.0167 loss2:0.8428 loss3:0.0909 | AUC:0.7497 Anomaly AUC:0.6611
[2023-09-08 20:59:52,552][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00050 | loss1:0.0043 loss2:0.7664 loss3:0.0612 | AUC:0.7743 Anomaly AUC:0.6601
[2023-09-08 21:00:14,327][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00050 | loss1:0.0036 loss2:0.7124 loss3:0.0532 | AUC:0.7585 Anomaly AUC:0.6476
[2023-09-08 21:00:36,124][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00050 | loss1:0.0024 loss2:0.6546 loss3:0.0472 | AUC:0.7631 Anomaly AUC:0.6589
[2023-09-08 21:00:58,021][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00050 | loss1:0.0025 loss2:0.5845 loss3:0.0414 | AUC:0.7552 Anomaly AUC:0.6402
[2023-09-08 21:01:19,971][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00050 | loss1:0.0023 loss2:0.5124 loss3:0.0386 | AUC:0.7537 Anomaly AUC:0.6360
[2023-09-08 21:01:41,801][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00050 | loss1:0.0024 loss2:0.4330 loss3:0.0365 | AUC:0.7618 Anomaly AUC:0.6321
[2023-09-08 21:02:03,719][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00050 | loss1:0.0024 loss2:0.3520 loss3:0.0327 | AUC:0.7478 Anomaly AUC:0.6316
[2023-09-08 21:02:25,620][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00050 | loss1:0.0023 loss2:0.2835 loss3:0.0316 | AUC:0.7179 Anomaly AUC:0.6179
[2023-09-08 21:02:47,494][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00050 | loss1:0.0017 loss2:0.2369 loss3:0.0302 | AUC:0.7577 Anomaly AUC:0.6416
[2023-09-08 21:03:09,499][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00050 | loss1:0.0015 loss2:0.1815 loss3:0.0288 | AUC:0.7728 Anomaly AUC:0.6446
[2023-09-08 21:03:31,538][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00050 | loss1:0.0011 loss2:0.1305 loss3:0.0254 | AUC:0.7698 Anomaly AUC:0.6463
[2023-09-08 21:03:53,664][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00050 | loss1:0.0020 loss2:0.1103 loss3:0.0243 | AUC:0.7268 Anomaly AUC:0.6480
[2023-09-08 21:04:15,722][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00050 | loss1:0.0012 loss2:0.0951 loss3:0.0235 | AUC:0.7518 Anomaly AUC:0.6396
[2023-09-08 21:04:37,712][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00050 | loss1:0.0011 loss2:0.0659 loss3:0.0203 | AUC:0.7565 Anomaly AUC:0.6309
[2023-09-08 21:04:59,751][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00050 | loss1:0.0010 loss2:0.0568 loss3:0.0188 | AUC:0.7341 Anomaly AUC:0.6174
[2023-09-08 21:05:21,839][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00050 | loss1:0.0010 loss2:0.0576 loss3:0.0202 | AUC:0.7767 Anomaly AUC:0.6656
[2023-09-08 21:05:43,775][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00050 | loss1:0.0008 loss2:0.0396 loss3:0.0171 | AUC:0.7419 Anomaly AUC:0.6347
[2023-09-08 21:06:05,659][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00050 | loss1:0.0007 loss2:0.0300 loss3:0.0174 | AUC:0.7759 Anomaly AUC:0.6505
[2023-09-08 21:06:27,727][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00050 | loss1:0.0009 loss2:0.0411 loss3:0.0178 | AUC:0.7783 Anomaly AUC:0.6380
[2023-09-08 21:06:49,836][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00050 | loss1:0.0028 loss2:0.0493 loss3:0.0268 | AUC:0.7325 Anomaly AUC:0.6413
[2023-09-08 21:07:11,861][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00050 | loss1:0.0006 loss2:0.0246 loss3:0.0167 | AUC:0.7263 Anomaly AUC:0.6456
[2023-09-08 21:07:33,877][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00050 | loss1:0.0006 loss2:0.0268 loss3:0.0146 | AUC:0.7146 Anomaly AUC:0.6498
[2023-09-08 21:07:55,945][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00050 | loss1:0.0006 loss2:0.0229 loss3:0.0156 | AUC:0.7704 Anomaly AUC:0.6522
[2023-09-08 21:08:17,898][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00050 | loss1:0.0008 loss2:0.0225 loss3:0.0150 | AUC:0.7419 Anomaly AUC:0.6398
[2023-09-08 21:08:39,972][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00050 | loss1:0.0008 loss2:0.0324 loss3:0.0167 | AUC:0.7696 Anomaly AUC:0.6429
[2023-09-08 21:09:02,249][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00050 | loss1:0.0008 loss2:0.0274 loss3:0.0178 | AUC:0.7424 Anomaly AUC:0.6362
[2023-09-08 21:09:24,261][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00050 | loss1:0.0005 loss2:0.0165 loss3:0.0147 | AUC:0.7618 Anomaly AUC:0.6432
[2023-09-08 21:09:46,314][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00050 | loss1:0.0033 loss2:0.0323 loss3:0.0270 | AUC:0.7365 Anomaly AUC:0.6545
[2023-09-08 21:10:08,307][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00050 | loss1:0.0012 loss2:0.0307 loss3:0.0236 | AUC:0.7089 Anomaly AUC:0.6618
Traceback (most recent call last):
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 203, in <module>
    main(cfg)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 170, in main
    train(model, train_nloader, train_aloader, test_loader, gt, logger)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 90, in train
    loss1, loss2, cost = train_func(train_nloader, train_aloader, model, optimizer, criterion, criterion2, criterion3, logger_wandb, args.lamda, args.alpha)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/train.py", line 23, in train_func
    seq_len = torch.sum(torch.max(torch.abs(v_input), dim=2)[0] > 0, 1)
KeyboardInterrupt