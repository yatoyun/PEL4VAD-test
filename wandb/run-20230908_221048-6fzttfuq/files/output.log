
8000 8100 2900
[2023-09-08 22:10:50,710][main.py][line:165][INFO] total params:7.5400M
[2023-09-08 22:10:50,710][main.py][line:168][INFO] Training Mode
[2023-09-08 22:10:50,710][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
)
[2023-09-08 22:10:50,711][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)
[2023-09-08 22:10:58,797][main.py][line:82][INFO] Random initialize AUCAUC:0.6179 Anomaly AUC:0.52117
[2023-09-08 22:11:17,078][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.4374 loss2:1.1496 loss3:0.3402 | AUC:0.8219 Anomaly AUC:0.6583
[2023-09-08 22:11:35,200][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.1790 loss2:0.8475 loss3:0.2032 | AUC:0.8436 Anomaly AUC:0.6864
[2023-09-08 22:11:53,413][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0842 loss2:0.7565 loss3:0.1042 | AUC:0.8460 Anomaly AUC:0.6831
[2023-09-08 22:12:11,971][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0399 loss2:0.6855 loss3:0.0485 | AUC:0.8587 Anomaly AUC:0.6962
[2023-09-08 22:12:30,528][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0148 loss2:0.6215 loss3:0.0261 | AUC:0.8524 Anomaly AUC:0.6937
[2023-09-08 22:12:49,262][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0100 loss2:0.5590 loss3:0.0178 | AUC:0.8458 Anomaly AUC:0.6755
[2023-09-08 22:13:07,911][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0159 loss2:0.5170 loss3:0.0152 | AUC:0.8415 Anomaly AUC:0.6765
[2023-09-08 22:13:26,631][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0140 loss2:0.4753 loss3:0.0136 | AUC:0.8468 Anomaly AUC:0.6826
[2023-09-08 22:13:45,346][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00009 | loss1:0.0104 loss2:0.4341 loss3:0.0113 | AUC:0.8509 Anomaly AUC:0.6931
[2023-09-08 22:14:04,106][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00009 | loss1:0.0027 loss2:0.3886 loss3:0.0077 | AUC:0.8513 Anomaly AUC:0.6933
[2023-09-08 22:14:22,847][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00009 | loss1:0.0064 loss2:0.3586 loss3:0.0062 | AUC:0.8455 Anomaly AUC:0.6762
[2023-09-08 22:14:41,755][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00009 | loss1:0.0070 loss2:0.3400 loss3:0.0046 | AUC:0.8511 Anomaly AUC:0.6916
[2023-09-08 22:15:00,658][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00009 | loss1:0.0017 loss2:0.3031 loss3:0.0025 | AUC:0.8508 Anomaly AUC:0.6883
[2023-09-08 22:15:19,497][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00009 | loss1:0.0012 loss2:0.2812 loss3:0.0019 | AUC:0.8512 Anomaly AUC:0.6891
[2023-09-08 22:15:38,275][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00009 | loss1:0.0008 loss2:0.2617 loss3:0.0018 | AUC:0.8510 Anomaly AUC:0.6914
[2023-09-08 22:15:57,145][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00008 | loss1:0.0009 loss2:0.2453 loss3:0.0017 | AUC:0.8509 Anomaly AUC:0.6916
[2023-09-08 22:16:16,018][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00008 | loss1:0.0010 loss2:0.2317 loss3:0.0020 | AUC:0.8414 Anomaly AUC:0.6816
[2023-09-08 22:16:34,957][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00008 | loss1:0.0007 loss2:0.2155 loss3:0.0016 | AUC:0.8435 Anomaly AUC:0.6786
[2023-09-08 22:16:53,823][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00008 | loss1:0.0006 loss2:0.2032 loss3:0.0015 | AUC:0.8470 Anomaly AUC:0.6808
[2023-09-08 22:17:12,659][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00008 | loss1:0.0415 loss2:0.2334 loss3:0.0067 | AUC:0.8521 Anomaly AUC:0.7027
[2023-09-08 22:17:31,460][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00007 | loss1:0.0253 loss2:0.2366 loss3:0.0065 | AUC:0.8503 Anomaly AUC:0.6948
[2023-09-08 22:17:50,296][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00007 | loss1:0.0025 loss2:0.1909 loss3:0.0026 | AUC:0.8472 Anomaly AUC:0.6932
[2023-09-08 22:18:09,068][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00007 | loss1:0.0010 loss2:0.1794 loss3:0.0020 | AUC:0.8491 Anomaly AUC:0.6958
[2023-09-08 22:18:27,818][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00007 | loss1:0.0008 loss2:0.1715 loss3:0.0016 | AUC:0.8492 Anomaly AUC:0.6964
[2023-09-08 22:18:46,720][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00006 | loss1:0.0007 loss2:0.1647 loss3:0.0015 | AUC:0.8491 Anomaly AUC:0.6908
[2023-09-08 22:19:05,569][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00006 | loss1:0.0006 loss2:0.1593 loss3:0.0014 | AUC:0.8501 Anomaly AUC:0.6929
[2023-09-08 22:19:24,455][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00006 | loss1:0.0005 loss2:0.1544 loss3:0.0013 | AUC:0.8496 Anomaly AUC:0.6926
[2023-09-08 22:19:43,386][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00006 | loss1:0.0005 loss2:0.1490 loss3:0.0012 | AUC:0.8499 Anomaly AUC:0.6933
[2023-09-08 22:20:02,298][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00005 | loss1:0.0005 loss2:0.1450 loss3:0.0011 | AUC:0.8500 Anomaly AUC:0.6949
[2023-09-08 22:20:21,199][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00005 | loss1:0.0004 loss2:0.1418 loss3:0.0011 | AUC:0.8506 Anomaly AUC:0.6953
[2023-09-08 22:20:40,075][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00005 | loss1:0.0004 loss2:0.1384 loss3:0.0011 | AUC:0.8491 Anomaly AUC:0.6992
[2023-09-08 22:20:58,950][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00004 | loss1:0.0010 loss2:0.1379 loss3:0.0013 | AUC:0.8520 Anomaly AUC:0.6992
[2023-09-08 22:21:17,853][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00004 | loss1:0.0006 loss2:0.1338 loss3:0.0012 | AUC:0.8464 Anomaly AUC:0.6875
[2023-09-08 22:21:36,802][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00004 | loss1:0.0004 loss2:0.1308 loss3:0.0010 | AUC:0.8502 Anomaly AUC:0.6936
[2023-09-08 22:21:55,616][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00004 | loss1:0.0004 loss2:0.1274 loss3:0.0009 | AUC:0.8507 Anomaly AUC:0.6942
[2023-09-08 22:22:14,645][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00003 | loss1:0.0003 loss2:0.1250 loss3:0.0009 | AUC:0.8508 Anomaly AUC:0.6935
[2023-09-08 22:22:33,590][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00003 | loss1:0.0003 loss2:0.1233 loss3:0.0009 | AUC:0.8512 Anomaly AUC:0.6922
[2023-09-08 22:22:52,581][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00003 | loss1:0.0003 loss2:0.1219 loss3:0.0009 | AUC:0.8520 Anomaly AUC:0.6931
[2023-09-08 22:23:11,486][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00003 | loss1:0.0003 loss2:0.1197 loss3:0.0008 | AUC:0.8521 Anomaly AUC:0.6920
[2023-09-08 22:23:30,356][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00003 | loss1:0.0003 loss2:0.1180 loss3:0.0008 | AUC:0.8521 Anomaly AUC:0.6922
[2023-09-08 22:23:49,208][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00002 | loss1:0.0003 loss2:0.1170 loss3:0.0008 | AUC:0.8530 Anomaly AUC:0.6926
[2023-09-08 22:24:08,095][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00002 | loss1:0.0003 loss2:0.1148 loss3:0.0008 | AUC:0.8528 Anomaly AUC:0.6927
[2023-09-08 22:24:27,063][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00002 | loss1:0.0003 loss2:0.1142 loss3:0.0008 | AUC:0.8531 Anomaly AUC:0.6918
[2023-09-08 22:24:46,090][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00002 | loss1:0.0003 loss2:0.1130 loss3:0.0007 | AUC:0.8519 Anomaly AUC:0.6921
[2023-09-08 22:25:05,195][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00001 | loss1:0.0003 loss2:0.1118 loss3:0.0008 | AUC:0.8517 Anomaly AUC:0.6931
[2023-09-08 22:25:24,327][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00001 | loss1:0.0003 loss2:0.1111 loss3:0.0007 | AUC:0.8532 Anomaly AUC:0.6941
[2023-09-08 22:25:43,270][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00001 | loss1:0.0002 loss2:0.1100 loss3:0.0007 | AUC:0.8533 Anomaly AUC:0.6935
[2023-09-08 22:26:02,311][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00001 | loss1:0.0003 loss2:0.1108 loss3:0.0007 | AUC:0.8518 Anomaly AUC:0.6918
[2023-09-08 22:26:21,168][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00001 | loss1:0.0002 loss2:0.1088 loss3:0.0007 | AUC:0.8529 Anomaly AUC:0.6937
[2023-09-08 22:26:40,135][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00001 | loss1:0.0002 loss2:0.1076 loss3:0.0007 | AUC:0.8534 Anomaly AUC:0.6949
[2023-09-08 22:26:59,143][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00001 | loss1:0.0002 loss2:0.1080 loss3:0.0007 | AUC:0.8529 Anomaly AUC:0.6942
[2023-09-08 22:27:18,080][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00000 | loss1:0.0002 loss2:0.1073 loss3:0.0007 | AUC:0.8534 Anomaly AUC:0.6949
[2023-09-08 22:27:36,942][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00000 | loss1:0.0002 loss2:0.1073 loss3:0.0007 | AUC:0.8534 Anomaly AUC:0.6950
[2023-09-08 22:27:56,033][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00000 | loss1:0.0002 loss2:0.1077 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6947
[2023-09-08 22:28:15,050][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00000 | loss1:0.0002 loss2:0.1065 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6944
[2023-09-08 22:28:33,965][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6945
[2023-09-08 22:28:52,920][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6941
[2023-09-08 22:29:11,840][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00000 | loss1:0.0002 loss2:0.1069 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:29:30,839][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00000 | loss1:0.0002 loss2:0.1063 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:29:49,740][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00000 | loss1:0.0002 loss2:0.1067 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:30:08,725][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00000 | loss1:0.0002 loss2:0.1067 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:30:27,631][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00000 | loss1:0.0002 loss2:0.1065 loss3:0.0007 | AUC:0.8527 Anomaly AUC:0.6940
[2023-09-08 22:30:46,648][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00000 | loss1:0.0002 loss2:0.1071 loss3:0.0007 | AUC:0.8528 Anomaly AUC:0.6940
[2023-09-08 22:31:05,749][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00000 | loss1:0.0002 loss2:0.1064 loss3:0.0007 | AUC:0.8529 Anomaly AUC:0.6940
[2023-09-08 22:31:24,721][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6941
[2023-09-08 22:31:43,661][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00000 | loss1:0.0002 loss2:0.1064 loss3:0.0007 | AUC:0.8531 Anomaly AUC:0.6947
[2023-09-08 22:32:02,799][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00000 | loss1:0.0002 loss2:0.1068 loss3:0.0007 | AUC:0.8533 Anomaly AUC:0.6945
[2023-09-08 22:32:21,846][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00000 | loss1:0.0002 loss2:0.1066 loss3:0.0006 | AUC:0.8525 Anomaly AUC:0.6933
[2023-09-08 22:32:40,855][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00001 | loss1:0.0002 loss2:0.1060 loss3:0.0007 | AUC:0.8523 Anomaly AUC:0.6932
[2023-09-08 22:32:59,941][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00001 | loss1:0.0002 loss2:0.1061 loss3:0.0007 | AUC:0.8530 Anomaly AUC:0.6939
[2023-09-08 22:33:18,955][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00001 | loss1:0.0002 loss2:0.1049 loss3:0.0007 | AUC:0.8513 Anomaly AUC:0.6918
[2023-09-08 22:33:38,010][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00001 | loss1:0.0002 loss2:0.1049 loss3:0.0007 | AUC:0.8511 Anomaly AUC:0.6912
[2023-09-08 22:33:56,968][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00001 | loss1:0.0002 loss2:0.1046 loss3:0.0007 | AUC:0.8508 Anomaly AUC:0.6912
[2023-09-08 22:34:15,944][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00001 | loss1:0.0002 loss2:0.1045 loss3:0.0007 | AUC:0.8420 Anomaly AUC:0.6810
[2023-09-08 22:34:35,114][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00001 | loss1:0.0002 loss2:0.1042 loss3:0.0007 | AUC:0.8477 Anomaly AUC:0.6875
[2023-09-08 22:34:54,140][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00002 | loss1:0.0012 loss2:0.1040 loss3:0.0008 | AUC:0.8393 Anomaly AUC:0.6859
[2023-09-08 22:35:13,177][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00002 | loss1:0.0033 loss2:0.1069 loss3:0.0015 | AUC:0.8485 Anomaly AUC:0.6949
[2023-09-08 22:35:32,328][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00002 | loss1:0.0009 loss2:0.1043 loss3:0.0011 | AUC:0.8437 Anomaly AUC:0.6878
[2023-09-08 22:35:51,417][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00002 | loss1:0.0003 loss2:0.1024 loss3:0.0009 | AUC:0.8446 Anomaly AUC:0.6877
[2023-09-08 22:36:10,408][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00002 | loss1:0.0002 loss2:0.1008 loss3:0.0008 | AUC:0.8433 Anomaly AUC:0.6889
[2023-09-08 22:36:29,490][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00003 | loss1:0.0002 loss2:0.0989 loss3:0.0007 | AUC:0.8483 Anomaly AUC:0.6918
[2023-09-08 22:36:48,638][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00003 | loss1:0.0002 loss2:0.0978 loss3:0.0007 | AUC:0.8494 Anomaly AUC:0.6939
[2023-09-08 22:37:07,707][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00003 | loss1:0.0008 loss2:0.0969 loss3:0.0008 | AUC:0.8448 Anomaly AUC:0.6881
[2023-09-08 22:37:26,603][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00003 | loss1:0.0118 loss2:0.1118 loss3:0.0031 | AUC:0.8404 Anomaly AUC:0.6791
[2023-09-08 22:37:45,742][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00004 | loss1:0.0016 loss2:0.0977 loss3:0.0014 | AUC:0.8441 Anomaly AUC:0.6877
[2023-09-08 22:38:04,813][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00004 | loss1:0.0015 loss2:0.0952 loss3:0.0013 | AUC:0.8378 Anomaly AUC:0.6815
[2023-09-08 22:38:23,928][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00004 | loss1:0.0007 loss2:0.0936 loss3:0.0012 | AUC:0.8310 Anomaly AUC:0.6670
[2023-09-08 22:38:43,035][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00004 | loss1:0.0004 loss2:0.0915 loss3:0.0011 | AUC:0.8457 Anomaly AUC:0.6833
[2023-09-08 22:39:02,136][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00005 | loss1:0.0003 loss2:0.0888 loss3:0.0009 | AUC:0.8424 Anomaly AUC:0.6805
[2023-09-08 22:39:21,247][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00005 | loss1:0.0002 loss2:0.0872 loss3:0.0008 | AUC:0.8440 Anomaly AUC:0.6805
[2023-09-08 22:39:40,459][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00005 | loss1:0.0002 loss2:0.0854 loss3:0.0007 | AUC:0.8432 Anomaly AUC:0.6769
[2023-09-08 22:39:59,470][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00006 | loss1:0.0002 loss2:0.0831 loss3:0.0007 | AUC:0.8440 Anomaly AUC:0.6791
[2023-09-08 22:40:18,548][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00006 | loss1:0.0001 loss2:0.0815 loss3:0.0007 | AUC:0.8424 Anomaly AUC:0.6777
[2023-09-08 22:40:37,776][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00006 | loss1:0.0001 loss2:0.0801 loss3:0.0007 | AUC:0.8425 Anomaly AUC:0.6764
[2023-09-08 22:40:57,069][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00006 | loss1:0.0001 loss2:0.0775 loss3:0.0006 | AUC:0.8450 Anomaly AUC:0.6809
[2023-09-08 22:41:16,246][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00007 | loss1:0.0400 loss2:0.1193 loss3:0.0063 | AUC:0.8221 Anomaly AUC:0.6701
[2023-09-08 22:41:35,425][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00007 | loss1:0.0137 loss2:0.1000 loss3:0.0041 | AUC:0.8448 Anomaly AUC:0.6889
[2023-09-08 22:41:54,473][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00007 | loss1:0.0006 loss2:0.0755 loss3:0.0014 | AUC:0.8448 Anomaly AUC:0.6865
[2023-09-08 22:42:13,626][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00007 | loss1:0.0003 loss2:0.0710 loss3:0.0010 | AUC:0.8451 Anomaly AUC:0.6879
[2023-09-08 22:42:32,658][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00007 | loss1:0.0008 loss2:0.0691 loss3:0.0009 | AUC:0.8404 Anomaly AUC:0.6825
[2023-09-08 22:42:32,683][main.py][line:116][INFO] Training completes in 31m 34s | best AUCAUC:0.8587 Anomaly AUC:0.6962