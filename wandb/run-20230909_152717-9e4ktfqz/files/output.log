
8000 8100 2900
[2023-09-09 15:27:19,171][main.py][line:165][INFO] total params:8.6101M
[2023-09-09 15:27:19,172][main.py][line:168][INFO] Training Mode
[2023-09-09 15:27:19,172][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (embedding2): Linear(in_features=1024, out_features=512, bias=True)
      (embedding3): Linear(in_features=1024, out_features=512, bias=True)
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)
[2023-09-09 15:27:19,172][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)
[2023-09-09 15:27:27,383][main.py][line:82][INFO] Random initialize AUCAUC:0.4906 Anomaly AUC:0.48936
[2023-09-09 15:27:46,162][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.1066 loss2:1.0301 loss3:0.3711 | AUC:0.7827 Anomaly AUC:0.6337
[2023-09-09 15:28:04,652][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0032 loss2:0.6988 loss3:0.2403 | AUC:0.7504 Anomaly AUC:0.6404
[2023-09-09 15:28:23,507][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0059 loss2:0.5982 loss3:0.1226 | AUC:0.7747 Anomaly AUC:0.6629
[2023-09-09 15:28:42,543][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0054 loss2:0.5092 loss3:0.0556 | AUC:0.7930 Anomaly AUC:0.6655
[2023-09-09 15:29:01,749][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0037 loss2:0.4276 loss3:0.0289 | AUC:0.8086 Anomaly AUC:0.6718
[2023-09-09 15:29:20,922][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0031 loss2:0.3685 loss3:0.0210 | AUC:0.8086 Anomaly AUC:0.6655
[2023-09-09 15:29:40,166][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0021 loss2:0.3267 loss3:0.0119 | AUC:0.8115 Anomaly AUC:0.6734
[2023-09-09 15:29:59,511][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0017 loss2:0.2945 loss3:0.0086 | AUC:0.8178 Anomaly AUC:0.6759
[2023-09-09 15:30:18,972][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0014 loss2:0.2688 loss3:0.0062 | AUC:0.8190 Anomaly AUC:0.6738
[2023-09-09 15:30:38,218][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0012 loss2:0.2525 loss3:0.0050 | AUC:0.8168 Anomaly AUC:0.6610
[2023-09-09 15:30:57,519][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0011 loss2:0.2403 loss3:0.0047 | AUC:0.8142 Anomaly AUC:0.6531
[2023-09-09 15:31:16,860][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0011 loss2:0.2292 loss3:0.0048 | AUC:0.8205 Anomaly AUC:0.6558
[2023-09-09 15:31:36,101][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0009 loss2:0.2164 loss3:0.0032 | AUC:0.8164 Anomaly AUC:0.6548
[2023-09-09 15:31:55,394][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0007 loss2:0.2069 loss3:0.0027 | AUC:0.8205 Anomaly AUC:0.6617
[2023-09-09 15:32:14,737][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0006 loss2:0.1998 loss3:0.0023 | AUC:0.8212 Anomaly AUC:0.6679
[2023-09-09 15:32:34,083][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0006 loss2:0.1915 loss3:0.0023 | AUC:0.8215 Anomaly AUC:0.6673
[2023-09-09 15:32:53,468][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0005 loss2:0.1854 loss3:0.0020 | AUC:0.8240 Anomaly AUC:0.6686
[2023-09-09 15:33:12,717][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0046 loss2:0.1994 loss3:0.0184 | AUC:0.7918 Anomaly AUC:0.6477
[2023-09-09 15:33:31,978][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0014 loss2:0.1799 loss3:0.0081 | AUC:0.8090 Anomaly AUC:0.6574
[2023-09-09 15:33:51,342][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0006 loss2:0.1679 loss3:0.0029 | AUC:0.8150 Anomaly AUC:0.6584
[2023-09-09 15:34:10,706][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0005 loss2:0.1607 loss3:0.0020 | AUC:0.8170 Anomaly AUC:0.6564
[2023-09-09 15:34:30,072][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0013 loss2:0.1577 loss3:0.0035 | AUC:0.7824 Anomaly AUC:0.6461
[2023-09-09 15:34:49,362][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0005 loss2:0.1517 loss3:0.0029 | AUC:0.8113 Anomaly AUC:0.6528
[2023-09-09 15:35:08,708][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0004 loss2:0.1456 loss3:0.0015 | AUC:0.8115 Anomaly AUC:0.6515
[2023-09-09 15:35:28,045][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0004 loss2:0.1411 loss3:0.0014 | AUC:0.8076 Anomaly AUC:0.6506
[2023-09-09 15:35:47,390][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0004 loss2:0.1360 loss3:0.0013 | AUC:0.7913 Anomaly AUC:0.6323
[2023-09-09 15:36:06,752][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0004 loss2:0.1318 loss3:0.0013 | AUC:0.7789 Anomaly AUC:0.6194
[2023-09-09 15:36:26,180][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0003 loss2:0.1272 loss3:0.0012 | AUC:0.7719 Anomaly AUC:0.6147
[2023-09-09 15:36:45,473][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0003 loss2:0.1220 loss3:0.0011 | AUC:0.7582 Anomaly AUC:0.6003
[2023-09-09 15:37:04,831][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0003 loss2:0.1183 loss3:0.0010 | AUC:0.7481 Anomaly AUC:0.5855
[2023-09-09 15:37:24,194][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0003 loss2:0.1139 loss3:0.0010 | AUC:0.7294 Anomaly AUC:0.5621
[2023-09-09 15:37:43,594][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0003 loss2:0.1104 loss3:0.0010 | AUC:0.7450 Anomaly AUC:0.5736
[2023-09-09 15:38:02,994][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0002 loss2:0.1063 loss3:0.0009 | AUC:0.7413 Anomaly AUC:0.5698
[2023-09-09 15:38:22,343][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0002 loss2:0.1029 loss3:0.0009 | AUC:0.7288 Anomaly AUC:0.5665
[2023-09-09 15:38:41,727][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0002 loss2:0.0990 loss3:0.0009 | AUC:0.7383 Anomaly AUC:0.5684
Traceback (most recent call last):
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 203, in <module>
    main(cfg)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 170, in main
    train(model, train_nloader, train_aloader, test_loader, gt, logger)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 97, in train
    auc, ab_auc = test_func(test_loader, model, gt, cfg.dataset)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/test.py", line 53, in test_func
    fpr, tpr, _ = roc_curve(list(gt), np.repeat(pred, 16))
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 211, in wrapper
    return func(*args, **kwargs)
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 1094, in roc_curve
    fps, tps, thresholds = _binary_clf_curve(
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 820, in _binary_clf_curve
    pos_label = _check_pos_label_consistency(pos_label, y_true)
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2234, in _check_pos_label_consistency
    classes = np.unique(y_true)
  File "<__array_function__ internals>", line 200, in unique
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
KeyboardInterrupt