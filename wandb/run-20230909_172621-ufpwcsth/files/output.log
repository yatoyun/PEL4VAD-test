
8000 8100 2900
[2023-09-09 17:26:23,637][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 17:26:23,638][main.py][line:168][INFO] Training Mode
[2023-09-09 17:26:23,638][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.5, inplace=False)
    (dropout2): Dropout(p=0.5, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.5, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.5, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.5, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.5, inplace=False)
)
[2023-09-09 17:26:23,638][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)
[2023-09-09 17:26:32,048][main.py][line:82][INFO] Random initialize AUCAUC:0.5541 Anomaly AUC:0.47597
[2023-09-09 17:26:51,585][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:1.2873 loss2:1.3461 loss3:0.3812 | AUC:0.8086 Anomaly AUC:0.5933
[2023-09-09 17:27:10,935][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.6488 loss2:1.2049 loss3:0.3334 | AUC:0.8136 Anomaly AUC:0.6094
[2023-09-09 17:27:30,242][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.4967 loss2:0.9823 loss3:0.2697 | AUC:0.8132 Anomaly AUC:0.6238
[2023-09-09 17:27:49,851][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.3189 loss2:0.8790 loss3:0.2008 | AUC:0.8361 Anomaly AUC:0.6451
[2023-09-09 17:28:09,483][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.2290 loss2:0.8330 loss3:0.1439 | AUC:0.8278 Anomaly AUC:0.6532
[2023-09-09 17:28:29,193][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.1453 loss2:0.7893 loss3:0.0969 | AUC:0.8190 Anomaly AUC:0.6523
[2023-09-09 17:28:49,107][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.1062 loss2:0.7552 loss3:0.0636 | AUC:0.8397 Anomaly AUC:0.6649
[2023-09-09 17:29:09,044][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0818 loss2:0.7260 loss3:0.0433 | AUC:0.8384 Anomaly AUC:0.6616
[2023-09-09 17:29:29,275][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0841 loss2:0.7055 loss3:0.0334 | AUC:0.8421 Anomaly AUC:0.6736
[2023-09-09 17:29:49,150][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0486 loss2:0.6688 loss3:0.0238 | AUC:0.8368 Anomaly AUC:0.6714
[2023-09-09 17:30:09,040][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0438 loss2:0.6473 loss3:0.0191 | AUC:0.8294 Anomaly AUC:0.6623
[2023-09-09 17:30:28,998][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0229 loss2:0.6117 loss3:0.0139 | AUC:0.8361 Anomaly AUC:0.6449
[2023-09-09 17:30:48,932][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0141 loss2:0.5722 loss3:0.0098 | AUC:0.8343 Anomaly AUC:0.6378
[2023-09-09 17:31:08,857][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0246 loss2:0.5350 loss3:0.0072 | AUC:0.8238 Anomaly AUC:0.6278
[2023-09-09 17:31:28,725][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0224 loss2:0.4978 loss3:0.0053 | AUC:0.8294 Anomaly AUC:0.6286
[2023-09-09 17:31:48,618][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0281 loss2:0.4618 loss3:0.0046 | AUC:0.8212 Anomaly AUC:0.6115
[2023-09-09 17:32:08,494][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0689 loss2:0.4674 loss3:0.0077 | AUC:0.7913 Anomaly AUC:0.5936
[2023-09-09 17:32:28,305][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0951 loss2:0.4920 loss3:0.0113 | AUC:0.7942 Anomaly AUC:0.6384
[2023-09-09 17:32:48,221][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0396 loss2:0.4302 loss3:0.0055 | AUC:0.8020 Anomaly AUC:0.5964
[2023-09-09 17:33:08,212][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0282 loss2:0.3750 loss3:0.0035 | AUC:0.8084 Anomaly AUC:0.5988
[2023-09-09 17:33:28,141][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0249 loss2:0.3402 loss3:0.0028 | AUC:0.7971 Anomaly AUC:0.5919
[2023-09-09 17:33:48,105][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0267 loss2:0.3120 loss3:0.0025 | AUC:0.8150 Anomaly AUC:0.6038
Traceback (most recent call last):
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 203, in <module>
    main(cfg)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 170, in main
    train(model, train_nloader, train_aloader, test_loader, gt, logger)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/main.py", line 90, in train
    loss1, loss2, cost = train_func(train_nloader, train_aloader, model, optimizer, criterion, criterion2, criterion3, logger_wandb, args.lamda, args.alpha)
  File "/home/yukaneko/dev/AbnormalDetection/PEL4VAD/train.py", line 14, in train_func
    in enumerate(zip(normal_dataloader, anomaly_dataloader)):
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 441, in __iter__
    return self._get_iterator()
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1024, in __init__
    index_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/multiprocessing/context.py", line 103, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/multiprocessing/queues.py", line 43, in __init__
    self._rlock = ctx.Lock()
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/multiprocessing/context.py", line 68, in Lock
    return Lock(ctx=self.get_context())
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/multiprocessing/synchronize.py", line 162, in __init__
    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)
  File "/home/yukaneko/miniconda3/envs/detection/lib/python3.10/multiprocessing/synchronize.py", line 57, in __init__
    sl = self._semlock = _multiprocessing.SemLock(
KeyboardInterrupt