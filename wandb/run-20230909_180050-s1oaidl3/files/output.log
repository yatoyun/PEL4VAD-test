
8000 8100 2900
[2023-09-09 18:00:52,690][main.py][line:165][INFO] total params:7.5605M
[2023-09-09 18:00:52,690][main.py][line:168][INFO] Training Mode
[2023-09-09 18:00:52,691][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)
[2023-09-09 18:00:52,691][main.py][line:79][INFO] Optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 5e-05
)
[2023-09-09 18:01:00,510][main.py][line:82][INFO] Random initialize AUCAUC:0.5659 Anomaly AUC:0.47441
[2023-09-09 18:01:18,153][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.5636 loss2:1.4155 loss3:0.3833 | AUC:0.8092 Anomaly AUC:0.5874
[2023-09-09 18:01:35,823][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0300 loss2:1.4223 loss3:0.3239 | AUC:0.7910 Anomaly AUC:0.6307
[2023-09-09 18:01:53,537][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0159 loss2:1.4176 loss3:0.2628 | AUC:0.7163 Anomaly AUC:0.5681
[2023-09-09 18:02:11,490][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0143 loss2:1.4106 loss3:0.2183 | AUC:0.7854 Anomaly AUC:0.6488
[2023-09-09 18:02:29,451][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0138 loss2:1.4118 loss3:0.1744 | AUC:0.7984 Anomaly AUC:0.6385
[2023-09-09 18:02:47,528][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0141 loss2:1.4125 loss3:0.1311 | AUC:0.7865 Anomaly AUC:0.6187
[2023-09-09 18:03:05,749][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0126 loss2:1.4138 loss3:0.1031 | AUC:0.7406 Anomaly AUC:0.5375
[2023-09-09 18:03:23,888][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0216 loss2:1.4108 loss3:0.1223 | AUC:0.7752 Anomaly AUC:0.6634
[2023-09-09 18:03:42,172][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0088 loss2:1.4042 loss3:0.0809 | AUC:0.7687 Anomaly AUC:0.5887
[2023-09-09 18:04:00,532][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0058 loss2:1.4067 loss3:0.0505 | AUC:0.7352 Anomaly AUC:0.5315
[2023-09-09 18:04:18,706][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0062 loss2:1.4062 loss3:0.0404 | AUC:0.7699 Anomaly AUC:0.5732
[2023-09-09 18:04:36,992][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0046 loss2:1.4027 loss3:0.0418 | AUC:0.7902 Anomaly AUC:0.6262
[2023-09-09 18:04:55,168][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0061 loss2:1.4097 loss3:0.0456 | AUC:0.5439 Anomaly AUC:0.4594
[2023-09-09 18:05:13,445][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0055 loss2:1.4111 loss3:0.0548 | AUC:0.7507 Anomaly AUC:0.5663
[2023-09-09 18:05:31,659][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.0045 loss2:1.4017 loss3:0.0500 | AUC:0.7705 Anomaly AUC:0.5984
[2023-09-09 18:05:49,960][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0070 loss2:1.4049 loss3:0.0489 | AUC:0.4080 Anomaly AUC:0.3828
[2023-09-09 18:06:08,288][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0029 loss2:1.4068 loss3:0.0441 | AUC:0.7729 Anomaly AUC:0.5815
[2023-09-09 18:06:26,698][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0021 loss2:1.4029 loss3:0.0332 | AUC:0.7609 Anomaly AUC:0.5669
[2023-09-09 18:06:44,979][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0013 loss2:1.4046 loss3:0.0223 | AUC:0.7938 Anomaly AUC:0.6053
[2023-09-09 18:07:03,143][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0011 loss2:1.4051 loss3:0.0197 | AUC:0.7938 Anomaly AUC:0.5717
[2023-09-09 18:07:21,326][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.1692 loss2:1.4029 loss3:0.0879 | AUC:0.6646 Anomaly AUC:0.6060
[2023-09-09 18:07:39,570][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.1666 loss2:1.4043 loss3:0.6775 | AUC:0.3393 Anomaly AUC:0.3466
[2023-09-09 18:07:57,740][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0080 loss2:1.3976 loss3:0.2538 | AUC:0.6150 Anomaly AUC:0.5557
[2023-09-09 18:08:15,947][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0102 loss2:1.4008 loss3:0.1148 | AUC:0.6733 Anomaly AUC:0.5553
[2023-09-09 18:08:34,225][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0067 loss2:1.4085 loss3:0.0591 | AUC:0.7416 Anomaly AUC:0.5927
[2023-09-09 18:08:52,449][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.0049 loss2:1.4068 loss3:0.0429 | AUC:0.7339 Anomaly AUC:0.5840
[2023-09-09 18:09:10,768][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.0039 loss2:1.4061 loss3:0.0395 | AUC:0.7482 Anomaly AUC:0.5878
[2023-09-09 18:09:28,947][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0029 loss2:1.4066 loss3:0.0318 | AUC:0.7776 Anomaly AUC:0.6166
[2023-09-09 18:09:47,250][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0028 loss2:1.4069 loss3:0.0285 | AUC:0.8015 Anomaly AUC:0.6283
[2023-09-09 18:10:05,588][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0032 loss2:1.4042 loss3:0.0333 | AUC:0.7486 Anomaly AUC:0.5734
[2023-09-09 18:10:23,796][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0028 loss2:1.4049 loss3:0.0272 | AUC:0.7638 Anomaly AUC:0.5733
[2023-09-09 18:10:42,098][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0017 loss2:1.4045 loss3:0.0205 | AUC:0.6781 Anomaly AUC:0.4903
[2023-09-09 18:11:00,465][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0013 loss2:1.4035 loss3:0.0207 | AUC:0.7936 Anomaly AUC:0.5867
[2023-09-09 18:11:18,870][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0019 loss2:1.4022 loss3:0.0261 | AUC:0.7750 Anomaly AUC:0.5684
[2023-09-09 18:11:37,147][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0043 loss2:1.4051 loss3:0.0230 | AUC:0.7631 Anomaly AUC:0.5550
[2023-09-09 18:11:55,377][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0014 loss2:1.4040 loss3:0.0184 | AUC:0.8090 Anomaly AUC:0.5932
[2023-09-09 18:12:13,668][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.1510 loss2:1.3977 loss3:0.2529 | AUC:0.6820 Anomaly AUC:0.5447
[2023-09-09 18:12:32,085][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0087 loss2:1.4033 loss3:0.0745 | AUC:0.7220 Anomaly AUC:0.5614
[2023-09-09 18:12:50,471][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0041 loss2:1.4041 loss3:0.0333 | AUC:0.7856 Anomaly AUC:0.6000
[2023-09-09 18:13:08,758][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0032 loss2:1.4064 loss3:0.0300 | AUC:0.6860 Anomaly AUC:0.5142
[2023-09-09 18:13:27,235][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0034 loss2:1.4031 loss3:0.0384 | AUC:0.7502 Anomaly AUC:0.5679
[2023-09-09 18:13:45,574][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0016 loss2:1.4036 loss3:0.0202 | AUC:0.7928 Anomaly AUC:0.5857
[2023-09-09 18:14:03,984][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0011 loss2:1.4044 loss3:0.0173 | AUC:0.7948 Anomaly AUC:0.5739
[2023-09-09 18:14:22,490][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0011 loss2:1.4026 loss3:0.0177 | AUC:0.7994 Anomaly AUC:0.5821
[2023-09-09 18:14:40,854][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0013 loss2:1.4040 loss3:0.0190 | AUC:0.8187 Anomaly AUC:0.6133
[2023-09-09 18:14:59,226][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0028 loss2:1.4031 loss3:0.0312 | AUC:0.7655 Anomaly AUC:0.5528
[2023-09-09 18:15:17,619][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0010 loss2:1.4022 loss3:0.0167 | AUC:0.7828 Anomaly AUC:0.5512
[2023-09-09 18:15:36,015][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0008 loss2:1.4008 loss3:0.0154 | AUC:0.7945 Anomaly AUC:0.5671
[2023-09-09 18:15:54,406][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0008 loss2:1.4018 loss3:0.0137 | AUC:0.7853 Anomaly AUC:0.5547
[2023-09-09 18:16:12,729][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0029 loss2:1.4006 loss3:0.0109 | AUC:0.7660 Anomaly AUC:0.5138
[2023-09-09 18:16:31,046][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0152 loss2:1.3975 loss3:0.0558 | AUC:0.7255 Anomaly AUC:0.5641
[2023-09-09 18:16:49,428][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0032 loss2:1.3973 loss3:0.0329 | AUC:0.7639 Anomaly AUC:0.5828
[2023-09-09 18:17:07,829][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0013 loss2:1.3991 loss3:0.0190 | AUC:0.7838 Anomaly AUC:0.5757
[2023-09-09 18:17:26,229][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0089 loss2:1.3968 loss3:0.0582 | AUC:0.7908 Anomaly AUC:0.6166
[2023-09-09 18:17:44,583][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0020 loss2:1.3991 loss3:0.0208 | AUC:0.8082 Anomaly AUC:0.6153
[2023-09-09 18:18:03,073][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0015 loss2:1.4003 loss3:0.0168 | AUC:0.7865 Anomaly AUC:0.5711
[2023-09-09 18:18:21,428][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0006 loss2:1.3981 loss3:0.0123 | AUC:0.7992 Anomaly AUC:0.5878
[2023-09-09 18:18:39,789][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0010 loss2:1.3965 loss3:0.0149 | AUC:0.7582 Anomaly AUC:0.5462
[2023-09-09 18:18:58,152][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0030 loss2:1.3983 loss3:0.0118 | AUC:0.7953 Anomaly AUC:0.5694
[2023-09-09 18:19:16,554][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0006 loss2:1.3949 loss3:0.0117 | AUC:0.7988 Anomaly AUC:0.5785
[2023-09-09 18:19:34,933][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0003 loss2:1.3942 loss3:0.0087 | AUC:0.8126 Anomaly AUC:0.5893
[2023-09-09 18:19:53,366][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0030 loss2:1.3940 loss3:0.0150 | AUC:0.7930 Anomaly AUC:0.5722
[2023-09-09 18:20:11,783][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0003 loss2:1.3954 loss3:0.0085 | AUC:0.8008 Anomaly AUC:0.5801
[2023-09-09 18:20:30,206][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0002 loss2:1.3943 loss3:0.0075 | AUC:0.8045 Anomaly AUC:0.5731
[2023-09-09 18:20:48,648][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.5268 loss2:1.3971 loss3:0.2943 | AUC:0.2727 Anomaly AUC:0.3382
[2023-09-09 18:21:07,057][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0086 loss2:1.3911 loss3:0.1531 | AUC:0.7260 Anomaly AUC:0.5351
[2023-09-09 18:21:25,619][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0057 loss2:1.3847 loss3:0.0454 | AUC:0.7697 Anomaly AUC:0.5762
[2023-09-09 18:21:44,001][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0038 loss2:1.3834 loss3:0.0249 | AUC:0.7922 Anomaly AUC:0.5884
[2023-09-09 18:22:02,580][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0022 loss2:1.3827 loss3:0.0159 | AUC:0.7999 Anomaly AUC:0.5930
[2023-09-09 18:22:21,025][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0022 loss2:1.3842 loss3:0.0146 | AUC:0.7896 Anomaly AUC:0.5687
[2023-09-09 18:22:39,476][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0012 loss2:1.3826 loss3:0.0112 | AUC:0.7930 Anomaly AUC:0.5712
[2023-09-09 18:22:57,883][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0012 loss2:1.3841 loss3:0.0104 | AUC:0.7900 Anomaly AUC:0.5698
[2023-09-09 18:23:16,291][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0006 loss2:1.3859 loss3:0.0086 | AUC:0.7937 Anomaly AUC:0.5660
[2023-09-09 18:23:34,576][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0008 loss2:1.3855 loss3:0.0086 | AUC:0.8097 Anomaly AUC:0.5913
[2023-09-09 18:23:53,070][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0033 loss2:1.3852 loss3:0.0089 | AUC:0.8009 Anomaly AUC:0.5826
[2023-09-09 18:24:11,502][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0005 loss2:1.3853 loss3:0.0079 | AUC:0.7552 Anomaly AUC:0.5134
[2023-09-09 18:24:29,869][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0065 loss2:1.3865 loss3:0.0281 | AUC:0.7753 Anomaly AUC:0.5662
[2023-09-09 18:24:48,328][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0006 loss2:1.3862 loss3:0.0086 | AUC:0.7837 Anomaly AUC:0.5681
[2023-09-09 18:25:06,812][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0004 loss2:1.3854 loss3:0.0073 | AUC:0.7941 Anomaly AUC:0.5784
[2023-09-09 18:25:25,219][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0004 loss2:1.3822 loss3:0.0072 | AUC:0.7845 Anomaly AUC:0.5583
[2023-09-09 18:25:43,796][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0003 loss2:1.3861 loss3:0.0067 | AUC:0.8120 Anomaly AUC:0.5988
[2023-09-09 18:26:02,132][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0682 loss2:1.3885 loss3:0.1084 | AUC:0.7489 Anomaly AUC:0.5408
[2023-09-09 18:26:20,596][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0071 loss2:1.3853 loss3:0.0286 | AUC:0.7743 Anomaly AUC:0.5328
[2023-09-09 18:26:39,133][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0080 loss2:1.3858 loss3:0.0174 | AUC:0.8028 Anomaly AUC:0.5708
[2023-09-09 18:26:57,602][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0072 loss2:1.3852 loss3:0.0298 | AUC:0.7660 Anomaly AUC:0.5307
[2023-09-09 18:27:16,000][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0027 loss2:1.3830 loss3:0.0163 | AUC:0.7670 Anomaly AUC:0.5209
[2023-09-09 18:27:34,458][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0065 loss2:1.3860 loss3:0.0294 | AUC:0.7787 Anomaly AUC:0.5759
[2023-09-09 18:27:52,841][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0057 loss2:1.3869 loss3:0.0185 | AUC:0.7806 Anomaly AUC:0.5656
[2023-09-09 18:28:11,215][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0009 loss2:1.3862 loss3:0.0115 | AUC:0.7692 Anomaly AUC:0.5359
[2023-09-09 18:28:29,637][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0006 loss2:1.3868 loss3:0.0090 | AUC:0.7712 Anomaly AUC:0.5205
[2023-09-09 18:28:48,076][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0006 loss2:1.3864 loss3:0.0082 | AUC:0.7965 Anomaly AUC:0.5514
[2023-09-09 18:29:06,517][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0003 loss2:1.3858 loss3:0.0068 | AUC:0.7906 Anomaly AUC:0.5359
[2023-09-09 18:29:24,883][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.2236 loss2:1.3847 loss3:0.0613 | AUC:0.7787 Anomaly AUC:0.5721
[2023-09-09 18:29:43,429][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0249 loss2:1.3973 loss3:0.1177 | AUC:0.8146 Anomaly AUC:0.6338
[2023-09-09 18:30:01,865][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0056 loss2:1.4015 loss3:0.0235 | AUC:0.8185 Anomaly AUC:0.6327
[2023-09-09 18:30:20,318][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0026 loss2:1.3981 loss3:0.0125 | AUC:0.8040 Anomaly AUC:0.5887
[2023-09-09 18:30:38,849][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0016 loss2:1.3978 loss3:0.0101 | AUC:0.8054 Anomaly AUC:0.5834
[2023-09-09 18:30:57,382][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0202 loss2:1.3973 loss3:0.0244 | AUC:0.6656 Anomaly AUC:0.4884
[2023-09-09 18:31:15,887][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0037 loss2:1.3946 loss3:0.0204 | AUC:0.7848 Anomaly AUC:0.5435
[2023-09-09 18:31:34,502][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0016 loss2:1.3941 loss3:0.0098 | AUC:0.7974 Anomaly AUC:0.5655
[2023-09-09 18:31:34,526][main.py][line:116][INFO] Training completes in 30m 34s | best AUCAUC:0.8187 Anomaly AUC:0.6133