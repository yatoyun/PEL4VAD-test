[2023-09-09 22:00:53,022][main.py][line:165][INFO] total params:7.5400M
[2023-09-09 22:00:53,023][main.py][line:168][INFO] Training Mode
[2023-09-09 22:00:53,023][main.py][line:78][INFO] Model:XModel(
  (self_attention): XEncoder(
    (self_attn): TCA(
      (q): Linear(in_features=1024, out_features=128, bias=True)
      (k): Linear(in_features=1024, out_features=128, bias=True)
      (v): Linear(in_features=1024, out_features=128, bias=True)
      (o): Linear(in_features=128, out_features=1024, bias=True)
      (act): Softmax(dim=-1)
    )
    (linear1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))
    (linear2): Conv1d(512, 300, kernel_size=(1,), stride=(1,))
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (loc_adj): DistanceAdj()
    (DR_DMU): WSAD(
      (embedding): Temporal(
        (conv_1): Sequential(
          (0): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))
          (1): ReLU()
        )
      )
      (triplet): TripletMarginLoss()
      (Amemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (Nmemory): Memory_Unit(
        (sig): Sigmoid()
      )
      (selfatt): Transformer(
        (layers): ModuleList(
          (0-1): 2 x ModuleList(
            (0): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): Attention(
                (attend): Softmax(dim=-1)
                (to_qkv): Linear(in_features=512, out_features=2048, bias=False)
                (to_out): Sequential(
                  (0): Linear(in_features=1024, out_features=512, bias=True)
                  (1): Dropout(p=0.1, inplace=False)
                )
              )
            )
            (1): PreNorm(
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (fn): FeedForward(
                (net): Sequential(
                  (0): Linear(in_features=512, out_features=512, bias=True)
                  (1): GELU(approximate='none')
                  (2): Dropout(p=0.1, inplace=False)
                  (3): Linear(in_features=512, out_features=512, bias=True)
                  (4): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
      (encoder_mu): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (encoder_var): Sequential(
        (0): Linear(in_features=512, out_features=512, bias=True)
      )
      (relu): ReLU()
    )
  )
  (classifier): Conv1d(300, 1, kernel_size=(9,), stride=(1,))
  (dropout): Dropout(p=0.1, inplace=False)
)
[2023-09-09 22:00:53,023][main.py][line:79][INFO] Optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0002
    lr: 0.0002
    maximize: False
    weight_decay: 5e-05
)
8000 8100 2900
[2023-09-09 22:01:01,114][main.py][line:82][INFO] Random initialize AUCAUC:0.5802 Anomaly AUC:0.50318
[2023-09-09 22:01:19,542][main.py][line:106][INFO] [Epoch:1/100]: lr:0.00010 | loss1:0.3629 loss2:1.1723 loss3:0.3335 | AUC:0.8102 Anomaly AUC:0.6669
[2023-09-09 22:01:37,718][main.py][line:106][INFO] [Epoch:2/100]: lr:0.00010 | loss1:0.0495 loss2:0.8062 loss3:0.2171 | AUC:0.8179 Anomaly AUC:0.6587
[2023-09-09 22:01:56,347][main.py][line:106][INFO] [Epoch:3/100]: lr:0.00010 | loss1:0.0280 loss2:0.6961 loss3:0.1359 | AUC:0.8214 Anomaly AUC:0.6624
[2023-09-09 22:02:15,038][main.py][line:106][INFO] [Epoch:4/100]: lr:0.00010 | loss1:0.0189 loss2:0.6194 loss3:0.0981 | AUC:0.8292 Anomaly AUC:0.6728
[2023-09-09 22:02:33,827][main.py][line:106][INFO] [Epoch:5/100]: lr:0.00010 | loss1:0.0143 loss2:0.5555 loss3:0.0708 | AUC:0.8317 Anomaly AUC:0.6518
[2023-09-09 22:02:52,666][main.py][line:106][INFO] [Epoch:6/100]: lr:0.00010 | loss1:0.0136 loss2:0.4994 loss3:0.0565 | AUC:0.7836 Anomaly AUC:0.6531
[2023-09-09 22:03:11,632][main.py][line:106][INFO] [Epoch:7/100]: lr:0.00010 | loss1:0.0137 loss2:0.5122 loss3:0.0665 | AUC:0.8327 Anomaly AUC:0.6630
[2023-09-09 22:03:30,608][main.py][line:106][INFO] [Epoch:8/100]: lr:0.00010 | loss1:0.0076 loss2:0.4117 loss3:0.0373 | AUC:0.8395 Anomaly AUC:0.6809
[2023-09-09 22:03:49,524][main.py][line:106][INFO] [Epoch:9/100]: lr:0.00010 | loss1:0.0057 loss2:0.3738 loss3:0.0292 | AUC:0.8489 Anomaly AUC:0.6593
[2023-09-09 22:04:08,388][main.py][line:106][INFO] [Epoch:10/100]: lr:0.00010 | loss1:0.0086 loss2:0.3559 loss3:0.0373 | AUC:0.8250 Anomaly AUC:0.6430
[2023-09-09 22:04:27,434][main.py][line:106][INFO] [Epoch:11/100]: lr:0.00010 | loss1:0.0058 loss2:0.3402 loss3:0.0309 | AUC:0.8418 Anomaly AUC:0.6575
[2023-09-09 22:04:46,368][main.py][line:106][INFO] [Epoch:12/100]: lr:0.00010 | loss1:0.0036 loss2:0.2973 loss3:0.0216 | AUC:0.8377 Anomaly AUC:0.6579
[2023-09-09 22:05:05,450][main.py][line:106][INFO] [Epoch:13/100]: lr:0.00010 | loss1:0.0030 loss2:0.2649 loss3:0.0160 | AUC:0.8457 Anomaly AUC:0.6731
[2023-09-09 22:05:24,606][main.py][line:106][INFO] [Epoch:14/100]: lr:0.00010 | loss1:0.0039 loss2:0.2580 loss3:0.0149 | AUC:0.8425 Anomaly AUC:0.6673
[2023-09-09 22:05:43,533][main.py][line:106][INFO] [Epoch:15/100]: lr:0.00010 | loss1:0.1191 loss2:0.6803 loss3:0.1154 | AUC:0.8265 Anomaly AUC:0.6525
[2023-09-09 22:06:02,407][main.py][line:106][INFO] [Epoch:16/100]: lr:0.00010 | loss1:0.0052 loss2:0.3414 loss3:0.0293 | AUC:0.8410 Anomaly AUC:0.6594
[2023-09-09 22:06:21,417][main.py][line:106][INFO] [Epoch:17/100]: lr:0.00010 | loss1:0.0031 loss2:0.2680 loss3:0.0202 | AUC:0.8262 Anomaly AUC:0.6383
[2023-09-09 22:06:40,397][main.py][line:106][INFO] [Epoch:18/100]: lr:0.00010 | loss1:0.0025 loss2:0.2436 loss3:0.0153 | AUC:0.8477 Anomaly AUC:0.6583
[2023-09-09 22:06:59,401][main.py][line:106][INFO] [Epoch:19/100]: lr:0.00010 | loss1:0.0019 loss2:0.2267 loss3:0.0118 | AUC:0.8415 Anomaly AUC:0.6448
[2023-09-09 22:07:18,301][main.py][line:106][INFO] [Epoch:20/100]: lr:0.00010 | loss1:0.0054 loss2:0.2651 loss3:0.0199 | AUC:0.8246 Anomaly AUC:0.6301
[2023-09-09 22:07:37,235][main.py][line:106][INFO] [Epoch:21/100]: lr:0.00010 | loss1:0.0023 loss2:0.2253 loss3:0.0149 | AUC:0.8414 Anomaly AUC:0.6453
[2023-09-09 22:07:56,178][main.py][line:106][INFO] [Epoch:22/100]: lr:0.00010 | loss1:0.0013 loss2:0.2006 loss3:0.0094 | AUC:0.8437 Anomaly AUC:0.6499
[2023-09-09 22:08:15,035][main.py][line:106][INFO] [Epoch:23/100]: lr:0.00010 | loss1:0.0010 loss2:0.1876 loss3:0.0079 | AUC:0.8423 Anomaly AUC:0.6461
[2023-09-09 22:08:33,994][main.py][line:106][INFO] [Epoch:24/100]: lr:0.00010 | loss1:0.0010 loss2:0.1833 loss3:0.0069 | AUC:0.8457 Anomaly AUC:0.6484
[2023-09-09 22:08:52,992][main.py][line:106][INFO] [Epoch:25/100]: lr:0.00010 | loss1:0.0008 loss2:0.1758 loss3:0.0060 | AUC:0.8433 Anomaly AUC:0.6462
[2023-09-09 22:09:12,053][main.py][line:106][INFO] [Epoch:26/100]: lr:0.00010 | loss1:0.3674 loss2:0.3584 loss3:0.6015 | AUC:0.7445 Anomaly AUC:0.5633
[2023-09-09 22:09:31,176][main.py][line:106][INFO] [Epoch:27/100]: lr:0.00010 | loss1:0.2199 loss2:0.9869 loss3:0.0964 | AUC:0.8305 Anomaly AUC:0.6557
[2023-09-09 22:09:50,323][main.py][line:106][INFO] [Epoch:28/100]: lr:0.00010 | loss1:0.0205 loss2:0.4275 loss3:0.0395 | AUC:0.8511 Anomaly AUC:0.6896
[2023-09-09 22:10:09,419][main.py][line:106][INFO] [Epoch:29/100]: lr:0.00010 | loss1:0.0141 loss2:0.2939 loss3:0.0308 | AUC:0.8457 Anomaly AUC:0.6699
[2023-09-09 22:10:28,420][main.py][line:106][INFO] [Epoch:30/100]: lr:0.00010 | loss1:0.0101 loss2:0.2448 loss3:0.0222 | AUC:0.8558 Anomaly AUC:0.6757
[2023-09-09 22:10:47,379][main.py][line:106][INFO] [Epoch:31/100]: lr:0.00010 | loss1:0.0040 loss2:0.2026 loss3:0.0100 | AUC:0.8527 Anomaly AUC:0.6790
[2023-09-09 22:11:06,364][main.py][line:106][INFO] [Epoch:32/100]: lr:0.00010 | loss1:0.0026 loss2:0.1861 loss3:0.0063 | AUC:0.8530 Anomaly AUC:0.6701
[2023-09-09 22:11:25,443][main.py][line:106][INFO] [Epoch:33/100]: lr:0.00010 | loss1:0.0102 loss2:0.2133 loss3:0.0150 | AUC:0.8339 Anomaly AUC:0.6836
[2023-09-09 22:11:44,744][main.py][line:106][INFO] [Epoch:34/100]: lr:0.00010 | loss1:0.0066 loss2:0.2166 loss3:0.0155 | AUC:0.8521 Anomaly AUC:0.6714
[2023-09-09 22:12:03,752][main.py][line:106][INFO] [Epoch:35/100]: lr:0.00010 | loss1:0.0020 loss2:0.1647 loss3:0.0048 | AUC:0.8540 Anomaly AUC:0.6725
[2023-09-09 22:12:22,853][main.py][line:106][INFO] [Epoch:36/100]: lr:0.00010 | loss1:0.0012 loss2:0.1519 loss3:0.0020 | AUC:0.8528 Anomaly AUC:0.6681
[2023-09-09 22:12:42,014][main.py][line:106][INFO] [Epoch:37/100]: lr:0.00010 | loss1:0.0093 loss2:0.1697 loss3:0.0066 | AUC:0.8387 Anomaly AUC:0.6868
[2023-09-09 22:13:01,034][main.py][line:106][INFO] [Epoch:38/100]: lr:0.00010 | loss1:0.0072 loss2:0.1852 loss3:0.0134 | AUC:0.8477 Anomaly AUC:0.6642
[2023-09-09 22:13:20,084][main.py][line:106][INFO] [Epoch:39/100]: lr:0.00010 | loss1:0.0053 loss2:0.1597 loss3:0.0124 | AUC:0.8409 Anomaly AUC:0.6615
[2023-09-09 22:13:39,092][main.py][line:106][INFO] [Epoch:40/100]: lr:0.00010 | loss1:0.0060 loss2:0.1606 loss3:0.0091 | AUC:0.8487 Anomaly AUC:0.6880
[2023-09-09 22:13:58,213][main.py][line:106][INFO] [Epoch:41/100]: lr:0.00010 | loss1:0.0032 loss2:0.1537 loss3:0.0070 | AUC:0.8524 Anomaly AUC:0.6725
[2023-09-09 22:14:17,447][main.py][line:106][INFO] [Epoch:42/100]: lr:0.00010 | loss1:0.0018 loss2:0.1269 loss3:0.0036 | AUC:0.8563 Anomaly AUC:0.6756
[2023-09-09 22:14:36,663][main.py][line:106][INFO] [Epoch:43/100]: lr:0.00010 | loss1:0.0010 loss2:0.1189 loss3:0.0019 | AUC:0.8539 Anomaly AUC:0.6736
[2023-09-09 22:14:55,800][main.py][line:106][INFO] [Epoch:44/100]: lr:0.00010 | loss1:0.0007 loss2:0.1106 loss3:0.0009 | AUC:0.8553 Anomaly AUC:0.6737
[2023-09-09 22:15:14,905][main.py][line:106][INFO] [Epoch:45/100]: lr:0.00010 | loss1:0.0009 loss2:0.1082 loss3:0.0013 | AUC:0.8513 Anomaly AUC:0.6749
[2023-09-09 22:15:33,924][main.py][line:106][INFO] [Epoch:46/100]: lr:0.00010 | loss1:0.0006 loss2:0.1016 loss3:0.0006 | AUC:0.8523 Anomaly AUC:0.6761
[2023-09-09 22:15:53,014][main.py][line:106][INFO] [Epoch:47/100]: lr:0.00010 | loss1:0.0005 loss2:0.0969 loss3:0.0005 | AUC:0.8487 Anomaly AUC:0.6726
[2023-09-09 22:16:12,197][main.py][line:106][INFO] [Epoch:48/100]: lr:0.00010 | loss1:0.0005 loss2:0.0946 loss3:0.0004 | AUC:0.8491 Anomaly AUC:0.6717
[2023-09-09 22:16:31,211][main.py][line:106][INFO] [Epoch:49/100]: lr:0.00010 | loss1:0.0005 loss2:0.0895 loss3:0.0003 | AUC:0.8513 Anomaly AUC:0.6716
[2023-09-09 22:16:50,331][main.py][line:106][INFO] [Epoch:50/100]: lr:0.00010 | loss1:0.0018 loss2:0.0880 loss3:0.0008 | AUC:0.8469 Anomaly AUC:0.6716
[2023-09-09 22:17:09,340][main.py][line:106][INFO] [Epoch:51/100]: lr:0.00010 | loss1:0.0790 loss2:0.2875 loss3:0.0450 | AUC:0.8353 Anomaly AUC:0.6690
[2023-09-09 22:17:28,460][main.py][line:106][INFO] [Epoch:52/100]: lr:0.00010 | loss1:0.0128 loss2:0.2782 loss3:0.0266 | AUC:0.8596 Anomaly AUC:0.6916
[2023-09-09 22:17:47,556][main.py][line:106][INFO] [Epoch:53/100]: lr:0.00010 | loss1:0.0127 loss2:0.1731 loss3:0.0378 | AUC:0.8263 Anomaly AUC:0.6504
[2023-09-09 22:18:06,617][main.py][line:106][INFO] [Epoch:54/100]: lr:0.00010 | loss1:0.0029 loss2:0.1098 loss3:0.0085 | AUC:0.8535 Anomaly AUC:0.6786
[2023-09-09 22:18:25,735][main.py][line:106][INFO] [Epoch:55/100]: lr:0.00010 | loss1:0.0013 loss2:0.0900 loss3:0.0035 | AUC:0.8548 Anomaly AUC:0.6818
[2023-09-09 22:18:44,871][main.py][line:106][INFO] [Epoch:56/100]: lr:0.00010 | loss1:0.0066 loss2:0.1150 loss3:0.0126 | AUC:0.8390 Anomaly AUC:0.6577
[2023-09-09 22:19:03,946][main.py][line:106][INFO] [Epoch:57/100]: lr:0.00010 | loss1:0.0012 loss2:0.0840 loss3:0.0038 | AUC:0.8473 Anomaly AUC:0.6642
[2023-09-09 22:19:23,111][main.py][line:106][INFO] [Epoch:58/100]: lr:0.00010 | loss1:0.0005 loss2:0.0732 loss3:0.0015 | AUC:0.8464 Anomaly AUC:0.6627
[2023-09-09 22:19:42,221][main.py][line:106][INFO] [Epoch:59/100]: lr:0.00010 | loss1:0.0005 loss2:0.0682 loss3:0.0009 | AUC:0.8463 Anomaly AUC:0.6619
[2023-09-09 22:20:01,394][main.py][line:106][INFO] [Epoch:60/100]: lr:0.00010 | loss1:0.0005 loss2:0.0651 loss3:0.0007 | AUC:0.8462 Anomaly AUC:0.6617
[2023-09-09 22:20:20,505][main.py][line:106][INFO] [Epoch:61/100]: lr:0.00010 | loss1:0.0004 loss2:0.0616 loss3:0.0006 | AUC:0.8449 Anomaly AUC:0.6603
[2023-09-09 22:20:39,672][main.py][line:106][INFO] [Epoch:62/100]: lr:0.00010 | loss1:0.0004 loss2:0.0588 loss3:0.0005 | AUC:0.8453 Anomaly AUC:0.6581
[2023-09-09 22:20:58,672][main.py][line:106][INFO] [Epoch:63/100]: lr:0.00010 | loss1:0.0004 loss2:0.0564 loss3:0.0004 | AUC:0.8456 Anomaly AUC:0.6599
[2023-09-09 22:21:17,780][main.py][line:106][INFO] [Epoch:64/100]: lr:0.00010 | loss1:0.0003 loss2:0.0534 loss3:0.0003 | AUC:0.8446 Anomaly AUC:0.6574
[2023-09-09 22:21:36,914][main.py][line:106][INFO] [Epoch:65/100]: lr:0.00010 | loss1:0.0003 loss2:0.0514 loss3:0.0004 | AUC:0.8468 Anomaly AUC:0.6625
[2023-09-09 22:21:56,061][main.py][line:106][INFO] [Epoch:66/100]: lr:0.00010 | loss1:0.0184 loss2:0.1443 loss3:0.0272 | AUC:0.8080 Anomaly AUC:0.6097
[2023-09-09 22:22:15,208][main.py][line:106][INFO] [Epoch:67/100]: lr:0.00010 | loss1:0.0057 loss2:0.0899 loss3:0.0249 | AUC:0.8488 Anomaly AUC:0.6737
[2023-09-09 22:22:34,383][main.py][line:106][INFO] [Epoch:68/100]: lr:0.00010 | loss1:0.0009 loss2:0.0531 loss3:0.0033 | AUC:0.8552 Anomaly AUC:0.6824
[2023-09-09 22:22:53,566][main.py][line:106][INFO] [Epoch:69/100]: lr:0.00010 | loss1:0.0004 loss2:0.0461 loss3:0.0014 | AUC:0.8572 Anomaly AUC:0.6871
[2023-09-09 22:23:12,740][main.py][line:106][INFO] [Epoch:70/100]: lr:0.00010 | loss1:0.0003 loss2:0.0431 loss3:0.0008 | AUC:0.8555 Anomaly AUC:0.6842
[2023-09-09 22:23:31,833][main.py][line:106][INFO] [Epoch:71/100]: lr:0.00010 | loss1:0.0003 loss2:0.0402 loss3:0.0006 | AUC:0.8538 Anomaly AUC:0.6798
[2023-09-09 22:23:50,958][main.py][line:106][INFO] [Epoch:72/100]: lr:0.00010 | loss1:0.0002 loss2:0.0383 loss3:0.0004 | AUC:0.8545 Anomaly AUC:0.6814
[2023-09-09 22:24:10,200][main.py][line:106][INFO] [Epoch:73/100]: lr:0.00010 | loss1:0.0002 loss2:0.0366 loss3:0.0003 | AUC:0.8535 Anomaly AUC:0.6796
[2023-09-09 22:24:29,397][main.py][line:106][INFO] [Epoch:74/100]: lr:0.00010 | loss1:0.0002 loss2:0.0351 loss3:0.0003 | AUC:0.8505 Anomaly AUC:0.6756
[2023-09-09 22:24:48,543][main.py][line:106][INFO] [Epoch:75/100]: lr:0.00010 | loss1:0.0002 loss2:0.0336 loss3:0.0002 | AUC:0.8498 Anomaly AUC:0.6744
[2023-09-09 22:25:07,664][main.py][line:106][INFO] [Epoch:76/100]: lr:0.00010 | loss1:0.0002 loss2:0.0319 loss3:0.0002 | AUC:0.8490 Anomaly AUC:0.6719
[2023-09-09 22:25:26,951][main.py][line:106][INFO] [Epoch:77/100]: lr:0.00010 | loss1:0.0002 loss2:0.0307 loss3:0.0002 | AUC:0.8515 Anomaly AUC:0.6719
[2023-09-09 22:25:46,258][main.py][line:106][INFO] [Epoch:78/100]: lr:0.00010 | loss1:0.0002 loss2:0.0295 loss3:0.0002 | AUC:0.8506 Anomaly AUC:0.6755
[2023-09-09 22:26:05,458][main.py][line:106][INFO] [Epoch:79/100]: lr:0.00010 | loss1:0.0001 loss2:0.0284 loss3:0.0001 | AUC:0.8506 Anomaly AUC:0.6771
[2023-09-09 22:26:24,678][main.py][line:106][INFO] [Epoch:80/100]: lr:0.00010 | loss1:0.0001 loss2:0.0269 loss3:0.0001 | AUC:0.8502 Anomaly AUC:0.6749
[2023-09-09 22:26:43,918][main.py][line:106][INFO] [Epoch:81/100]: lr:0.00010 | loss1:0.0001 loss2:0.0255 loss3:0.0001 | AUC:0.8467 Anomaly AUC:0.6707
[2023-09-09 22:27:03,155][main.py][line:106][INFO] [Epoch:82/100]: lr:0.00010 | loss1:0.0001 loss2:0.0242 loss3:0.0001 | AUC:0.8470 Anomaly AUC:0.6698
[2023-09-09 22:27:22,467][main.py][line:106][INFO] [Epoch:83/100]: lr:0.00010 | loss1:0.0001 loss2:0.0233 loss3:0.0001 | AUC:0.8499 Anomaly AUC:0.6714
[2023-09-09 22:27:41,750][main.py][line:106][INFO] [Epoch:84/100]: lr:0.00010 | loss1:0.0001 loss2:0.0225 loss3:0.0001 | AUC:0.8501 Anomaly AUC:0.6740
[2023-09-09 22:28:01,070][main.py][line:106][INFO] [Epoch:85/100]: lr:0.00010 | loss1:0.0001 loss2:0.0213 loss3:0.0001 | AUC:0.8483 Anomaly AUC:0.6700
[2023-09-09 22:28:20,325][main.py][line:106][INFO] [Epoch:86/100]: lr:0.00010 | loss1:0.0001 loss2:0.0205 loss3:0.0001 | AUC:0.8442 Anomaly AUC:0.6652
[2023-09-09 22:28:39,741][main.py][line:106][INFO] [Epoch:87/100]: lr:0.00010 | loss1:0.0001 loss2:0.0192 loss3:0.0001 | AUC:0.8450 Anomaly AUC:0.6622
[2023-09-09 22:28:59,089][main.py][line:106][INFO] [Epoch:88/100]: lr:0.00010 | loss1:0.0001 loss2:0.0185 loss3:0.0001 | AUC:0.8475 Anomaly AUC:0.6695
[2023-09-09 22:29:18,313][main.py][line:106][INFO] [Epoch:89/100]: lr:0.00010 | loss1:0.0001 loss2:0.0177 loss3:0.0001 | AUC:0.8455 Anomaly AUC:0.6667
[2023-09-09 22:29:37,551][main.py][line:106][INFO] [Epoch:90/100]: lr:0.00010 | loss1:0.0001 loss2:0.0168 loss3:0.0001 | AUC:0.8473 Anomaly AUC:0.6689
[2023-09-09 22:29:57,001][main.py][line:106][INFO] [Epoch:91/100]: lr:0.00010 | loss1:0.0001 loss2:0.0161 loss3:0.0001 | AUC:0.8471 Anomaly AUC:0.6655
[2023-09-09 22:30:16,223][main.py][line:106][INFO] [Epoch:92/100]: lr:0.00010 | loss1:0.0483 loss2:0.1007 loss3:0.0221 | AUC:0.8012 Anomaly AUC:0.6002
[2023-09-09 22:30:35,354][main.py][line:106][INFO] [Epoch:93/100]: lr:0.00010 | loss1:0.0963 loss2:0.3540 loss3:0.0411 | AUC:0.8166 Anomaly AUC:0.6200
[2023-09-09 22:30:54,623][main.py][line:106][INFO] [Epoch:94/100]: lr:0.00010 | loss1:0.0022 loss2:0.0420 loss3:0.0045 | AUC:0.8195 Anomaly AUC:0.6181
[2023-09-09 22:31:13,886][main.py][line:106][INFO] [Epoch:95/100]: lr:0.00010 | loss1:0.0007 loss2:0.0253 loss3:0.0014 | AUC:0.8295 Anomaly AUC:0.6383
[2023-09-09 22:31:33,067][main.py][line:106][INFO] [Epoch:96/100]: lr:0.00010 | loss1:0.0002 loss2:0.0189 loss3:0.0007 | AUC:0.8361 Anomaly AUC:0.6521
[2023-09-09 22:31:52,236][main.py][line:106][INFO] [Epoch:97/100]: lr:0.00010 | loss1:0.0003 loss2:0.0178 loss3:0.0007 | AUC:0.8314 Anomaly AUC:0.6413
[2023-09-09 22:32:11,457][main.py][line:106][INFO] [Epoch:98/100]: lr:0.00010 | loss1:0.0002 loss2:0.0152 loss3:0.0003 | AUC:0.8351 Anomaly AUC:0.6513
[2023-09-09 22:32:30,678][main.py][line:106][INFO] [Epoch:99/100]: lr:0.00010 | loss1:0.0002 loss2:0.0139 loss3:0.0002 | AUC:0.8355 Anomaly AUC:0.6508
[2023-09-09 22:32:50,073][main.py][line:106][INFO] [Epoch:100/100]: lr:0.00010 | loss1:0.0001 loss2:0.0130 loss3:0.0002 | AUC:0.8354 Anomaly AUC:0.6507
[2023-09-09 22:32:50,098][main.py][line:116][INFO] Training completes in 31m 49s | best AUCAUC:0.8596 Anomaly AUC:0.6916